/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-09-03 09:15:27,620   INFO  **********************Start logging**********************
2025-09-03 09:15:27,620   INFO  CUDA_VISIBLE_DEVICES=ALL
2025-09-03 09:15:27,620   INFO  Training in distributed mode : total_batch_size: 32
2025-09-03 09:15:27,620   INFO  cfg_file         cfgs/sparse_models/sparse_former_light.yaml
2025-09-03 09:15:27,620   INFO  batch_size       4
2025-09-03 09:15:27,620   INFO  epochs           20
2025-09-03 09:15:27,620   INFO  workers          12
2025-09-03 09:15:27,620   INFO  extra_tag        default
2025-09-03 09:15:27,620   INFO  ckpt             None
2025-09-03 09:15:27,620   INFO  pretrained_model None
2025-09-03 09:15:27,621   INFO  launcher         pytorch
2025-09-03 09:15:27,621   INFO  tcp_port         18888
2025-09-03 09:15:27,621   INFO  sync_bn          True
2025-09-03 09:15:27,621   INFO  fix_random_seed  False
2025-09-03 09:15:27,621   INFO  ckpt_save_interval 1
2025-09-03 09:15:27,621   INFO  local_rank       0
2025-09-03 09:15:27,621   INFO  max_ckpt_save_num 30
2025-09-03 09:15:27,621   INFO  merge_all_iters_to_one_epoch False
2025-09-03 09:15:27,621   INFO  set_cfgs         None
2025-09-03 09:15:27,621   INFO  max_waiting_mins 0
2025-09-03 09:15:27,621   INFO  start_epoch      0
2025-09-03 09:15:27,621   INFO  num_epochs_to_eval 0
2025-09-03 09:15:27,621   INFO  save_to_file     False
2025-09-03 09:15:27,621   INFO  use_tqdm_to_record False
2025-09-03 09:15:27,621   INFO  logger_iter_interval 50
2025-09-03 09:15:27,621   INFO  ckpt_save_time_interval 300
2025-09-03 09:15:27,621   INFO  wo_gpu_stat      True
2025-09-03 09:15:27,621   INFO  use_amp          False
2025-09-03 09:15:27,621   INFO  eval_map         False
2025-09-03 09:15:27,621   INFO  dataset          nuscenes
2025-09-03 09:15:27,621   INFO  root_dir         /mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2
2025-09-03 09:15:27,621   INFO  output_dir       /mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/workdir/voxelnext/encoder/voxelnext_en_3layer_1lc_zhx_de_1layer_v3_32p_.0diff_.1lr_.1wd
2025-09-03 09:15:27,621   INFO  cfg.ROOT_DIR: /mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2
2025-09-03 09:15:27,621   INFO  cfg.LOCAL_RANK: 0
2025-09-03 09:15:27,621   INFO  cfg.CLASS_NAMES: ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone']
2025-09-03 09:15:27,621   INFO  ----------- DATA_CONFIG -----------
2025-09-03 09:15:27,622   INFO  cfg.DATA_CONFIG.DATASET: NuScenesDataset
2025-09-03 09:15:27,622   INFO  cfg.DATA_CONFIG.DATA_PATH: /mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/data/nuscenes
2025-09-03 09:15:27,622   INFO  cfg.DATA_CONFIG.VERSION: v1.0-trainval
2025-09-03 09:15:27,622   INFO  cfg.DATA_CONFIG.MAX_SWEEPS: 10
2025-09-03 09:15:27,622   INFO  cfg.DATA_CONFIG.PRED_VELOCITY: True
2025-09-03 09:15:27,622   INFO  cfg.DATA_CONFIG.SET_NAN_VELOCITY_TO_ZEROS: True
2025-09-03 09:15:27,622   INFO  cfg.DATA_CONFIG.FILTER_MIN_POINTS_IN_GT: 1
2025-09-03 09:15:27,622   INFO  ----------- DATA_SPLIT -----------
2025-09-03 09:15:27,622   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train
2025-09-03 09:15:27,622   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val
2025-09-03 09:15:27,622   INFO  ----------- INFO_PATH -----------
2025-09-03 09:15:27,622   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['nuscenes_infos_10sweeps_train.pkl']
2025-09-03 09:15:27,622   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['nuscenes_infos_10sweeps_val.pkl']
2025-09-03 09:15:27,622   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [-54.0, -54.0, -5.0, 54.0, 54.0, 3.0]
2025-09-03 09:15:27,622   INFO  cfg.DATA_CONFIG.BALANCED_RESAMPLING: True
2025-09-03 09:15:27,622   INFO  ----------- DATA_AUGMENTOR -----------
2025-09-03 09:15:27,622   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']
2025-09-03 09:15:27,622   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'DB_INFO_PATH': ['nuscenes_dbinfos_10sweeps_withvelo.pkl'], 'USE_SHARED_MEMORY': True, 'DB_DATA_PATH': ['nuscenes_10sweeps_withvelo_lidar.npy'], 'PREPARE': {'filter_by_min_points': ['car:5', 'truck:5', 'construction_vehicle:5', 'bus:5', 'trailer:5', 'barrier:5', 'motorcycle:5', 'bicycle:5', 'pedestrian:5', 'traffic_cone:5']}, 'SAMPLE_GROUPS': ['car:2', 'truck:3', 'construction_vehicle:7', 'bus:4', 'trailer:6', 'barrier:2', 'motorcycle:6', 'bicycle:6', 'pedestrian:2', 'traffic_cone:2'], 'NUM_POINT_FEATURES': 5, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': True}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x', 'y']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.9, 1.1]}, {'NAME': 'random_world_translation', 'NOISE_TRANSLATE_STD': [0.5, 0.5, 0.5]}]
2025-09-03 09:15:27,625   INFO  ----------- POINT_FEATURE_ENCODING -----------
2025-09-03 09:15:27,625   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding
2025-09-03 09:15:27,625   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity', 'timestamp']
2025-09-03 09:15:27,625   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity', 'timestamp']
2025-09-03 09:15:27,625   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True, 'MASK_Z': True}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': True}}, {'NAME': 'transform_points_to_voxels_placeholder', 'VOXEL_SIZE': [0.075, 0.075, 0.2]}]
2025-09-03 09:15:27,625   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: cfgs/dataset_configs/nuscenes_dataset.yaml
2025-09-03 09:15:27,625   INFO  ----------- MODEL -----------
2025-09-03 09:15:27,625   INFO  cfg.MODEL.NAME: TransFusion
2025-09-03 09:15:27,625   INFO  ----------- VFE -----------
2025-09-03 09:15:27,625   INFO  cfg.MODEL.VFE.NAME: DynamicVoxelVFE
2025-09-03 09:15:27,625   INFO  cfg.MODEL.VFE.USE_NORM: True
2025-09-03 09:15:27,625   INFO  cfg.MODEL.VFE.WITH_DISTANCE: False
2025-09-03 09:15:27,625   INFO  cfg.MODEL.VFE.USE_ABSLOTE_XYZ: True
2025-09-03 09:15:27,626   INFO  cfg.MODEL.VFE.NUM_FILTERS: [64, 64]
2025-09-03 09:15:27,626   INFO  ----------- BACKBONE_3D -----------
2025-09-03 09:15:27,626   INFO  cfg.MODEL.BACKBONE_3D.NAME: VoxelResBackBone8xVoxelNeXt
2025-09-03 09:15:27,626   INFO  cfg.MODEL.BACKBONE_3D.CHANNELS: [64, 64, 64, 128, 128]
2025-09-03 09:15:27,626   INFO  ----------- DENSE_HEAD -----------
2025-09-03 09:15:27,626   INFO  cfg.MODEL.DENSE_HEAD.NAME: SparseFormerHead
2025-09-03 09:15:27,626   INFO  ----------- SPENCODER -----------
2025-09-03 09:15:27,626   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.NUM_LAYERS: 3
2025-09-03 09:15:27,626   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.ORDERS: [['z', 'z-trans'], ['hilbert', 'hilbert-trans'], ['x', 'y']]
2025-09-03 09:15:27,626   INFO  ----------- SMSA -----------
2025-09-03 09:15:27,626   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.EMBED_DIM: 128
2025-09-03 09:15:27,626   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.DEPTH: 8
2025-09-03 09:15:27,626   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.NUM_LEVELS: 3
2025-09-03 09:15:27,626   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.WINDOW_SHAPE: [9, 9]
2025-09-03 09:15:27,626   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.DROP_PATH: 0.2
2025-09-03 09:15:27,626   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.SPATIAL_ENHANCE: True
2025-09-03 09:15:27,626   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.FUSED_ADD_NORM: True
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.RMS_NORM: True
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.NORM_EPSILON: 1e-05
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.RESIDUAL_IN_FP32: True
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.DIFF_COEF: 0.0
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.DIFF_KERNEL: [7, 5, 3]
2025-09-03 09:15:27,627   INFO  ----------- SPDECODER -----------
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.NUM_LAYERS: 1
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.NUM_LEVELS: 3
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.WINDOW_SHAPE: [[9, 9], [5, 5], [3, 3]]
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.NUM_POINTS: [32, 32, 32]
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.DEPTH: [8, 7, 6]
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.FFN_DIM: 256
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.DROPOUT: 0.1
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.NUM_HEADS: 8
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.FUSION_HEADS: 4
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.ORDERS: [['x', 'y']]
2025-09-03 09:15:27,627   INFO  ----------- SDCA -----------
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.SDCA.EMBED_DIM: 128
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.SDCA.NUM_HEADS: 8
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.SDCA.DROPOUT: 0.1
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.CLASS_AGNOSTIC: False
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.USE_BIAS_BEFORE_NORM: True
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.USE_TENSOR_MASK: True
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.USE_DENSE_HEATMAP: True
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.INPUT_FEATURES: 128
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.NUM_PROPOSALS: 300
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.HIDDEN_CHANNEL: 128
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.NUM_CLASSES: 10
2025-09-03 09:15:27,627   INFO  cfg.MODEL.DENSE_HEAD.NUM_HEADS: 8
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.NMS_KERNEL_SIZE: 3
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.FFN_CHANNEL: 256
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.DROPOUT: 0.1
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.BN_MOMENTUM: 0.1
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.ACTIVATION: relu
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.NUM_HM_CONV: 2
2025-09-03 09:15:27,628   INFO  ----------- SEPARATE_HEAD_CFG -----------
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_ORDER: ['center', 'height', 'dim', 'rot', 'vel', 'iou']
2025-09-03 09:15:27,628   INFO  ----------- HEAD_DICT -----------
2025-09-03 09:15:27,628   INFO  ----------- center -----------
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center.out_channels: 2
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center.num_conv: 2
2025-09-03 09:15:27,628   INFO  ----------- height -----------
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.height.out_channels: 1
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.height.num_conv: 2
2025-09-03 09:15:27,628   INFO  ----------- dim -----------
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.dim.out_channels: 3
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.dim.num_conv: 2
2025-09-03 09:15:27,628   INFO  ----------- rot -----------
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.rot.out_channels: 2
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.rot.num_conv: 2
2025-09-03 09:15:27,628   INFO  ----------- vel -----------
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.vel.out_channels: 2
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.vel.num_conv: 2
2025-09-03 09:15:27,628   INFO  ----------- iou -----------
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.iou.out_channels: 1
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.iou.num_conv: 2
2025-09-03 09:15:27,628   INFO  ----------- TARGET_ASSIGNER_CONFIG -----------
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.DATASET: nuScenes
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.FEATURE_MAP_STRIDE: 8
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.GAUSSIAN_OVERLAP: 0.1
2025-09-03 09:15:27,628   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.MIN_RADIUS: 2
2025-09-03 09:15:27,628   INFO  ----------- HUNGARIAN_ASSIGNER -----------
2025-09-03 09:15:27,628   INFO  ----------- cls_cost -----------
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.HUNGARIAN_ASSIGNER.cls_cost.gamma: 2.0
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.HUNGARIAN_ASSIGNER.cls_cost.alpha: 0.25
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.HUNGARIAN_ASSIGNER.cls_cost.weight: 0.15
2025-09-03 09:15:27,629   INFO  ----------- reg_cost -----------
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.HUNGARIAN_ASSIGNER.reg_cost.weight: 0.25
2025-09-03 09:15:27,629   INFO  ----------- iou_cost -----------
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.HUNGARIAN_ASSIGNER.iou_cost.weight: 0.25
2025-09-03 09:15:27,629   INFO  ----------- LOSS_CONFIG -----------
2025-09-03 09:15:27,629   INFO  ----------- LOSS_WEIGHTS -----------
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.cls_weight: 1.0
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.bbox_weight: 0.25
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.hm_weight: 1.0
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.iou_weight: 0.5
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.iou_reg_weight: 0.5
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2]
2025-09-03 09:15:27,629   INFO  ----------- LOSS_CLS -----------
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_CLS.use_sigmoid: True
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_CLS.gamma: 2.0
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_CLS.alpha: 0.25
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_IOU: True
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_IOU_REG: True
2025-09-03 09:15:27,629   INFO  ----------- POST_PROCESSING -----------
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.SCORE_THRESH: 0.0
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.POST_CENTER_RANGE: [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.USE_IOU_TO_RECTIFY_SCORE: True
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.IOU_RECTIFIER: [0.5]
2025-09-03 09:15:27,629   INFO  ----------- NMS_CONFIG -----------
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.NMS_CONFIG.NMS_TYPE: nms_gpu
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.NMS_CONFIG.NMS_THRESH: 0.2
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.NMS_CONFIG.NMS_PRE_MAXSIZE: 1000
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.NMS_CONFIG.NMS_POST_MAXSIZE: 100
2025-09-03 09:15:27,629   INFO  cfg.MODEL.DENSE_HEAD.NMS_CONFIG.SCORE_THRES: 0.0
2025-09-03 09:15:27,629   INFO  ----------- POST_PROCESSING -----------
2025-09-03 09:15:27,629   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]
2025-09-03 09:15:27,630   INFO  cfg.MODEL.POST_PROCESSING.SCORE_THRESH: 0.1
2025-09-03 09:15:27,630   INFO  cfg.MODEL.POST_PROCESSING.OUTPUT_RAW_SCORE: False
2025-09-03 09:15:27,630   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: kitti
2025-09-03 09:15:27,630   INFO  ----------- NMS_CONFIG -----------
2025-09-03 09:15:27,630   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.MULTI_CLASSES_NMS: True
2025-09-03 09:15:27,630   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_TYPE: nms_gpu
2025-09-03 09:15:27,630   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_THRESH: 0.2
2025-09-03 09:15:27,630   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_PRE_MAXSIZE: 1000
2025-09-03 09:15:27,630   INFO  cfg.MODEL.POST_PROCESSING.NMS_CONFIG.NMS_POST_MAXSIZE: 83
2025-09-03 09:15:27,630   INFO  ----------- OPTIMIZATION -----------
2025-09-03 09:15:27,630   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 4
2025-09-03 09:15:27,630   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 20
2025-09-03 09:15:27,630   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle
2025-09-03 09:15:27,630   INFO  cfg.OPTIMIZATION.LR: 0.001
2025-09-03 09:15:27,630   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01
2025-09-03 09:15:27,630   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9
2025-09-03 09:15:27,630   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]
2025-09-03 09:15:27,630   INFO  cfg.OPTIMIZATION.PCT_START: 0.4
2025-09-03 09:15:27,630   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 10
2025-09-03 09:15:27,630   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]
2025-09-03 09:15:27,630   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1
2025-09-03 09:15:27,630   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07
2025-09-03 09:15:27,630   INFO  cfg.OPTIMIZATION.LR_WARMUP: False
2025-09-03 09:15:27,630   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1
2025-09-03 09:15:27,630   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 35
2025-09-03 09:15:27,630   INFO  cfg.OPTIMIZATION.LOSS_SCALE_FP16: 4.0
2025-09-03 09:15:27,630   INFO  ----------- HOOK -----------
2025-09-03 09:15:27,630   INFO  ----------- DisableAugmentationHook -----------
2025-09-03 09:15:27,631   INFO  cfg.HOOK.DisableAugmentationHook.DISABLE_AUG_LIST: ['gt_sampling']
2025-09-03 09:15:27,631   INFO  cfg.HOOK.DisableAugmentationHook.NUM_LAST_EPOCHS: 4
2025-09-03 09:15:27,631   INFO  cfg.TAG: sparse_former_light
2025-09-03 09:15:27,631   INFO  cfg.EXP_GROUP_PATH: sparse_models
2025-09-03 09:15:27,631   INFO  cfg.OUTPUT_DIR: /mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/workdir/voxelnext/encoder/voxelnext_en_3layer_1lc_zhx_de_1layer_v3_32p_.0diff_.1lr_.1wd
2025-09-03 09:15:27,638   INFO  ----------- Create dataloader & network & optimizer -----------
2025-09-03 09:15:32,988   INFO  Database filter by min points car: 339949 => 294532
2025-09-03 09:15:32,999   INFO  Database filter by min points truck: 65262 => 60344
2025-09-03 09:15:33,001   INFO  Database filter by min points construction_vehicle: 11050 => 10589
2025-09-03 09:15:33,002   INFO  Database filter by min points bus: 12286 => 11619
2025-09-03 09:15:33,005   INFO  Database filter by min points trailer: 19202 => 17934
2025-09-03 09:15:33,017   INFO  Database filter by min points barrier: 107507 => 101993
2025-09-03 09:15:33,019   INFO  Database filter by min points motorcycle: 8846 => 8055
2025-09-03 09:15:33,020   INFO  Database filter by min points bicycle: 8185 => 7531
2025-09-03 09:15:33,036   INFO  Database filter by min points pedestrian: 161928 => 148520
2025-09-03 09:15:33,044   INFO  Database filter by min points traffic_cone: 62964 => 55504
2025-09-03 09:15:33,044   INFO  Loading GT database to shared memory
eflops79:23:23 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:23:23 [0] NCCL INFO Bootstrap : Using bond0:10.16.10.225<0>
eflops79:23:23 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
eflops79:23:23 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
eflops79:23:23 [0] NCCL INFO cudaDriverVersion 12050
NCCL version 2.18.5+cuda11.8
eflops79:28:28 [5] NCCL INFO cudaDriverVersion 12050
eflops79:29:29 [6] NCCL INFO cudaDriverVersion 12050
eflops79:25:25 [2] NCCL INFO cudaDriverVersion 12050
eflops79:28:28 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:29:29 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:25:25 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:27:27 [4] NCCL INFO cudaDriverVersion 12050
eflops79:30:30 [7] NCCL INFO cudaDriverVersion 12050
eflops79:26:26 [3] NCCL INFO cudaDriverVersion 12050
eflops79:24:24 [1] NCCL INFO cudaDriverVersion 12050
eflops79:27:27 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:30:30 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:26:26 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:24:24 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:28:28 [5] NCCL INFO Bootstrap : Using bond0:10.16.10.225<0>
eflops79:25:25 [2] NCCL INFO Bootstrap : Using bond0:10.16.10.225<0>
eflops79:30:30 [7] NCCL INFO Bootstrap : Using bond0:10.16.10.225<0>
eflops79:26:26 [3] NCCL INFO Bootstrap : Using bond0:10.16.10.225<0>
eflops79:29:29 [6] NCCL INFO Bootstrap : Using bond0:10.16.10.225<0>
eflops79:24:24 [1] NCCL INFO Bootstrap : Using bond0:10.16.10.225<0>
eflops79:28:28 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
eflops79:28:28 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
eflops79:30:30 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
eflops79:26:26 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
eflops79:30:30 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
eflops79:26:26 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
eflops79:27:27 [4] NCCL INFO Bootstrap : Using bond0:10.16.10.225<0>
eflops79:25:25 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
eflops79:25:25 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
eflops79:29:29 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
eflops79:29:29 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
eflops79:24:24 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
eflops79:24:24 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
eflops79:27:27 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
eflops79:27:27 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
eflops79:26:100 [3] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
eflops79:26:100 [3] NCCL INFO P2P plugin IBext
eflops79:26:100 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond

eflops79:26:100 [3] ibvwrap.c:66 NCCL WARN Call to ibv_open_device failed

eflops79:26:100 [3] p2p_plugin.c:233 NCCL WARN NET/IB : Unable to open device mlx5_bond_0
eflops79:26:100 [3] NCCL INFO NET/IB : No device found.
eflops79:26:100 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
eflops79:26:100 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:26:100 [3] NCCL INFO NET/Socket : Using [0]bond0:10.16.10.225<0>
eflops79:26:100 [3] NCCL INFO Using network Socket
eflops79:29:105 [6] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
eflops79:29:105 [6] NCCL INFO P2P plugin IBext
eflops79:29:105 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:27:102 [4] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
eflops79:27:102 [4] NCCL INFO P2P plugin IBext
eflops79:27:102 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:28:106 [5] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
eflops79:28:106 [5] NCCL INFO P2P plugin IBext
eflops79:28:106 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:23:99 [0] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
eflops79:23:99 [0] NCCL INFO P2P plugin IBext
eflops79:23:99 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:24:104 [1] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
eflops79:24:104 [1] NCCL INFO P2P plugin IBext
eflops79:24:104 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:25:103 [2] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
eflops79:25:103 [2] NCCL INFO P2P plugin IBext
eflops79:25:103 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:30:101 [7] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
eflops79:30:101 [7] NCCL INFO P2P plugin IBext
eflops79:30:101 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond

eflops79:29:105 [6] ibvwrap.c:66 NCCL WARN Call to ibv_open_device failed

eflops79:29:105 [6] p2p_plugin.c:233 NCCL WARN NET/IB : Unable to open device mlx5_bond_0
eflops79:29:105 [6] NCCL INFO NET/IB : No device found.
eflops79:29:105 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.

eflops79:27:102 [4] ibvwrap.c:66 NCCL WARN Call to ibv_open_device failed

eflops79:27:102 [4] p2p_plugin.c:233 NCCL WARN NET/IB : Unable to open device mlx5_bond_0
eflops79:27:102 [4] NCCL INFO NET/IB : No device found.
eflops79:29:105 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:27:102 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
eflops79:27:102 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond

eflops79:28:106 [5] ibvwrap.c:66 NCCL WARN Call to ibv_open_device failed

eflops79:28:106 [5] p2p_plugin.c:233 NCCL WARN NET/IB : Unable to open device mlx5_bond_0
eflops79:28:106 [5] NCCL INFO NET/IB : No device found.
eflops79:28:106 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
eflops79:28:106 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond

eflops79:24:104 [1] ibvwrap.c:66 NCCL WARN Call to ibv_open_device failed

eflops79:24:104 [1] p2p_plugin.c:233 NCCL WARN NET/IB : Unable to open device mlx5_bond_0
eflops79:24:104 [1] NCCL INFO NET/IB : No device found.
eflops79:24:104 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
eflops79:24:104 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond

eflops79:23:99 [0] ibvwrap.c:66 NCCL WARN Call to ibv_open_device failed

eflops79:23:99 [0] p2p_plugin.c:233 NCCL WARN NET/IB : Unable to open device mlx5_bond_0
eflops79:23:99 [0] NCCL INFO NET/IB : No device found.
eflops79:23:99 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
eflops79:23:99 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:29:105 [6] NCCL INFO NET/Socket : Using [0]bond0:10.16.10.225<0>
eflops79:29:105 [6] NCCL INFO Using network Socket
eflops79:27:102 [4] NCCL INFO NET/Socket : Using [0]bond0:10.16.10.225<0>
eflops79:27:102 [4] NCCL INFO Using network Socket
eflops79:28:106 [5] NCCL INFO NET/Socket : Using [0]bond0:10.16.10.225<0>
eflops79:28:106 [5] NCCL INFO Using network Socket
eflops79:24:104 [1] NCCL INFO NET/Socket : Using [0]bond0:10.16.10.225<0>
eflops79:24:104 [1] NCCL INFO Using network Socket
eflops79:23:99 [0] NCCL INFO NET/Socket : Using [0]bond0:10.16.10.225<0>
eflops79:23:99 [0] NCCL INFO Using network Socket

eflops79:25:103 [2] ibvwrap.c:66 NCCL WARN Call to ibv_open_device failed

eflops79:25:103 [2] p2p_plugin.c:233 NCCL WARN NET/IB : Unable to open device mlx5_bond_0
eflops79:25:103 [2] NCCL INFO NET/IB : No device found.
eflops79:25:103 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
eflops79:25:103 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond

eflops79:30:101 [7] ibvwrap.c:66 NCCL WARN Call to ibv_open_device failed

eflops79:30:101 [7] p2p_plugin.c:233 NCCL WARN NET/IB : Unable to open device mlx5_bond_0
eflops79:30:101 [7] NCCL INFO NET/IB : No device found.
eflops79:30:101 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
eflops79:30:101 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops79:25:103 [2] NCCL INFO NET/Socket : Using [0]bond0:10.16.10.225<0>
eflops79:25:103 [2] NCCL INFO Using network Socket
eflops79:30:101 [7] NCCL INFO NET/Socket : Using [0]bond0:10.16.10.225<0>
eflops79:30:101 [7] NCCL INFO Using network Socket
eflops79:25:103 [2] NCCL INFO comm 0x121ebaf0 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 29000 commId 0xf3104e65231a057b - Init START
eflops79:24:104 [1] NCCL INFO comm 0x112472a0 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 26000 commId 0xf3104e65231a057b - Init START
eflops79:26:100 [3] NCCL INFO comm 0x11c00ee0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 2d000 commId 0xf3104e65231a057b - Init START
eflops79:27:102 [4] NCCL INFO comm 0x11826ca0 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId a5000 commId 0xf3104e65231a057b - Init START
eflops79:23:99 [0] NCCL INFO comm 0x11738380 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 25000 commId 0xf3104e65231a057b - Init START
eflops79:28:106 [5] NCCL INFO comm 0x10d1e280 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId a6000 commId 0xf3104e65231a057b - Init START
eflops79:30:101 [7] NCCL INFO comm 0x107c0fd0 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId ad000 commId 0xf3104e65231a057b - Init START
eflops79:29:105 [6] NCCL INFO comm 0x123636c0 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId a9000 commId 0xf3104e65231a057b - Init START
eflops79:23:99 [0] NCCL INFO Setting affinity for GPU 0 to ff0000,00000000,00ff0000
eflops79:26:100 [3] NCCL INFO Setting affinity for GPU 3 to ff0000,00000000,00ff0000
eflops79:27:102 [4] NCCL INFO Setting affinity for GPU 4 to ff0000,00000000,00ff0000,00000000
eflops79:24:104 [1] NCCL INFO Setting affinity for GPU 1 to ff0000,00000000,00ff0000
eflops79:29:105 [6] NCCL INFO Setting affinity for GPU 6 to ff0000,00000000,00ff0000,00000000
eflops79:30:101 [7] NCCL INFO Setting affinity for GPU 7 to ff0000,00000000,00ff0000,00000000
eflops79:25:103 [2] NCCL INFO Setting affinity for GPU 2 to ff0000,00000000,00ff0000
eflops79:28:106 [5] NCCL INFO Setting affinity for GPU 5 to ff0000,00000000,00ff0000,00000000
eflops79:30:101 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6
eflops79:30:101 [7] NCCL INFO P2P Chunksize set to 131072
eflops79:24:104 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0
eflops79:25:103 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1
eflops79:23:99 [0] NCCL INFO Channel 00/04 :    0   1   2   3   4   5   6   7
eflops79:25:103 [2] NCCL INFO P2P Chunksize set to 131072
eflops79:23:99 [0] NCCL INFO Channel 01/04 :    0   1   2   3   4   5   6   7
eflops79:24:104 [1] NCCL INFO P2P Chunksize set to 131072
eflops79:29:105 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5
eflops79:23:99 [0] NCCL INFO Channel 02/04 :    0   1   2   3   4   5   6   7
eflops79:23:99 [0] NCCL INFO Channel 03/04 :    0   1   2   3   4   5   6   7
eflops79:29:105 [6] NCCL INFO P2P Chunksize set to 131072
eflops79:28:106 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4
eflops79:23:99 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1
eflops79:28:106 [5] NCCL INFO P2P Chunksize set to 131072
eflops79:23:99 [0] NCCL INFO P2P Chunksize set to 131072
eflops79:27:102 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3
eflops79:27:102 [4] NCCL INFO P2P Chunksize set to 131072
eflops79:26:100 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2
eflops79:26:100 [3] NCCL INFO P2P Chunksize set to 131072
eflops79:25:103 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/IPC
eflops79:29:105 [6] NCCL INFO Channel 00/0 : 6[6] -> 7[7] via P2P/IPC
eflops79:24:104 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/IPC
eflops79:27:102 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/IPC
eflops79:30:101 [7] NCCL INFO Channel 00/0 : 7[7] -> 0[0] via P2P/IPC
eflops79:26:100 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/IPC
eflops79:25:103 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/IPC
eflops79:24:104 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/IPC
eflops79:29:105 [6] NCCL INFO Channel 01/0 : 6[6] -> 7[7] via P2P/IPC
eflops79:28:106 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[6] via P2P/IPC
eflops79:27:102 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/IPC
eflops79:30:101 [7] NCCL INFO Channel 01/0 : 7[7] -> 0[0] via P2P/IPC
eflops79:28:106 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[6] via P2P/IPC
eflops79:24:104 [1] NCCL INFO Channel 02/0 : 1[1] -> 2[2] via P2P/IPC
eflops79:29:105 [6] NCCL INFO Channel 02/0 : 6[6] -> 7[7] via P2P/IPC
eflops79:27:102 [4] NCCL INFO Channel 02/0 : 4[4] -> 5[5] via P2P/IPC
eflops79:30:101 [7] NCCL INFO Channel 02/0 : 7[7] -> 0[0] via P2P/IPC
eflops79:28:106 [5] NCCL INFO Channel 02/0 : 5[5] -> 6[6] via P2P/IPC
eflops79:24:104 [1] NCCL INFO Channel 03/0 : 1[1] -> 2[2] via P2P/IPC
eflops79:29:105 [6] NCCL INFO Channel 03/0 : 6[6] -> 7[7] via P2P/IPC
eflops79:27:102 [4] NCCL INFO Channel 03/0 : 4[4] -> 5[5] via P2P/IPC
eflops79:30:101 [7] NCCL INFO Channel 03/0 : 7[7] -> 0[0] via P2P/IPC
eflops79:28:106 [5] NCCL INFO Channel 03/0 : 5[5] -> 6[6] via P2P/IPC
eflops79:26:100 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[4] via P2P/IPC
eflops79:26:100 [3] NCCL INFO Channel 02/0 : 3[3] -> 4[4] via P2P/IPC
eflops79:23:99 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/IPC
eflops79:26:100 [3] NCCL INFO Channel 03/0 : 3[3] -> 4[4] via P2P/IPC
eflops79:23:99 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/IPC
eflops79:23:99 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/IPC
eflops79:23:99 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/IPC
eflops79:29:105 [6] NCCL INFO Connected all rings
eflops79:28:106 [5] NCCL INFO Connected all rings
eflops79:25:103 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/IPC
eflops79:29:105 [6] NCCL INFO Channel 00/0 : 6[6] -> 5[5] via P2P/IPC
eflops79:25:103 [2] NCCL INFO Channel 03/0 : 2[2] -> 3[3] via P2P/IPC
eflops79:27:102 [4] NCCL INFO Connected all rings
eflops79:29:105 [6] NCCL INFO Channel 01/0 : 6[6] -> 5[5] via P2P/IPC
eflops79:29:105 [6] NCCL INFO Channel 02/0 : 6[6] -> 5[5] via P2P/IPC
eflops79:28:106 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/IPC
eflops79:29:105 [6] NCCL INFO Channel 03/0 : 6[6] -> 5[5] via P2P/IPC
eflops79:28:106 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/IPC
eflops79:28:106 [5] NCCL INFO Channel 02/0 : 5[5] -> 4[4] via P2P/IPC
eflops79:24:104 [1] NCCL INFO Connected all rings
eflops79:26:100 [3] NCCL INFO Connected all rings
eflops79:27:102 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/IPC
eflops79:27:102 [4] NCCL INFO Channel 01/0 : 4[4] -> 3[3] via P2P/IPC
eflops79:30:101 [7] NCCL INFO Connected all rings
eflops79:30:101 [7] NCCL INFO Channel 00/0 : 7[7] -> 6[6] via P2P/IPC
eflops79:23:99 [0] NCCL INFO Connected all rings
eflops79:27:102 [4] NCCL INFO Channel 02/0 : 4[4] -> 3[3] via P2P/IPC
eflops79:30:101 [7] NCCL INFO Channel 01/0 : 7[7] -> 6[6] via P2P/IPC
eflops79:27:102 [4] NCCL INFO Channel 03/0 : 4[4] -> 3[3] via P2P/IPC
eflops79:26:100 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/IPC
eflops79:24:104 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/IPC
eflops79:30:101 [7] NCCL INFO Channel 02/0 : 7[7] -> 6[6] via P2P/IPC
eflops79:26:100 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/IPC
eflops79:24:104 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/IPC
eflops79:30:101 [7] NCCL INFO Channel 03/0 : 7[7] -> 6[6] via P2P/IPC
eflops79:25:103 [2] NCCL INFO Connected all rings
eflops79:26:100 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/IPC
eflops79:24:104 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/IPC
eflops79:28:106 [5] NCCL INFO Channel 03/0 : 5[5] -> 4[4] via P2P/IPC
eflops79:26:100 [3] NCCL INFO Channel 03/0 : 3[3] -> 2[2] via P2P/IPC
eflops79:24:104 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/IPC
eflops79:30:101 [7] NCCL INFO Connected all trees
eflops79:30:101 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
eflops79:30:101 [7] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
eflops79:25:103 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/IPC
eflops79:23:99 [0] NCCL INFO Connected all trees
eflops79:23:99 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
eflops79:23:99 [0] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
eflops79:25:103 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/IPC
eflops79:28:106 [5] NCCL INFO Connected all trees
eflops79:28:106 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
eflops79:28:106 [5] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
eflops79:25:103 [2] NCCL INFO Channel 02/0 : 2[2] -> 1[1] via P2P/IPC
eflops79:27:102 [4] NCCL INFO Connected all trees
eflops79:27:102 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
eflops79:27:102 [4] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
eflops79:25:103 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/IPC
eflops79:29:105 [6] NCCL INFO Connected all trees
eflops79:29:105 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
eflops79:29:105 [6] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
eflops79:26:100 [3] NCCL INFO Connected all trees
eflops79:26:100 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
eflops79:26:100 [3] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
eflops79:24:104 [1] NCCL INFO Connected all trees
eflops79:24:104 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
eflops79:24:104 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
eflops79:25:103 [2] NCCL INFO Connected all trees
eflops79:25:103 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
eflops79:25:103 [2] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
eflops79:24:104 [1] NCCL INFO comm 0x112472a0 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 26000 commId 0xf3104e65231a057b - Init COMPLETE
eflops79:28:106 [5] NCCL INFO comm 0x10d1e280 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId a6000 commId 0xf3104e65231a057b - Init COMPLETE
eflops79:26:100 [3] NCCL INFO comm 0x11c00ee0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 2d000 commId 0xf3104e65231a057b - Init COMPLETE
eflops79:30:101 [7] NCCL INFO comm 0x107c0fd0 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId ad000 commId 0xf3104e65231a057b - Init COMPLETE
eflops79:27:102 [4] NCCL INFO comm 0x11826ca0 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId a5000 commId 0xf3104e65231a057b - Init COMPLETE
eflops79:29:105 [6] NCCL INFO comm 0x123636c0 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId a9000 commId 0xf3104e65231a057b - Init COMPLETE
eflops79:23:99 [0] NCCL INFO comm 0x11738380 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 25000 commId 0xf3104e65231a057b - Init COMPLETE
eflops79:25:103 [2] NCCL INFO comm 0x121ebaf0 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 29000 commId 0xf3104e65231a057b - Init COMPLETE
2025-09-03 09:15:44,825   INFO  GT database has been saved to shared memory
2025-09-03 09:15:44,945   INFO  Loading NuScenes dataset
2025-09-03 09:15:46,654   INFO  Total samples for NuScenes dataset: 28130
2025-09-03 09:15:46,913   INFO  Total samples after balanced resampling: 123580
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
epochs:   0%|          | 0/20 [00:00<?, ?it/s]epochs:   0%|          | 0/20 [00:00<?, ?it/s]epochs:   0%|          | 0/20 [00:00<?, ?it/s]2025-09-03 09:15:48,805   INFO  ----------- Model TransFusion created, param count: 14007135 -----------
epochs:   0%|          | 0/20 [00:00<?, ?it/s]epochs:   0%|          | 0/20 [00:00<?, ?it/s]epochs:   0%|          | 0/20 [00:00<?, ?it/s]epochs:   0%|          | 0/20 [00:00<?, ?it/s]2025-09-03 09:15:48,805   INFO  DistributedDataParallel(
  (module): TransFusion(
    (vfe): DynamicVoxelVFE(
      (pfn_layers): ModuleList(
        (0): PFNLayerV2(
          (linear): Linear(in_features=11, out_features=32, bias=False)
          (norm): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): PFNLayerV2(
          (linear): Linear(in_features=64, out_features=64, bias=False)
          (norm): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
    )
    (backbone_3d): VoxelResBackBone8xVoxelNeXt(
      (conv_input): SparseSequential(
        (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (conv1): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (conv2): SparseSequential(
        (0): SparseSequential(
          (0): SparseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
        (2): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (conv3): SparseSequential(
        (0): SparseSequential(
          (0): SparseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
        (2): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (conv4): SparseSequential(
        (0): SparseSequential(
          (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
        (2): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (conv5): SparseSequential(
        (0): SparseSequential(
          (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
        (2): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (conv6): SparseSequential(
        (0): SparseSequential(
          (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
        (2): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (map_to_bev_module): None
    (pfe): None
    (backbone_2d): None
    (dense_head): SparseFormerHead(
      (loss_cls): SigmoidFocalClassificationLoss()
      (loss_bbox): L1Loss()
      (loss_heatmap): GaussianFocalLoss()
      (heatmap_head): SparseSequential(
        (0): SubMConv2d(128, 128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): SubMConv2d(128, 10, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
      )
      (shared_conv): SparseSequential(
        (0): SparseConv2d(128, 128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], output_padding=[0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): SubMConv2d(128, 128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (4): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (class_encoding): Conv1d(10, 128, kernel_size=(1,), stride=(1,))
      (prediction_head): SeparateHead(
        (center): Sequential(
          (0): Sequential(
            (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
        )
        (height): Sequential(
          (0): Sequential(
            (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv1d(64, 1, kernel_size=(1,), stride=(1,))
        )
        (dim): Sequential(
          (0): Sequential(
            (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv1d(64, 3, kernel_size=(1,), stride=(1,))
        )
        (rot): Sequential(
          (0): Sequential(
            (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
        )
        (vel): Sequential(
          (0): Sequential(
            (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
        )
        (iou): Sequential(
          (0): Sequential(
            (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv1d(64, 1, kernel_size=(1,), stride=(1,))
        )
        (heatmap): Sequential(
          (0): Sequential(
            (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv1d(64, 10, kernel_size=(1,), stride=(1,))
        )
      )
      (encoder): SPEncoder(
        (blocks): ModuleList(
          (0): SMSA(
            (forward_blocks): ModuleList(
              (0-1): 2 x Block(
                (mixer): Mamba(
                  (in_proj): Linear(in_features=128, out_features=512, bias=False)
                  (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
                  (act): SiLU()
                  (x_proj): Linear(in_features=256, out_features=40, bias=False)
                  (dt_proj): Linear(in_features=8, out_features=256, bias=True)
                  (out_proj): Linear(in_features=256, out_features=128, bias=False)
                )
                (norm): RMSNorm()
              )
            )
            (backward_blocks): ModuleList(
              (0-1): 2 x Block(
                (mixer): Mamba(
                  (in_proj): Linear(in_features=128, out_features=512, bias=False)
                  (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
                  (act): SiLU()
                  (x_proj): Linear(in_features=256, out_features=40, bias=False)
                  (dt_proj): Linear(in_features=8, out_features=256, bias=True)
                  (out_proj): Linear(in_features=256, out_features=128, bias=False)
                )
                (norm): RMSNorm()
              )
            )
            (forward_norms): ModuleList(
              (0-1): 2 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (backward_norms): ModuleList(
              (0-1): 2 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (output_norms): ModuleList(
              (0-1): 2 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.200)
            (locals): ModuleList(
              (0-2): 3 x ResidualSparseBasicBlock(
                (conv1): SubMConv2d(128, 128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (act): GELU(approximate='none')
              )
            )
            (input_layer): SerializationLayer(
              (serialization): ZOrderSerialization()
            )
          )
          (1): SMSA(
            (forward_blocks): ModuleList(
              (0-1): 2 x Block(
                (mixer): Mamba(
                  (in_proj): Linear(in_features=128, out_features=512, bias=False)
                  (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
                  (act): SiLU()
                  (x_proj): Linear(in_features=256, out_features=40, bias=False)
                  (dt_proj): Linear(in_features=8, out_features=256, bias=True)
                  (out_proj): Linear(in_features=256, out_features=128, bias=False)
                )
                (norm): RMSNorm()
              )
            )
            (backward_blocks): ModuleList(
              (0-1): 2 x Block(
                (mixer): Mamba(
                  (in_proj): Linear(in_features=128, out_features=512, bias=False)
                  (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
                  (act): SiLU()
                  (x_proj): Linear(in_features=256, out_features=40, bias=False)
                  (dt_proj): Linear(in_features=8, out_features=256, bias=True)
                  (out_proj): Linear(in_features=256, out_features=128, bias=False)
                )
                (norm): RMSNorm()
              )
            )
            (forward_norms): ModuleList(
              (0-1): 2 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (backward_norms): ModuleList(
              (0-1): 2 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (output_norms): ModuleList(
              (0-1): 2 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.200)
            (locals): ModuleList(
              (0-2): 3 x ResidualSparseBasicBlock(
                (conv1): SubMConv2d(128, 128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (act): GELU(approximate='none')
              )
            )
            (input_layer): SerializationLayer(
              (serialization): HilbertSerialization()
            )
          )
          (2): SMSA(
            (forward_blocks): ModuleList(
              (0-1): 2 x Block(
                (mixer): Mamba(
                  (in_proj): Linear(in_features=128, out_features=512, bias=False)
                  (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
                  (act): SiLU()
                  (x_proj): Linear(in_features=256, out_features=40, bias=False)
                  (dt_proj): Linear(in_features=8, out_features=256, bias=True)
                  (out_proj): Linear(in_features=256, out_features=128, bias=False)
                )
                (norm): RMSNorm()
              )
            )
            (backward_blocks): ModuleList(
              (0-1): 2 x Block(
                (mixer): Mamba(
                  (in_proj): Linear(in_features=128, out_features=512, bias=False)
                  (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
                  (act): SiLU()
                  (x_proj): Linear(in_features=256, out_features=40, bias=False)
                  (dt_proj): Linear(in_features=8, out_features=256, bias=True)
                  (out_proj): Linear(in_features=256, out_features=128, bias=False)
                )
                (norm): RMSNorm()
              )
            )
            (forward_norms): ModuleList(
              (0-1): 2 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (backward_norms): ModuleList(
              (0-1): 2 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (output_norms): ModuleList(
              (0-1): 2 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (drop_path): DropPath(drop_prob=0.200)
            (locals): ModuleList(
              (0-2): 3 x ResidualSparseBasicBlock(
                (conv1): SubMConv2d(128, 128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (act): GELU(approximate='none')
              )
            )
            (input_layer): SerializationLayer(
              (serialization): FlattenWindowsSerialization()
            )
          )
        )
        (embeddings): ModuleList(
          (0-2): 3 x MSSubConvEmbeddingLearned(
            (stem): ModuleList(
              (0-2): 3 x SparseBasicBlock(
                (conv1): SubMConv2d(2, 128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
                (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
                (relu): ReLU(inplace=True)
                (conv2): SubMConv2d(128, 128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
              )
            )
          )
        )
      )
      (decoder): SPDecoder(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
        )
        (cross_attn): ModuleList(
          (0): ModuleList(
            (0-2): 3 x SDCA(
              (input_layer): SerializationLayer(
                (serialization): FlattenWindowsSerialization()
              )
              (blocks): ModuleList(
                (0-1): 2 x DeformableAttention(
                  (sampling_offsets): Linear(in_features=128, out_features=256, bias=True)
                  (sampling_weights): Linear(in_features=128, out_features=256, bias=True)
                  (value_proj): Linear(in_features=128, out_features=128, bias=True)
                  (output_proj): Linear(in_features=128, out_features=128, bias=True)
                  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
        (fusions): ModuleList(
          (0): LevelFusion(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
            )
            (dropout): Dropout(p=0.1, inplace=False)
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
        )
        (linear1): Linear(in_features=128, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=128, bias=True)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_posembed): ConvEmbeddingLearned(
          (stem): Sequential(
            (0): Conv1d(2, 128, kernel_size=(1,), stride=(1,))
            (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (cross_posembed): MSSubConvEmbeddingLearned(
          (stem): ModuleList(
            (0-2): 3 x SparseBasicBlock(
              (conv1): SubMConv2d(2, 128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
              (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
              (conv2): SubMConv2d(128, 128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            )
          )
        )
      )
    )
    (point_head): None
    (roi_head): None
  )
)
2025-09-03 09:15:48,810   INFO  **********************Start training sparse_models/sparse_former_light(default)**********************
epochs:   0%|          | 0/20 [00:00<?, ?it/s]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/ops/iou3d_nms/iou3d_nms_utils.py:102: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overlaps_bev = torch.cuda.FloatTensor(torch.Size((boxes_a.shape[0], 1))).zero_()  # (N, M)
/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/ops/iou3d_nms/iou3d_nms_utils.py:102: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overlaps_bev = torch.cuda.FloatTensor(torch.Size((boxes_a.shape[0], 1))).zero_()  # (N, M)
/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/ops/iou3d_nms/iou3d_nms_utils.py:102: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overlaps_bev = torch.cuda.FloatTensor(torch.Size((boxes_a.shape[0], 1))).zero_()  # (N, M)
/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/ops/iou3d_nms/iou3d_nms_utils.py:102: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overlaps_bev = torch.cuda.FloatTensor(torch.Size((boxes_a.shape[0], 1))).zero_()  # (N, M)
/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/ops/iou3d_nms/iou3d_nms_utils.py:102: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overlaps_bev = torch.cuda.FloatTensor(torch.Size((boxes_a.shape[0], 1))).zero_()  # (N, M)
/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/ops/iou3d_nms/iou3d_nms_utils.py:102: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overlaps_bev = torch.cuda.FloatTensor(torch.Size((boxes_a.shape[0], 1))).zero_()  # (N, M)
/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/ops/iou3d_nms/iou3d_nms_utils.py:102: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overlaps_bev = torch.cuda.FloatTensor(torch.Size((boxes_a.shape[0], 1))).zero_()  # (N, M)
/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/ops/iou3d_nms/iou3d_nms_utils.py:102: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overlaps_bev = torch.cuda.FloatTensor(torch.Size((boxes_a.shape[0], 1))).zero_()  # (N, M)
/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/utils/commu_utils.py:66: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = torch.ByteStorage.from_buffer(buffer)
/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/utils/commu_utils.py:66: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = torch.ByteStorage.from_buffer(buffer)
/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/utils/commu_utils.py:66: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = torch.ByteStorage.from_buffer(buffer)
/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/utils/commu_utils.py:66: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = torch.ByteStorage.from_buffer(buffer)
/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/utils/commu_utils.py:66: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = torch.ByteStorage.from_buffer(buffer)
/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/utils/commu_utils.py:66: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = torch.ByteStorage.from_buffer(buffer)
/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/utils/commu_utils.py:66: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = torch.ByteStorage.from_buffer(buffer)
/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/utils/commu_utils.py:66: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = torch.ByteStorage.from_buffer(buffer)
2025-09-03 09:16:12,412   INFO  Train:    1/20 (  5%) [   0/3862 (  0%)]  Loss: 408.6 (409.)  LR: 1.000e-04  Grad: 35.0000  max=3.5109(module.dense_head.heatmap_head.3.bias)  min: -0.3955(module.dense_head.heatmap_head.1.bias)  NaN: False  loss_hm=400.9497, loss_cls=0.4728, loss_bbox=6.4259, matched_ious=0.0039, loss_iou=0.2547, loss_iou_reg=0.4666, d_time=2.77(2.77), f_time=19.14(19.14), b_time=21.91(21.91)  Time cost: 00:21/23:24:27 [00:23/468:09:12]  Acc_iter 1           Data time: 2.77(2.77)  Forward time: 19.14(19.14)  Batch time: 21.91(21.91)
2025-09-03 09:17:27,609   INFO  Train:    1/20 (  5%) [  49/3862 (  1%)]  Loss: 230.8 (365.)  LR: 1.000e-04  Grad: 35.0000  max=3.7104(module.dense_head.heatmap_head.3.bias)  min: -0.6705(module.dense_head.heatmap_head.1.bias)  NaN: False  loss_hm=356.5261, loss_cls=0.4807, loss_bbox=6.3339, matched_ious=0.0031, loss_iou=0.2081, loss_iou_reg=0.4214, d_time=0.01(0.06), f_time=1.31(1.88), b_time=1.32(1.94)  Time cost: 01:37/2:03:18 [01:38/41:36:09]  Acc_iter 50          Data time: 0.01(0.06)  Forward time: 1.31(1.88)  Batch time: 1.32(1.94)
2025-09-03 09:18:39,979   INFO  Train:    1/20 (  5%) [  99/3862 (  3%)]  Loss: 141.4 (267.)  LR: 1.000e-04  Grad: 35.0000  max=3.5763(module.dense_head.heatmap_head.3.bias)  min: -0.6109(module.dense_head.heatmap_head.1.bias)  NaN: False  loss_hm=161.1570, loss_cls=0.4175, loss_bbox=6.0765, matched_ious=0.0080, loss_iou=0.1398, loss_iou_reg=0.4623, d_time=0.01(0.04), f_time=1.53(1.66), b_time=1.53(1.69)  Time cost: 02:49/1:46:13 [02:51/36:17:45]  Acc_iter 100         Data time: 0.01(0.04)  Forward time: 1.53(1.66)  Batch time: 1.53(1.69)
2025-09-03 09:19:58,513   INFO  Train:    1/20 (  5%) [ 149/3862 (  4%)]  Loss: 78.70 (208.)  LR: 1.001e-04  Grad: 35.0000  max=3.2579(module.dense_head.heatmap_head.3.bias)  min: -0.6207(module.dense_head.heatmap_head.1.bias)  NaN: False  loss_hm=85.6788, loss_cls=0.3823, loss_bbox=5.6728, matched_ious=0.0096, loss_iou=0.0998, loss_iou_reg=0.4561, d_time=0.01(0.03), f_time=1.41(1.63), b_time=1.41(1.65)  Time cost: 04:07/1:42:16 [04:09/35:23:34]  Acc_iter 150         Data time: 0.01(0.03)  Forward time: 1.41(1.63)  Batch time: 1.41(1.65)
2025-09-03 09:21:11,539   INFO  Train:    1/20 (  5%) [ 199/3862 (  5%)]  Loss: 39.08 (169.)  LR: 1.001e-04  Grad: 35.0000  max=3.0019(module.dense_head.heatmap_head.3.bias)  min: -0.7104(module.dense_head.heatmap_head.1.bias)  NaN: False  loss_hm=45.3801, loss_cls=0.3566, loss_bbox=5.6888, matched_ious=0.0131, loss_iou=0.0963, loss_iou_reg=0.4487, d_time=0.00(0.02), f_time=1.44(1.58), b_time=1.44(1.61)  Time cost: 05:20/1:37:58 [05:22/34:20:29]  Acc_iter 200         Data time: 0.00(0.02)  Forward time: 1.44(1.58)  Batch time: 1.44(1.61)
2025-09-03 09:22:26,013   INFO  Train:    1/20 (  5%) [ 249/3862 (  6%)]  Loss: 25.76 (142.)  LR: 1.001e-04  Grad: 35.0000  max=3.0815(module.dense_head.heatmap_head.3.bias)  min: -0.6986(module.dense_head.heatmap_head.1.bias)  NaN: False  loss_hm=25.3514, loss_cls=0.3514, loss_bbox=5.7609, matched_ious=0.0147, loss_iou=0.0932, loss_iou_reg=0.4417, d_time=0.01(0.02), f_time=1.54(1.56), b_time=1.54(1.58)  Time cost: 06:35/1:35:14 [06:37/33:49:34]  Acc_iter 250         Data time: 0.01(0.02)  Forward time: 1.54(1.56)  Batch time: 1.54(1.58)
2025-09-03 09:23:39,433   INFO  Train:    1/20 (  5%) [ 299/3862 (  8%)]  Loss: 14.50 (121.)  LR: 1.002e-04  Grad: 35.0000  max=3.0685(module.dense_head.heatmap_head.3.bias)  min: -0.6753(module.dense_head.heatmap_head.1.bias)  NaN: False  loss_hm=13.0541, loss_cls=0.3472, loss_bbox=5.6995, matched_ious=0.0195, loss_iou=0.0864, loss_iou_reg=0.4377, d_time=0.01(0.02), f_time=1.44(1.55), b_time=1.44(1.56)  Time cost: 07:48/1:32:48 [07:50/33:24:03]  Acc_iter 300         Data time: 0.01(0.02)  Forward time: 1.44(1.55)  Batch time: 1.44(1.56)
2025-09-03 09:24:57,433   INFO  Train:    1/20 (  5%) [ 349/3862 (  9%)]  Loss: 10.75 (106.)  LR: 1.003e-04  Grad: 19.9894  max=1.3921(module.dense_head.heatmap_head.3.bias)  min: -0.5292(module.dense_head.encoder.blocks.0.forward_blocks.0.mixer.conv1d.bias)  NaN: False  loss_hm=7.1302, loss_cls=0.3469, loss_bbox=5.6421, matched_ious=0.0232, loss_iou=0.0892, loss_iou_reg=0.4333, d_time=0.01(0.02), f_time=1.42(1.55), b_time=1.42(1.56)  Time cost: 09:06/1:31:28 [09:08/33:22:14]  Acc_iter 350         Data time: 0.01(0.02)  Forward time: 1.42(1.55)  Batch time: 1.42(1.56)
2025-09-03 09:26:10,425   INFO  Train:    1/20 (  5%) [ 399/3862 ( 10%)]  Loss: 11.09 (94.2)  LR: 1.004e-04  Grad: 13.8436  max=0.8786(module.dense_head.heatmap_head.3.bias)  min: -0.3151(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=4.8610, loss_cls=0.3447, loss_bbox=5.5212, matched_ious=0.0257, loss_iou=0.0872, loss_iou_reg=0.4346, d_time=0.01(0.01), f_time=1.41(1.53), b_time=1.41(1.55)  Time cost: 10:19/1:29:26 [10:21/33:04:31]  Acc_iter 400         Data time: 0.01(0.01)  Forward time: 1.41(1.53)  Batch time: 1.41(1.55)
2025-09-03 09:27:22,098   INFO  Train:    1/20 (  5%) [ 449/3862 ( 12%)]  Loss: 9.214 (84.9)  LR: 1.005e-04  Grad: 13.6368  max=0.6137(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.4122(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=3.9147, loss_cls=0.3514, loss_bbox=5.3221, matched_ious=0.0305, loss_iou=0.0865, loss_iou_reg=0.4319, d_time=0.01(0.01), f_time=1.45(1.52), b_time=1.46(1.54)  Time cost: 11:31/1:27:24 [11:33/32:46:42]  Acc_iter 450         Data time: 0.01(0.01)  Forward time: 1.45(1.52)  Batch time: 1.46(1.54)
2025-09-03 09:28:33,129   INFO  Train:    1/20 (  5%) [ 499/3862 ( 13%)]  Loss: 10.01 (77.4)  LR: 1.006e-04  Grad: 14.7257  max=0.7256(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.4318(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=3.4901, loss_cls=0.3590, loss_bbox=5.1922, matched_ious=0.0374, loss_iou=0.0929, loss_iou_reg=0.4256, d_time=0.01(0.01), f_time=1.36(1.51), b_time=1.36(1.53)  Time cost: 12:42/1:25:28 [12:44/32:30:35]  Acc_iter 500         Data time: 0.01(0.01)  Forward time: 1.36(1.51)  Batch time: 1.36(1.53)
2025-09-03 09:29:42,658   INFO  Train:    1/20 (  5%) [ 549/3862 ( 14%)]  Loss: 9.055 (71.2)  LR: 1.007e-04  Grad: 18.2103  max=0.7261(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6954(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=3.1791, loss_cls=0.3553, loss_bbox=6.0245, matched_ious=0.0357, loss_iou=0.0989, loss_iou_reg=0.4207, d_time=0.00(0.01), f_time=1.31(1.50), b_time=1.32(1.51)  Time cost: 13:52/1:23:32 [13:53/32:13:41]  Acc_iter 550         Data time: 0.00(0.01)  Forward time: 1.31(1.50)  Batch time: 1.32(1.51)
2025-09-03 09:30:50,328   INFO  Train:    1/20 (  5%) [ 599/3862 ( 16%)]  Loss: 9.008 (66.1)  LR: 1.008e-04  Grad: 21.3844  max=0.8246(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9304(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=2.9170, loss_cls=0.3589, loss_bbox=5.5811, matched_ious=0.0383, loss_iou=0.0994, loss_iou_reg=0.4172, d_time=0.01(0.01), f_time=1.37(1.49), b_time=1.37(1.50)  Time cost: 14:59/1:21:33 [15:01/31:55:27]  Acc_iter 600         Data time: 0.01(0.01)  Forward time: 1.37(1.49)  Batch time: 1.37(1.50)
2025-09-03 09:32:01,303   INFO  Train:    1/20 (  5%) [ 649/3862 ( 17%)]  Loss: 9.053 (61.7)  LR: 1.010e-04  Grad: 23.0381  max=0.9370(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0046(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=2.7279, loss_cls=0.3550, loss_bbox=4.9582, matched_ious=0.0465, loss_iou=0.0959, loss_iou_reg=0.4100, d_time=0.00(0.02), f_time=1.28(1.48), b_time=1.28(1.49)  Time cost: 16:10/1:19:58 [16:12/31:46:20]  Acc_iter 650         Data time: 0.00(0.02)  Forward time: 1.28(1.48)  Batch time: 1.28(1.49)
2025-09-03 09:33:09,954   INFO  Train:    1/20 (  5%) [ 699/3862 ( 18%)]  Loss: 7.805 (57.8)  LR: 1.011e-04  Grad: 24.8332  max=1.2583(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2604(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=2.5426, loss_cls=0.3597, loss_bbox=4.5968, matched_ious=0.0600, loss_iou=0.0967, loss_iou_reg=0.4078, d_time=0.01(0.02), f_time=1.41(1.47), b_time=1.42(1.48)  Time cost: 17:19/1:18:16 [17:21/31:34:07]  Acc_iter 700         Data time: 0.01(0.02)  Forward time: 1.41(1.47)  Batch time: 1.42(1.48)
2025-09-03 09:34:19,401   INFO  Train:    1/20 (  5%) [ 749/3862 ( 19%)]  Loss: 6.816 (54.5)  LR: 1.013e-04  Grad: 26.4039  max=1.2505(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2372(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=2.4014, loss_cls=0.3576, loss_bbox=4.2046, matched_ious=0.0772, loss_iou=0.0988, loss_iou_reg=0.4014, d_time=0.00(0.01), f_time=1.27(1.46), b_time=1.28(1.48)  Time cost: 18:28/1:16:42 [18:30/31:24:45]  Acc_iter 750         Data time: 0.00(0.01)  Forward time: 1.27(1.46)  Batch time: 1.28(1.48)
2025-09-03 09:35:27,949   INFO  Train:    1/20 (  5%) [ 799/3862 ( 21%)]  Loss: 6.999 (51.5)  LR: 1.015e-04  Grad: 28.1331  max=1.2581(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2109(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=2.2552, loss_cls=0.3552, loss_bbox=3.7470, matched_ious=0.0951, loss_iou=0.0983, loss_iou_reg=0.3951, d_time=0.01(0.01), f_time=1.30(1.46), b_time=1.31(1.47)  Time cost: 19:37/1:15:07 [19:39/31:14:57]  Acc_iter 800         Data time: 0.01(0.01)  Forward time: 1.30(1.46)  Batch time: 1.31(1.47)
2025-09-03 09:36:37,141   INFO  Train:    1/20 (  5%) [ 849/3862 ( 22%)]  Loss: 6.770 (48.8)  LR: 1.017e-04  Grad: 29.0055  max=1.2510(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1953(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=2.1986, loss_cls=0.3545, loss_bbox=3.4214, matched_ious=0.1199, loss_iou=0.0998, loss_iou_reg=0.3846, d_time=0.01(0.01), f_time=1.36(1.45), b_time=1.37(1.47)  Time cost: 20:46/1:13:38 [20:48/31:07:09]  Acc_iter 850         Data time: 0.01(0.01)  Forward time: 1.36(1.45)  Batch time: 1.37(1.47)
2025-09-03 09:37:50,703   INFO  Train:    1/20 (  5%) [ 899/3862 ( 23%)]  Loss: 6.569 (46.5)  LR: 1.019e-04  Grad: 29.7785  max=1.2494(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1953(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=2.0721, loss_cls=0.3520, loss_bbox=3.1019, matched_ious=0.1357, loss_iou=0.0979, loss_iou_reg=0.3808, d_time=0.01(0.01), f_time=1.34(1.45), b_time=1.35(1.47)  Time cost: 22:00/1:12:26 [22:01/31:06:15]  Acc_iter 900         Data time: 0.01(0.01)  Forward time: 1.34(1.45)  Batch time: 1.35(1.47)
2025-09-03 09:39:02,347   INFO  Train:    1/20 (  5%) [ 949/3862 ( 25%)]  Loss: 4.976 (44.3)  LR: 1.021e-04  Grad: 30.5493  max=1.2473(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1951(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=2.0196, loss_cls=0.3512, loss_bbox=2.8922, matched_ious=0.1529, loss_iou=0.1020, loss_iou_reg=0.3703, d_time=0.01(0.01), f_time=1.39(1.45), b_time=1.39(1.47)  Time cost: 23:11/1:11:07 [23:13/31:02:46]  Acc_iter 950         Data time: 0.01(0.01)  Forward time: 1.39(1.45)  Batch time: 1.39(1.47)
2025-09-03 09:40:11,973   INFO  Train:    1/20 (  5%) [ 999/3862 ( 26%)]  Loss: 5.251 (42.4)  LR: 1.023e-04  Grad: 31.3253  max=1.2374(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2107(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.9051, loss_cls=0.3395, loss_bbox=2.6534, matched_ious=0.1686, loss_iou=0.1039, loss_iou_reg=0.3650, d_time=0.01(0.01), f_time=1.34(1.45), b_time=1.34(1.46)  Time cost: 24:21/1:09:43 [24:23/30:56:56]  Acc_iter 1000        Data time: 0.01(0.01)  Forward time: 1.34(1.45)  Batch time: 1.34(1.46)
2025-09-03 09:41:21,448   INFO  Train:    1/20 (  5%) [1049/3862 ( 27%)]  Loss: 4.571 (40.6)  LR: 1.026e-04  Grad: 31.8037  max=1.2538(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2143(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.8359, loss_cls=0.3307, loss_bbox=2.5214, matched_ious=0.1801, loss_iou=0.1035, loss_iou_reg=0.3610, d_time=0.01(0.01), f_time=1.35(1.45), b_time=1.37(1.46)  Time cost: 25:30/1:08:21 [25:32/30:51:22]  Acc_iter 1050        Data time: 0.01(0.01)  Forward time: 1.35(1.45)  Batch time: 1.37(1.46)
2025-09-03 09:42:31,461   INFO  Train:    1/20 (  5%) [1099/3862 ( 28%)]  Loss: 4.793 (39.0)  LR: 1.028e-04  Grad: 32.4892  max=1.2685(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2223(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.8004, loss_cls=0.3250, loss_bbox=2.3424, matched_ious=0.1899, loss_iou=0.1036, loss_iou_reg=0.3571, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.38(1.46)  Time cost: 26:40/1:07:01 [26:42/30:46:50]  Acc_iter 1100        Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.38(1.46)
2025-09-03 09:43:45,679   INFO  Train:    1/20 (  5%) [1149/3862 ( 30%)]  Loss: 4.451 (37.5)  LR: 1.031e-04  Grad: 32.8084  max=1.2669(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2208(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.7697, loss_cls=0.3223, loss_bbox=2.3621, matched_ious=0.1966, loss_iou=0.1035, loss_iou_reg=0.3532, d_time=0.00(0.01), f_time=1.36(1.44), b_time=1.36(1.46)  Time cost: 27:55/1:05:51 [27:56/30:47:13]  Acc_iter 1150        Data time: 0.00(0.01)  Forward time: 1.36(1.44)  Batch time: 1.36(1.46)
2025-09-03 09:44:56,922   INFO  Train:    1/20 (  5%) [1199/3862 ( 31%)]  Loss: 4.564 (36.1)  LR: 1.033e-04  Grad: 33.3840  max=1.2698(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.2371(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.6883, loss_cls=0.3127, loss_bbox=2.1686, matched_ious=0.2101, loss_iou=0.1041, loss_iou_reg=0.3466, d_time=0.00(0.01), f_time=1.31(1.44), b_time=1.31(1.46)  Time cost: 29:06/1:04:35 [29:08/30:44:20]  Acc_iter 1200        Data time: 0.00(0.01)  Forward time: 1.31(1.44)  Batch time: 1.31(1.46)
2025-09-03 09:46:06,810   INFO  Train:    1/20 (  5%) [1249/3862 ( 32%)]  Loss: 5.585 (34.9)  LR: 1.036e-04  Grad: 33.6964  max=1.2785(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2302(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.7085, loss_cls=0.3124, loss_bbox=2.1755, matched_ious=0.2150, loss_iou=0.1045, loss_iou_reg=0.3445, d_time=0.00(0.01), f_time=1.49(1.44), b_time=1.50(1.45)  Time cost: 30:16/1:03:16 [30:17/30:40:12]  Acc_iter 1250        Data time: 0.00(0.01)  Forward time: 1.49(1.44)  Batch time: 1.50(1.45)
2025-09-03 09:47:16,529   INFO  Train:    1/20 (  5%) [1299/3862 ( 34%)]  Loss: 4.540 (33.7)  LR: 1.039e-04  Grad: 34.1319  max=1.2863(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2293(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.6039, loss_cls=0.2986, loss_bbox=2.0642, matched_ious=0.2207, loss_iou=0.1049, loss_iou_reg=0.3426, d_time=0.01(0.01), f_time=1.29(1.44), b_time=1.30(1.45)  Time cost: 31:25/1:01:58 [31:27/30:36:08]  Acc_iter 1300        Data time: 0.01(0.01)  Forward time: 1.29(1.44)  Batch time: 1.30(1.45)
2025-09-03 09:48:27,057   INFO  Train:    1/20 (  5%) [1349/3862 ( 35%)]  Loss: 4.340 (32.6)  LR: 1.042e-04  Grad: 34.4889  max=1.2845(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2321(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.6030, loss_cls=0.3017, loss_bbox=1.9447, matched_ious=0.2317, loss_iou=0.1056, loss_iou_reg=0.3350, d_time=0.00(0.01), f_time=1.35(1.44), b_time=1.35(1.45)  Time cost: 32:36/1:00:41 [32:38/30:33:03]  Acc_iter 1350        Data time: 0.00(0.01)  Forward time: 1.35(1.44)  Batch time: 1.35(1.45)
2025-09-03 09:49:41,859   INFO  Train:    1/20 (  5%) [1399/3862 ( 36%)]  Loss: 4.183 (31.6)  LR: 1.045e-04  Grad: 34.8593  max=1.2857(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2377(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.5841, loss_cls=0.2960, loss_bbox=1.9644, matched_ious=0.2343, loss_iou=0.1062, loss_iou_reg=0.3350, d_time=0.01(0.01), f_time=1.39(1.44), b_time=1.40(1.45)  Time cost: 33:51/59:33 [33:52/30:33:57]  Acc_iter 1400        Data time: 0.01(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.45)
2025-09-03 09:50:51,240   INFO  Train:    1/20 (  5%) [1449/3862 ( 38%)]  Loss: 4.217 (30.7)  LR: 1.049e-04  Grad: 34.9583  max=1.2771(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2371(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.5629, loss_cls=0.2958, loss_bbox=1.9252, matched_ious=0.2440, loss_iou=0.1078, loss_iou_reg=0.3307, d_time=0.01(0.01), f_time=1.39(1.44), b_time=1.39(1.45)  Time cost: 35:00/58:15 [35:02/30:29:59]  Acc_iter 1450        Data time: 0.01(0.01)  Forward time: 1.39(1.44)  Batch time: 1.39(1.45)
2025-09-03 09:52:01,557   INFO  Train:    1/20 (  5%) [1499/3862 ( 39%)]  Loss: 3.868 (29.8)  LR: 1.052e-04  Grad: 34.9650  max=1.2575(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2238(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.5250, loss_cls=0.2907, loss_bbox=1.9361, matched_ious=0.2401, loss_iou=0.1064, loss_iou_reg=0.3300, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 36:10/56:59 [36:12/30:27:00]  Acc_iter 1500        Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-03 09:53:11,181   INFO  Train:    1/20 (  5%) [1549/3862 ( 40%)]  Loss: 4.165 (28.9)  LR: 1.056e-04  Grad: 34.9571  max=1.2390(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2148(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.4805, loss_cls=0.2823, loss_bbox=1.8593, matched_ious=0.2494, loss_iou=0.1085, loss_iou_reg=0.3247, d_time=0.01(0.01), f_time=1.30(1.43), b_time=1.30(1.45)  Time cost: 37:20/55:43 [37:22/30:23:34]  Acc_iter 1550        Data time: 0.01(0.01)  Forward time: 1.30(1.43)  Batch time: 1.30(1.45)
2025-09-03 09:54:21,755   INFO  Train:    1/20 (  5%) [1599/3862 ( 41%)]  Loss: 3.749 (28.2)  LR: 1.059e-04  Grad: 34.9892  max=1.2218(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2115(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.5031, loss_cls=0.2819, loss_bbox=1.9294, matched_ious=0.2465, loss_iou=0.1090, loss_iou_reg=0.3246, d_time=0.01(0.01), f_time=1.34(1.43), b_time=1.34(1.44)  Time cost: 38:31/54:28 [38:32/30:21:01]  Acc_iter 1600        Data time: 0.01(0.01)  Forward time: 1.34(1.43)  Batch time: 1.34(1.44)
2025-09-03 09:55:37,406   INFO  Train:    1/20 (  5%) [1649/3862 ( 43%)]  Loss: 3.195 (27.4)  LR: 1.063e-04  Grad: 34.9140  max=1.2162(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2081(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.4652, loss_cls=0.2808, loss_bbox=1.8533, matched_ious=0.2533, loss_iou=0.1067, loss_iou_reg=0.3242, d_time=0.01(0.01), f_time=1.31(1.44), b_time=1.31(1.45)  Time cost: 39:46/53:21 [39:48/30:22:26]  Acc_iter 1650        Data time: 0.01(0.01)  Forward time: 1.31(1.44)  Batch time: 1.31(1.45)
2025-09-03 09:56:47,334   INFO  Train:    1/20 (  5%) [1699/3862 ( 44%)]  Loss: 4.094 (26.7)  LR: 1.067e-04  Grad: 34.9776  max=1.2160(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2334(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.4594, loss_cls=0.2817, loss_bbox=1.7963, matched_ious=0.2622, loss_iou=0.1094, loss_iou_reg=0.3190, d_time=0.00(0.01), f_time=1.40(1.43), b_time=1.41(1.45)  Time cost: 40:56/52:05 [40:58/30:19:27]  Acc_iter 1700        Data time: 0.00(0.01)  Forward time: 1.40(1.43)  Batch time: 1.41(1.45)
2025-09-03 09:57:57,531   INFO  Train:    1/20 (  5%) [1749/3862 ( 45%)]  Loss: 4.590 (26.1)  LR: 1.071e-04  Grad: 35.0000  max=1.2200(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2608(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.4180, loss_cls=0.2715, loss_bbox=1.8109, matched_ious=0.2575, loss_iou=0.1077, loss_iou_reg=0.3195, d_time=0.01(0.01), f_time=1.33(1.43), b_time=1.33(1.44)  Time cost: 42:06/50:51 [42:08/30:16:46]  Acc_iter 1750        Data time: 0.01(0.01)  Forward time: 1.33(1.43)  Batch time: 1.33(1.44)
2025-09-03 09:59:07,700   INFO  Train:    1/20 (  5%) [1799/3862 ( 47%)]  Loss: 3.082 (25.5)  LR: 1.075e-04  Grad: 34.9575  max=1.2245(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2905(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.4034, loss_cls=0.2701, loss_bbox=1.7588, matched_ious=0.2663, loss_iou=0.1073, loss_iou_reg=0.3145, d_time=0.01(0.01), f_time=1.43(1.43), b_time=1.44(1.44)  Time cost: 43:17/49:36 [43:18/30:14:09]  Acc_iter 1800        Data time: 0.01(0.01)  Forward time: 1.43(1.43)  Batch time: 1.44(1.44)
2025-09-03 10:00:19,204   INFO  Train:    1/20 (  5%) [1849/3862 ( 48%)]  Loss: 3.661 (24.9)  LR: 1.079e-04  Grad: 34.9607  max=1.3930(module.vfe.pfn_layers.0.linear.weight)  min: -1.2983(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.3819, loss_cls=0.2707, loss_bbox=1.7288, matched_ious=0.2710, loss_iou=0.1094, loss_iou_reg=0.3135, d_time=0.01(0.01), f_time=1.38(1.43), b_time=1.39(1.44)  Time cost: 44:28/48:23 [44:30/30:12:30]  Acc_iter 1850        Data time: 0.01(0.01)  Forward time: 1.38(1.43)  Batch time: 1.39(1.44)
2025-09-03 10:01:35,182   INFO  Train:    1/20 (  5%) [1899/3862 ( 49%)]  Loss: 3.642 (24.3)  LR: 1.084e-04  Grad: 34.9594  max=1.2631(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3342(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.3666, loss_cls=0.2674, loss_bbox=1.6504, matched_ious=0.2762, loss_iou=0.1090, loss_iou_reg=0.3092, d_time=0.01(0.01), f_time=1.28(1.43), b_time=1.28(1.44)  Time cost: 45:44/47:15 [45:46/30:13:51]  Acc_iter 1900        Data time: 0.01(0.01)  Forward time: 1.28(1.43)  Batch time: 1.28(1.44)
2025-09-03 10:02:46,094   INFO  Train:    1/20 (  5%) [1949/3862 ( 50%)]  Loss: 3.927 (23.8)  LR: 1.088e-04  Grad: 34.8930  max=1.2621(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3440(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.3963, loss_cls=0.2752, loss_bbox=1.6732, matched_ious=0.2757, loss_iou=0.1092, loss_iou_reg=0.3108, d_time=0.00(0.01), f_time=1.53(1.43), b_time=1.53(1.44)  Time cost: 46:55/46:02 [46:57/30:11:48]  Acc_iter 1950        Data time: 0.00(0.01)  Forward time: 1.53(1.43)  Batch time: 1.53(1.44)
2025-09-03 10:03:55,633   INFO  Train:    1/20 (  5%) [1999/3862 ( 52%)]  Loss: 3.527 (23.3)  LR: 1.093e-04  Grad: 34.9262  max=1.2645(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3698(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.3240, loss_cls=0.2604, loss_bbox=1.6743, matched_ious=0.2757, loss_iou=0.1083, loss_iou_reg=0.3081, d_time=0.01(0.01), f_time=1.33(1.43), b_time=1.33(1.44)  Time cost: 48:05/44:47 [48:06/30:08:56]  Acc_iter 2000        Data time: 0.01(0.01)  Forward time: 1.33(1.43)  Batch time: 1.33(1.44)
2025-09-03 10:05:05,748   INFO  Train:    1/20 (  5%) [2049/3862 ( 53%)]  Loss: 3.949 (22.8)  LR: 1.097e-04  Grad: 34.9347  max=1.2855(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3871(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.3488, loss_cls=0.2654, loss_bbox=1.6366, matched_ious=0.2774, loss_iou=0.1094, loss_iou_reg=0.3090, d_time=0.02(0.01), f_time=1.33(1.43), b_time=1.35(1.44)  Time cost: 49:15/43:33 [49:16/30:06:30]  Acc_iter 2050        Data time: 0.02(0.01)  Forward time: 1.33(1.43)  Batch time: 1.35(1.44)
2025-09-03 10:06:16,959   INFO  Train:    1/20 (  5%) [2099/3862 ( 54%)]  Loss: 3.320 (22.4)  LR: 1.102e-04  Grad: 34.9645  max=1.2978(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.4044(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.3305, loss_cls=0.2628, loss_bbox=1.6489, matched_ious=0.2834, loss_iou=0.1094, loss_iou_reg=0.3046, d_time=0.01(0.01), f_time=1.36(1.43), b_time=1.37(1.44)  Time cost: 50:26/42:20 [50:28/30:04:47]  Acc_iter 2100        Data time: 0.01(0.01)  Forward time: 1.36(1.43)  Batch time: 1.37(1.44)
2025-09-03 10:07:32,214   INFO  Train:    1/20 (  5%) [2149/3862 ( 56%)]  Loss: 3.979 (21.9)  LR: 1.107e-04  Grad: 34.9327  max=1.3074(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.4262(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.3204, loss_cls=0.2616, loss_bbox=1.6310, matched_ious=0.2850, loss_iou=0.1096, loss_iou_reg=0.3039, d_time=0.00(0.01), f_time=1.38(1.43), b_time=1.39(1.44)  Time cost: 51:41/41:11 [51:43/30:05:27]  Acc_iter 2150        Data time: 0.00(0.01)  Forward time: 1.38(1.43)  Batch time: 1.39(1.44)
2025-09-03 10:08:42,189   INFO  Train:    1/20 (  5%) [2199/3862 ( 57%)]  Loss: 3.702 (21.5)  LR: 1.112e-04  Grad: 34.8532  max=1.3017(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.4332(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.2982, loss_cls=0.2515, loss_bbox=1.6313, matched_ious=0.2821, loss_iou=0.1084, loss_iou_reg=0.3055, d_time=0.01(0.01), f_time=1.42(1.43), b_time=1.43(1.44)  Time cost: 52:51/39:57 [52:53/30:03:01]  Acc_iter 2200        Data time: 0.01(0.01)  Forward time: 1.42(1.43)  Batch time: 1.43(1.44)
2025-09-03 10:09:52,556   INFO  Train:    1/20 (  5%) [2249/3862 ( 58%)]  Loss: 2.873 (21.1)  LR: 1.117e-04  Grad: 34.8565  max=1.3164(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.4467(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.2892, loss_cls=0.2544, loss_bbox=1.5719, matched_ious=0.2867, loss_iou=0.1108, loss_iou_reg=0.3020, d_time=0.01(0.01), f_time=1.38(1.43), b_time=1.39(1.44)  Time cost: 54:01/38:44 [54:03/30:00:52]  Acc_iter 2250        Data time: 0.01(0.01)  Forward time: 1.38(1.43)  Batch time: 1.39(1.44)
2025-09-03 10:11:03,957   INFO  Train:    1/20 (  5%) [2299/3862 ( 60%)]  Loss: 3.200 (20.7)  LR: 1.122e-04  Grad: 34.8803  max=1.3194(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.7875(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.3096, loss_cls=0.2634, loss_bbox=1.5222, matched_ious=0.2932, loss_iou=0.1098, loss_iou_reg=0.2999, d_time=0.01(0.01), f_time=1.40(1.43), b_time=1.41(1.44)  Time cost: 55:13/37:31 [55:15/29:59:19]  Acc_iter 2300        Data time: 0.01(0.01)  Forward time: 1.40(1.43)  Batch time: 1.41(1.44)
2025-09-03 10:12:14,892   INFO  Train:    1/20 (  5%) [2349/3862 ( 61%)]  Loss: 3.363 (20.4)  LR: 1.128e-04  Grad: 34.8695  max=1.3121(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.4496(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.2664, loss_cls=0.2516, loss_bbox=1.5471, matched_ious=0.2916, loss_iou=0.1096, loss_iou_reg=0.3006, d_time=0.01(0.01), f_time=1.33(1.43), b_time=1.34(1.44)  Time cost: 56:24/36:18 [56:26/29:57:32]  Acc_iter 2350        Data time: 0.01(0.01)  Forward time: 1.33(1.43)  Batch time: 1.34(1.44)
2025-09-03 10:13:30,253   INFO  Train:    1/20 (  5%) [2399/3862 ( 62%)]  Loss: 3.431 (20.0)  LR: 1.133e-04  Grad: 34.9161  max=1.3114(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.4872(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.2227, loss_cls=0.2421, loss_bbox=1.5398, matched_ious=0.2913, loss_iou=0.1100, loss_iou_reg=0.2996, d_time=0.01(0.01), f_time=1.48(1.43), b_time=1.49(1.44)  Time cost: 57:39/35:08 [57:41/29:58:05]  Acc_iter 2400        Data time: 0.01(0.01)  Forward time: 1.48(1.43)  Batch time: 1.49(1.44)
2025-09-03 10:14:41,064   INFO  Train:    1/20 (  5%) [2449/3862 ( 63%)]  Loss: 3.382 (19.7)  LR: 1.139e-04  Grad: 34.7763  max=1.3204(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.4746(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.2298, loss_cls=0.2421, loss_bbox=1.5695, matched_ious=0.2894, loss_iou=0.1102, loss_iou_reg=0.2983, d_time=0.01(0.01), f_time=1.34(1.43), b_time=1.35(1.44)  Time cost: 58:50/33:56 [58:52/29:56:14]  Acc_iter 2450        Data time: 0.01(0.01)  Forward time: 1.34(1.43)  Batch time: 1.35(1.44)
2025-09-03 10:15:50,853   INFO  Train:    1/20 (  5%) [2499/3862 ( 65%)]  Loss: 3.857 (19.3)  LR: 1.145e-04  Grad: 34.7888  max=1.3292(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.4877(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.2363, loss_cls=0.2461, loss_bbox=1.4971, matched_ious=0.2958, loss_iou=0.1083, loss_iou_reg=0.2994, d_time=0.01(0.01), f_time=1.39(1.43), b_time=1.40(1.44)  Time cost: 1:00:00/32:42 [1:00:01/29:53:54]  Acc_iter 2500        Data time: 0.01(0.01)  Forward time: 1.39(1.43)  Batch time: 1.40(1.44)
2025-09-03 10:17:01,907   INFO  Train:    1/20 (  5%) [2549/3862 ( 66%)]  Loss: 3.901 (19.0)  LR: 1.150e-04  Grad: 34.8734  max=2.2647(module.vfe.pfn_layers.0.linear.weight)  min: -1.4958(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.1909, loss_cls=0.2379, loss_bbox=1.5157, matched_ious=0.2977, loss_iou=0.1107, loss_iou_reg=0.2969, d_time=0.01(0.01), f_time=1.32(1.43), b_time=1.32(1.44)  Time cost: 1:01:11/31:30 [1:01:13/29:52:14]  Acc_iter 2550        Data time: 0.01(0.01)  Forward time: 1.32(1.43)  Batch time: 1.32(1.44)
2025-09-03 10:18:12,389   INFO  Train:    1/20 (  5%) [2599/3862 ( 67%)]  Loss: 3.170 (18.7)  LR: 1.156e-04  Grad: 34.7020  max=1.3630(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.9027(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.2324, loss_cls=0.2448, loss_bbox=1.5326, matched_ious=0.2976, loss_iou=0.1110, loss_iou_reg=0.2947, d_time=0.01(0.01), f_time=1.44(1.43), b_time=1.45(1.44)  Time cost: 1:02:21/30:17 [1:02:23/29:50:19]  Acc_iter 2600        Data time: 0.01(0.01)  Forward time: 1.44(1.43)  Batch time: 1.45(1.44)
2025-09-03 10:19:27,905   INFO  Train:    1/20 (  5%) [2649/3862 ( 69%)]  Loss: 2.969 (18.4)  LR: 1.162e-04  Grad: 34.7527  max=2.4240(module.vfe.pfn_layers.0.linear.weight)  min: -2.8409(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.1988, loss_cls=0.2417, loss_bbox=1.5049, matched_ious=0.3023, loss_iou=0.1110, loss_iou_reg=0.2924, d_time=0.00(0.01), f_time=1.33(1.43), b_time=1.34(1.44)  Time cost: 1:03:37/29:07 [1:03:39/29:50:47]  Acc_iter 2650        Data time: 0.00(0.01)  Forward time: 1.33(1.43)  Batch time: 1.34(1.44)
2025-09-03 10:20:37,993   INFO  Train:    1/20 (  5%) [2699/3862 ( 70%)]  Loss: 3.145 (18.2)  LR: 1.168e-04  Grad: 34.6067  max=1.3180(module.dense_head.decoder.self_attn.in_proj_weight)  min: -4.0084(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.1716, loss_cls=0.2361, loss_bbox=1.4897, matched_ious=0.3014, loss_iou=0.1116, loss_iou_reg=0.2942, d_time=0.00(0.01), f_time=1.36(1.43), b_time=1.36(1.44)  Time cost: 1:04:47/27:54 [1:04:49/29:48:42]  Acc_iter 2700        Data time: 0.00(0.01)  Forward time: 1.36(1.43)  Batch time: 1.36(1.44)
2025-09-03 10:21:48,684   INFO  Train:    1/20 (  5%) [2749/3862 ( 71%)]  Loss: 3.292 (17.9)  LR: 1.175e-04  Grad: 34.6054  max=1.7594(module.vfe.pfn_layers.0.linear.weight)  min: -1.9717(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.2073, loss_cls=0.2398, loss_bbox=1.5151, matched_ious=0.2978, loss_iou=0.1105, loss_iou_reg=0.2970, d_time=0.00(0.01), f_time=1.30(1.43), b_time=1.31(1.44)  Time cost: 1:05:58/26:41 [1:05:59/29:46:55]  Acc_iter 2750        Data time: 0.00(0.01)  Forward time: 1.30(1.43)  Batch time: 1.31(1.44)
2025-09-03 10:22:59,740   INFO  Train:    1/20 (  5%) [2799/3862 ( 72%)]  Loss: 3.516 (17.6)  LR: 1.181e-04  Grad: 34.5738  max=1.3250(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.9834(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.1662, loss_cls=0.2427, loss_bbox=1.4624, matched_ious=0.3099, loss_iou=0.1113, loss_iou_reg=0.2918, d_time=0.00(0.01), f_time=1.31(1.43), b_time=1.31(1.44)  Time cost: 1:07:09/25:29 [1:07:10/29:45:18]  Acc_iter 2800        Data time: 0.00(0.01)  Forward time: 1.31(1.43)  Batch time: 1.31(1.44)
2025-09-03 10:24:10,858   INFO  Train:    1/20 (  5%) [2849/3862 ( 74%)]  Loss: 3.488 (17.4)  LR: 1.188e-04  Grad: 34.2919  max=2.6991(module.vfe.pfn_layers.0.linear.weight)  min: -3.0400(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.1673, loss_cls=0.2372, loss_bbox=1.4497, matched_ious=0.3083, loss_iou=0.1106, loss_iou_reg=0.2901, d_time=0.00(0.01), f_time=2.29(1.43), b_time=2.29(1.44)  Time cost: 1:08:20/24:17 [1:08:21/29:43:45]  Acc_iter 2850        Data time: 0.00(0.01)  Forward time: 2.29(1.43)  Batch time: 2.29(1.44)
2025-09-03 10:25:25,154   INFO  Train:    1/20 (  5%) [2899/3862 ( 75%)]  Loss: 3.577 (17.1)  LR: 1.194e-04  Grad: 34.2586  max=1.3394(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.9460(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.1356, loss_cls=0.2259, loss_bbox=1.4597, matched_ious=0.3078, loss_iou=0.1113, loss_iou_reg=0.2889, d_time=0.01(0.01), f_time=1.34(1.43), b_time=1.35(1.44)  Time cost: 1:09:34/23:06 [1:09:36/29:43:34]  Acc_iter 2900        Data time: 0.01(0.01)  Forward time: 1.34(1.43)  Batch time: 1.35(1.44)
2025-09-03 10:26:35,592   INFO  Train:    1/20 (  5%) [2949/3862 ( 76%)]  Loss: 3.253 (16.9)  LR: 1.201e-04  Grad: 34.4075  max=1.4048(module.vfe.pfn_layers.0.linear.weight)  min: -1.5266(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.1158, loss_cls=0.2289, loss_bbox=1.3997, matched_ious=0.3100, loss_iou=0.1109, loss_iou_reg=0.2915, d_time=0.01(0.01), f_time=1.34(1.43), b_time=1.34(1.44)  Time cost: 1:10:44/21:53 [1:10:46/29:41:43]  Acc_iter 2950        Data time: 0.01(0.01)  Forward time: 1.34(1.43)  Batch time: 1.34(1.44)
2025-09-03 10:27:46,266   INFO  Train:    1/20 (  5%) [2999/3862 ( 78%)]  Loss: 3.297 (16.7)  LR: 1.208e-04  Grad: 33.1329  max=1.3097(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.6355(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.1805, loss_cls=0.2405, loss_bbox=1.4483, matched_ious=0.3150, loss_iou=0.1102, loss_iou_reg=0.2859, d_time=0.00(0.01), f_time=1.31(1.43), b_time=1.31(1.44)  Time cost: 1:11:55/20:41 [1:11:57/29:39:59]  Acc_iter 3000        Data time: 0.00(0.01)  Forward time: 1.31(1.43)  Batch time: 1.31(1.44)
2025-09-03 10:28:56,537   INFO  Train:    1/20 (  5%) [3049/3862 ( 79%)]  Loss: 3.218 (16.5)  LR: 1.215e-04  Grad: 33.7775  max=5.6173(module.vfe.pfn_layers.0.linear.weight)  min: -1.8054(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.1360, loss_cls=0.2285, loss_bbox=1.4213, matched_ious=0.3137, loss_iou=0.1098, loss_iou_reg=0.2873, d_time=0.00(0.01), f_time=1.36(1.43), b_time=1.36(1.44)  Time cost: 1:13:05/19:29 [1:13:07/29:38:07]  Acc_iter 3050        Data time: 0.00(0.01)  Forward time: 1.36(1.43)  Batch time: 1.36(1.44)
2025-09-03 10:30:08,122   INFO  Train:    1/20 (  5%) [3099/3862 ( 80%)]  Loss: 3.427 (16.2)  LR: 1.222e-04  Grad: 33.5246  max=2.3514(module.vfe.pfn_layers.0.linear.weight)  min: -3.1238(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.1258, loss_cls=0.2251, loss_bbox=1.4120, matched_ious=0.3184, loss_iou=0.1116, loss_iou_reg=0.2856, d_time=0.01(0.01), f_time=1.40(1.43), b_time=1.41(1.44)  Time cost: 1:14:17/18:17 [1:14:19/29:36:48]  Acc_iter 3100        Data time: 0.01(0.01)  Forward time: 1.40(1.43)  Batch time: 1.41(1.44)
2025-09-03 10:31:21,943   INFO  Train:    1/20 (  5%) [3149/3862 ( 82%)]  Loss: 2.918 (16.0)  LR: 1.229e-04  Grad: 33.1189  max=1.3573(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.4968(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.1229, loss_cls=0.2249, loss_bbox=1.4255, matched_ious=0.3136, loss_iou=0.1110, loss_iou_reg=0.2872, d_time=0.00(0.01), f_time=1.36(1.43), b_time=1.37(1.44)  Time cost: 1:15:31/17:05 [1:15:33/29:36:21]  Acc_iter 3150        Data time: 0.00(0.01)  Forward time: 1.36(1.43)  Batch time: 1.37(1.44)
2025-09-03 10:32:32,380   INFO  Train:    1/20 (  5%) [3199/3862 ( 83%)]  Loss: 3.271 (15.8)  LR: 1.236e-04  Grad: 33.4336  max=1.3951(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.6054(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.1145, loss_cls=0.2215, loss_bbox=1.4180, matched_ious=0.3151, loss_iou=0.1112, loss_iou_reg=0.2870, d_time=0.01(0.01), f_time=1.39(1.43), b_time=1.40(1.44)  Time cost: 1:16:41/15:53 [1:16:43/29:34:35]  Acc_iter 3200        Data time: 0.01(0.01)  Forward time: 1.39(1.43)  Batch time: 1.40(1.44)
2025-09-03 10:33:43,942   INFO  Train:    1/20 (  5%) [3249/3862 ( 84%)]  Loss: 3.249 (15.6)  LR: 1.243e-04  Grad: 33.5934  max=1.4088(module.vfe.pfn_layers.0.linear.weight)  min: -2.8169(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.1419, loss_cls=0.2261, loss_bbox=1.4234, matched_ious=0.3191, loss_iou=0.1121, loss_iou_reg=0.2833, d_time=0.00(0.01), f_time=1.38(1.43), b_time=1.39(1.44)  Time cost: 1:17:53/14:41 [1:17:55/29:33:15]  Acc_iter 3250        Data time: 0.00(0.01)  Forward time: 1.38(1.43)  Batch time: 1.39(1.44)
2025-09-03 10:34:54,096   INFO  Train:    1/20 (  5%) [3299/3862 ( 85%)]  Loss: 3.442 (15.4)  LR: 1.251e-04  Grad: 34.0055  max=3.3910(module.vfe.pfn_layers.0.linear.weight)  min: -3.4480(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.0863, loss_cls=0.2172, loss_bbox=1.3964, matched_ious=0.3225, loss_iou=0.1100, loss_iou_reg=0.2862, d_time=0.00(0.01), f_time=1.35(1.43), b_time=1.35(1.44)  Time cost: 1:19:03/13:29 [1:19:05/29:31:24]  Acc_iter 3300        Data time: 0.00(0.01)  Forward time: 1.35(1.43)  Batch time: 1.35(1.44)
2025-09-03 10:36:07,178   INFO  Train:    1/20 (  5%) [3349/3862 ( 87%)]  Loss: 3.255 (15.3)  LR: 1.258e-04  Grad: 34.6573  max=3.1854(module.vfe.pfn_layers.0.linear.weight)  min: -7.1282(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.1283, loss_cls=0.2204, loss_bbox=1.4407, matched_ious=0.3086, loss_iou=0.1112, loss_iou_reg=0.2886, d_time=0.01(0.01), f_time=1.44(1.43), b_time=1.45(1.44)  Time cost: 1:20:16/12:17 [1:20:18/29:30:39]  Acc_iter 3350        Data time: 0.01(0.01)  Forward time: 1.44(1.43)  Batch time: 1.45(1.44)
2025-09-03 10:37:21,003   INFO  Train:    1/20 (  5%) [3399/3862 ( 88%)]  Loss: 2.677 (15.1)  LR: 1.266e-04  Grad: 33.9948  max=1.5290(module.vfe.pfn_layers.0.linear.weight)  min: -3.5270(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.0894, loss_cls=0.2166, loss_bbox=1.3839, matched_ious=0.3227, loss_iou=0.1102, loss_iou_reg=0.2848, d_time=0.01(0.01), f_time=1.34(1.43), b_time=1.35(1.44)  Time cost: 1:21:30/11:05 [1:21:32/29:30:09]  Acc_iter 3400        Data time: 0.01(0.01)  Forward time: 1.34(1.43)  Batch time: 1.35(1.44)
2025-09-03 10:38:31,401   INFO  Train:    1/20 (  5%) [3449/3862 ( 89%)]  Loss: 3.195 (14.9)  LR: 1.274e-04  Grad: 34.0771  max=1.9703(module.vfe.pfn_layers.0.linear.weight)  min: -3.1872(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.1251, loss_cls=0.2220, loss_bbox=1.4172, matched_ious=0.3227, loss_iou=0.1110, loss_iou_reg=0.2832, d_time=0.01(0.01), f_time=1.45(1.43), b_time=1.45(1.44)  Time cost: 1:22:40/09:53 [1:22:42/29:28:25]  Acc_iter 3450        Data time: 0.01(0.01)  Forward time: 1.45(1.43)  Batch time: 1.45(1.44)
2025-09-03 10:39:43,096   INFO  Train:    1/20 (  5%) [3499/3862 ( 91%)]  Loss: 3.124 (14.7)  LR: 1.282e-04  Grad: 34.3571  max=4.2696(module.vfe.pfn_layers.0.linear.weight)  min: -4.5026(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.1070, loss_cls=0.2209, loss_bbox=1.3816, matched_ious=0.3241, loss_iou=0.1112, loss_iou_reg=0.2843, d_time=0.01(0.01), f_time=1.39(1.43), b_time=1.40(1.44)  Time cost: 1:23:52/08:41 [1:23:54/29:27:09]  Acc_iter 3500        Data time: 0.01(0.01)  Forward time: 1.39(1.43)  Batch time: 1.40(1.44)
2025-09-03 10:40:53,688   INFO  Train:    1/20 (  5%) [3549/3862 ( 92%)]  Loss: 2.808 (14.6)  LR: 1.290e-04  Grad: 33.7038  max=1.4710(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.5200(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.0969, loss_cls=0.2134, loss_bbox=1.4060, matched_ious=0.3264, loss_iou=0.1130, loss_iou_reg=0.2813, d_time=0.01(0.01), f_time=1.39(1.43), b_time=1.39(1.44)  Time cost: 1:25:03/07:29 [1:25:04/29:25:30]  Acc_iter 3550        Data time: 0.01(0.01)  Forward time: 1.39(1.43)  Batch time: 1.39(1.44)
2025-09-03 10:42:08,273   INFO  Train:    1/20 (  5%) [3599/3862 ( 93%)]  Loss: 3.502 (14.4)  LR: 1.298e-04  Grad: 32.5739  max=1.4404(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.1538(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.0814, loss_cls=0.2119, loss_bbox=1.3759, matched_ious=0.3254, loss_iou=0.1097, loss_iou_reg=0.2842, d_time=0.01(0.01), f_time=1.48(1.43), b_time=1.49(1.44)  Time cost: 1:26:17/06:18 [1:26:19/29:25:13]  Acc_iter 3600        Data time: 0.01(0.01)  Forward time: 1.48(1.43)  Batch time: 1.49(1.44)
2025-09-03 10:43:20,685   INFO  Train:    1/20 (  5%) [3649/3862 ( 94%)]  Loss: 2.785 (14.3)  LR: 1.306e-04  Grad: 32.8190  max=2.7413(module.vfe.pfn_layers.0.linear.weight)  min: -1.7684(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.0678, loss_cls=0.2098, loss_bbox=1.3445, matched_ious=0.3278, loss_iou=0.1116, loss_iou_reg=0.2824, d_time=0.01(0.01), f_time=1.48(1.43), b_time=1.48(1.44)  Time cost: 1:27:30/05:06 [1:27:31/29:24:11]  Acc_iter 3650        Data time: 0.01(0.01)  Forward time: 1.48(1.43)  Batch time: 1.48(1.44)
2025-09-03 10:44:31,056   INFO  Train:    1/20 (  5%) [3699/3862 ( 96%)]  Loss: 3.283 (14.1)  LR: 1.315e-04  Grad: 33.1339  max=1.4765(module.dense_head.decoder.self_attn.in_proj_weight)  min: -4.8018(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.0826, loss_cls=0.2128, loss_bbox=1.3794, matched_ious=0.3297, loss_iou=0.1108, loss_iou_reg=0.2811, d_time=0.01(0.01), f_time=1.35(1.43), b_time=1.36(1.44)  Time cost: 1:28:40/03:54 [1:28:42/29:22:29]  Acc_iter 3700        Data time: 0.01(0.01)  Forward time: 1.35(1.43)  Batch time: 1.36(1.44)
2025-09-03 10:45:42,513   INFO  Train:    1/20 (  5%) [3749/3862 ( 97%)]  Loss: 2.944 (14.0)  LR: 1.323e-04  Grad: 33.0031  max=1.8900(module.vfe.pfn_layers.0.linear.weight)  min: -1.7482(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.0629, loss_cls=0.2055, loss_bbox=1.3397, matched_ious=0.3238, loss_iou=0.1095, loss_iou_reg=0.2823, d_time=0.01(0.01), f_time=1.35(1.43), b_time=1.36(1.44)  Time cost: 1:29:51/02:42 [1:29:53/29:21:08]  Acc_iter 3750        Data time: 0.01(0.01)  Forward time: 1.35(1.43)  Batch time: 1.36(1.44)
2025-09-03 10:46:52,899   INFO  Train:    1/20 (  5%) [3799/3862 ( 98%)]  Loss: 2.698 (13.8)  LR: 1.332e-04  Grad: 33.1912  max=2.1738(module.vfe.pfn_layers.0.linear.weight)  min: -2.2532(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.0723, loss_cls=0.2081, loss_bbox=1.3663, matched_ious=0.3320, loss_iou=0.1113, loss_iou_reg=0.2783, d_time=0.01(0.01), f_time=1.43(1.43), b_time=1.44(1.44)  Time cost: 1:31:02/01:30 [1:31:04/29:19:27]  Acc_iter 3800        Data time: 0.01(0.01)  Forward time: 1.43(1.43)  Batch time: 1.44(1.44)
2025-09-03 10:48:07,760   INFO  Train:    1/20 (  5%) [3849/3862 (100%)]  Loss: 3.118 (13.7)  LR: 1.340e-04  Grad: 33.2965  max=1.7794(module.vfe.pfn_layers.0.linear.weight)  min: -1.5100(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.0701, loss_cls=0.2082, loss_bbox=1.3628, matched_ious=0.3311, loss_iou=0.1114, loss_iou_reg=0.2802, d_time=0.00(0.01), f_time=1.39(1.43), b_time=1.40(1.44)  Time cost: 1:32:17/00:18 [1:32:18/29:19:12]  Acc_iter 3850        Data time: 0.00(0.01)  Forward time: 1.39(1.43)  Batch time: 1.40(1.44)
2025-09-03 10:48:23,905   INFO  Train:    1/20 (  5%) [3861/3862 (100%)]  Loss: 2.985 (13.6)  LR: 1.342e-04  Grad: 33.4653  max=1.5205(module.dense_head.decoder.self_attn.in_proj_weight)  min: -3.6223(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.0844, loss_cls=0.2092, loss_bbox=1.3349, matched_ious=0.3309, loss_iou=0.1103, loss_iou_reg=0.2823, d_time=0.00(0.01), f_time=1.33(1.43), b_time=1.33(1.44)  Time cost: 1:32:33/00:01 [1:32:35/29:18:34]  Acc_iter 3862        Data time: 0.00(0.01)  Forward time: 1.33(1.43)  Batch time: 1.33(1.44)

                                               [Aepochs:   5%|▌         | 1/20 [1:32:35<29:19:09, 5555.24s/it]epochs:   5%|▌         | 1/20 [1:32:35<29:19:10, 5555.31s/it]epochs:   5%|▌         | 1/20 [1:32:35<29:19:11, 5555.32s/it]epochs:   5%|▌         | 1/20 [1:32:35<29:19:11, 5555.33s/it]epochs:   5%|▌         | 1/20 [1:32:35<29:19:11, 5555.33s/it]epochs:   5%|▌         | 1/20 [1:32:35<29:19:11, 5555.33s/it]epochs:   5%|▌         | 1/20 [1:32:35<29:19:11, 5555.33s/it]epochs:   5%|▌         | 1/20 [1:32:35<29:19:15, 5555.55s/it]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-03 10:48:29,755   INFO  Train:    2/20 ( 10%) [   0/3862 (  0%)]  Loss: 2.874 (2.87)  LR: 1.343e-04  Grad: 33.3445  max=2.4533(module.vfe.pfn_layers.0.linear.weight)  min: -1.5085(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.0623, loss_cls=0.2034, loss_bbox=1.1987, matched_ious=0.3578, loss_iou=0.1170, loss_iou_reg=0.2927, d_time=1.94(1.94), f_time=2.77(2.77), b_time=4.71(4.71)  Time cost: 00:04/4:43:34 [1:32:40/89:47:48]  Acc_iter 3863        Data time: 1.94(1.94)  Forward time: 2.77(2.77)  Batch time: 4.71(4.71)
2025-09-03 10:49:22,330   INFO  Train:    2/20 ( 10%) [  37/3862 (  1%)]  Loss: 2.713 (2.96)  LR: 1.349e-04  Grad: 33.3751  max=1.5262(module.dense_head.decoder.self_attn.in_proj_weight)  min: -3.4749(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.0760, loss_cls=0.2066, loss_bbox=1.2936, matched_ious=0.3348, loss_iou=0.1092, loss_iou_reg=0.2798, d_time=0.01(0.06), f_time=1.41(1.45), b_time=1.42(1.51)  Time cost: 00:56/1:35:35 [1:33:33/30:32:51]  Acc_iter 3900        Data time: 0.01(0.06)  Forward time: 1.41(1.45)  Batch time: 1.42(1.51)
2025-09-03 10:50:34,427   INFO  Train:    2/20 ( 10%) [  87/3862 (  2%)]  Loss: 3.340 (2.98)  LR: 1.358e-04  Grad: 33.7971  max=2.7064(module.vfe.pfn_layers.0.linear.weight)  min: -4.6862(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.0623, loss_cls=0.2065, loss_bbox=1.3406, matched_ious=0.3395, loss_iou=0.1107, loss_iou_reg=0.2758, d_time=0.00(0.03), f_time=1.36(1.44), b_time=1.36(1.47)  Time cost: 02:09/1:32:17 [1:34:45/29:51:45]  Acc_iter 3950        Data time: 0.00(0.03)  Forward time: 1.36(1.44)  Batch time: 1.36(1.47)
2025-09-03 10:51:45,803   INFO  Train:    2/20 ( 10%) [ 137/3862 (  4%)]  Loss: 2.844 (2.98)  LR: 1.367e-04  Grad: 33.6018  max=3.0838(module.vfe.pfn_layers.0.linear.weight)  min: -1.5114(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.0654, loss_cls=0.2088, loss_bbox=1.3190, matched_ious=0.3359, loss_iou=0.1102, loss_iou_reg=0.2795, d_time=0.01(0.02), f_time=1.35(1.43), b_time=1.35(1.45)  Time cost: 03:20/1:30:10 [1:35:56/29:33:10]  Acc_iter 4000        Data time: 0.01(0.02)  Forward time: 1.35(1.43)  Batch time: 1.35(1.45)
2025-09-03 10:52:57,060   INFO  Train:    2/20 ( 10%) [ 187/3862 (  5%)]  Loss: 3.055 (2.98)  LR: 1.376e-04  Grad: 33.8228  max=3.6395(module.vfe.pfn_layers.0.linear.weight)  min: -1.6835(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.0370, loss_cls=0.1999, loss_bbox=1.3318, matched_ious=0.3423, loss_iou=0.1112, loss_iou_reg=0.2761, d_time=0.00(0.02), f_time=1.41(1.43), b_time=1.42(1.45)  Time cost: 04:31/1:28:31 [1:37:08/29:23:01]  Acc_iter 4050        Data time: 0.00(0.02)  Forward time: 1.41(1.43)  Batch time: 1.42(1.45)
2025-09-03 10:54:14,310   INFO  Train:    2/20 ( 10%) [ 237/3862 (  6%)]  Loss: 3.128 (2.95)  LR: 1.385e-04  Grad: 33.9985  max=3.7846(module.vfe.pfn_layers.0.linear.weight)  min: -1.5269(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.0104, loss_cls=0.1968, loss_bbox=1.2784, matched_ious=0.3476, loss_iou=0.1087, loss_iou_reg=0.2757, d_time=0.01(0.02), f_time=1.44(1.45), b_time=1.45(1.47)  Time cost: 05:48/1:28:35 [1:38:25/29:47:22]  Acc_iter 4100        Data time: 0.01(0.02)  Forward time: 1.44(1.45)  Batch time: 1.45(1.47)
2025-09-03 10:55:24,961   INFO  Train:    2/20 ( 10%) [ 287/3862 (  7%)]  Loss: 3.302 (2.95)  LR: 1.395e-04  Grad: 33.8553  max=1.6610(module.vfe.pfn_layers.0.linear.weight)  min: -2.5875(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.0525, loss_cls=0.2011, loss_bbox=1.3065, matched_ious=0.3392, loss_iou=0.1105, loss_iou_reg=0.2776, d_time=0.01(0.02), f_time=1.37(1.44), b_time=1.37(1.46)  Time cost: 06:59/1:26:48 [1:39:36/29:34:53]  Acc_iter 4150        Data time: 0.01(0.02)  Forward time: 1.37(1.44)  Batch time: 1.37(1.46)
2025-09-03 10:56:36,726   INFO  Train:    2/20 ( 10%) [ 337/3862 (  9%)]  Loss: 3.437 (2.95)  LR: 1.404e-04  Grad: 33.9794  max=1.8694(module.vfe.pfn_layers.0.linear.weight)  min: -1.5257(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.0433, loss_cls=0.2003, loss_bbox=1.3347, matched_ious=0.3412, loss_iou=0.1092, loss_iou_reg=0.2773, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.43(1.45)  Time cost: 08:11/1:25:24 [1:40:47/29:29:46]  Acc_iter 4200        Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.43(1.45)
2025-09-03 10:57:47,066   INFO  Train:    2/20 ( 10%) [ 387/3862 ( 10%)]  Loss: 2.964 (2.96)  LR: 1.414e-04  Grad: 34.3756  max=3.1742(module.vfe.pfn_layers.0.linear.weight)  min: -3.3018(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.0432, loss_cls=0.1961, loss_bbox=1.3369, matched_ious=0.3407, loss_iou=0.1099, loss_iou_reg=0.2773, d_time=0.00(0.01), f_time=1.39(1.44), b_time=1.40(1.45)  Time cost: 09:21/1:23:50 [1:41:58/29:21:11]  Acc_iter 4250        Data time: 0.00(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.45)
2025-09-03 10:58:57,194   INFO  Train:    2/20 ( 10%) [ 437/3862 ( 11%)]  Loss: 2.699 (2.94)  LR: 1.423e-04  Grad: 33.9747  max=2.1981(module.vfe.pfn_layers.0.linear.weight)  min: -1.5216(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.9936, loss_cls=0.1943, loss_bbox=1.2225, matched_ious=0.3503, loss_iou=0.1100, loss_iou_reg=0.2760, d_time=0.01(0.01), f_time=1.34(1.43), b_time=1.34(1.44)  Time cost: 10:31/1:22:20 [1:43:08/29:13:42]  Acc_iter 4300        Data time: 0.01(0.01)  Forward time: 1.34(1.43)  Batch time: 1.34(1.44)
2025-09-03 11:00:13,629   INFO  Train:    2/20 ( 10%) [ 487/3862 ( 13%)]  Loss: 2.475 (2.93)  LR: 1.433e-04  Grad: 33.7679  max=2.3648(module.vfe.pfn_layers.0.linear.weight)  min: -1.4994(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.0168, loss_cls=0.1941, loss_bbox=1.2794, matched_ious=0.3483, loss_iou=0.1106, loss_iou_reg=0.2746, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.43(1.45)  Time cost: 11:48/1:21:38 [1:44:24/29:23:13]  Acc_iter 4350        Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.43(1.45)
2025-09-03 11:01:23,645   INFO  Train:    2/20 ( 10%) [ 537/3862 ( 14%)]  Loss: 2.377 (2.92)  LR: 1.443e-04  Grad: 34.4099  max=3.2817(module.vfe.pfn_layers.0.linear.weight)  min: -5.9754(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.0019, loss_cls=0.1896, loss_bbox=1.2748, matched_ious=0.3478, loss_iou=0.1104, loss_iou_reg=0.2763, d_time=0.00(0.01), f_time=1.36(1.44), b_time=1.36(1.45)  Time cost: 12:58/1:20:10 [1:45:34/29:16:15]  Acc_iter 4400        Data time: 0.00(0.01)  Forward time: 1.36(1.44)  Batch time: 1.36(1.45)
2025-09-03 11:02:34,994   INFO  Train:    2/20 ( 10%) [ 587/3862 ( 15%)]  Loss: 2.716 (2.92)  LR: 1.453e-04  Grad: 34.8570  max=5.2940(module.vfe.pfn_layers.0.linear.weight)  min: -5.3918(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.0139, loss_cls=0.1896, loss_bbox=1.2794, matched_ious=0.3466, loss_iou=0.1096, loss_iou_reg=0.2760, d_time=0.01(0.01), f_time=1.29(1.43), b_time=1.30(1.45)  Time cost: 14:09/1:18:52 [1:46:46/29:12:59]  Acc_iter 4450        Data time: 0.01(0.01)  Forward time: 1.29(1.43)  Batch time: 1.30(1.45)
2025-09-03 11:03:45,836   INFO  Train:    2/20 ( 10%) [ 637/3862 ( 16%)]  Loss: 2.887 (2.92)  LR: 1.463e-04  Grad: 33.4564  max=1.6155(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.5889(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=1.0132, loss_cls=0.1884, loss_bbox=1.3144, matched_ious=0.3493, loss_iou=0.1114, loss_iou_reg=0.2737, d_time=0.00(0.01), f_time=1.38(1.43), b_time=1.38(1.44)  Time cost: 15:20/1:17:32 [1:47:56/29:09:08]  Acc_iter 4500        Data time: 0.00(0.01)  Forward time: 1.38(1.43)  Batch time: 1.38(1.44)
2025-09-03 11:04:56,209   INFO  Train:    2/20 ( 10%) [ 687/3862 ( 18%)]  Loss: 3.099 (2.91)  LR: 1.473e-04  Grad: 33.6083  max=2.7592(module.vfe.pfn_layers.0.linear.weight)  min: -1.4929(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.0292, loss_cls=0.1932, loss_bbox=1.2667, matched_ious=0.3550, loss_iou=0.1103, loss_iou_reg=0.2713, d_time=0.00(0.01), f_time=1.43(1.43), b_time=1.43(1.44)  Time cost: 16:30/1:16:12 [1:49:07/29:04:50]  Acc_iter 4550        Data time: 0.00(0.01)  Forward time: 1.43(1.43)  Batch time: 1.43(1.44)
2025-09-03 11:06:12,672   INFO  Train:    2/20 ( 10%) [ 737/3862 ( 19%)]  Loss: 2.892 (2.91)  LR: 1.483e-04  Grad: 33.2953  max=2.0476(module.vfe.pfn_layers.0.linear.weight)  min: -2.5393(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9972, loss_cls=0.1856, loss_bbox=1.2654, matched_ious=0.3524, loss_iou=0.1105, loss_iou_reg=0.2747, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 17:47/1:15:19 [1:50:23/29:10:56]  Acc_iter 4600        Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-03 11:07:24,078   INFO  Train:    2/20 ( 10%) [ 787/3862 ( 20%)]  Loss: 2.962 (2.90)  LR: 1.494e-04  Grad: 33.9111  max=3.8026(module.vfe.pfn_layers.0.linear.weight)  min: -5.1167(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9635, loss_cls=0.1799, loss_bbox=1.1957, matched_ious=0.3550, loss_iou=0.1091, loss_iou_reg=0.2767, d_time=0.00(0.01), f_time=1.37(1.43), b_time=1.38(1.45)  Time cost: 18:58/1:14:03 [1:51:35/29:08:20]  Acc_iter 4650        Data time: 0.00(0.01)  Forward time: 1.37(1.43)  Batch time: 1.38(1.45)
2025-09-03 11:08:34,844   INFO  Train:    2/20 ( 10%) [ 837/3862 ( 22%)]  Loss: 2.561 (2.89)  LR: 1.504e-04  Grad: 33.5036  max=2.1990(module.vfe.pfn_layers.0.linear.weight)  min: -1.4885(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.9806, loss_cls=0.1842, loss_bbox=1.2330, matched_ious=0.3567, loss_iou=0.1106, loss_iou_reg=0.2715, d_time=0.00(0.01), f_time=1.38(1.43), b_time=1.38(1.44)  Time cost: 20:09/1:12:46 [1:52:45/29:04:59]  Acc_iter 4700        Data time: 0.00(0.01)  Forward time: 1.38(1.43)  Batch time: 1.38(1.44)
2025-09-03 11:09:44,711   INFO  Train:    2/20 ( 10%) [ 887/3862 ( 23%)]  Loss: 2.918 (2.89)  LR: 1.515e-04  Grad: 33.8433  max=4.6668(module.vfe.pfn_layers.0.linear.weight)  min: -1.4907(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.0425, loss_cls=0.1943, loss_bbox=1.2593, matched_ious=0.3606, loss_iou=0.1092, loss_iou_reg=0.2706, d_time=0.01(0.01), f_time=1.32(1.43), b_time=1.33(1.44)  Time cost: 21:19/1:11:26 [1:53:55/29:00:39]  Acc_iter 4750        Data time: 0.01(0.01)  Forward time: 1.32(1.43)  Batch time: 1.33(1.44)
2025-09-03 11:10:55,084   INFO  Train:    2/20 ( 10%) [ 937/3862 ( 24%)]  Loss: 2.620 (2.88)  LR: 1.525e-04  Grad: 33.8033  max=1.6705(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.3445(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9841, loss_cls=0.1848, loss_bbox=1.2020, matched_ious=0.3675, loss_iou=0.1094, loss_iou_reg=0.2685, d_time=0.00(0.01), f_time=1.38(1.43), b_time=1.39(1.44)  Time cost: 22:29/1:10:08 [1:55:06/28:57:19]  Acc_iter 4800        Data time: 0.00(0.01)  Forward time: 1.38(1.43)  Batch time: 1.39(1.44)
2025-09-03 11:12:12,099   INFO  Train:    2/20 ( 10%) [ 987/3862 ( 26%)]  Loss: 2.235 (2.88)  LR: 1.536e-04  Grad: 34.3504  max=4.8838(module.vfe.pfn_layers.0.linear.weight)  min: -2.9536(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9786, loss_cls=0.1793, loss_bbox=1.2402, matched_ious=0.3600, loss_iou=0.1077, loss_iou_reg=0.2734, d_time=0.01(0.01), f_time=1.36(1.43), b_time=1.36(1.44)  Time cost: 23:46/1:09:11 [1:56:23/29:02:18]  Acc_iter 4850        Data time: 0.01(0.01)  Forward time: 1.36(1.43)  Batch time: 1.36(1.44)
2025-09-03 11:13:23,886   INFO  Train:    2/20 ( 10%) [1037/3862 ( 27%)]  Loss: 3.246 (2.87)  LR: 1.547e-04  Grad: 33.8079  max=2.4843(module.vfe.pfn_layers.0.linear.weight)  min: -1.4994(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.9861, loss_cls=0.1806, loss_bbox=1.2371, matched_ious=0.3607, loss_iou=0.1096, loss_iou_reg=0.2705, d_time=0.01(0.01), f_time=1.45(1.43), b_time=1.46(1.44)  Time cost: 24:58/1:07:58 [1:57:35/29:00:37]  Acc_iter 4900        Data time: 0.01(0.01)  Forward time: 1.45(1.43)  Batch time: 1.46(1.44)
2025-09-03 11:14:35,179   INFO  Train:    2/20 ( 10%) [1087/3862 ( 28%)]  Loss: 3.195 (2.87)  LR: 1.558e-04  Grad: 34.0218  max=1.6972(module.dense_head.decoder.self_attn.in_proj_weight)  min: -4.2528(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9996, loss_cls=0.1834, loss_bbox=1.2156, matched_ious=0.3601, loss_iou=0.1086, loss_iou_reg=0.2732, d_time=0.01(0.01), f_time=1.43(1.43), b_time=1.44(1.44)  Time cost: 26:09/1:06:43 [1:58:46/28:58:26]  Acc_iter 4950        Data time: 0.01(0.01)  Forward time: 1.43(1.43)  Batch time: 1.44(1.44)
2025-09-03 11:15:45,528   INFO  Train:    2/20 ( 10%) [1137/3862 ( 29%)]  Loss: 3.213 (2.87)  LR: 1.569e-04  Grad: 33.5735  max=1.9854(module.vfe.pfn_layers.0.linear.weight)  min: -1.5022(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=1.0021, loss_cls=0.1805, loss_bbox=1.2399, matched_ious=0.3625, loss_iou=0.1109, loss_iou_reg=0.2697, d_time=0.01(0.01), f_time=1.48(1.43), b_time=1.49(1.44)  Time cost: 27:20/1:05:27 [1:59:56/28:55:19]  Acc_iter 5000        Data time: 0.01(0.01)  Forward time: 1.48(1.43)  Batch time: 1.49(1.44)
2025-09-03 11:16:55,622   INFO  Train:    2/20 ( 10%) [1187/3862 ( 31%)]  Loss: 2.440 (2.86)  LR: 1.580e-04  Grad: 33.7523  max=1.6806(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.6871(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9705, loss_cls=0.1777, loss_bbox=1.2043, matched_ious=0.3715, loss_iou=0.1094, loss_iou_reg=0.2664, d_time=0.00(0.01), f_time=1.37(1.43), b_time=1.37(1.44)  Time cost: 28:30/1:04:10 [2:01:06/28:52:07]  Acc_iter 5050        Data time: 0.00(0.01)  Forward time: 1.37(1.43)  Batch time: 1.37(1.44)
2025-09-03 11:18:11,655   INFO  Train:    2/20 ( 10%) [1237/3862 ( 32%)]  Loss: 2.665 (2.86)  LR: 1.591e-04  Grad: 33.5629  max=1.6752(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.9365(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9804, loss_cls=0.1747, loss_bbox=1.2757, matched_ious=0.3613, loss_iou=0.1069, loss_iou_reg=0.2704, d_time=0.00(0.01), f_time=1.39(1.43), b_time=1.40(1.44)  Time cost: 29:46/1:03:07 [2:02:22/28:54:52]  Acc_iter 5100        Data time: 0.00(0.01)  Forward time: 1.39(1.43)  Batch time: 1.40(1.44)
2025-09-03 11:19:23,176   INFO  Train:    2/20 ( 10%) [1287/3862 ( 33%)]  Loss: 2.376 (2.85)  LR: 1.603e-04  Grad: 33.9679  max=1.6879(module.dense_head.decoder.self_attn.in_proj_weight)  min: -4.8583(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9597, loss_cls=0.1780, loss_bbox=1.1755, matched_ious=0.3655, loss_iou=0.1075, loss_iou_reg=0.2727, d_time=0.02(0.01), f_time=1.39(1.43), b_time=1.40(1.44)  Time cost: 30:57/1:01:54 [2:03:34/28:53:05]  Acc_iter 5150        Data time: 0.02(0.01)  Forward time: 1.39(1.43)  Batch time: 1.40(1.44)
2025-09-03 11:20:34,480   INFO  Train:    2/20 ( 10%) [1337/3862 ( 35%)]  Loss: 2.456 (2.85)  LR: 1.614e-04  Grad: 33.8157  max=1.6923(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.4880(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9642, loss_cls=0.1755, loss_bbox=1.2245, matched_ious=0.3683, loss_iou=0.1087, loss_iou_reg=0.2710, d_time=0.01(0.01), f_time=1.45(1.43), b_time=1.46(1.44)  Time cost: 32:09/1:00:40 [2:04:45/28:51:08]  Acc_iter 5200        Data time: 0.01(0.01)  Forward time: 1.45(1.43)  Batch time: 1.46(1.44)
2025-09-03 11:21:44,802   INFO  Train:    2/20 ( 10%) [1387/3862 ( 36%)]  Loss: 2.846 (2.84)  LR: 1.626e-04  Grad: 34.2559  max=1.6782(module.dense_head.decoder.self_attn.in_proj_weight)  min: -5.8557(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9643, loss_cls=0.1749, loss_bbox=1.2126, matched_ious=0.3677, loss_iou=0.1058, loss_iou_reg=0.2698, d_time=0.00(0.01), f_time=1.45(1.43), b_time=1.46(1.44)  Time cost: 33:19/59:25 [2:05:55/28:48:25]  Acc_iter 5250        Data time: 0.00(0.01)  Forward time: 1.45(1.43)  Batch time: 1.46(1.44)
2025-09-03 11:22:55,324   INFO  Train:    2/20 ( 10%) [1437/3862 ( 37%)]  Loss: 2.790 (2.84)  LR: 1.638e-04  Grad: 34.1696  max=5.5351(module.vfe.pfn_layers.0.linear.weight)  min: -3.2746(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9643, loss_cls=0.1751, loss_bbox=1.2109, matched_ious=0.3746, loss_iou=0.1068, loss_iou_reg=0.2677, d_time=0.01(0.01), f_time=1.47(1.43), b_time=1.47(1.44)  Time cost: 34:29/58:10 [2:07:06/28:45:57]  Acc_iter 5300        Data time: 0.01(0.01)  Forward time: 1.47(1.43)  Batch time: 1.47(1.44)
2025-09-03 11:24:11,620   INFO  Train:    2/20 ( 10%) [1487/3862 ( 39%)]  Loss: 2.961 (2.83)  LR: 1.649e-04  Grad: 34.0026  max=3.5700(module.vfe.pfn_layers.0.linear.weight)  min: -2.3999(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9568, loss_cls=0.1731, loss_bbox=1.1976, matched_ious=0.3735, loss_iou=0.1092, loss_iou_reg=0.2682, d_time=0.00(0.01), f_time=1.37(1.43), b_time=1.37(1.44)  Time cost: 35:46/57:05 [2:08:22/28:48:14]  Acc_iter 5350        Data time: 0.00(0.01)  Forward time: 1.37(1.43)  Batch time: 1.37(1.44)
2025-09-03 11:25:22,110   INFO  Train:    2/20 ( 10%) [1537/3862 ( 40%)]  Loss: 2.416 (2.83)  LR: 1.661e-04  Grad: 33.3817  max=3.3542(module.vfe.pfn_layers.0.linear.weight)  min: -1.4809(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.9509, loss_cls=0.1716, loss_bbox=1.2170, matched_ious=0.3699, loss_iou=0.1078, loss_iou_reg=0.2693, d_time=0.01(0.01), f_time=1.36(1.43), b_time=1.36(1.44)  Time cost: 36:56/55:51 [2:09:33/28:45:46]  Acc_iter 5400        Data time: 0.01(0.01)  Forward time: 1.36(1.43)  Batch time: 1.36(1.44)
2025-09-03 11:26:32,241   INFO  Train:    2/20 ( 10%) [1587/3862 ( 41%)]  Loss: 2.785 (2.82)  LR: 1.673e-04  Grad: 33.9832  max=5.8743(module.vfe.pfn_layers.0.linear.weight)  min: -1.4852(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.9341, loss_cls=0.1739, loss_bbox=1.1623, matched_ious=0.3778, loss_iou=0.1082, loss_iou_reg=0.2681, d_time=0.01(0.01), f_time=1.35(1.43), b_time=1.36(1.44)  Time cost: 38:06/54:36 [2:10:43/28:43:07]  Acc_iter 5450        Data time: 0.01(0.01)  Forward time: 1.35(1.43)  Batch time: 1.36(1.44)
2025-09-03 11:27:42,871   INFO  Train:    2/20 ( 10%) [1637/3862 ( 42%)]  Loss: 2.491 (2.82)  LR: 1.685e-04  Grad: 33.5406  max=2.2957(module.vfe.pfn_layers.0.linear.weight)  min: -1.4902(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.9498, loss_cls=0.1717, loss_bbox=1.1705, matched_ious=0.3715, loss_iou=0.1089, loss_iou_reg=0.2703, d_time=0.01(0.01), f_time=1.46(1.43), b_time=1.47(1.44)  Time cost: 39:17/53:22 [2:11:53/28:40:54]  Acc_iter 5500        Data time: 0.01(0.01)  Forward time: 1.46(1.43)  Batch time: 1.47(1.44)
2025-09-03 11:28:55,203   INFO  Train:    2/20 ( 10%) [1687/3862 ( 44%)]  Loss: 2.932 (2.81)  LR: 1.698e-04  Grad: 33.6844  max=2.6093(module.vfe.pfn_layers.0.linear.weight)  min: -1.4912(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.9308, loss_cls=0.1671, loss_bbox=1.1469, matched_ious=0.3755, loss_iou=0.1070, loss_iou_reg=0.2705, d_time=0.01(0.01), f_time=1.45(1.43), b_time=1.46(1.44)  Time cost: 40:29/52:10 [2:13:06/28:39:58]  Acc_iter 5550        Data time: 0.01(0.01)  Forward time: 1.45(1.43)  Batch time: 1.46(1.44)
2025-09-03 11:30:10,831   INFO  Train:    2/20 ( 10%) [1737/3862 ( 45%)]  Loss: 2.231 (2.81)  LR: 1.710e-04  Grad: 34.0589  max=1.6723(module.dense_head.decoder.self_attn.in_proj_weight)  min: -4.6752(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9414, loss_cls=0.1713, loss_bbox=1.1634, matched_ious=0.3789, loss_iou=0.1081, loss_iou_reg=0.2689, d_time=0.00(0.01), f_time=1.31(1.43), b_time=1.32(1.44)  Time cost: 41:45/51:03 [2:14:21/28:41:17]  Acc_iter 5600        Data time: 0.00(0.01)  Forward time: 1.31(1.43)  Batch time: 1.32(1.44)
2025-09-03 11:31:21,543   INFO  Train:    2/20 ( 10%) [1787/3862 ( 46%)]  Loss: 3.170 (2.81)  LR: 1.722e-04  Grad: 33.2162  max=1.6445(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.3556(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9499, loss_cls=0.1706, loss_bbox=1.1892, matched_ious=0.3857, loss_iou=0.1067, loss_iou_reg=0.2655, d_time=0.00(0.01), f_time=1.44(1.43), b_time=1.44(1.44)  Time cost: 42:56/49:49 [2:15:32/28:39:10]  Acc_iter 5650        Data time: 0.00(0.01)  Forward time: 1.44(1.43)  Batch time: 1.44(1.44)
2025-09-03 11:32:32,569   INFO  Train:    2/20 ( 10%) [1837/3862 ( 48%)]  Loss: 2.555 (2.80)  LR: 1.735e-04  Grad: 33.2905  max=2.6731(module.vfe.pfn_layers.0.linear.weight)  min: -1.4757(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.9625, loss_cls=0.1732, loss_bbox=1.1529, matched_ious=0.3799, loss_iou=0.1072, loss_iou_reg=0.2682, d_time=0.00(0.01), f_time=1.44(1.43), b_time=1.45(1.44)  Time cost: 44:07/48:36 [2:16:43/28:37:18]  Acc_iter 5700        Data time: 0.00(0.01)  Forward time: 1.44(1.43)  Batch time: 1.45(1.44)
2025-09-03 11:33:42,937   INFO  Train:    2/20 ( 10%) [1887/3862 ( 49%)]  Loss: 2.587 (2.80)  LR: 1.747e-04  Grad: 33.9632  max=6.3874(module.vfe.pfn_layers.0.linear.weight)  min: -1.5636(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9408, loss_cls=0.1671, loss_bbox=1.1810, matched_ious=0.3856, loss_iou=0.1058, loss_iou_reg=0.2659, d_time=0.01(0.01), f_time=1.44(1.43), b_time=1.44(1.44)  Time cost: 45:17/47:22 [2:17:54/28:35:04]  Acc_iter 5750        Data time: 0.01(0.01)  Forward time: 1.44(1.43)  Batch time: 1.44(1.44)
2025-09-03 11:34:55,264   INFO  Train:    2/20 ( 10%) [1937/3862 ( 50%)]  Loss: 3.000 (2.79)  LR: 1.760e-04  Grad: 34.1195  max=5.5080(module.vfe.pfn_layers.0.linear.weight)  min: -2.6333(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9372, loss_cls=0.1688, loss_bbox=1.1742, matched_ious=0.3823, loss_iou=0.1067, loss_iou_reg=0.2666, d_time=0.00(0.01), f_time=1.46(1.43), b_time=1.46(1.44)  Time cost: 46:29/46:11 [2:19:06/28:34:05]  Acc_iter 5800        Data time: 0.00(0.01)  Forward time: 1.46(1.43)  Batch time: 1.46(1.44)
2025-09-03 11:36:10,056   INFO  Train:    2/20 ( 10%) [1987/3862 ( 51%)]  Loss: 2.569 (2.79)  LR: 1.773e-04  Grad: 33.7221  max=2.4139(module.vfe.pfn_layers.0.linear.weight)  min: -4.6782(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9194, loss_cls=0.1652, loss_bbox=1.1442, matched_ious=0.3778, loss_iou=0.1081, loss_iou_reg=0.2677, d_time=0.01(0.01), f_time=1.32(1.43), b_time=1.33(1.44)  Time cost: 47:44/45:01 [2:20:21/28:34:34]  Acc_iter 5850        Data time: 0.01(0.01)  Forward time: 1.32(1.43)  Batch time: 1.33(1.44)
2025-09-03 11:37:20,846   INFO  Train:    2/20 ( 10%) [2037/3862 ( 53%)]  Loss: 2.588 (2.79)  LR: 1.786e-04  Grad: 33.8097  max=4.6764(module.vfe.pfn_layers.0.linear.weight)  min: -1.4935(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.9242, loss_cls=0.1669, loss_bbox=1.1524, matched_ious=0.3893, loss_iou=0.1071, loss_iou_reg=0.2630, d_time=0.01(0.01), f_time=1.52(1.43), b_time=1.52(1.44)  Time cost: 48:55/43:48 [2:21:31/28:32:38]  Acc_iter 5900        Data time: 0.01(0.01)  Forward time: 1.52(1.43)  Batch time: 1.52(1.44)
2025-09-03 11:38:31,370   INFO  Train:    2/20 ( 10%) [2087/3862 ( 54%)]  Loss: 2.753 (2.78)  LR: 1.799e-04  Grad: 33.6695  max=3.9228(module.vfe.pfn_layers.0.linear.weight)  min: -1.4903(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.9364, loss_cls=0.1650, loss_bbox=1.1402, matched_ious=0.3856, loss_iou=0.1072, loss_iou_reg=0.2642, d_time=0.00(0.01), f_time=1.41(1.43), b_time=1.42(1.44)  Time cost: 50:06/42:35 [2:22:42/28:30:35]  Acc_iter 5950        Data time: 0.00(0.01)  Forward time: 1.41(1.43)  Batch time: 1.42(1.44)
2025-09-03 11:39:42,398   INFO  Train:    2/20 ( 10%) [2137/3862 ( 55%)]  Loss: 2.636 (2.78)  LR: 1.812e-04  Grad: 35.0000  max=11.2653(module.vfe.pfn_layers.0.linear.weight)  min: -1.4771(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.9410, loss_cls=0.1657, loss_bbox=1.1445, matched_ious=0.3807, loss_iou=0.1073, loss_iou_reg=0.2661, d_time=0.01(0.01), f_time=1.40(1.43), b_time=1.40(1.44)  Time cost: 51:17/41:22 [2:23:53/28:28:51]  Acc_iter 6000        Data time: 0.01(0.01)  Forward time: 1.40(1.43)  Batch time: 1.40(1.44)
2025-09-03 11:40:57,445   INFO  Train:    2/20 ( 10%) [2187/3862 ( 57%)]  Loss: 2.932 (2.78)  LR: 1.825e-04  Grad: 33.3349  max=1.6471(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.9987(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9568, loss_cls=0.1686, loss_bbox=1.1841, matched_ious=0.3769, loss_iou=0.1080, loss_iou_reg=0.2706, d_time=0.00(0.01), f_time=1.48(1.43), b_time=1.49(1.44)  Time cost: 52:32/40:13 [2:25:08/28:29:19]  Acc_iter 6050        Data time: 0.00(0.01)  Forward time: 1.48(1.43)  Batch time: 1.49(1.44)
2025-09-03 11:42:11,187   INFO  Train:    2/20 ( 10%) [2237/3862 ( 58%)]  Loss: 2.608 (2.77)  LR: 1.838e-04  Grad: 33.5235  max=3.2337(module.vfe.pfn_layers.0.linear.weight)  min: -1.4776(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.9261, loss_cls=0.1629, loss_bbox=1.1286, matched_ious=0.3863, loss_iou=0.1095, loss_iou_reg=0.2658, d_time=0.00(0.01), f_time=1.41(1.43), b_time=1.42(1.44)  Time cost: 53:45/39:02 [2:26:22/28:29:02]  Acc_iter 6100        Data time: 0.00(0.01)  Forward time: 1.41(1.43)  Batch time: 1.42(1.44)
2025-09-03 11:43:21,967   INFO  Train:    2/20 ( 10%) [2287/3862 ( 59%)]  Loss: 2.717 (2.77)  LR: 1.851e-04  Grad: 33.6228  max=1.6502(module.dense_head.decoder.self_attn.in_proj_weight)  min: -4.0844(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9360, loss_cls=0.1652, loss_bbox=1.1259, matched_ious=0.3888, loss_iou=0.1066, loss_iou_reg=0.2662, d_time=0.01(0.01), f_time=1.35(1.43), b_time=1.36(1.44)  Time cost: 54:56/37:49 [2:27:33/28:27:09]  Acc_iter 6150        Data time: 0.01(0.01)  Forward time: 1.35(1.43)  Batch time: 1.36(1.44)
2025-09-03 11:44:32,700   INFO  Train:    2/20 ( 10%) [2337/3862 ( 61%)]  Loss: 2.978 (2.76)  LR: 1.865e-04  Grad: 33.2181  max=1.6485(module.dense_head.decoder.self_attn.in_proj_weight)  min: -3.4803(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9110, loss_cls=0.1615, loss_bbox=1.1782, matched_ious=0.3855, loss_iou=0.1061, loss_iou_reg=0.2676, d_time=0.01(0.01), f_time=1.47(1.43), b_time=1.48(1.44)  Time cost: 56:07/36:36 [2:28:43/28:25:18]  Acc_iter 6200        Data time: 0.01(0.01)  Forward time: 1.47(1.43)  Batch time: 1.48(1.44)
2025-09-03 11:45:43,825   INFO  Train:    2/20 ( 10%) [2387/3862 ( 62%)]  Loss: 2.502 (2.76)  LR: 1.878e-04  Grad: 33.5701  max=5.5324(module.vfe.pfn_layers.0.linear.weight)  min: -1.4619(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.9114, loss_cls=0.1622, loss_bbox=1.1455, matched_ious=0.3840, loss_iou=0.1058, loss_iou_reg=0.2685, d_time=0.01(0.01), f_time=1.40(1.43), b_time=1.42(1.44)  Time cost: 57:18/35:23 [2:29:54/28:23:39]  Acc_iter 6250        Data time: 0.01(0.01)  Forward time: 1.40(1.43)  Batch time: 1.42(1.44)
2025-09-03 11:47:01,031   INFO  Train:    2/20 ( 10%) [2437/3862 ( 63%)]  Loss: 2.762 (2.76)  LR: 1.892e-04  Grad: 33.3757  max=1.6644(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.5283(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9044, loss_cls=0.1596, loss_bbox=1.1357, matched_ious=0.3907, loss_iou=0.1062, loss_iou_reg=0.2646, d_time=0.55(0.01), f_time=2.10(1.43), b_time=2.65(1.44)  Time cost: 58:35/34:14 [2:31:12/28:24:59]  Acc_iter 6300        Data time: 0.55(0.01)  Forward time: 2.10(1.43)  Batch time: 2.65(1.44)
2025-09-03 11:48:12,062   INFO  Train:    2/20 ( 10%) [2487/3862 ( 64%)]  Loss: 2.471 (2.75)  LR: 1.906e-04  Grad: 33.4044  max=2.3870(module.vfe.pfn_layers.0.linear.weight)  min: -1.4682(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.9042, loss_cls=0.1625, loss_bbox=1.0954, matched_ious=0.4008, loss_iou=0.1054, loss_iou_reg=0.2598, d_time=0.01(0.01), f_time=1.34(1.43), b_time=1.35(1.44)  Time cost: 59:46/33:02 [2:32:23/28:23:16]  Acc_iter 6350        Data time: 0.01(0.01)  Forward time: 1.34(1.43)  Batch time: 1.35(1.44)
2025-09-03 11:49:23,129   INFO  Train:    2/20 ( 10%) [2537/3862 ( 66%)]  Loss: 2.917 (2.75)  LR: 1.919e-04  Grad: 33.6178  max=1.6503(module.dense_head.decoder.self_attn.in_proj_weight)  min: -3.1996(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9241, loss_cls=0.1635, loss_bbox=1.1385, matched_ious=0.3940, loss_iou=0.1069, loss_iou_reg=0.2613, d_time=0.01(0.01), f_time=1.33(1.43), b_time=1.34(1.44)  Time cost: 1:00:57/31:49 [2:33:34/28:21:36]  Acc_iter 6400        Data time: 0.01(0.01)  Forward time: 1.33(1.43)  Batch time: 1.34(1.44)
2025-09-03 11:50:34,299   INFO  Train:    2/20 ( 10%) [2587/3862 ( 67%)]  Loss: 2.416 (2.75)  LR: 1.933e-04  Grad: 33.7142  max=1.6577(module.dense_head.decoder.self_attn.in_proj_weight)  min: -3.7698(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9040, loss_cls=0.1590, loss_bbox=1.1291, matched_ious=0.3956, loss_iou=0.1063, loss_iou_reg=0.2620, d_time=0.01(0.01), f_time=1.48(1.43), b_time=1.48(1.44)  Time cost: 1:02:08/30:37 [2:34:45/28:19:59]  Acc_iter 6450        Data time: 0.01(0.01)  Forward time: 1.48(1.43)  Batch time: 1.48(1.44)
2025-09-03 11:51:44,888   INFO  Train:    2/20 ( 10%) [2637/3862 ( 68%)]  Loss: 2.343 (2.74)  LR: 1.947e-04  Grad: 34.3121  max=1.6653(module.dense_head.decoder.self_attn.in_proj_weight)  min: -5.3327(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8990, loss_cls=0.1625, loss_bbox=1.0732, matched_ious=0.4001, loss_iou=0.1058, loss_iou_reg=0.2614, d_time=0.00(0.01), f_time=1.39(1.43), b_time=1.40(1.44)  Time cost: 1:03:19/29:24 [2:35:56/28:18:09]  Acc_iter 6500        Data time: 0.00(0.01)  Forward time: 1.39(1.43)  Batch time: 1.40(1.44)
2025-09-03 11:53:01,400   INFO  Train:    2/20 ( 10%) [2687/3862 ( 70%)]  Loss: 2.641 (2.74)  LR: 1.961e-04  Grad: 33.7830  max=3.2881(module.vfe.pfn_layers.0.linear.weight)  min: -1.4773(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.8869, loss_cls=0.1557, loss_bbox=1.1198, matched_ious=0.3976, loss_iou=0.1044, loss_iou_reg=0.2615, d_time=0.01(0.01), f_time=1.42(1.43), b_time=1.43(1.44)  Time cost: 1:04:36/28:14 [2:37:12/28:18:55]  Acc_iter 6550        Data time: 0.01(0.01)  Forward time: 1.42(1.43)  Batch time: 1.43(1.44)
2025-09-03 11:54:12,212   INFO  Train:    2/20 ( 10%) [2737/3862 ( 71%)]  Loss: 2.551 (2.73)  LR: 1.976e-04  Grad: 34.0596  max=1.5601(module.dense_head.decoder.self_attn.in_proj_weight)  min: -12.6419(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9175, loss_cls=0.1629, loss_bbox=1.1271, matched_ious=0.3935, loss_iou=0.1047, loss_iou_reg=0.2659, d_time=0.00(0.01), f_time=1.41(1.43), b_time=1.42(1.44)  Time cost: 1:05:46/27:01 [2:38:23/28:17:09]  Acc_iter 6600        Data time: 0.00(0.01)  Forward time: 1.41(1.43)  Batch time: 1.42(1.44)
2025-09-03 11:55:23,002   INFO  Train:    2/20 ( 10%) [2787/3862 ( 72%)]  Loss: 2.294 (2.73)  LR: 1.990e-04  Grad: 32.0504  max=4.9280(module.vfe.pfn_layers.0.linear.weight)  min: -2.7909(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8881, loss_cls=0.1576, loss_bbox=1.1030, matched_ious=0.4015, loss_iou=0.1054, loss_iou_reg=0.2592, d_time=0.01(0.01), f_time=1.33(1.43), b_time=1.34(1.44)  Time cost: 1:06:57/25:49 [2:39:34/28:15:25]  Acc_iter 6650        Data time: 0.01(0.01)  Forward time: 1.33(1.43)  Batch time: 1.34(1.44)
2025-09-03 11:56:33,527   INFO  Train:    2/20 ( 10%) [2837/3862 ( 73%)]  Loss: 2.599 (2.73)  LR: 2.004e-04  Grad: 33.6184  max=3.0501(module.vfe.pfn_layers.0.linear.weight)  min: -9.8941(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9184, loss_cls=0.1603, loss_bbox=1.0978, matched_ious=0.4011, loss_iou=0.1055, loss_iou_reg=0.2600, d_time=0.00(0.01), f_time=1.37(1.43), b_time=1.37(1.44)  Time cost: 1:08:08/24:36 [2:40:44/28:13:35]  Acc_iter 6700        Data time: 0.00(0.01)  Forward time: 1.37(1.43)  Batch time: 1.37(1.44)
2025-09-03 11:57:44,983   INFO  Train:    2/20 ( 10%) [2887/3862 ( 75%)]  Loss: 2.593 (2.72)  LR: 2.019e-04  Grad: 32.8927  max=8.3224(module.vfe.pfn_layers.0.linear.weight)  min: -1.4353(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9061, loss_cls=0.1585, loss_bbox=1.0755, matched_ious=0.3970, loss_iou=0.1047, loss_iou_reg=0.2647, d_time=0.01(0.01), f_time=1.36(1.43), b_time=1.37(1.44)  Time cost: 1:09:19/23:24 [2:41:56/28:12:09]  Acc_iter 6750        Data time: 0.01(0.01)  Forward time: 1.36(1.43)  Batch time: 1.37(1.44)
2025-09-03 11:59:01,837   INFO  Train:    2/20 ( 10%) [2937/3862 ( 76%)]  Loss: 2.169 (2.72)  LR: 2.033e-04  Grad: 32.0652  max=1.5689(module.dense_head.decoder.self_attn.in_proj_weight)  min: -3.4557(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8927, loss_cls=0.1588, loss_bbox=1.0333, matched_ious=0.4049, loss_iou=0.1048, loss_iou_reg=0.2611, d_time=0.00(0.01), f_time=1.47(1.43), b_time=1.48(1.44)  Time cost: 1:10:36/22:13 [2:43:12/28:12:53]  Acc_iter 6800        Data time: 0.00(0.01)  Forward time: 1.47(1.43)  Batch time: 1.48(1.44)
2025-09-03 12:00:11,586   INFO  Train:    2/20 ( 10%) [2987/3862 ( 77%)]  Loss: 2.418 (2.71)  LR: 2.048e-04  Grad: 32.1891  max=1.9061(module.vfe.pfn_layers.0.linear.weight)  min: -3.5678(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8845, loss_cls=0.1571, loss_bbox=1.0764, matched_ious=0.3997, loss_iou=0.1043, loss_iou_reg=0.2617, d_time=0.01(0.01), f_time=1.39(1.43), b_time=1.40(1.44)  Time cost: 1:11:46/21:01 [2:44:22/28:10:45]  Acc_iter 6850        Data time: 0.01(0.01)  Forward time: 1.39(1.43)  Batch time: 1.40(1.44)
2025-09-03 12:01:22,368   INFO  Train:    2/20 ( 10%) [3037/3862 ( 79%)]  Loss: 2.266 (2.71)  LR: 2.063e-04  Grad: 32.0680  max=1.5743(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3825(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.8773, loss_cls=0.1550, loss_bbox=1.1092, matched_ious=0.3973, loss_iou=0.1057, loss_iou_reg=0.2628, d_time=0.00(0.01), f_time=1.44(1.43), b_time=1.44(1.44)  Time cost: 1:12:57/19:48 [2:45:33/28:09:04]  Acc_iter 6900        Data time: 0.00(0.01)  Forward time: 1.44(1.43)  Batch time: 1.44(1.44)
2025-09-03 12:02:36,979   INFO  Train:    2/20 ( 10%) [3087/3862 ( 80%)]  Loss: 2.701 (2.71)  LR: 2.077e-04  Grad: 30.2103  max=3.2452(module.vfe.pfn_layers.0.linear.weight)  min: -1.4426(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8638, loss_cls=0.1522, loss_bbox=1.1000, matched_ious=0.4028, loss_iou=0.1042, loss_iou_reg=0.2611, d_time=0.01(0.01), f_time=1.40(1.43), b_time=1.40(1.44)  Time cost: 1:14:11/18:37 [2:46:48/28:08:50]  Acc_iter 6950        Data time: 0.01(0.01)  Forward time: 1.40(1.43)  Batch time: 1.40(1.44)
2025-09-03 12:03:49,426   INFO  Train:    2/20 ( 10%) [3137/3862 ( 81%)]  Loss: 2.688 (2.70)  LR: 2.092e-04  Grad: 30.4840  max=4.3370(module.vfe.pfn_layers.0.linear.weight)  min: -1.2947(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.8864, loss_cls=0.1558, loss_bbox=1.1008, matched_ious=0.4017, loss_iou=0.1044, loss_iou_reg=0.2624, d_time=0.00(0.01), f_time=3.02(1.43), b_time=3.03(1.44)  Time cost: 1:15:24/17:25 [2:48:00/28:07:47]  Acc_iter 7000        Data time: 0.00(0.01)  Forward time: 3.02(1.43)  Batch time: 3.03(1.44)
2025-09-03 12:05:05,376   INFO  Train:    2/20 ( 10%) [3187/3862 ( 83%)]  Loss: 2.334 (2.70)  LR: 2.107e-04  Grad: 30.2624  max=2.7823(module.vfe.pfn_layers.0.linear.weight)  min: -1.4121(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8664, loss_cls=0.1520, loss_bbox=1.0966, matched_ious=0.4082, loss_iou=0.1048, loss_iou_reg=0.2612, d_time=0.00(0.01), f_time=1.46(1.43), b_time=1.47(1.44)  Time cost: 1:16:40/16:13 [2:49:16/28:08:00]  Acc_iter 7050        Data time: 0.00(0.01)  Forward time: 1.46(1.43)  Batch time: 1.47(1.44)
2025-09-03 12:06:16,247   INFO  Train:    2/20 ( 10%) [3237/3862 ( 84%)]  Loss: 2.747 (2.70)  LR: 2.122e-04  Grad: 32.6079  max=4.7109(module.vfe.pfn_layers.0.linear.weight)  min: -11.2523(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8819, loss_cls=0.1564, loss_bbox=1.1117, matched_ious=0.4047, loss_iou=0.1044, loss_iou_reg=0.2598, d_time=0.00(0.01), f_time=1.40(1.43), b_time=1.41(1.44)  Time cost: 1:17:50/15:01 [2:50:27/28:06:20]  Acc_iter 7100        Data time: 0.00(0.01)  Forward time: 1.40(1.43)  Batch time: 1.41(1.44)
2025-09-03 12:07:27,378   INFO  Train:    2/20 ( 10%) [3287/3862 ( 85%)]  Loss: 2.361 (2.70)  LR: 2.138e-04  Grad: 32.6095  max=10.7581(module.vfe.pfn_layers.0.linear.weight)  min: -5.4631(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.9183, loss_cls=0.1619, loss_bbox=1.0911, matched_ious=0.4042, loss_iou=0.1043, loss_iou_reg=0.2599, d_time=0.01(0.01), f_time=1.41(1.43), b_time=1.42(1.44)  Time cost: 1:19:02/13:49 [2:51:38/28:04:46]  Acc_iter 7150        Data time: 0.01(0.01)  Forward time: 1.41(1.43)  Batch time: 1.42(1.44)
2025-09-03 12:08:38,061   INFO  Train:    2/20 ( 10%) [3337/3862 ( 86%)]  Loss: 2.189 (2.69)  LR: 2.153e-04  Grad: 30.4887  max=1.4861(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.2120(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8995, loss_cls=0.1558, loss_bbox=1.0713, matched_ious=0.4056, loss_iou=0.1045, loss_iou_reg=0.2624, d_time=0.00(0.01), f_time=1.42(1.43), b_time=1.43(1.44)  Time cost: 1:20:12/12:36 [2:52:49/28:03:04]  Acc_iter 7200        Data time: 0.00(0.01)  Forward time: 1.42(1.43)  Batch time: 1.43(1.44)
2025-09-03 12:09:50,345   INFO  Train:    2/20 ( 10%) [3387/3862 ( 88%)]  Loss: 2.469 (2.69)  LR: 2.168e-04  Grad: 32.4173  max=10.8854(module.vfe.pfn_layers.0.linear.weight)  min: -2.5613(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8796, loss_cls=0.1537, loss_bbox=1.0706, matched_ious=0.4089, loss_iou=0.1039, loss_iou_reg=0.2611, d_time=0.01(0.01), f_time=1.41(1.43), b_time=1.41(1.44)  Time cost: 1:21:24/11:24 [2:54:01/28:01:56]  Acc_iter 7250        Data time: 0.01(0.01)  Forward time: 1.41(1.43)  Batch time: 1.41(1.44)
2025-09-03 12:11:04,879   INFO  Train:    2/20 ( 10%) [3437/3862 ( 89%)]  Loss: 2.467 (2.69)  LR: 2.184e-04  Grad: 31.0044  max=3.3361(module.vfe.pfn_layers.0.linear.weight)  min: -4.2898(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8769, loss_cls=0.1550, loss_bbox=1.0854, matched_ious=0.4046, loss_iou=0.1039, loss_iou_reg=0.2628, d_time=0.00(0.01), f_time=1.41(1.43), b_time=1.41(1.44)  Time cost: 1:22:39/10:13 [2:55:15/28:01:34]  Acc_iter 7300        Data time: 0.00(0.01)  Forward time: 1.41(1.43)  Batch time: 1.41(1.44)
2025-09-03 12:12:16,122   INFO  Train:    2/20 ( 10%) [3487/3862 ( 90%)]  Loss: 2.267 (2.68)  LR: 2.199e-04  Grad: 31.2275  max=4.4198(module.vfe.pfn_layers.0.linear.weight)  min: -2.7222(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8622, loss_cls=0.1488, loss_bbox=1.0456, matched_ious=0.4146, loss_iou=0.1027, loss_iou_reg=0.2575, d_time=0.00(0.01), f_time=1.42(1.43), b_time=1.43(1.44)  Time cost: 1:23:50/09:00 [2:56:27/28:00:04]  Acc_iter 7350        Data time: 0.00(0.01)  Forward time: 1.42(1.43)  Batch time: 1.43(1.44)
2025-09-03 12:13:26,610   INFO  Train:    2/20 ( 10%) [3537/3862 ( 92%)]  Loss: 2.411 (2.68)  LR: 2.215e-04  Grad: 31.5977  max=5.9357(module.vfe.pfn_layers.0.linear.weight)  min: -1.3062(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.8871, loss_cls=0.1555, loss_bbox=1.0831, matched_ious=0.4042, loss_iou=0.1049, loss_iou_reg=0.2625, d_time=0.00(0.01), f_time=1.44(1.43), b_time=1.45(1.44)  Time cost: 1:25:01/07:48 [2:57:37/27:58:20]  Acc_iter 7400        Data time: 0.00(0.01)  Forward time: 1.44(1.43)  Batch time: 1.45(1.44)
2025-09-03 12:14:37,341   INFO  Train:    2/20 ( 10%) [3587/3862 ( 93%)]  Loss: 1.956 (2.68)  LR: 2.230e-04  Grad: 31.0822  max=3.7883(module.vfe.pfn_layers.0.linear.weight)  min: -2.0664(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8669, loss_cls=0.1533, loss_bbox=1.0529, matched_ious=0.4119, loss_iou=0.1033, loss_iou_reg=0.2600, d_time=0.01(0.01), f_time=1.33(1.43), b_time=1.33(1.44)  Time cost: 1:26:11/06:36 [2:58:48/27:56:41]  Acc_iter 7450        Data time: 0.01(0.01)  Forward time: 1.33(1.43)  Batch time: 1.33(1.44)
2025-09-03 12:15:48,904   INFO  Train:    2/20 ( 10%) [3637/3862 ( 94%)]  Loss: 2.801 (2.67)  LR: 2.246e-04  Grad: 31.1972  max=3.7020(module.vfe.pfn_layers.0.linear.weight)  min: -2.6587(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8771, loss_cls=0.1536, loss_bbox=1.0324, matched_ious=0.4138, loss_iou=0.1039, loss_iou_reg=0.2574, d_time=0.01(0.01), f_time=1.31(1.43), b_time=1.31(1.44)  Time cost: 1:27:23/05:24 [3:00:00/27:55:19]  Acc_iter 7500        Data time: 0.01(0.01)  Forward time: 1.31(1.43)  Batch time: 1.31(1.44)
2025-09-03 12:17:04,990   INFO  Train:    2/20 ( 10%) [3687/3862 ( 95%)]  Loss: 2.372 (2.67)  LR: 2.262e-04  Grad: 31.5616  max=8.5326(module.vfe.pfn_layers.0.linear.weight)  min: -1.2835(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.8649, loss_cls=0.1523, loss_bbox=1.0363, matched_ious=0.4175, loss_iou=0.1044, loss_iou_reg=0.2559, d_time=0.01(0.01), f_time=1.53(1.43), b_time=1.54(1.44)  Time cost: 1:28:39/04:12 [3:01:16/27:55:23]  Acc_iter 7550        Data time: 0.01(0.01)  Forward time: 1.53(1.43)  Batch time: 1.54(1.44)
2025-09-03 12:18:15,568   INFO  Train:    2/20 ( 10%) [3737/3862 ( 97%)]  Loss: 2.521 (2.67)  LR: 2.278e-04  Grad: 29.6467  max=1.4261(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.6228(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8688, loss_cls=0.1545, loss_bbox=1.0229, matched_ious=0.4162, loss_iou=0.1045, loss_iou_reg=0.2582, d_time=0.01(0.01), f_time=1.46(1.43), b_time=1.47(1.44)  Time cost: 1:29:50/03:00 [3:02:26/27:53:42]  Acc_iter 7600        Data time: 0.01(0.01)  Forward time: 1.46(1.43)  Batch time: 1.47(1.44)
2025-09-03 12:19:25,828   INFO  Train:    2/20 ( 10%) [3787/3862 ( 98%)]  Loss: 2.379 (2.66)  LR: 2.294e-04  Grad: 30.3476  max=6.0273(module.vfe.pfn_layers.0.linear.weight)  min: -2.7284(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8665, loss_cls=0.1519, loss_bbox=1.0443, matched_ious=0.4119, loss_iou=0.1042, loss_iou_reg=0.2609, d_time=0.00(0.01), f_time=1.58(1.43), b_time=1.58(1.44)  Time cost: 1:31:00/01:48 [3:03:36/27:51:56]  Acc_iter 7650        Data time: 0.00(0.01)  Forward time: 1.58(1.43)  Batch time: 1.58(1.44)
2025-09-03 12:20:37,036   INFO  Train:    2/20 ( 10%) [3837/3862 ( 99%)]  Loss: 2.296 (2.66)  LR: 2.310e-04  Grad: 31.2455  max=9.4664(module.vfe.pfn_layers.0.linear.weight)  min: -2.5270(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8605, loss_cls=0.1475, loss_bbox=1.0985, matched_ious=0.4092, loss_iou=0.1040, loss_iou_reg=0.2607, d_time=0.00(0.01), f_time=1.37(1.43), b_time=1.37(1.44)  Time cost: 1:32:11/00:36 [3:04:48/27:50:29]  Acc_iter 7700        Data time: 0.00(0.01)  Forward time: 1.37(1.43)  Batch time: 1.37(1.44)
2025-09-03 12:21:10,030   INFO  Train:    2/20 ( 10%) [3861/3862 (100%)]  Loss: 1.925 (2.66)  LR: 2.318e-04  Grad: 29.8301  max=3.8347(module.vfe.pfn_layers.0.linear.weight)  min: -4.5371(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8384, loss_cls=0.1487, loss_bbox=0.9409, matched_ious=0.4225, loss_iou=0.1039, loss_iou_reg=0.2555, d_time=0.00(0.01), f_time=1.37(1.43), b_time=1.37(1.44)  Time cost: 1:32:44/00:01 [3:05:21/27:49:25]  Acc_iter 7724        Data time: 0.00(0.01)  Forward time: 1.37(1.43)  Batch time: 1.37(1.44)

                                               [Aepochs:  10%|█         | 2/20 [3:05:21<27:48:30, 5561.70s/it]epochs:  10%|█         | 2/20 [3:05:21<27:48:30, 5561.69s/it]epochs:  10%|█         | 2/20 [3:05:21<27:48:30, 5561.71s/it]epochs:  10%|█         | 2/20 [3:05:21<27:48:30, 5561.71s/it]epochs:  10%|█         | 2/20 [3:05:21<27:48:30, 5561.72s/it]epochs:  10%|█         | 2/20 [3:05:21<27:48:31, 5561.73s/it]epochs:  10%|█         | 2/20 [3:05:21<27:48:31, 5561.73s/it]epochs:  10%|█         | 2/20 [3:05:21<27:48:31, 5561.75s/it]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-03 12:21:15,453   INFO  Train:    3/20 ( 15%) [   0/3862 (  0%)]  Loss: 2.104 (2.10)  LR: 2.318e-04  Grad: 29.3456  max=1.5620(module.vfe.pfn_layers.0.linear.weight)  min: -1.4570(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8057, loss_cls=0.1452, loss_bbox=0.7997, matched_ious=0.4422, loss_iou=0.1065, loss_iou_reg=0.2473, d_time=2.01(2.01), f_time=2.20(2.20), b_time=4.21(4.21)  Time cost: 00:04/4:19:55 [3:05:26/77:58:37]  Acc_iter 7725        Data time: 2.01(2.01)  Forward time: 2.20(2.20)  Batch time: 4.21(4.21)
2025-09-03 12:21:51,424   INFO  Train:    3/20 ( 15%) [  25/3862 (  1%)]  Loss: 2.027 (2.39)  LR: 2.326e-04  Grad: 29.3060  max=1.4041(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3411(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8598, loss_cls=0.1528, loss_bbox=1.0260, matched_ious=0.4220, loss_iou=0.1041, loss_iou_reg=0.2553, d_time=0.01(0.08), f_time=1.42(1.46), b_time=1.42(1.55)  Time cost: 00:40/1:38:27 [3:06:02/29:43:10]  Acc_iter 7750        Data time: 0.01(0.08)  Forward time: 1.42(1.46)  Batch time: 1.42(1.55)
2025-09-03 12:23:08,341   INFO  Train:    3/20 ( 15%) [  75/3862 (  2%)]  Loss: 2.175 (2.36)  LR: 2.342e-04  Grad: 28.5663  max=6.2107(module.vfe.pfn_layers.0.linear.weight)  min: -1.1711(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.8446, loss_cls=0.1508, loss_bbox=0.9939, matched_ious=0.4223, loss_iou=0.1037, loss_iou_reg=0.2567, d_time=0.01(0.04), f_time=1.34(1.50), b_time=1.35(1.54)  Time cost: 01:56/1:37:07 [3:07:19/29:40:53]  Acc_iter 7800        Data time: 0.01(0.04)  Forward time: 1.34(1.50)  Batch time: 1.35(1.54)
2025-09-03 12:24:19,689   INFO  Train:    3/20 ( 15%) [ 125/3862 (  3%)]  Loss: 2.807 (2.38)  LR: 2.359e-04  Grad: 28.0199  max=1.7112(module.vfe.pfn_layers.0.linear.weight)  min: -1.2107(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8611, loss_cls=0.1524, loss_bbox=1.0389, matched_ious=0.4228, loss_iou=0.1047, loss_iou_reg=0.2551, d_time=0.01(0.03), f_time=1.48(1.47), b_time=1.49(1.50)  Time cost: 03:08/1:33:04 [3:08:30/28:48:18]  Acc_iter 7850        Data time: 0.01(0.03)  Forward time: 1.48(1.47)  Batch time: 1.49(1.50)
2025-09-03 12:25:29,964   INFO  Train:    3/20 ( 15%) [ 175/3862 (  5%)]  Loss: 2.841 (2.39)  LR: 2.375e-04  Grad: 29.2209  max=3.1663(module.vfe.pfn_layers.0.linear.weight)  min: -7.7404(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8493, loss_cls=0.1469, loss_bbox=1.0484, matched_ious=0.4139, loss_iou=0.1045, loss_iou_reg=0.2592, d_time=0.01(0.02), f_time=1.36(1.45), b_time=1.37(1.47)  Time cost: 04:18/1:30:16 [3:09:41/28:17:52]  Acc_iter 7900        Data time: 0.01(0.02)  Forward time: 1.36(1.45)  Batch time: 1.37(1.47)
2025-09-03 12:26:42,254   INFO  Train:    3/20 ( 15%) [ 225/3862 (  6%)]  Loss: 3.443 (2.39)  LR: 2.392e-04  Grad: 28.4854  max=1.3398(module.dense_head.decoder.self_attn.in_proj_weight)  min: -4.3324(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8600, loss_cls=0.1515, loss_bbox=1.0214, matched_ious=0.4119, loss_iou=0.1047, loss_iou_reg=0.2608, d_time=0.01(0.02), f_time=1.48(1.45), b_time=1.48(1.46)  Time cost: 05:30/1:28:44 [3:10:53/28:10:38]  Acc_iter 7950        Data time: 0.01(0.02)  Forward time: 1.48(1.45)  Batch time: 1.48(1.46)
2025-09-03 12:27:53,856   INFO  Train:    3/20 ( 15%) [ 275/3862 (  7%)]  Loss: 2.320 (2.39)  LR: 2.408e-04  Grad: 30.2045  max=1.3415(module.dense_head.decoder.self_attn.in_proj_weight)  min: -10.3621(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8627, loss_cls=0.1505, loss_bbox=1.0291, matched_ious=0.4203, loss_iou=0.1036, loss_iou_reg=0.2559, d_time=0.01(0.02), f_time=1.37(1.44), b_time=1.38(1.46)  Time cost: 06:42/1:27:10 [3:12:04/28:02:44]  Acc_iter 8000        Data time: 0.01(0.02)  Forward time: 1.37(1.44)  Batch time: 1.38(1.46)
2025-09-03 12:29:08,860   INFO  Train:    3/20 ( 15%) [ 325/3862 (  8%)]  Loss: 2.054 (2.39)  LR: 2.425e-04  Grad: 28.5450  max=1.3471(module.dense_head.decoder.self_attn.in_proj_weight)  min: -3.3476(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8591, loss_cls=0.1503, loss_bbox=0.9956, matched_ious=0.4182, loss_iou=0.1036, loss_iou_reg=0.2581, d_time=0.00(0.01), f_time=1.36(1.45), b_time=1.37(1.47)  Time cost: 07:57/1:26:20 [3:13:19/28:08:57]  Acc_iter 8050        Data time: 0.00(0.01)  Forward time: 1.36(1.45)  Batch time: 1.37(1.47)
2025-09-03 12:30:19,386   INFO  Train:    3/20 ( 15%) [ 375/3862 ( 10%)]  Loss: 2.651 (2.39)  LR: 2.442e-04  Grad: 30.3054  max=9.6776(module.vfe.pfn_layers.0.linear.weight)  min: -2.9724(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8588, loss_cls=0.1489, loss_bbox=1.0478, matched_ious=0.4197, loss_iou=0.1039, loss_iou_reg=0.2567, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.43(1.46)  Time cost: 09:07/1:24:42 [3:14:30/27:59:27]  Acc_iter 8100        Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.43(1.46)
2025-09-03 12:31:31,193   INFO  Train:    3/20 ( 15%) [ 425/3862 ( 11%)]  Loss: 2.235 (2.39)  LR: 2.458e-04  Grad: 28.7601  max=2.6867(module.vfe.pfn_layers.0.linear.weight)  min: -3.4783(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8582, loss_cls=0.1486, loss_bbox=1.0039, matched_ious=0.4248, loss_iou=0.1016, loss_iou_reg=0.2536, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.42(1.46)  Time cost: 10:19/1:23:20 [3:15:42/27:55:22]  Acc_iter 8150        Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.46)
2025-09-03 12:32:42,131   INFO  Train:    3/20 ( 15%) [ 475/3862 ( 12%)]  Loss: 2.517 (2.39)  LR: 2.475e-04  Grad: 28.7037  max=3.5244(module.vfe.pfn_layers.0.linear.weight)  min: -1.1715(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.8667, loss_cls=0.1502, loss_bbox=1.0270, matched_ious=0.4180, loss_iou=0.1019, loss_iou_reg=0.2571, d_time=0.00(0.01), f_time=1.39(1.44), b_time=1.39(1.45)  Time cost: 11:30/1:21:54 [3:16:53/27:49:47]  Acc_iter 8200        Data time: 0.00(0.01)  Forward time: 1.39(1.44)  Batch time: 1.39(1.45)
2025-09-03 12:33:54,786   INFO  Train:    3/20 ( 15%) [ 525/3862 ( 14%)]  Loss: 2.449 (2.39)  LR: 2.492e-04  Grad: 28.6915  max=1.3590(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.5322(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8544, loss_cls=0.1476, loss_bbox=1.0031, matched_ious=0.4203, loss_iou=0.1019, loss_iou_reg=0.2572, d_time=0.01(0.01), f_time=1.46(1.44), b_time=1.46(1.45)  Time cost: 12:43/1:20:43 [3:18:05/27:48:47]  Acc_iter 8250        Data time: 0.01(0.01)  Forward time: 1.46(1.44)  Batch time: 1.46(1.45)
2025-09-03 12:35:09,433   INFO  Train:    3/20 ( 15%) [ 575/3862 ( 15%)]  Loss: 2.037 (2.39)  LR: 2.509e-04  Grad: 29.8386  max=3.2157(module.vfe.pfn_layers.0.linear.weight)  min: -7.6178(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8565, loss_cls=0.1471, loss_bbox=1.0041, matched_ious=0.4211, loss_iou=0.1026, loss_iou_reg=0.2563, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.42(1.46)  Time cost: 13:58/1:19:42 [3:19:20/27:51:43]  Acc_iter 8300        Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.46)
2025-09-03 12:36:20,421   INFO  Train:    3/20 ( 15%) [ 625/3862 ( 16%)]  Loss: 2.112 (2.38)  LR: 2.527e-04  Grad: 29.5882  max=6.9868(module.vfe.pfn_layers.0.linear.weight)  min: -1.8167(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8224, loss_cls=0.1456, loss_bbox=0.9573, matched_ious=0.4296, loss_iou=0.1022, loss_iou_reg=0.2539, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.38(1.45)  Time cost: 15:09/1:18:20 [3:20:31/27:47:18]  Acc_iter 8350        Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.38(1.45)
2025-09-03 12:37:31,225   INFO  Train:    3/20 ( 15%) [ 675/3862 ( 17%)]  Loss: 2.036 (2.37)  LR: 2.544e-04  Grad: 29.0613  max=1.3579(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.9997(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8376, loss_cls=0.1454, loss_bbox=0.9696, matched_ious=0.4277, loss_iou=0.1028, loss_iou_reg=0.2543, d_time=0.01(0.01), f_time=1.34(1.44), b_time=1.35(1.45)  Time cost: 16:19/1:16:59 [3:21:42/27:43:02]  Acc_iter 8400        Data time: 0.01(0.01)  Forward time: 1.34(1.44)  Batch time: 1.35(1.45)
2025-09-03 12:38:42,101   INFO  Train:    3/20 ( 15%) [ 725/3862 ( 19%)]  Loss: 2.198 (2.37)  LR: 2.561e-04  Grad: 28.6395  max=3.1286(module.vfe.pfn_layers.0.linear.weight)  min: -3.5222(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8244, loss_cls=0.1438, loss_bbox=0.9589, matched_ious=0.4330, loss_iou=0.1026, loss_iou_reg=0.2521, d_time=0.01(0.01), f_time=1.33(1.44), b_time=1.34(1.45)  Time cost: 17:30/1:15:40 [3:22:53/27:39:17]  Acc_iter 8450        Data time: 0.01(0.01)  Forward time: 1.33(1.44)  Batch time: 1.34(1.45)
2025-09-03 12:39:55,185   INFO  Train:    3/20 ( 15%) [ 775/3862 ( 20%)]  Loss: 2.309 (2.36)  LR: 2.578e-04  Grad: 27.9669  max=7.1476(module.vfe.pfn_layers.0.linear.weight)  min: -3.5449(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8298, loss_cls=0.1458, loss_bbox=0.9334, matched_ious=0.4341, loss_iou=0.1016, loss_iou_reg=0.2531, d_time=0.00(0.01), f_time=2.31(1.44), b_time=2.31(1.45)  Time cost: 18:43/1:14:30 [3:24:06/27:39:09]  Acc_iter 8500        Data time: 0.00(0.01)  Forward time: 2.31(1.44)  Batch time: 2.31(1.45)
2025-09-03 12:41:09,047   INFO  Train:    3/20 ( 15%) [ 825/3862 ( 21%)]  Loss: 2.360 (2.36)  LR: 2.596e-04  Grad: 27.9002  max=6.0739(module.vfe.pfn_layers.0.linear.weight)  min: -1.0861(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.8274, loss_cls=0.1457, loss_bbox=0.9750, matched_ious=0.4274, loss_iou=0.1036, loss_iou_reg=0.2559, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 19:57/1:13:23 [3:25:20/27:39:58]  Acc_iter 8550        Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-03 12:42:20,641   INFO  Train:    3/20 ( 15%) [ 875/3862 ( 23%)]  Loss: 2.043 (2.36)  LR: 2.613e-04  Grad: 27.6176  max=5.8646(module.vfe.pfn_layers.0.linear.weight)  min: -1.9202(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8348, loss_cls=0.1474, loss_bbox=0.9859, matched_ious=0.4281, loss_iou=0.1024, loss_iou_reg=0.2544, d_time=0.01(0.01), f_time=1.49(1.44), b_time=1.50(1.45)  Time cost: 21:09/1:12:07 [3:26:31/27:37:34]  Acc_iter 8600        Data time: 0.01(0.01)  Forward time: 1.49(1.44)  Batch time: 1.50(1.45)
2025-09-03 12:43:31,260   INFO  Train:    3/20 ( 15%) [ 925/3862 ( 24%)]  Loss: 2.385 (2.35)  LR: 2.631e-04  Grad: 29.1491  max=1.2679(module.dense_head.decoder.self_attn.in_proj_weight)  min: -9.8787(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8295, loss_cls=0.1444, loss_bbox=0.9738, matched_ious=0.4277, loss_iou=0.1028, loss_iou_reg=0.2564, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 22:19/1:10:49 [3:27:42/27:34:06]  Acc_iter 8650        Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-03 12:44:43,391   INFO  Train:    3/20 ( 15%) [ 975/3862 ( 25%)]  Loss: 2.397 (2.35)  LR: 2.649e-04  Grad: 27.4008  max=4.6214(module.vfe.pfn_layers.0.linear.weight)  min: -1.0857(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.8305, loss_cls=0.1429, loss_bbox=1.0188, matched_ious=0.4236, loss_iou=0.1029, loss_iou_reg=0.2567, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 23:31/1:09:36 [3:28:54/27:32:39]  Acc_iter 8700        Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-03 12:45:57,687   INFO  Train:    3/20 ( 15%) [1025/3862 ( 27%)]  Loss: 2.625 (2.35)  LR: 2.666e-04  Grad: 27.7418  max=1.2671(module.dense_head.decoder.self_attn.in_proj_weight)  min: -4.5263(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8429, loss_cls=0.1471, loss_bbox=0.9865, matched_ious=0.4259, loss_iou=0.1023, loss_iou_reg=0.2557, d_time=0.01(0.01), f_time=2.29(1.44), b_time=2.29(1.45)  Time cost: 24:46/1:08:29 [3:30:08/27:33:38]  Acc_iter 8750        Data time: 0.01(0.01)  Forward time: 2.29(1.44)  Batch time: 2.29(1.45)
2025-09-03 12:47:09,434   INFO  Train:    3/20 ( 15%) [1075/3862 ( 28%)]  Loss: 2.647 (2.35)  LR: 2.684e-04  Grad: 25.8652  max=3.8076(module.vfe.pfn_layers.0.linear.weight)  min: -1.0241(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.8364, loss_cls=0.1472, loss_bbox=0.9649, matched_ious=0.4264, loss_iou=0.1033, loss_iou_reg=0.2566, d_time=0.00(0.01), f_time=1.52(1.44), b_time=1.53(1.45)  Time cost: 25:58/1:07:15 [3:31:20/27:31:41]  Acc_iter 8800        Data time: 0.00(0.01)  Forward time: 1.52(1.44)  Batch time: 1.53(1.45)
2025-09-03 12:48:20,047   INFO  Train:    3/20 ( 15%) [1125/3862 ( 29%)]  Loss: 2.123 (2.35)  LR: 2.702e-04  Grad: 26.2498  max=1.0644(module.dense_head.decoder.self_attn.in_proj_weight)  min: -9.0199(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8311, loss_cls=0.1468, loss_bbox=0.9597, matched_ious=0.4359, loss_iou=0.1013, loss_iou_reg=0.2522, d_time=0.01(0.01), f_time=1.47(1.43), b_time=1.47(1.45)  Time cost: 27:08/1:05:58 [3:32:31/27:28:41]  Acc_iter 8850        Data time: 0.01(0.01)  Forward time: 1.47(1.43)  Batch time: 1.47(1.45)
2025-09-03 12:49:31,564   INFO  Train:    3/20 ( 15%) [1175/3862 ( 30%)]  Loss: 2.330 (2.34)  LR: 2.720e-04  Grad: 25.0202  max=1.0672(module.dense_head.decoder.self_attn.in_proj_weight)  min: -10.2728(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8279, loss_cls=0.1445, loss_bbox=0.9499, matched_ious=0.4379, loss_iou=0.1012, loss_iou_reg=0.2515, d_time=0.01(0.01), f_time=1.43(1.43), b_time=1.43(1.45)  Time cost: 28:20/1:04:44 [3:33:42/27:26:42]  Acc_iter 8900        Data time: 0.01(0.01)  Forward time: 1.43(1.43)  Batch time: 1.43(1.45)
2025-09-03 12:50:42,656   INFO  Train:    3/20 ( 15%) [1225/3862 ( 32%)]  Loss: 2.342 (2.34)  LR: 2.738e-04  Grad: 23.9881  max=5.8379(module.vfe.pfn_layers.0.linear.weight)  min: -0.9099(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.8261, loss_cls=0.1433, loss_bbox=0.9682, matched_ious=0.4323, loss_iou=0.1032, loss_iou_reg=0.2517, d_time=0.01(0.01), f_time=1.35(1.43), b_time=1.36(1.44)  Time cost: 29:31/1:03:29 [3:34:53/27:24:23]  Acc_iter 8950        Data time: 0.01(0.01)  Forward time: 1.35(1.43)  Batch time: 1.36(1.44)
2025-09-03 12:51:57,450   INFO  Train:    3/20 ( 15%) [1275/3862 ( 33%)]  Loss: 2.712 (2.34)  LR: 2.756e-04  Grad: 23.6000  max=2.1642(module.vfe.pfn_layers.0.linear.weight)  min: -5.0829(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8369, loss_cls=0.1456, loss_bbox=1.0053, matched_ious=0.4267, loss_iou=0.1017, loss_iou_reg=0.2556, d_time=0.01(0.01), f_time=2.47(1.43), b_time=2.48(1.45)  Time cost: 30:46/1:02:22 [3:36:08/27:25:27]  Acc_iter 9000        Data time: 0.01(0.01)  Forward time: 2.47(1.43)  Batch time: 2.48(1.45)
2025-09-03 12:53:08,760   INFO  Train:    3/20 ( 15%) [1325/3862 ( 34%)]  Loss: 2.149 (2.34)  LR: 2.774e-04  Grad: 23.3217  max=3.1683(module.vfe.pfn_layers.0.linear.weight)  min: -2.2694(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8145, loss_cls=0.1424, loss_bbox=0.9746, matched_ious=0.4288, loss_iou=0.1025, loss_iou_reg=0.2554, d_time=0.01(0.01), f_time=1.37(1.43), b_time=1.38(1.45)  Time cost: 31:57/1:01:08 [3:37:19/27:23:22]  Acc_iter 9050        Data time: 0.01(0.01)  Forward time: 1.37(1.43)  Batch time: 1.38(1.45)
2025-09-03 12:54:19,529   INFO  Train:    3/20 ( 15%) [1375/3862 ( 36%)]  Loss: 2.269 (2.34)  LR: 2.793e-04  Grad: 23.6221  max=1.0719(module.dense_head.decoder.self_attn.in_proj_weight)  min: -4.8375(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8259, loss_cls=0.1448, loss_bbox=0.9464, matched_ious=0.4328, loss_iou=0.1018, loss_iou_reg=0.2526, d_time=0.01(0.01), f_time=1.48(1.43), b_time=1.48(1.44)  Time cost: 33:08/59:53 [3:38:30/27:20:54]  Acc_iter 9100        Data time: 0.01(0.01)  Forward time: 1.48(1.43)  Batch time: 1.48(1.44)
2025-09-03 12:55:32,106   INFO  Train:    3/20 ( 15%) [1425/3862 ( 37%)]  Loss: 2.282 (2.34)  LR: 2.811e-04  Grad: 24.2545  max=4.9582(module.vfe.pfn_layers.0.linear.weight)  min: -4.6125(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8317, loss_cls=0.1427, loss_bbox=0.9730, matched_ious=0.4347, loss_iou=0.1025, loss_iou_reg=0.2527, d_time=0.01(0.01), f_time=1.41(1.43), b_time=1.42(1.45)  Time cost: 34:20/58:41 [3:39:43/27:19:58]  Acc_iter 9150        Data time: 0.01(0.01)  Forward time: 1.41(1.43)  Batch time: 1.42(1.45)
2025-09-03 12:56:42,963   INFO  Train:    3/20 ( 15%) [1475/3862 ( 38%)]  Loss: 2.055 (2.34)  LR: 2.829e-04  Grad: 23.6016  max=2.2144(module.vfe.pfn_layers.0.linear.weight)  min: -4.0184(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8176, loss_cls=0.1443, loss_bbox=0.9868, matched_ious=0.4305, loss_iou=0.1009, loss_iou_reg=0.2546, d_time=0.01(0.01), f_time=1.37(1.43), b_time=1.38(1.44)  Time cost: 35:31/57:27 [3:40:54/27:17:41]  Acc_iter 9200        Data time: 0.01(0.01)  Forward time: 1.37(1.43)  Batch time: 1.38(1.44)
2025-09-03 12:57:57,752   INFO  Train:    3/20 ( 15%) [1525/3862 ( 39%)]  Loss: 2.363 (2.33)  LR: 2.848e-04  Grad: 23.5033  max=2.5687(module.vfe.pfn_layers.0.linear.weight)  min: -3.2757(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8186, loss_cls=0.1414, loss_bbox=0.9593, matched_ious=0.4318, loss_iou=0.1026, loss_iou_reg=0.2546, d_time=0.01(0.01), f_time=1.27(1.43), b_time=1.28(1.45)  Time cost: 36:46/56:18 [3:42:08/27:18:24]  Acc_iter 9250        Data time: 0.01(0.01)  Forward time: 1.27(1.43)  Batch time: 1.28(1.45)
2025-09-03 12:59:08,681   INFO  Train:    3/20 ( 15%) [1575/3862 ( 41%)]  Loss: 2.184 (2.33)  LR: 2.866e-04  Grad: 23.5087  max=1.3778(module.vfe.pfn_layers.0.linear.weight)  min: -3.5086(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8411, loss_cls=0.1442, loss_bbox=0.9800, matched_ious=0.4365, loss_iou=0.1001, loss_iou_reg=0.2526, d_time=0.01(0.01), f_time=1.35(1.43), b_time=1.35(1.45)  Time cost: 37:57/55:04 [3:43:19/27:16:13]  Acc_iter 9300        Data time: 0.01(0.01)  Forward time: 1.35(1.43)  Batch time: 1.35(1.45)
2025-09-03 13:00:20,083   INFO  Train:    3/20 ( 15%) [1625/3862 ( 42%)]  Loss: 2.619 (2.33)  LR: 2.885e-04  Grad: 24.9083  max=8.7653(module.vfe.pfn_layers.0.linear.weight)  min: -0.9094(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.8266, loss_cls=0.1452, loss_bbox=0.9534, matched_ious=0.4379, loss_iou=0.1004, loss_iou_reg=0.2522, d_time=0.01(0.01), f_time=1.41(1.43), b_time=1.42(1.44)  Time cost: 39:08/53:51 [3:44:31/27:14:25]  Acc_iter 9350        Data time: 0.01(0.01)  Forward time: 1.41(1.43)  Batch time: 1.42(1.44)
2025-09-03 13:01:32,391   INFO  Train:    3/20 ( 15%) [1675/3862 ( 43%)]  Loss: 2.108 (2.33)  LR: 2.903e-04  Grad: 23.5472  max=1.4487(module.vfe.pfn_layers.0.linear.weight)  min: -2.7418(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8416, loss_cls=0.1440, loss_bbox=0.9976, matched_ious=0.4307, loss_iou=0.1013, loss_iou_reg=0.2544, d_time=0.01(0.01), f_time=1.43(1.43), b_time=1.44(1.44)  Time cost: 40:20/52:39 [3:45:43/27:13:16]  Acc_iter 9400        Data time: 0.01(0.01)  Forward time: 1.43(1.43)  Batch time: 1.44(1.44)
2025-09-03 13:02:43,112   INFO  Train:    3/20 ( 15%) [1725/3862 ( 45%)]  Loss: 1.892 (2.33)  LR: 2.922e-04  Grad: 23.7594  max=3.7380(module.vfe.pfn_layers.0.linear.weight)  min: -0.9102(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.8017, loss_cls=0.1380, loss_bbox=0.9461, matched_ious=0.4397, loss_iou=0.1037, loss_iou_reg=0.2517, d_time=0.00(0.01), f_time=1.32(1.43), b_time=1.32(1.44)  Time cost: 41:31/51:25 [3:46:54/27:11:05]  Acc_iter 9450        Data time: 0.00(0.01)  Forward time: 1.32(1.43)  Batch time: 1.32(1.44)
2025-09-03 13:03:57,690   INFO  Train:    3/20 ( 15%) [1775/3862 ( 46%)]  Loss: 2.618 (2.33)  LR: 2.941e-04  Grad: 26.0094  max=1.0769(module.dense_head.decoder.self_attn.in_proj_weight)  min: -9.1434(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7921, loss_cls=0.1364, loss_bbox=0.9471, matched_ious=0.4343, loss_iou=0.1020, loss_iou_reg=0.2559, d_time=0.00(0.01), f_time=1.37(1.43), b_time=1.37(1.45)  Time cost: 42:46/50:15 [3:48:08/27:11:24]  Acc_iter 9500        Data time: 0.00(0.01)  Forward time: 1.37(1.43)  Batch time: 1.37(1.45)
2025-09-03 13:05:07,711   INFO  Train:    3/20 ( 15%) [1825/3862 ( 47%)]  Loss: 1.960 (2.32)  LR: 2.960e-04  Grad: 21.3931  max=5.2822(module.vfe.pfn_layers.0.linear.weight)  min: -4.0430(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8162, loss_cls=0.1406, loss_bbox=0.9455, matched_ious=0.4348, loss_iou=0.1012, loss_iou_reg=0.2521, d_time=0.01(0.01), f_time=1.39(1.43), b_time=1.39(1.44)  Time cost: 43:56/49:00 [3:49:18/27:08:49]  Acc_iter 9550        Data time: 0.01(0.01)  Forward time: 1.39(1.43)  Batch time: 1.39(1.44)
2025-09-03 13:06:19,546   INFO  Train:    3/20 ( 15%) [1875/3862 ( 49%)]  Loss: 2.028 (2.32)  LR: 2.979e-04  Grad: 20.8363  max=4.5839(module.vfe.pfn_layers.0.linear.weight)  min: -2.2055(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7931, loss_cls=0.1384, loss_bbox=0.9145, matched_ious=0.4433, loss_iou=0.1021, loss_iou_reg=0.2524, d_time=0.01(0.01), f_time=1.43(1.43), b_time=1.43(1.44)  Time cost: 45:08/47:48 [3:50:30/27:07:24]  Acc_iter 9600        Data time: 0.01(0.01)  Forward time: 1.43(1.43)  Batch time: 1.43(1.44)
2025-09-03 13:07:29,938   INFO  Train:    3/20 ( 15%) [1925/3862 ( 50%)]  Loss: 2.777 (2.32)  LR: 2.998e-04  Grad: 21.4451  max=2.9917(module.vfe.pfn_layers.0.linear.weight)  min: -6.8863(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8095, loss_cls=0.1429, loss_bbox=0.9643, matched_ious=0.4364, loss_iou=0.1009, loss_iou_reg=0.2542, d_time=0.00(0.01), f_time=1.43(1.43), b_time=1.43(1.44)  Time cost: 46:18/46:34 [3:51:41/27:05:10]  Acc_iter 9650        Data time: 0.00(0.01)  Forward time: 1.43(1.43)  Batch time: 1.43(1.44)
2025-09-03 13:08:41,317   INFO  Train:    3/20 ( 15%) [1975/3862 ( 51%)]  Loss: 2.132 (2.32)  LR: 3.017e-04  Grad: 20.6802  max=4.0197(module.vfe.pfn_layers.0.linear.weight)  min: -3.7866(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8034, loss_cls=0.1409, loss_bbox=0.9339, matched_ious=0.4395, loss_iou=0.1004, loss_iou_reg=0.2505, d_time=0.01(0.01), f_time=1.46(1.43), b_time=1.46(1.44)  Time cost: 47:29/45:21 [3:52:52/27:03:32]  Acc_iter 9700        Data time: 0.01(0.01)  Forward time: 1.46(1.43)  Batch time: 1.46(1.44)
2025-09-03 13:09:56,371   INFO  Train:    3/20 ( 15%) [2025/3862 ( 52%)]  Loss: 2.366 (2.31)  LR: 3.036e-04  Grad: 21.0076  max=3.1573(module.vfe.pfn_layers.0.linear.weight)  min: -5.8492(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7873, loss_cls=0.1377, loss_bbox=0.9136, matched_ious=0.4479, loss_iou=0.1004, loss_iou_reg=0.2494, d_time=0.01(0.01), f_time=1.36(1.43), b_time=1.36(1.44)  Time cost: 48:44/44:12 [3:54:07/27:03:58]  Acc_iter 9750        Data time: 0.01(0.01)  Forward time: 1.36(1.43)  Batch time: 1.36(1.44)
2025-09-03 13:11:06,597   INFO  Train:    3/20 ( 15%) [2075/3862 ( 54%)]  Loss: 1.862 (2.31)  LR: 3.055e-04  Grad: 21.2268  max=5.5183(module.vfe.pfn_layers.0.linear.weight)  min: -0.7669(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.8075, loss_cls=0.1400, loss_bbox=0.9442, matched_ious=0.4427, loss_iou=0.1004, loss_iou_reg=0.2512, d_time=0.00(0.01), f_time=1.40(1.43), b_time=1.40(1.44)  Time cost: 49:55/42:58 [3:55:17/27:01:42]  Acc_iter 9800        Data time: 0.00(0.01)  Forward time: 1.40(1.43)  Batch time: 1.40(1.44)
2025-09-03 13:12:18,784   INFO  Train:    3/20 ( 15%) [2125/3862 ( 55%)]  Loss: 2.044 (2.31)  LR: 3.074e-04  Grad: 19.4477  max=0.8483(module.dense_head.decoder.self_attn.in_proj_weight)  min: -3.4991(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8255, loss_cls=0.1428, loss_bbox=0.9507, matched_ious=0.4403, loss_iou=0.1011, loss_iou_reg=0.2517, d_time=0.00(0.01), f_time=1.47(1.43), b_time=1.47(1.44)  Time cost: 51:07/41:46 [3:56:29/27:00:31]  Acc_iter 9850        Data time: 0.00(0.01)  Forward time: 1.47(1.43)  Batch time: 1.47(1.44)
2025-09-03 13:13:29,417   INFO  Train:    3/20 ( 15%) [2175/3862 ( 56%)]  Loss: 2.289 (2.31)  LR: 3.094e-04  Grad: 20.2920  max=5.7994(module.vfe.pfn_layers.0.linear.weight)  min: -3.9343(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7983, loss_cls=0.1373, loss_bbox=0.9065, matched_ious=0.4420, loss_iou=0.1018, loss_iou_reg=0.2500, d_time=0.01(0.01), f_time=1.51(1.43), b_time=1.52(1.44)  Time cost: 52:18/40:32 [3:57:40/26:58:32]  Acc_iter 9900        Data time: 0.01(0.01)  Forward time: 1.51(1.43)  Batch time: 1.52(1.44)
2025-09-03 13:14:40,724   INFO  Train:    3/20 ( 15%) [2225/3862 ( 58%)]  Loss: 1.977 (2.31)  LR: 3.113e-04  Grad: 23.5237  max=0.8550(module.dense_head.decoder.self_attn.in_proj_weight)  min: -13.5619(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8040, loss_cls=0.1415, loss_bbox=0.9166, matched_ious=0.4465, loss_iou=0.1005, loss_iou_reg=0.2480, d_time=0.00(0.01), f_time=1.48(1.43), b_time=1.48(1.44)  Time cost: 53:29/39:20 [3:58:51/26:56:56]  Acc_iter 9950        Data time: 0.00(0.01)  Forward time: 1.48(1.43)  Batch time: 1.48(1.44)
2025-09-03 13:15:56,612   INFO  Train:    3/20 ( 15%) [2275/3862 ( 59%)]  Loss: 2.388 (2.31)  LR: 3.132e-04  Grad: 20.8730  max=4.2010(module.vfe.pfn_layers.0.linear.weight)  min: -7.0537(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8188, loss_cls=0.1416, loss_bbox=0.9400, matched_ious=0.4419, loss_iou=0.1023, loss_iou_reg=0.2506, d_time=0.00(0.01), f_time=1.40(1.43), b_time=1.40(1.44)  Time cost: 54:45/38:10 [4:00:07/26:57:36]  Acc_iter 10000       Data time: 0.00(0.01)  Forward time: 1.40(1.43)  Batch time: 1.40(1.44)
2025-09-03 13:17:07,161   INFO  Train:    3/20 ( 15%) [2325/3862 ( 60%)]  Loss: 1.917 (2.30)  LR: 3.152e-04  Grad: 21.0939  max=7.0191(module.vfe.pfn_layers.0.linear.weight)  min: -4.6755(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8017, loss_cls=0.1379, loss_bbox=0.9481, matched_ious=0.4307, loss_iou=0.1006, loss_iou_reg=0.2574, d_time=0.00(0.01), f_time=1.41(1.43), b_time=1.41(1.44)  Time cost: 55:55/36:57 [4:01:18/26:55:37]  Acc_iter 10050       Data time: 0.00(0.01)  Forward time: 1.41(1.43)  Batch time: 1.41(1.44)
2025-09-03 13:18:19,333   INFO  Train:    3/20 ( 15%) [2375/3862 ( 61%)]  Loss: 2.136 (2.30)  LR: 3.171e-04  Grad: 19.6092  max=3.7190(module.vfe.pfn_layers.0.linear.weight)  min: -0.7211(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7774, loss_cls=0.1371, loss_bbox=0.8845, matched_ious=0.4441, loss_iou=0.1013, loss_iou_reg=0.2526, d_time=0.01(0.01), f_time=1.49(1.43), b_time=1.50(1.44)  Time cost: 57:07/35:45 [4:02:30/26:54:26]  Acc_iter 10100       Data time: 0.01(0.01)  Forward time: 1.49(1.43)  Batch time: 1.50(1.44)
2025-09-03 13:19:29,808   INFO  Train:    3/20 ( 15%) [2425/3862 ( 63%)]  Loss: 2.221 (2.30)  LR: 3.191e-04  Grad: 20.0988  max=2.8939(module.vfe.pfn_layers.0.linear.weight)  min: -4.9262(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8048, loss_cls=0.1401, loss_bbox=0.9109, matched_ious=0.4501, loss_iou=0.0997, loss_iou_reg=0.2470, d_time=0.01(0.01), f_time=1.33(1.43), b_time=1.33(1.44)  Time cost: 58:18/34:32 [4:03:40/26:52:28]  Acc_iter 10150       Data time: 0.01(0.01)  Forward time: 1.33(1.43)  Batch time: 1.33(1.44)
2025-09-03 13:20:40,335   INFO  Train:    3/20 ( 15%) [2475/3862 ( 64%)]  Loss: 2.269 (2.30)  LR: 3.211e-04  Grad: 24.2759  max=13.2442(module.vfe.pfn_layers.0.linear.weight)  min: -6.7231(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8063, loss_cls=0.1405, loss_bbox=0.9331, matched_ious=0.4397, loss_iou=0.1019, loss_iou_reg=0.2519, d_time=0.01(0.01), f_time=1.38(1.43), b_time=1.38(1.44)  Time cost: 59:28/33:19 [4:04:51/26:50:33]  Acc_iter 10200       Data time: 0.01(0.01)  Forward time: 1.38(1.43)  Batch time: 1.38(1.44)
2025-09-03 13:21:55,361   INFO  Train:    3/20 ( 15%) [2525/3862 ( 65%)]  Loss: 2.035 (2.30)  LR: 3.230e-04  Grad: 22.7207  max=11.4871(module.vfe.pfn_layers.0.linear.weight)  min: -3.5786(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7995, loss_cls=0.1362, loss_bbox=0.9177, matched_ious=0.4470, loss_iou=0.1017, loss_iou_reg=0.2511, d_time=0.01(0.01), f_time=1.39(1.43), b_time=1.39(1.44)  Time cost: 1:00:43/32:08 [4:06:06/26:50:40]  Acc_iter 10250       Data time: 0.01(0.01)  Forward time: 1.39(1.43)  Batch time: 1.39(1.44)
2025-09-03 13:23:06,015   INFO  Train:    3/20 ( 15%) [2575/3862 ( 67%)]  Loss: 2.239 (2.29)  LR: 3.250e-04  Grad: 20.8083  max=6.8521(module.vfe.pfn_layers.0.linear.weight)  min: -3.6368(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8052, loss_cls=0.1389, loss_bbox=0.9343, matched_ious=0.4456, loss_iou=0.1005, loss_iou_reg=0.2497, d_time=0.01(0.01), f_time=1.34(1.43), b_time=1.35(1.44)  Time cost: 1:01:54/30:55 [4:07:17/26:48:49]  Acc_iter 10300       Data time: 0.01(0.01)  Forward time: 1.34(1.43)  Batch time: 1.35(1.44)
2025-09-03 13:24:17,308   INFO  Train:    3/20 ( 15%) [2625/3862 ( 68%)]  Loss: 2.086 (2.29)  LR: 3.270e-04  Grad: 17.1178  max=1.2228(module.vfe.pfn_layers.0.linear.weight)  min: -0.9799(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8039, loss_cls=0.1390, loss_bbox=0.9438, matched_ious=0.4443, loss_iou=0.1023, loss_iou_reg=0.2506, d_time=0.01(0.01), f_time=1.41(1.43), b_time=1.41(1.44)  Time cost: 1:03:05/29:43 [4:08:28/26:47:16]  Acc_iter 10350       Data time: 0.01(0.01)  Forward time: 1.41(1.43)  Batch time: 1.41(1.44)
2025-09-03 13:25:28,616   INFO  Train:    3/20 ( 15%) [2675/3862 ( 69%)]  Loss: 2.291 (2.29)  LR: 3.290e-04  Grad: 17.4573  max=1.9433(module.vfe.pfn_layers.0.linear.weight)  min: -2.1586(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8079, loss_cls=0.1384, loss_bbox=0.9288, matched_ious=0.4394, loss_iou=0.1008, loss_iou_reg=0.2537, d_time=0.00(0.01), f_time=1.65(1.43), b_time=1.66(1.44)  Time cost: 1:04:17/28:30 [4:09:39/26:45:45]  Acc_iter 10400       Data time: 0.00(0.01)  Forward time: 1.65(1.43)  Batch time: 1.66(1.44)
2025-09-03 13:26:39,719   INFO  Train:    3/20 ( 15%) [2725/3862 ( 71%)]  Loss: 2.343 (2.29)  LR: 3.310e-04  Grad: 18.2146  max=2.9889(module.vfe.pfn_layers.0.linear.weight)  min: -4.7920(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8044, loss_cls=0.1374, loss_bbox=0.9250, matched_ious=0.4390, loss_iou=0.1007, loss_iou_reg=0.2544, d_time=0.00(0.01), f_time=1.37(1.43), b_time=1.37(1.44)  Time cost: 1:05:28/27:18 [4:10:50/26:44:09]  Acc_iter 10450       Data time: 0.00(0.01)  Forward time: 1.37(1.43)  Batch time: 1.37(1.44)
2025-09-03 13:27:55,434   INFO  Train:    3/20 ( 15%) [2775/3862 ( 72%)]  Loss: 2.286 (2.29)  LR: 3.330e-04  Grad: 17.6540  max=1.9536(module.vfe.pfn_layers.0.linear.weight)  min: -2.9530(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8027, loss_cls=0.1392, loss_bbox=0.9314, matched_ious=0.4434, loss_iou=0.1003, loss_iou_reg=0.2509, d_time=0.01(0.01), f_time=1.36(1.43), b_time=1.37(1.44)  Time cost: 1:06:44/26:07 [4:12:06/26:44:25]  Acc_iter 10500       Data time: 0.01(0.01)  Forward time: 1.36(1.43)  Batch time: 1.37(1.44)
2025-09-03 13:29:07,272   INFO  Train:    3/20 ( 15%) [2825/3862 ( 73%)]  Loss: 2.147 (2.29)  LR: 3.350e-04  Grad: 23.2796  max=15.4289(module.vfe.pfn_layers.0.linear.weight)  min: -0.6440(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7967, loss_cls=0.1359, loss_bbox=0.9148, matched_ious=0.4503, loss_iou=0.1020, loss_iou_reg=0.2487, d_time=0.01(0.01), f_time=1.33(1.43), b_time=1.33(1.44)  Time cost: 1:07:55/24:55 [4:13:18/26:43:06]  Acc_iter 10550       Data time: 0.01(0.01)  Forward time: 1.33(1.43)  Batch time: 1.33(1.44)
2025-09-03 13:30:17,693   INFO  Train:    3/20 ( 15%) [2875/3862 ( 74%)]  Loss: 2.171 (2.29)  LR: 3.370e-04  Grad: 35.0000  max=17.7321(module.vfe.pfn_layers.0.linear.weight)  min: -25.6507(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7820, loss_cls=0.1370, loss_bbox=0.9042, matched_ious=0.4537, loss_iou=0.0999, loss_iou_reg=0.2473, d_time=0.01(0.01), f_time=1.31(1.43), b_time=1.32(1.44)  Time cost: 1:09:06/23:42 [4:14:28/26:41:15]  Acc_iter 10600       Data time: 0.01(0.01)  Forward time: 1.31(1.43)  Batch time: 1.32(1.44)
2025-09-03 13:31:28,614   INFO  Train:    3/20 ( 15%) [2925/3862 ( 76%)]  Loss: 2.096 (2.28)  LR: 3.390e-04  Grad: 15.8100  max=0.6718(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.9708(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7599, loss_cls=0.1311, loss_bbox=0.8716, matched_ious=0.4547, loss_iou=0.1008, loss_iou_reg=0.2480, d_time=0.01(0.01), f_time=1.53(1.43), b_time=1.53(1.44)  Time cost: 1:10:17/22:30 [4:15:39/26:39:37]  Acc_iter 10650       Data time: 0.01(0.01)  Forward time: 1.53(1.43)  Batch time: 1.53(1.44)
2025-09-03 13:32:39,604   INFO  Train:    3/20 ( 15%) [2975/3862 ( 77%)]  Loss: 2.067 (2.28)  LR: 3.410e-04  Grad: 17.7117  max=8.0182(module.vfe.pfn_layers.0.linear.weight)  min: -0.5748(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7960, loss_cls=0.1401, loss_bbox=0.9165, matched_ious=0.4399, loss_iou=0.1025, loss_iou_reg=0.2530, d_time=0.01(0.01), f_time=1.51(1.43), b_time=1.51(1.44)  Time cost: 1:11:28/21:18 [4:16:50/26:38:00]  Acc_iter 10700       Data time: 0.01(0.01)  Forward time: 1.51(1.43)  Batch time: 1.51(1.44)
2025-09-03 13:33:55,134   INFO  Train:    3/20 ( 15%) [3025/3862 ( 78%)]  Loss: 2.029 (2.28)  LR: 3.431e-04  Grad: 16.7527  max=0.6753(module.dense_head.decoder.self_attn.in_proj_weight)  min: -5.0623(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.8149, loss_cls=0.1405, loss_bbox=0.9000, matched_ious=0.4455, loss_iou=0.1003, loss_iou_reg=0.2509, d_time=0.00(0.01), f_time=1.46(1.43), b_time=1.46(1.44)  Time cost: 1:12:43/20:07 [4:18:06/26:38:05]  Acc_iter 10750       Data time: 0.00(0.01)  Forward time: 1.46(1.43)  Batch time: 1.46(1.44)
2025-09-03 13:35:06,016   INFO  Train:    3/20 ( 15%) [3075/3862 ( 80%)]  Loss: 1.852 (2.28)  LR: 3.451e-04  Grad: 16.2536  max=0.6740(module.dense_head.decoder.self_attn.in_proj_weight)  min: -3.5466(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7727, loss_cls=0.1356, loss_bbox=0.8764, matched_ious=0.4531, loss_iou=0.0989, loss_iou_reg=0.2482, d_time=0.00(0.01), f_time=1.39(1.43), b_time=1.39(1.44)  Time cost: 1:13:54/18:54 [4:19:17/26:36:26]  Acc_iter 10800       Data time: 0.00(0.01)  Forward time: 1.39(1.43)  Batch time: 1.39(1.44)
2025-09-03 13:36:16,481   INFO  Train:    3/20 ( 15%) [3125/3862 ( 81%)]  Loss: 2.612 (2.28)  LR: 3.471e-04  Grad: 17.7532  max=2.3530(module.vfe.pfn_layers.0.linear.weight)  min: -8.4145(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7829, loss_cls=0.1350, loss_bbox=0.8996, matched_ious=0.4500, loss_iou=0.0988, loss_iou_reg=0.2495, d_time=0.00(0.01), f_time=1.42(1.43), b_time=1.42(1.44)  Time cost: 1:15:05/17:42 [4:20:27/26:34:40]  Acc_iter 10850       Data time: 0.00(0.01)  Forward time: 1.42(1.43)  Batch time: 1.42(1.44)
2025-09-03 13:37:27,590   INFO  Train:    3/20 ( 15%) [3175/3862 ( 82%)]  Loss: 2.094 (2.27)  LR: 3.492e-04  Grad: 16.0837  max=0.6639(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.7565(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7980, loss_cls=0.1351, loss_bbox=0.8814, matched_ious=0.4570, loss_iou=0.1006, loss_iou_reg=0.2471, d_time=0.00(0.01), f_time=1.39(1.43), b_time=1.40(1.44)  Time cost: 1:16:16/16:29 [4:21:38/26:33:08]  Acc_iter 10900       Data time: 0.00(0.01)  Forward time: 1.39(1.43)  Batch time: 1.40(1.44)
2025-09-03 13:38:38,588   INFO  Train:    3/20 ( 15%) [3225/3862 ( 84%)]  Loss: 2.157 (2.27)  LR: 3.512e-04  Grad: 18.5519  max=6.0937(module.vfe.pfn_layers.0.linear.weight)  min: -7.9001(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7620, loss_cls=0.1342, loss_bbox=0.8713, matched_ious=0.4527, loss_iou=0.0986, loss_iou_reg=0.2479, d_time=0.01(0.01), f_time=1.36(1.43), b_time=1.36(1.44)  Time cost: 1:17:27/15:17 [4:22:49/26:31:35]  Acc_iter 10950       Data time: 0.01(0.01)  Forward time: 1.36(1.43)  Batch time: 1.36(1.44)
2025-09-03 13:39:52,819   INFO  Train:    3/20 ( 15%) [3275/3862 ( 85%)]  Loss: 2.330 (2.27)  LR: 3.533e-04  Grad: 17.9820  max=0.6739(module.dense_head.decoder.self_attn.in_proj_weight)  min: -6.4662(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7849, loss_cls=0.1340, loss_bbox=0.8943, matched_ious=0.4559, loss_iou=0.0985, loss_iou_reg=0.2471, d_time=0.00(0.01), f_time=1.35(1.43), b_time=1.35(1.44)  Time cost: 1:18:41/14:05 [4:24:03/26:31:07]  Acc_iter 11000       Data time: 0.00(0.01)  Forward time: 1.35(1.43)  Batch time: 1.35(1.44)
2025-09-03 13:41:04,991   INFO  Train:    3/20 ( 15%) [3325/3862 ( 86%)]  Loss: 2.019 (2.27)  LR: 3.554e-04  Grad: 18.3987  max=3.0715(module.vfe.pfn_layers.0.linear.weight)  min: -9.0034(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7798, loss_cls=0.1359, loss_bbox=0.9014, matched_ious=0.4519, loss_iou=0.0986, loss_iou_reg=0.2488, d_time=0.00(0.01), f_time=1.40(1.43), b_time=1.40(1.44)  Time cost: 1:19:53/12:53 [4:25:16/26:29:57]  Acc_iter 11050       Data time: 0.00(0.01)  Forward time: 1.40(1.43)  Batch time: 1.40(1.44)
2025-09-03 13:42:15,367   INFO  Train:    3/20 ( 15%) [3375/3862 ( 87%)]  Loss: 2.240 (2.27)  LR: 3.574e-04  Grad: 18.1520  max=5.7819(module.vfe.pfn_layers.0.linear.weight)  min: -5.4124(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7766, loss_cls=0.1344, loss_bbox=0.8751, matched_ious=0.4584, loss_iou=0.0978, loss_iou_reg=0.2454, d_time=0.00(0.01), f_time=1.33(1.43), b_time=1.34(1.44)  Time cost: 1:21:03/11:41 [4:26:26/26:28:12]  Acc_iter 11100       Data time: 0.00(0.01)  Forward time: 1.33(1.43)  Batch time: 1.34(1.44)
2025-09-03 13:43:26,100   INFO  Train:    3/20 ( 15%) [3425/3862 ( 89%)]  Loss: 2.258 (2.26)  LR: 3.595e-04  Grad: 17.8462  max=0.6780(module.dense_head.decoder.self_attn.in_proj_weight)  min: -7.0687(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7653, loss_cls=0.1321, loss_bbox=0.8865, matched_ious=0.4553, loss_iou=0.0999, loss_iou_reg=0.2490, d_time=0.01(0.01), f_time=1.41(1.43), b_time=1.42(1.44)  Time cost: 1:22:14/10:29 [4:27:37/26:26:35]  Acc_iter 11150       Data time: 0.01(0.01)  Forward time: 1.41(1.43)  Batch time: 1.42(1.44)
2025-09-03 13:44:36,541   INFO  Train:    3/20 ( 15%) [3475/3862 ( 90%)]  Loss: 2.050 (2.26)  LR: 3.616e-04  Grad: 16.3878  max=1.4579(module.vfe.pfn_layers.0.linear.weight)  min: -2.5712(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7763, loss_cls=0.1347, loss_bbox=0.8761, matched_ious=0.4573, loss_iou=0.1004, loss_iou_reg=0.2477, d_time=0.00(0.01), f_time=1.41(1.43), b_time=1.42(1.44)  Time cost: 1:23:25/09:17 [4:28:47/26:24:53]  Acc_iter 11200       Data time: 0.00(0.01)  Forward time: 1.41(1.43)  Batch time: 1.42(1.44)
2025-09-03 13:45:50,873   INFO  Train:    3/20 ( 15%) [3525/3862 ( 91%)]  Loss: 1.951 (2.26)  LR: 3.636e-04  Grad: 16.6899  max=4.3371(module.vfe.pfn_layers.0.linear.weight)  min: -0.5769(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7872, loss_cls=0.1375, loss_bbox=0.9038, matched_ious=0.4600, loss_iou=0.0993, loss_iou_reg=0.2441, d_time=0.01(0.01), f_time=1.42(1.43), b_time=1.43(1.44)  Time cost: 1:24:39/08:05 [4:30:01/26:24:25]  Acc_iter 11250       Data time: 0.01(0.01)  Forward time: 1.42(1.43)  Batch time: 1.43(1.44)
2025-09-03 13:47:02,581   INFO  Train:    3/20 ( 15%) [3575/3862 ( 93%)]  Loss: 1.979 (2.26)  LR: 3.657e-04  Grad: 16.6868  max=1.7372(module.vfe.pfn_layers.0.linear.weight)  min: -4.0531(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7845, loss_cls=0.1348, loss_bbox=0.8694, matched_ious=0.4623, loss_iou=0.0989, loss_iou_reg=0.2445, d_time=0.00(0.01), f_time=1.46(1.43), b_time=1.46(1.44)  Time cost: 1:25:51/06:53 [4:31:13/26:23:07]  Acc_iter 11300       Data time: 0.00(0.01)  Forward time: 1.46(1.43)  Batch time: 1.46(1.44)
2025-09-03 13:48:14,348   INFO  Train:    3/20 ( 15%) [3625/3862 ( 94%)]  Loss: 2.170 (2.26)  LR: 3.678e-04  Grad: 18.1783  max=6.9510(module.vfe.pfn_layers.0.linear.weight)  min: -4.7439(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7666, loss_cls=0.1326, loss_bbox=0.9182, matched_ious=0.4575, loss_iou=0.0999, loss_iou_reg=0.2475, d_time=0.01(0.01), f_time=1.43(1.43), b_time=1.43(1.44)  Time cost: 1:27:02/05:41 [4:32:25/26:21:50]  Acc_iter 11350       Data time: 0.01(0.01)  Forward time: 1.43(1.43)  Batch time: 1.43(1.44)
2025-09-03 13:49:25,281   INFO  Train:    3/20 ( 15%) [3675/3862 ( 95%)]  Loss: 2.007 (2.26)  LR: 3.699e-04  Grad: 17.0637  max=0.6760(module.dense_head.decoder.self_attn.in_proj_weight)  min: -3.8599(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7618, loss_cls=0.1302, loss_bbox=0.9147, matched_ious=0.4518, loss_iou=0.0990, loss_iou_reg=0.2504, d_time=0.00(0.01), f_time=1.42(1.43), b_time=1.43(1.44)  Time cost: 1:28:13/04:29 [4:33:36/26:20:19]  Acc_iter 11400       Data time: 0.00(0.01)  Forward time: 1.42(1.43)  Batch time: 1.43(1.44)
2025-09-03 13:50:37,599   INFO  Train:    3/20 ( 15%) [3725/3862 ( 96%)]  Loss: 2.310 (2.26)  LR: 3.720e-04  Grad: 16.4227  max=2.1626(module.vfe.pfn_layers.0.linear.weight)  min: -0.7245(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7684, loss_cls=0.1347, loss_bbox=0.8759, matched_ious=0.4535, loss_iou=0.0999, loss_iou_reg=0.2496, d_time=0.41(0.01), f_time=1.44(1.43), b_time=1.85(1.44)  Time cost: 1:29:26/03:17 [4:34:48/26:19:12]  Acc_iter 11450       Data time: 0.41(0.01)  Forward time: 1.44(1.43)  Batch time: 1.85(1.44)
2025-09-03 13:51:51,788   INFO  Train:    3/20 ( 15%) [3775/3862 ( 98%)]  Loss: 2.023 (2.25)  LR: 3.741e-04  Grad: 17.6566  max=4.1378(module.vfe.pfn_layers.0.linear.weight)  min: -4.3621(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7791, loss_cls=0.1329, loss_bbox=0.9036, matched_ious=0.4529, loss_iou=0.0999, loss_iou_reg=0.2499, d_time=0.01(0.01), f_time=1.38(1.43), b_time=1.38(1.44)  Time cost: 1:30:40/02:05 [4:36:02/26:18:38]  Acc_iter 11500       Data time: 0.01(0.01)  Forward time: 1.38(1.43)  Batch time: 1.38(1.44)
2025-09-03 13:53:03,118   INFO  Train:    3/20 ( 15%) [3825/3862 ( 99%)]  Loss: 2.329 (2.25)  LR: 3.762e-04  Grad: 18.5476  max=5.6074(module.vfe.pfn_layers.0.linear.weight)  min: -4.4435(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7931, loss_cls=0.1334, loss_bbox=0.8951, matched_ious=0.4504, loss_iou=0.0993, loss_iou_reg=0.2493, d_time=0.00(0.01), f_time=1.38(1.43), b_time=1.39(1.44)  Time cost: 1:31:51/00:53 [4:37:14/26:17:14]  Acc_iter 11550       Data time: 0.00(0.01)  Forward time: 1.38(1.43)  Batch time: 1.39(1.44)
2025-09-03 13:53:52,658   INFO  Train:    3/20 ( 15%) [3861/3862 (100%)]  Loss: 2.158 (2.25)  LR: 3.778e-04  Grad: 16.5417  max=0.6750(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.1109(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7792, loss_cls=0.1343, loss_bbox=0.8692, matched_ious=0.4558, loss_iou=0.0984, loss_iou_reg=0.2486, d_time=0.00(0.01), f_time=1.27(1.43), b_time=1.28(1.44)  Time cost: 1:32:41/00:01 [4:38:03/26:15:43]  Acc_iter 11586       Data time: 0.00(0.01)  Forward time: 1.27(1.43)  Batch time: 1.28(1.44)

                                               [Aepochs:  15%|█▌        | 3/20 [4:38:04<26:15:55, 5562.11s/it]epochs:  15%|█▌        | 3/20 [4:38:04<26:15:55, 5562.11s/it]epochs:  15%|█▌        | 3/20 [4:38:04<26:15:56, 5562.13s/it]epochs:  15%|█▌        | 3/20 [4:38:04<26:15:56, 5562.12s/it]epochs:  15%|█▌        | 3/20 [4:38:04<26:15:56, 5562.13s/it]epochs:  15%|█▌        | 3/20 [4:38:04<26:15:56, 5562.13s/it]epochs:  15%|█▌        | 3/20 [4:38:04<26:15:56, 5562.14s/it]epochs:  15%|█▌        | 3/20 [4:38:04<26:15:57, 5562.18s/it]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-03 13:53:58,323   INFO  Train:    4/20 ( 20%) [   0/3862 (  0%)]  Loss: 2.133 (2.13)  LR: 3.778e-04  Grad: 19.0272  max=7.1306(module.vfe.pfn_layers.0.linear.weight)  min: -4.3653(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7616, loss_cls=0.1308, loss_bbox=0.8864, matched_ious=0.4568, loss_iou=0.1052, loss_iou_reg=0.2486, d_time=2.00(2.00), f_time=2.43(2.43), b_time=4.43(4.43)  Time cost: 00:04/4:29:05 [4:38:09/76:14:40]  Acc_iter 11587       Data time: 2.00(2.00)  Forward time: 2.43(2.43)  Batch time: 4.43(4.43)
2025-09-03 13:54:17,048   INFO  Train:    4/20 ( 20%) [  13/3862 (  0%)]  Loss: 1.902 (2.15)  LR: 3.783e-04  Grad: 17.1120  max=4.3407(module.vfe.pfn_layers.0.linear.weight)  min: -0.5766(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7698, loss_cls=0.1360, loss_bbox=0.8891, matched_ious=0.4407, loss_iou=0.1036, loss_iou_reg=0.2581, d_time=0.00(0.15), f_time=1.47(1.51), b_time=1.47(1.66)  Time cost: 00:22/1:45:02 [4:38:28/29:51:15]  Acc_iter 11600       Data time: 0.00(0.15)  Forward time: 1.47(1.51)  Batch time: 1.47(1.66)
2025-09-03 13:55:29,122   INFO  Train:    4/20 ( 20%) [  63/3862 (  2%)]  Loss: 2.173 (2.14)  LR: 3.805e-04  Grad: 19.3575  max=7.1214(module.vfe.pfn_layers.0.linear.weight)  min: -6.3139(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7718, loss_cls=0.1344, loss_bbox=0.8729, matched_ious=0.4540, loss_iou=0.1016, loss_iou_reg=0.2496, d_time=0.01(0.04), f_time=1.38(1.45), b_time=1.39(1.49)  Time cost: 01:34/1:33:59 [4:39:40/27:02:39]  Acc_iter 11650       Data time: 0.01(0.04)  Forward time: 1.38(1.45)  Batch time: 1.39(1.49)
2025-09-03 13:56:44,450   INFO  Train:    4/20 ( 20%) [ 113/3862 (  3%)]  Loss: 2.705 (2.15)  LR: 3.826e-04  Grad: 18.6270  max=0.6725(module.dense_head.decoder.self_attn.in_proj_weight)  min: -5.6936(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7705, loss_cls=0.1319, loss_bbox=0.9122, matched_ious=0.4555, loss_iou=0.0984, loss_iou_reg=0.2498, d_time=0.00(0.02), f_time=1.57(1.47), b_time=1.57(1.49)  Time cost: 02:50/1:33:21 [4:40:55/27:12:03]  Acc_iter 11700       Data time: 0.00(0.02)  Forward time: 1.57(1.47)  Batch time: 1.57(1.49)
2025-09-03 13:57:57,317   INFO  Train:    4/20 ( 20%) [ 163/3862 (  4%)]  Loss: 2.108 (2.13)  LR: 3.847e-04  Grad: 21.5731  max=13.5309(module.vfe.pfn_layers.0.linear.weight)  min: -1.5123(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7524, loss_cls=0.1306, loss_bbox=0.8478, matched_ious=0.4586, loss_iou=0.0998, loss_iou_reg=0.2478, d_time=0.01(0.03), f_time=1.47(1.46), b_time=1.48(1.48)  Time cost: 04:03/1:31:25 [4:42:08/26:58:34]  Acc_iter 11750       Data time: 0.01(0.03)  Forward time: 1.47(1.46)  Batch time: 1.48(1.48)
2025-09-03 13:59:07,901   INFO  Train:    4/20 ( 20%) [ 213/3862 (  6%)]  Loss: 2.398 (2.12)  LR: 3.868e-04  Grad: 23.5641  max=14.8422(module.vfe.pfn_layers.0.linear.weight)  min: -7.3137(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7589, loss_cls=0.1296, loss_bbox=0.8559, matched_ious=0.4628, loss_iou=0.0982, loss_iou_reg=0.2430, d_time=0.01(0.02), f_time=1.36(1.45), b_time=1.37(1.47)  Time cost: 05:13/1:29:10 [4:43:19/26:39:10]  Acc_iter 11800       Data time: 0.01(0.02)  Forward time: 1.36(1.45)  Batch time: 1.37(1.47)
2025-09-03 14:00:18,887   INFO  Train:    4/20 ( 20%) [ 263/3862 (  7%)]  Loss: 2.118 (2.11)  LR: 3.890e-04  Grad: 21.2822  max=8.9256(module.vfe.pfn_layers.0.linear.weight)  min: -5.7047(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7479, loss_cls=0.1321, loss_bbox=0.8607, matched_ious=0.4581, loss_iou=0.0995, loss_iou_reg=0.2493, d_time=0.00(0.02), f_time=1.38(1.44), b_time=1.38(1.46)  Time cost: 06:24/1:27:25 [4:44:30/26:28:22]  Acc_iter 11850       Data time: 0.00(0.02)  Forward time: 1.38(1.44)  Batch time: 1.38(1.46)
2025-09-03 14:01:30,247   INFO  Train:    4/20 ( 20%) [ 313/3862 (  8%)]  Loss: 2.343 (2.11)  LR: 3.911e-04  Grad: 17.9809  max=5.9239(module.vfe.pfn_layers.0.linear.weight)  min: -0.8511(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7586, loss_cls=0.1287, loss_bbox=0.8692, matched_ious=0.4558, loss_iou=0.0996, loss_iou_reg=0.2493, d_time=0.00(0.02), f_time=1.41(1.44), b_time=1.41(1.45)  Time cost: 07:36/1:25:55 [4:45:41/26:21:55]  Acc_iter 11900       Data time: 0.00(0.02)  Forward time: 1.41(1.44)  Batch time: 1.41(1.45)
2025-09-03 14:02:45,513   INFO  Train:    4/20 ( 20%) [ 363/3862 (  9%)]  Loss: 2.047 (2.11)  LR: 3.933e-04  Grad: 19.0490  max=6.5603(module.vfe.pfn_layers.0.linear.weight)  min: -5.8713(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7542, loss_cls=0.1312, loss_bbox=0.8608, matched_ious=0.4642, loss_iou=0.0978, loss_iou_reg=0.2434, d_time=0.01(0.02), f_time=1.33(1.44), b_time=1.33(1.46)  Time cost: 08:51/1:25:08 [4:46:56/26:28:35]  Acc_iter 11950       Data time: 0.01(0.02)  Forward time: 1.33(1.44)  Batch time: 1.33(1.46)
2025-09-03 14:03:57,559   INFO  Train:    4/20 ( 20%) [ 413/3862 ( 11%)]  Loss: 2.071 (2.10)  LR: 3.954e-04  Grad: 18.3949  max=5.7215(module.vfe.pfn_layers.0.linear.weight)  min: -4.0357(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7379, loss_cls=0.1277, loss_bbox=0.8439, matched_ious=0.4639, loss_iou=0.1003, loss_iou_reg=0.2444, d_time=0.00(0.02), f_time=1.44(1.44), b_time=1.44(1.46)  Time cost: 10:03/1:23:47 [4:48:08/26:24:53]  Acc_iter 12000       Data time: 0.00(0.02)  Forward time: 1.44(1.44)  Batch time: 1.44(1.46)
2025-09-03 14:05:08,265   INFO  Train:    4/20 ( 20%) [ 463/3862 ( 12%)]  Loss: 2.030 (2.10)  LR: 3.975e-04  Grad: 17.9151  max=4.3213(module.vfe.pfn_layers.0.linear.weight)  min: -0.5821(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7464, loss_cls=0.1298, loss_bbox=0.8744, matched_ious=0.4577, loss_iou=0.0998, loss_iou_reg=0.2472, d_time=0.00(0.02), f_time=1.36(1.44), b_time=1.37(1.45)  Time cost: 11:14/1:22:18 [4:49:19/26:18:35]  Acc_iter 12050       Data time: 0.00(0.02)  Forward time: 1.36(1.44)  Batch time: 1.37(1.45)
2025-09-03 14:06:18,940   INFO  Train:    4/20 ( 20%) [ 513/3862 ( 13%)]  Loss: 1.993 (2.10)  LR: 3.997e-04  Grad: 17.5684  max=3.0148(module.vfe.pfn_layers.0.linear.weight)  min: -0.5831(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7481, loss_cls=0.1280, loss_bbox=0.8689, matched_ious=0.4559, loss_iou=0.0990, loss_iou_reg=0.2476, d_time=0.01(0.01), f_time=1.39(1.43), b_time=1.39(1.45)  Time cost: 12:24/1:20:52 [4:50:30/26:13:12]  Acc_iter 12100       Data time: 0.01(0.01)  Forward time: 1.39(1.43)  Batch time: 1.39(1.45)
2025-09-03 14:07:30,296   INFO  Train:    4/20 ( 20%) [ 563/3862 ( 15%)]  Loss: 1.926 (2.10)  LR: 4.019e-04  Grad: 17.7340  max=0.6797(module.dense_head.decoder.self_attn.in_proj_weight)  min: -4.4506(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7462, loss_cls=0.1275, loss_bbox=0.8516, matched_ious=0.4627, loss_iou=0.0999, loss_iou_reg=0.2468, d_time=0.00(0.01), f_time=1.34(1.43), b_time=1.35(1.45)  Time cost: 13:36/1:19:34 [4:51:41/26:09:53]  Acc_iter 12150       Data time: 0.00(0.01)  Forward time: 1.34(1.43)  Batch time: 1.35(1.45)
2025-09-03 14:08:46,467   INFO  Train:    4/20 ( 20%) [ 613/3862 ( 16%)]  Loss: 1.971 (2.09)  LR: 4.040e-04  Grad: 18.2277  max=3.0585(module.vfe.pfn_layers.0.linear.weight)  min: -5.0723(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7356, loss_cls=0.1277, loss_bbox=0.8348, matched_ious=0.4645, loss_iou=0.0982, loss_iou_reg=0.2453, d_time=0.01(0.01), f_time=2.41(1.44), b_time=2.42(1.45)  Time cost: 14:52/1:18:41 [4:52:57/26:15:25]  Acc_iter 12200       Data time: 0.01(0.01)  Forward time: 2.41(1.44)  Batch time: 2.42(1.45)
2025-09-03 14:09:57,136   INFO  Train:    4/20 ( 20%) [ 663/3862 ( 17%)]  Loss: 2.203 (2.09)  LR: 4.062e-04  Grad: 13.7600  max=0.4458(module.dense_head.decoder.self_attn.in_proj_weight)  min: -6.3945(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7397, loss_cls=0.1287, loss_bbox=0.8441, matched_ious=0.4626, loss_iou=0.0980, loss_iou_reg=0.2492, d_time=0.00(0.01), f_time=1.44(1.44), b_time=1.45(1.45)  Time cost: 16:03/1:17:19 [4:54:08/26:10:57]  Acc_iter 12250       Data time: 0.00(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.45)
2025-09-03 14:11:08,357   INFO  Train:    4/20 ( 20%) [ 713/3862 ( 18%)]  Loss: 2.003 (2.09)  LR: 4.084e-04  Grad: 12.8737  max=1.8171(module.vfe.pfn_layers.0.linear.weight)  min: -4.6172(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7599, loss_cls=0.1298, loss_bbox=0.8824, matched_ious=0.4556, loss_iou=0.0993, loss_iou_reg=0.2492, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 17:14/1:16:01 [4:55:19/26:07:47]  Acc_iter 12300       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-03 14:12:18,985   INFO  Train:    4/20 ( 20%) [ 763/3862 ( 20%)]  Loss: 1.827 (2.09)  LR: 4.105e-04  Grad: 11.7575  max=0.9666(module.vfe.pfn_layers.0.linear.weight)  min: -2.2378(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7577, loss_cls=0.1324, loss_bbox=0.8534, matched_ious=0.4615, loss_iou=0.0996, loss_iou_reg=0.2468, d_time=0.01(0.01), f_time=1.33(1.43), b_time=1.34(1.45)  Time cost: 18:24/1:14:41 [4:56:30/26:04:02]  Acc_iter 12350       Data time: 0.01(0.01)  Forward time: 1.33(1.43)  Batch time: 1.34(1.45)
2025-09-03 14:13:31,162   INFO  Train:    4/20 ( 20%) [ 813/3862 ( 21%)]  Loss: 1.961 (2.09)  LR: 4.127e-04  Grad: 12.6820  max=4.1828(module.vfe.pfn_layers.0.linear.weight)  min: -0.3908(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7461, loss_cls=0.1294, loss_bbox=0.8221, matched_ious=0.4639, loss_iou=0.0995, loss_iou_reg=0.2462, d_time=0.00(0.01), f_time=1.36(1.43), b_time=1.36(1.45)  Time cost: 19:37/1:13:28 [4:57:42/26:02:39]  Acc_iter 12400       Data time: 0.00(0.01)  Forward time: 1.36(1.43)  Batch time: 1.36(1.45)
2025-09-03 14:14:47,190   INFO  Train:    4/20 ( 20%) [ 863/3862 ( 22%)]  Loss: 1.932 (2.09)  LR: 4.149e-04  Grad: 31.1078  max=15.1308(module.vfe.pfn_layers.0.linear.weight)  min: -21.8779(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7687, loss_cls=0.1293, loss_bbox=0.9072, matched_ious=0.4606, loss_iou=0.0991, loss_iou_reg=0.2455, d_time=0.01(0.01), f_time=1.47(1.44), b_time=1.47(1.45)  Time cost: 20:53/1:12:29 [4:58:58/26:06:06]  Acc_iter 12450       Data time: 0.01(0.01)  Forward time: 1.47(1.44)  Batch time: 1.47(1.45)
2025-09-03 14:15:58,280   INFO  Train:    4/20 ( 20%) [ 913/3862 ( 24%)]  Loss: 1.900 (2.09)  LR: 4.171e-04  Grad: 13.0843  max=4.5400(module.vfe.pfn_layers.0.linear.weight)  min: -3.2455(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7685, loss_cls=0.1317, loss_bbox=0.8318, matched_ious=0.4658, loss_iou=0.0983, loss_iou_reg=0.2441, d_time=0.01(0.01), f_time=1.37(1.44), b_time=1.37(1.45)  Time cost: 22:04/1:11:12 [5:00:09/26:03:13]  Acc_iter 12500       Data time: 0.01(0.01)  Forward time: 1.37(1.44)  Batch time: 1.37(1.45)
2025-09-03 14:17:09,123   INFO  Train:    4/20 ( 20%) [ 963/3862 ( 25%)]  Loss: 1.953 (2.09)  LR: 4.193e-04  Grad: 14.2717  max=2.1593(module.vfe.pfn_layers.0.linear.weight)  min: -7.7628(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7647, loss_cls=0.1309, loss_bbox=0.8915, matched_ious=0.4595, loss_iou=0.0989, loss_iou_reg=0.2485, d_time=0.01(0.01), f_time=1.37(1.43), b_time=1.38(1.45)  Time cost: 23:14/1:09:55 [5:01:20/26:00:13]  Acc_iter 12550       Data time: 0.01(0.01)  Forward time: 1.37(1.43)  Batch time: 1.38(1.45)
2025-09-03 14:18:20,319   INFO  Train:    4/20 ( 20%) [1013/3862 ( 26%)]  Loss: 2.279 (2.09)  LR: 4.215e-04  Grad: 14.6737  max=0.5111(module.vfe.pfn_layers.0.linear.weight)  min: -6.0325(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7611, loss_cls=0.1294, loss_bbox=0.8483, matched_ious=0.4601, loss_iou=0.0994, loss_iou_reg=0.2466, d_time=0.01(0.01), f_time=1.45(1.43), b_time=1.46(1.45)  Time cost: 24:26/1:08:39 [5:02:31/25:57:47]  Acc_iter 12600       Data time: 0.01(0.01)  Forward time: 1.45(1.43)  Batch time: 1.46(1.45)
2025-09-03 14:19:31,891   INFO  Train:    4/20 ( 20%) [1063/3862 ( 28%)]  Loss: 1.978 (2.09)  LR: 4.236e-04  Grad: 12.3028  max=0.4482(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.6089(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7452, loss_cls=0.1283, loss_bbox=0.8112, matched_ious=0.4651, loss_iou=0.0986, loss_iou_reg=0.2445, d_time=0.00(0.01), f_time=1.43(1.43), b_time=1.43(1.45)  Time cost: 25:37/1:07:25 [5:03:43/25:55:51]  Acc_iter 12650       Data time: 0.00(0.01)  Forward time: 1.43(1.43)  Batch time: 1.43(1.45)
2025-09-03 14:20:49,102   INFO  Train:    4/20 ( 20%) [1113/3862 ( 29%)]  Loss: 2.245 (2.09)  LR: 4.258e-04  Grad: 24.5437  max=0.4507(module.dense_head.decoder.self_attn.in_proj_weight)  min: -20.6767(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7454, loss_cls=0.1305, loss_bbox=0.8111, matched_ious=0.4773, loss_iou=0.0973, loss_iou_reg=0.2415, d_time=0.00(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 26:54/1:06:25 [5:05:00/25:59:25]  Acc_iter 12700       Data time: 0.00(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-03 14:21:59,782   INFO  Train:    4/20 ( 20%) [1163/3862 ( 30%)]  Loss: 1.898 (2.09)  LR: 4.280e-04  Grad: 17.8436  max=2.0460(module.vfe.pfn_layers.0.linear.weight)  min: -13.0589(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7704, loss_cls=0.1318, loss_bbox=0.8538, matched_ious=0.4656, loss_iou=0.0988, loss_iou_reg=0.2446, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.45(1.45)  Time cost: 28:05/1:05:08 [5:06:10/25:56:33]  Acc_iter 12750       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.45)
2025-09-03 14:23:10,405   INFO  Train:    4/20 ( 20%) [1213/3862 ( 31%)]  Loss: 1.932 (2.09)  LR: 4.302e-04  Grad: 13.6327  max=0.7611(module.vfe.pfn_layers.0.linear.weight)  min: -6.5485(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7495, loss_cls=0.1294, loss_bbox=0.8563, matched_ious=0.4676, loss_iou=0.0979, loss_iou_reg=0.2440, d_time=0.01(0.01), f_time=1.36(1.43), b_time=1.37(1.45)  Time cost: 29:16/1:03:52 [5:07:21/25:53:45]  Acc_iter 12800       Data time: 0.01(0.01)  Forward time: 1.36(1.43)  Batch time: 1.37(1.45)
2025-09-03 14:24:21,699   INFO  Train:    4/20 ( 20%) [1263/3862 ( 33%)]  Loss: 2.491 (2.09)  LR: 4.325e-04  Grad: 21.8197  max=1.5516(module.vfe.pfn_layers.0.linear.weight)  min: -18.2272(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7475, loss_cls=0.1308, loss_bbox=0.8227, matched_ious=0.4709, loss_iou=0.0988, loss_iou_reg=0.2455, d_time=0.01(0.01), f_time=1.48(1.43), b_time=1.49(1.45)  Time cost: 30:27/1:02:37 [5:08:32/25:51:40]  Acc_iter 12850       Data time: 0.01(0.01)  Forward time: 1.48(1.43)  Batch time: 1.49(1.45)
2025-09-03 14:25:32,989   INFO  Train:    4/20 ( 20%) [1313/3862 ( 34%)]  Loss: 2.013 (2.09)  LR: 4.347e-04  Grad: 16.3218  max=8.8188(module.vfe.pfn_layers.0.linear.weight)  min: -6.9003(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7435, loss_cls=0.1291, loss_bbox=0.8640, matched_ious=0.4595, loss_iou=0.0983, loss_iou_reg=0.2480, d_time=0.00(0.01), f_time=1.34(1.43), b_time=1.35(1.45)  Time cost: 31:38/1:01:23 [5:09:44/25:49:38]  Acc_iter 12900       Data time: 0.00(0.01)  Forward time: 1.34(1.43)  Batch time: 1.35(1.45)
2025-09-03 14:26:48,550   INFO  Train:    4/20 ( 20%) [1363/3862 ( 35%)]  Loss: 1.820 (2.09)  LR: 4.369e-04  Grad: 12.0918  max=3.9755(module.vfe.pfn_layers.0.linear.weight)  min: -1.4841(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7437, loss_cls=0.1299, loss_bbox=0.8543, matched_ious=0.4542, loss_iou=0.1003, loss_iou_reg=0.2512, d_time=0.01(0.01), f_time=1.47(1.44), b_time=1.48(1.45)  Time cost: 32:54/1:00:17 [5:10:59/25:51:02]  Acc_iter 12950       Data time: 0.01(0.01)  Forward time: 1.47(1.44)  Batch time: 1.48(1.45)
2025-09-03 14:27:59,219   INFO  Train:    4/20 ( 20%) [1413/3862 ( 37%)]  Loss: 1.817 (2.08)  LR: 4.391e-04  Grad: 14.4686  max=8.0855(module.vfe.pfn_layers.0.linear.weight)  min: -3.3966(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7106, loss_cls=0.1248, loss_bbox=0.8125, matched_ious=0.4664, loss_iou=0.0980, loss_iou_reg=0.2466, d_time=0.01(0.01), f_time=1.40(1.43), b_time=1.40(1.45)  Time cost: 34:05/59:02 [5:12:10/25:48:32]  Acc_iter 13000       Data time: 0.01(0.01)  Forward time: 1.40(1.43)  Batch time: 1.40(1.45)
2025-09-03 14:29:10,108   INFO  Train:    4/20 ( 20%) [1463/3862 ( 38%)]  Loss: 2.040 (2.08)  LR: 4.413e-04  Grad: 11.6666  max=0.4134(module.dense_head.decoder.self_attn.in_proj_weight)  min: -3.1288(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7224, loss_cls=0.1255, loss_bbox=0.8205, matched_ious=0.4681, loss_iou=0.0982, loss_iou_reg=0.2457, d_time=0.00(0.01), f_time=1.45(1.43), b_time=1.46(1.45)  Time cost: 35:15/57:47 [5:13:21/25:46:17]  Acc_iter 13050       Data time: 0.00(0.01)  Forward time: 1.45(1.43)  Batch time: 1.46(1.45)
2025-09-03 14:30:21,194   INFO  Train:    4/20 ( 20%) [1513/3862 ( 39%)]  Loss: 2.084 (2.08)  LR: 4.435e-04  Grad: 11.4950  max=1.7611(module.vfe.pfn_layers.0.linear.weight)  min: -1.1625(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7673, loss_cls=0.1326, loss_bbox=0.8560, matched_ious=0.4683, loss_iou=0.0964, loss_iou_reg=0.2439, d_time=0.01(0.01), f_time=1.47(1.43), b_time=1.48(1.44)  Time cost: 36:27/56:33 [5:14:32/25:44:15]  Acc_iter 13100       Data time: 0.01(0.01)  Forward time: 1.47(1.43)  Batch time: 1.48(1.44)
2025-09-03 14:31:32,690   INFO  Train:    4/20 ( 20%) [1563/3862 ( 40%)]  Loss: 2.274 (2.08)  LR: 4.458e-04  Grad: 11.6097  max=0.4112(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.4435(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7214, loss_cls=0.1227, loss_bbox=0.8365, matched_ious=0.4649, loss_iou=0.1017, loss_iou_reg=0.2464, d_time=0.01(0.01), f_time=1.33(1.43), b_time=1.33(1.44)  Time cost: 37:38/55:19 [5:15:43/25:42:33]  Acc_iter 13150       Data time: 0.01(0.01)  Forward time: 1.33(1.43)  Batch time: 1.33(1.44)
2025-09-03 14:32:48,493   INFO  Train:    4/20 ( 20%) [1613/3862 ( 42%)]  Loss: 1.987 (2.08)  LR: 4.480e-04  Grad: 13.6658  max=5.1829(module.vfe.pfn_layers.0.linear.weight)  min: -0.3756(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7323, loss_cls=0.1262, loss_bbox=0.8445, matched_ious=0.4696, loss_iou=0.0989, loss_iou_reg=0.2433, d_time=0.01(0.01), f_time=1.32(1.44), b_time=1.33(1.45)  Time cost: 38:54/54:12 [5:16:59/25:43:44]  Acc_iter 13200       Data time: 0.01(0.01)  Forward time: 1.32(1.44)  Batch time: 1.33(1.45)
2025-09-03 14:33:59,531   INFO  Train:    4/20 ( 20%) [1663/3862 ( 43%)]  Loss: 1.998 (2.07)  LR: 4.502e-04  Grad: 13.3338  max=5.9126(module.vfe.pfn_layers.0.linear.weight)  min: -3.3313(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7114, loss_cls=0.1230, loss_bbox=0.7901, matched_ious=0.4709, loss_iou=0.0989, loss_iou_reg=0.2436, d_time=0.00(0.01), f_time=1.40(1.43), b_time=1.40(1.45)  Time cost: 40:05/52:58 [5:18:10/25:41:42]  Acc_iter 13250       Data time: 0.00(0.01)  Forward time: 1.40(1.43)  Batch time: 1.40(1.45)
2025-09-03 14:35:10,827   INFO  Train:    4/20 ( 20%) [1713/3862 ( 44%)]  Loss: 2.033 (2.07)  LR: 4.524e-04  Grad: 12.5793  max=2.9710(module.vfe.pfn_layers.0.linear.weight)  min: -3.8036(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7295, loss_cls=0.1254, loss_bbox=0.8319, matched_ious=0.4653, loss_iou=0.1009, loss_iou_reg=0.2471, d_time=0.00(0.01), f_time=1.43(1.43), b_time=1.43(1.45)  Time cost: 41:16/51:45 [5:19:21/25:39:53]  Acc_iter 13300       Data time: 0.00(0.01)  Forward time: 1.43(1.43)  Batch time: 1.43(1.45)
2025-09-03 14:36:21,166   INFO  Train:    4/20 ( 20%) [1763/3862 ( 46%)]  Loss: 1.943 (2.07)  LR: 4.547e-04  Grad: 12.3137  max=1.6385(module.vfe.pfn_layers.0.linear.weight)  min: -3.5357(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7313, loss_cls=0.1285, loss_bbox=0.8264, matched_ious=0.4678, loss_iou=0.0977, loss_iou_reg=0.2455, d_time=0.01(0.01), f_time=1.44(1.43), b_time=1.45(1.44)  Time cost: 42:27/50:30 [5:20:32/25:37:32]  Acc_iter 13350       Data time: 0.01(0.01)  Forward time: 1.44(1.43)  Batch time: 1.45(1.44)
2025-09-03 14:37:33,295   INFO  Train:    4/20 ( 20%) [1813/3862 ( 47%)]  Loss: 2.462 (2.07)  LR: 4.569e-04  Grad: 14.9721  max=6.8002(module.vfe.pfn_layers.0.linear.weight)  min: -0.3926(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7349, loss_cls=0.1251, loss_bbox=0.8212, matched_ious=0.4721, loss_iou=0.0972, loss_iou_reg=0.2426, d_time=0.00(0.01), f_time=1.36(1.43), b_time=1.36(1.44)  Time cost: 43:39/49:18 [5:21:44/25:36:17]  Acc_iter 13400       Data time: 0.00(0.01)  Forward time: 1.36(1.43)  Batch time: 1.36(1.44)
2025-09-03 14:38:48,635   INFO  Train:    4/20 ( 20%) [1863/3862 ( 48%)]  Loss: 2.103 (2.07)  LR: 4.592e-04  Grad: 14.1129  max=7.6734(module.vfe.pfn_layers.0.linear.weight)  min: -1.1453(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7194, loss_cls=0.1254, loss_bbox=0.8154, matched_ious=0.4704, loss_iou=0.0971, loss_iou_reg=0.2449, d_time=0.01(0.01), f_time=1.46(1.43), b_time=1.47(1.45)  Time cost: 44:54/48:09 [5:22:59/25:36:53]  Acc_iter 13450       Data time: 0.01(0.01)  Forward time: 1.46(1.43)  Batch time: 1.47(1.45)
2025-09-03 14:39:59,621   INFO  Train:    4/20 ( 20%) [1913/3862 ( 50%)]  Loss: 1.856 (2.07)  LR: 4.614e-04  Grad: 14.2926  max=6.9890(module.vfe.pfn_layers.0.linear.weight)  min: -3.5295(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7503, loss_cls=0.1275, loss_bbox=0.8362, matched_ious=0.4697, loss_iou=0.0972, loss_iou_reg=0.2441, d_time=0.01(0.01), f_time=1.40(1.43), b_time=1.41(1.45)  Time cost: 46:05/46:56 [5:24:10/25:34:58]  Acc_iter 13500       Data time: 0.01(0.01)  Forward time: 1.40(1.43)  Batch time: 1.41(1.45)
2025-09-03 14:41:10,118   INFO  Train:    4/20 ( 20%) [1963/3862 ( 51%)]  Loss: 2.097 (2.07)  LR: 4.636e-04  Grad: 14.9218  max=5.2601(module.vfe.pfn_layers.0.linear.weight)  min: -7.2357(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7459, loss_cls=0.1286, loss_bbox=0.8727, matched_ious=0.4672, loss_iou=0.0983, loss_iou_reg=0.2455, d_time=0.00(0.01), f_time=1.47(1.43), b_time=1.47(1.44)  Time cost: 47:15/45:42 [5:25:21/25:32:48]  Acc_iter 13550       Data time: 0.00(0.01)  Forward time: 1.47(1.43)  Batch time: 1.47(1.44)
2025-09-03 14:42:21,434   INFO  Train:    4/20 ( 20%) [2013/3862 ( 52%)]  Loss: 1.934 (2.07)  LR: 4.659e-04  Grad: 12.4903  max=2.6803(module.vfe.pfn_layers.0.linear.weight)  min: -2.2930(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7299, loss_cls=0.1269, loss_bbox=0.8168, matched_ious=0.4701, loss_iou=0.0989, loss_iou_reg=0.2463, d_time=0.01(0.01), f_time=1.44(1.43), b_time=1.45(1.44)  Time cost: 48:27/44:29 [5:26:32/25:31:08]  Acc_iter 13600       Data time: 0.01(0.01)  Forward time: 1.44(1.43)  Batch time: 1.45(1.44)
2025-09-03 14:43:33,675   INFO  Train:    4/20 ( 20%) [2063/3862 ( 53%)]  Loss: 2.077 (2.07)  LR: 4.681e-04  Grad: 14.6775  max=3.5838(module.vfe.pfn_layers.0.linear.weight)  min: -7.4163(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7185, loss_cls=0.1247, loss_bbox=0.8404, matched_ious=0.4735, loss_iou=0.0983, loss_iou_reg=0.2427, d_time=0.01(0.01), f_time=2.29(1.43), b_time=2.29(1.44)  Time cost: 49:39/43:17 [5:27:44/25:29:58]  Acc_iter 13650       Data time: 0.01(0.01)  Forward time: 2.29(1.43)  Batch time: 2.29(1.44)
2025-09-03 14:44:48,501   INFO  Train:    4/20 ( 20%) [2113/3862 ( 55%)]  Loss: 2.318 (2.07)  LR: 4.704e-04  Grad: 12.4646  max=0.9665(module.vfe.pfn_layers.0.linear.weight)  min: -2.6805(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7418, loss_cls=0.1289, loss_bbox=0.8633, matched_ious=0.4666, loss_iou=0.0990, loss_iou_reg=0.2454, d_time=0.00(0.01), f_time=1.43(1.43), b_time=1.44(1.44)  Time cost: 50:54/42:07 [5:28:59/25:30:06]  Acc_iter 13700       Data time: 0.00(0.01)  Forward time: 1.43(1.43)  Batch time: 1.44(1.44)
2025-09-03 14:45:59,869   INFO  Train:    4/20 ( 20%) [2163/3862 ( 56%)]  Loss: 1.779 (2.06)  LR: 4.726e-04  Grad: 13.4597  max=4.4986(module.vfe.pfn_layers.0.linear.weight)  min: -0.4163(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7183, loss_cls=0.1234, loss_bbox=0.7797, matched_ious=0.4783, loss_iou=0.0983, loss_iou_reg=0.2417, d_time=0.01(0.01), f_time=1.47(1.43), b_time=1.47(1.44)  Time cost: 52:05/40:54 [5:30:10/25:28:28]  Acc_iter 13750       Data time: 0.01(0.01)  Forward time: 1.47(1.43)  Batch time: 1.47(1.44)
2025-09-03 14:47:10,873   INFO  Train:    4/20 ( 20%) [2213/3862 ( 57%)]  Loss: 1.731 (2.06)  LR: 4.749e-04  Grad: 17.1229  max=11.1695(module.vfe.pfn_layers.0.linear.weight)  min: -1.0406(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7179, loss_cls=0.1265, loss_bbox=0.7940, matched_ious=0.4791, loss_iou=0.0950, loss_iou_reg=0.2394, d_time=0.01(0.01), f_time=1.35(1.43), b_time=1.36(1.44)  Time cost: 53:16/39:40 [5:31:21/25:26:41]  Acc_iter 13800       Data time: 0.01(0.01)  Forward time: 1.35(1.43)  Batch time: 1.36(1.44)
2025-09-03 14:48:21,469   INFO  Train:    4/20 ( 20%) [2263/3862 ( 59%)]  Loss: 2.019 (2.06)  LR: 4.772e-04  Grad: 12.8220  max=3.4571(module.vfe.pfn_layers.0.linear.weight)  min: -0.4209(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7388, loss_cls=0.1272, loss_bbox=0.7971, matched_ious=0.4804, loss_iou=0.0967, loss_iou_reg=0.2394, d_time=0.00(0.01), f_time=1.40(1.43), b_time=1.40(1.44)  Time cost: 54:27/38:27 [5:32:32/25:24:44]  Acc_iter 13850       Data time: 0.00(0.01)  Forward time: 1.40(1.43)  Batch time: 1.40(1.44)
2025-09-03 14:49:34,991   INFO  Train:    4/20 ( 20%) [2313/3862 ( 60%)]  Loss: 2.085 (2.06)  LR: 4.794e-04  Grad: 13.5886  max=0.9963(module.vfe.pfn_layers.0.linear.weight)  min: -5.3136(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7387, loss_cls=0.1292, loss_bbox=0.7957, matched_ious=0.4737, loss_iou=0.0969, loss_iou_reg=0.2430, d_time=0.01(0.01), f_time=1.42(1.43), b_time=1.43(1.44)  Time cost: 55:40/37:16 [5:33:46/25:24:09]  Acc_iter 13900       Data time: 0.01(0.01)  Forward time: 1.42(1.43)  Batch time: 1.43(1.44)
2025-09-03 14:50:49,452   INFO  Train:    4/20 ( 20%) [2363/3862 ( 61%)]  Loss: 1.953 (2.06)  LR: 4.817e-04  Grad: 17.9670  max=6.0493(module.vfe.pfn_layers.0.linear.weight)  min: -10.9624(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7304, loss_cls=0.1270, loss_bbox=0.7754, matched_ious=0.4805, loss_iou=0.0978, loss_iou_reg=0.2398, d_time=0.00(0.01), f_time=1.42(1.43), b_time=1.43(1.44)  Time cost: 56:55/36:05 [5:35:00/25:23:58]  Acc_iter 13950       Data time: 0.00(0.01)  Forward time: 1.42(1.43)  Batch time: 1.43(1.44)
2025-09-03 14:51:59,890   INFO  Train:    4/20 ( 20%) [2413/3862 ( 62%)]  Loss: 2.172 (2.06)  LR: 4.839e-04  Grad: 13.1061  max=2.7848(module.vfe.pfn_layers.0.linear.weight)  min: -0.4348(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7348, loss_cls=0.1284, loss_bbox=0.8288, matched_ious=0.4769, loss_iou=0.0974, loss_iou_reg=0.2406, d_time=0.00(0.01), f_time=1.47(1.43), b_time=1.47(1.44)  Time cost: 58:05/34:52 [5:36:11/25:21:58]  Acc_iter 14000       Data time: 0.00(0.01)  Forward time: 1.47(1.43)  Batch time: 1.47(1.44)
2025-09-03 14:53:11,020   INFO  Train:    4/20 ( 20%) [2463/3862 ( 64%)]  Loss: 2.128 (2.06)  LR: 4.862e-04  Grad: 12.5903  max=0.5594(module.vfe.pfn_layers.0.linear.weight)  min: -0.8412(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7393, loss_cls=0.1289, loss_bbox=0.7818, matched_ious=0.4792, loss_iou=0.0963, loss_iou_reg=0.2410, d_time=0.01(0.01), f_time=1.39(1.43), b_time=1.40(1.44)  Time cost: 59:16/33:39 [5:37:22/25:20:19]  Acc_iter 14050       Data time: 0.01(0.01)  Forward time: 1.39(1.43)  Batch time: 1.40(1.44)
2025-09-03 14:54:23,253   INFO  Train:    4/20 ( 20%) [2513/3862 ( 65%)]  Loss: 1.895 (2.05)  LR: 4.885e-04  Grad: 13.4803  max=0.8002(module.vfe.pfn_layers.0.linear.weight)  min: -4.6962(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7022, loss_cls=0.1234, loss_bbox=0.7865, matched_ious=0.4776, loss_iou=0.0984, loss_iou_reg=0.2423, d_time=0.01(0.01), f_time=1.40(1.43), b_time=1.41(1.44)  Time cost: 1:00:29/32:27 [5:38:34/25:19:08]  Acc_iter 14100       Data time: 0.01(0.01)  Forward time: 1.40(1.43)  Batch time: 1.41(1.44)
2025-09-03 14:55:35,304   INFO  Train:    4/20 ( 20%) [2563/3862 ( 66%)]  Loss: 1.893 (2.05)  LR: 4.907e-04  Grad: 13.5204  max=1.2294(module.vfe.pfn_layers.0.linear.weight)  min: -4.3869(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7292, loss_cls=0.1254, loss_bbox=0.8215, matched_ious=0.4680, loss_iou=0.0987, loss_iou_reg=0.2468, d_time=0.01(0.01), f_time=1.29(1.43), b_time=1.30(1.44)  Time cost: 1:01:41/31:15 [5:39:46/25:17:52]  Acc_iter 14150       Data time: 0.01(0.01)  Forward time: 1.29(1.43)  Batch time: 1.30(1.44)
2025-09-03 14:56:49,727   INFO  Train:    4/20 ( 20%) [2613/3862 ( 68%)]  Loss: 2.450 (2.05)  LR: 4.930e-04  Grad: 12.9854  max=0.4437(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.4035(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7208, loss_cls=0.1236, loss_bbox=0.7944, matched_ious=0.4768, loss_iou=0.0966, loss_iou_reg=0.2401, d_time=0.01(0.01), f_time=1.47(1.43), b_time=1.48(1.44)  Time cost: 1:02:55/30:04 [5:41:00/25:17:34]  Acc_iter 14200       Data time: 0.01(0.01)  Forward time: 1.47(1.43)  Batch time: 1.48(1.44)
2025-09-03 14:58:00,414   INFO  Train:    4/20 ( 20%) [2663/3862 ( 69%)]  Loss: 1.914 (2.05)  LR: 4.953e-04  Grad: 13.0194  max=0.9333(module.vfe.pfn_layers.0.linear.weight)  min: -1.7873(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7174, loss_cls=0.1243, loss_bbox=0.8060, matched_ious=0.4729, loss_iou=0.0971, loss_iou_reg=0.2440, d_time=0.01(0.01), f_time=1.37(1.43), b_time=1.38(1.44)  Time cost: 1:04:06/28:51 [5:42:11/25:15:46]  Acc_iter 14250       Data time: 0.01(0.01)  Forward time: 1.37(1.43)  Batch time: 1.38(1.44)
2025-09-03 14:59:11,238   INFO  Train:    4/20 ( 20%) [2713/3862 ( 70%)]  Loss: 1.989 (2.05)  LR: 4.975e-04  Grad: 14.8300  max=5.8846(module.vfe.pfn_layers.0.linear.weight)  min: -0.4544(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7128, loss_cls=0.1258, loss_bbox=0.7781, matched_ious=0.4776, loss_iou=0.0975, loss_iou_reg=0.2427, d_time=0.01(0.01), f_time=1.47(1.43), b_time=1.48(1.44)  Time cost: 1:05:17/27:38 [5:43:22/25:14:02]  Acc_iter 14300       Data time: 0.01(0.01)  Forward time: 1.47(1.43)  Batch time: 1.48(1.44)
2025-09-03 15:00:23,566   INFO  Train:    4/20 ( 20%) [2763/3862 ( 72%)]  Loss: 2.229 (2.05)  LR: 4.998e-04  Grad: 13.7716  max=0.6827(module.vfe.pfn_layers.0.linear.weight)  min: -4.5764(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7264, loss_cls=0.1245, loss_bbox=0.7993, matched_ious=0.4763, loss_iou=0.0979, loss_iou_reg=0.2415, d_time=0.01(0.01), f_time=1.32(1.43), b_time=1.33(1.44)  Time cost: 1:06:29/26:26 [5:44:34/25:12:54]  Acc_iter 14350       Data time: 0.01(0.01)  Forward time: 1.32(1.43)  Batch time: 1.33(1.44)
2025-09-03 15:01:35,536   INFO  Train:    4/20 ( 20%) [2813/3862 ( 73%)]  Loss: 1.923 (2.05)  LR: 5.021e-04  Grad: 13.2259  max=1.5879(module.vfe.pfn_layers.0.linear.weight)  min: -1.2928(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7181, loss_cls=0.1253, loss_bbox=0.7952, matched_ious=0.4816, loss_iou=0.0977, loss_iou_reg=0.2400, d_time=0.01(0.01), f_time=1.39(1.43), b_time=1.40(1.44)  Time cost: 1:07:41/25:14 [5:45:46/25:11:37]  Acc_iter 14400       Data time: 0.01(0.01)  Forward time: 1.39(1.43)  Batch time: 1.40(1.44)
2025-09-03 15:02:50,227   INFO  Train:    4/20 ( 20%) [2863/3862 ( 74%)]  Loss: 2.116 (2.05)  LR: 5.044e-04  Grad: 14.5250  max=5.1647(module.vfe.pfn_layers.0.linear.weight)  min: -0.4658(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7073, loss_cls=0.1228, loss_bbox=0.8021, matched_ious=0.4784, loss_iou=0.0982, loss_iou_reg=0.2416, d_time=0.00(0.01), f_time=1.46(1.43), b_time=1.47(1.44)  Time cost: 1:08:56/24:02 [5:47:01/25:11:20]  Acc_iter 14450       Data time: 0.00(0.01)  Forward time: 1.46(1.43)  Batch time: 1.47(1.44)
2025-09-03 15:04:01,376   INFO  Train:    4/20 ( 20%) [2913/3862 ( 75%)]  Loss: 2.131 (2.04)  LR: 5.066e-04  Grad: 13.7601  max=0.4624(module.dense_head.decoder.self_attn.in_proj_weight)  min: -3.7761(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7105, loss_cls=0.1236, loss_bbox=0.7585, matched_ious=0.4809, loss_iou=0.0978, loss_iou_reg=0.2419, d_time=0.01(0.01), f_time=1.41(1.43), b_time=1.42(1.44)  Time cost: 1:10:07/22:50 [5:48:12/25:09:45]  Acc_iter 14500       Data time: 0.01(0.01)  Forward time: 1.41(1.43)  Batch time: 1.42(1.44)
2025-09-03 15:05:12,608   INFO  Train:    4/20 ( 20%) [2963/3862 ( 77%)]  Loss: 1.917 (2.04)  LR: 5.089e-04  Grad: 14.7751  max=0.4425(module.dense_head.decoder.self_attn.in_proj_weight)  min: -7.4113(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7084, loss_cls=0.1221, loss_bbox=0.8165, matched_ious=0.4762, loss_iou=0.0974, loss_iou_reg=0.2430, d_time=0.01(0.01), f_time=1.42(1.43), b_time=1.42(1.44)  Time cost: 1:11:18/21:37 [5:49:23/25:08:13]  Acc_iter 14550       Data time: 0.01(0.01)  Forward time: 1.42(1.43)  Batch time: 1.42(1.44)
2025-09-03 15:06:24,152   INFO  Train:    4/20 ( 20%) [3013/3862 ( 78%)]  Loss: 2.109 (2.04)  LR: 5.112e-04  Grad: 13.4815  max=3.2093(module.vfe.pfn_layers.0.linear.weight)  min: -2.5007(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7197, loss_cls=0.1236, loss_bbox=0.8030, matched_ious=0.4809, loss_iou=0.0965, loss_iou_reg=0.2416, d_time=0.00(0.01), f_time=1.44(1.43), b_time=1.45(1.44)  Time cost: 1:12:30/20:25 [5:50:35/25:06:48]  Acc_iter 14600       Data time: 0.00(0.01)  Forward time: 1.44(1.43)  Batch time: 1.45(1.44)
2025-09-03 15:07:37,127   INFO  Train:    4/20 ( 20%) [3063/3862 ( 79%)]  Loss: 2.643 (2.04)  LR: 5.135e-04  Grad: 14.0085  max=5.6944(module.vfe.pfn_layers.0.linear.weight)  min: -0.4588(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7243, loss_cls=0.1231, loss_bbox=0.8079, matched_ious=0.4810, loss_iou=0.0978, loss_iou_reg=0.2416, d_time=0.00(0.01), f_time=2.23(1.43), b_time=2.24(1.44)  Time cost: 1:13:43/19:13 [5:51:48/25:05:52]  Acc_iter 14650       Data time: 0.00(0.01)  Forward time: 2.23(1.43)  Batch time: 2.24(1.44)
2025-09-03 15:08:50,500   INFO  Train:    4/20 ( 20%) [3113/3862 ( 81%)]  Loss: 2.213 (2.04)  LR: 5.158e-04  Grad: 13.1593  max=2.6206(module.vfe.pfn_layers.0.linear.weight)  min: -0.7960(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7227, loss_cls=0.1255, loss_bbox=0.7994, matched_ious=0.4747, loss_iou=0.0979, loss_iou_reg=0.2441, d_time=0.00(0.01), f_time=1.40(1.43), b_time=1.40(1.44)  Time cost: 1:14:56/18:01 [5:53:01/25:05:04]  Acc_iter 14700       Data time: 0.00(0.01)  Forward time: 1.40(1.43)  Batch time: 1.40(1.44)
2025-09-03 15:10:01,309   INFO  Train:    4/20 ( 20%) [3163/3862 ( 82%)]  Loss: 2.082 (2.04)  LR: 5.180e-04  Grad: 13.3408  max=3.0294(module.vfe.pfn_layers.0.linear.weight)  min: -1.2477(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7287, loss_cls=0.1251, loss_bbox=0.8025, matched_ious=0.4801, loss_iou=0.0978, loss_iou_reg=0.2400, d_time=0.00(0.01), f_time=1.44(1.43), b_time=1.45(1.44)  Time cost: 1:16:07/16:48 [5:54:12/25:03:24]  Acc_iter 14750       Data time: 0.00(0.01)  Forward time: 1.44(1.43)  Batch time: 1.45(1.44)
2025-09-03 15:11:12,873   INFO  Train:    4/20 ( 20%) [3213/3862 ( 83%)]  Loss: 2.199 (2.04)  LR: 5.203e-04  Grad: 13.1363  max=1.6514(module.vfe.pfn_layers.0.linear.weight)  min: -0.4739(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6946, loss_cls=0.1192, loss_bbox=0.7963, matched_ious=0.4755, loss_iou=0.0973, loss_iou_reg=0.2426, d_time=0.00(0.01), f_time=1.51(1.43), b_time=1.51(1.44)  Time cost: 1:17:18/15:36 [5:55:23/25:02:00]  Acc_iter 14800       Data time: 0.00(0.01)  Forward time: 1.51(1.43)  Batch time: 1.51(1.44)
2025-09-03 15:12:25,126   INFO  Train:    4/20 ( 20%) [3263/3862 ( 84%)]  Loss: 1.475 (2.04)  LR: 5.226e-04  Grad: 13.1609  max=1.0201(module.vfe.pfn_layers.0.linear.weight)  min: -0.4660(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6862, loss_cls=0.1184, loss_bbox=0.7840, matched_ious=0.4736, loss_iou=0.0972, loss_iou_reg=0.2453, d_time=0.00(0.01), f_time=1.52(1.43), b_time=1.52(1.44)  Time cost: 1:18:30/14:24 [5:56:36/25:00:50]  Acc_iter 14850       Data time: 0.00(0.01)  Forward time: 1.52(1.43)  Batch time: 1.52(1.44)
2025-09-03 15:13:41,134   INFO  Train:    4/20 ( 20%) [3313/3862 ( 86%)]  Loss: 1.695 (2.03)  LR: 5.249e-04  Grad: 14.6115  max=4.6607(module.vfe.pfn_layers.0.linear.weight)  min: -0.4680(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7077, loss_cls=0.1230, loss_bbox=0.7829, matched_ious=0.4822, loss_iou=0.0956, loss_iou_reg=0.2399, d_time=0.38(0.01), f_time=2.22(1.43), b_time=2.60(1.44)  Time cost: 1:19:47/13:13 [5:57:52/25:00:50]  Acc_iter 14900       Data time: 0.38(0.01)  Forward time: 2.22(1.43)  Batch time: 2.60(1.44)
2025-09-03 15:14:52,114   INFO  Train:    4/20 ( 20%) [3363/3862 ( 87%)]  Loss: 2.070 (2.03)  LR: 5.272e-04  Grad: 14.2956  max=5.2280(module.vfe.pfn_layers.0.linear.weight)  min: -1.0540(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6986, loss_cls=0.1219, loss_bbox=0.8120, matched_ious=0.4800, loss_iou=0.0944, loss_iou_reg=0.2405, d_time=0.01(0.01), f_time=1.36(1.43), b_time=1.37(1.44)  Time cost: 1:20:57/12:00 [5:59:03/24:59:15]  Acc_iter 14950       Data time: 0.01(0.01)  Forward time: 1.36(1.43)  Batch time: 1.37(1.44)
2025-09-03 15:16:02,923   INFO  Train:    4/20 ( 20%) [3413/3862 ( 88%)]  Loss: 2.080 (2.03)  LR: 5.295e-04  Grad: 14.9632  max=5.9710(module.vfe.pfn_layers.0.linear.weight)  min: -3.3202(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7192, loss_cls=0.1232, loss_bbox=0.8031, matched_ious=0.4812, loss_iou=0.0962, loss_iou_reg=0.2402, d_time=0.01(0.01), f_time=1.48(1.43), b_time=1.48(1.44)  Time cost: 1:22:08/10:48 [6:00:14/24:57:37]  Acc_iter 15000       Data time: 0.01(0.01)  Forward time: 1.48(1.43)  Batch time: 1.48(1.44)
2025-09-03 15:17:14,888   INFO  Train:    4/20 ( 20%) [3463/3862 ( 90%)]  Loss: 1.979 (2.03)  LR: 5.317e-04  Grad: 20.6786  max=8.5998(module.vfe.pfn_layers.0.linear.weight)  min: -12.2455(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7305, loss_cls=0.1245, loss_bbox=0.8112, matched_ious=0.4792, loss_iou=0.0972, loss_iou_reg=0.2402, d_time=0.01(0.01), f_time=1.31(1.43), b_time=1.32(1.44)  Time cost: 1:23:20/09:36 [6:01:26/24:56:21]  Acc_iter 15050       Data time: 0.01(0.01)  Forward time: 1.31(1.43)  Batch time: 1.32(1.44)
2025-09-03 15:18:25,923   INFO  Train:    4/20 ( 20%) [3513/3862 ( 91%)]  Loss: 1.781 (2.03)  LR: 5.340e-04  Grad: 14.0281  max=3.0793(module.vfe.pfn_layers.0.linear.weight)  min: -2.2989(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6998, loss_cls=0.1229, loss_bbox=0.7768, matched_ious=0.4809, loss_iou=0.0963, loss_iou_reg=0.2410, d_time=0.01(0.01), f_time=1.43(1.43), b_time=1.43(1.44)  Time cost: 1:24:31/08:23 [6:02:37/24:54:48]  Acc_iter 15100       Data time: 0.01(0.01)  Forward time: 1.43(1.43)  Batch time: 1.43(1.44)
2025-09-03 15:19:42,626   INFO  Train:    4/20 ( 20%) [3563/3862 ( 92%)]  Loss: 2.192 (2.03)  LR: 5.363e-04  Grad: 15.4145  max=0.4820(module.dense_head.decoder.self_attn.in_proj_weight)  min: -5.1931(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6802, loss_cls=0.1184, loss_bbox=0.7729, matched_ious=0.4803, loss_iou=0.0977, loss_iou_reg=0.2408, d_time=0.00(0.01), f_time=1.41(1.43), b_time=1.41(1.44)  Time cost: 1:25:48/07:11 [6:03:53/24:54:55]  Acc_iter 15150       Data time: 0.00(0.01)  Forward time: 1.41(1.43)  Batch time: 1.41(1.44)
2025-09-03 15:20:53,835   INFO  Train:    4/20 ( 20%) [3613/3862 ( 94%)]  Loss: 2.055 (2.03)  LR: 5.386e-04  Grad: 14.2199  max=0.7438(module.vfe.pfn_layers.0.linear.weight)  min: -3.9142(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7071, loss_cls=0.1202, loss_bbox=0.8353, matched_ious=0.4777, loss_iou=0.0979, loss_iou_reg=0.2417, d_time=0.01(0.01), f_time=1.39(1.43), b_time=1.40(1.44)  Time cost: 1:26:59/05:59 [6:05:04/24:53:25]  Acc_iter 15200       Data time: 0.01(0.01)  Forward time: 1.39(1.43)  Batch time: 1.40(1.44)
2025-09-03 15:22:05,185   INFO  Train:    4/20 ( 20%) [3663/3862 ( 95%)]  Loss: 1.944 (2.03)  LR: 5.409e-04  Grad: 13.8078  max=1.6997(module.vfe.pfn_layers.0.linear.weight)  min: -1.2851(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7007, loss_cls=0.1181, loss_bbox=0.8024, matched_ious=0.4846, loss_iou=0.0970, loss_iou_reg=0.2399, d_time=0.01(0.01), f_time=1.33(1.43), b_time=1.33(1.44)  Time cost: 1:28:11/04:47 [6:06:16/24:51:59]  Acc_iter 15250       Data time: 0.01(0.01)  Forward time: 1.33(1.43)  Batch time: 1.33(1.44)
2025-09-03 15:23:17,280   INFO  Train:    4/20 ( 20%) [3713/3862 ( 96%)]  Loss: 1.967 (2.03)  LR: 5.432e-04  Grad: 13.9397  max=1.5752(module.vfe.pfn_layers.0.linear.weight)  min: -1.9075(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6903, loss_cls=0.1199, loss_bbox=0.8037, matched_ious=0.4842, loss_iou=0.0966, loss_iou_reg=0.2398, d_time=0.01(0.01), f_time=1.51(1.43), b_time=1.52(1.44)  Time cost: 1:29:23/03:35 [6:07:28/24:50:45]  Acc_iter 15300       Data time: 0.01(0.01)  Forward time: 1.51(1.43)  Batch time: 1.52(1.44)
2025-09-03 15:24:28,128   INFO  Train:    4/20 ( 20%) [3763/3862 ( 97%)]  Loss: 1.757 (2.03)  LR: 5.455e-04  Grad: 14.3958  max=2.5813(module.vfe.pfn_layers.0.linear.weight)  min: -3.2743(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7087, loss_cls=0.1221, loss_bbox=0.7989, matched_ious=0.4795, loss_iou=0.0972, loss_iou_reg=0.2434, d_time=0.01(0.01), f_time=1.42(1.43), b_time=1.43(1.44)  Time cost: 1:30:33/02:22 [6:08:39/24:49:10]  Acc_iter 15350       Data time: 0.01(0.01)  Forward time: 1.42(1.43)  Batch time: 1.43(1.44)
2025-09-03 15:25:43,670   INFO  Train:    4/20 ( 20%) [3813/3862 ( 99%)]  Loss: 1.630 (2.03)  LR: 5.478e-04  Grad: 13.8490  max=0.4986(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5043(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7125, loss_cls=0.1213, loss_bbox=0.7887, matched_ious=0.4767, loss_iou=0.0984, loss_iou_reg=0.2438, d_time=0.01(0.01), f_time=1.48(1.43), b_time=1.49(1.44)  Time cost: 1:31:49/01:10 [6:09:54/24:48:52]  Acc_iter 15400       Data time: 0.01(0.01)  Forward time: 1.48(1.43)  Batch time: 1.49(1.44)
2025-09-03 15:26:50,733   INFO  Train:    4/20 ( 20%) [3861/3862 (100%)]  Loss: 1.920 (2.02)  LR: 5.500e-04  Grad: 17.2760  max=6.8118(module.vfe.pfn_layers.0.linear.weight)  min: -0.5090(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6999, loss_cls=0.1203, loss_bbox=0.7644, matched_ious=0.4845, loss_iou=0.0948, loss_iou_reg=0.2410, d_time=0.00(0.01), f_time=1.46(1.43), b_time=1.47(1.44)  Time cost: 1:32:56/00:01 [6:11:01/24:47:07]  Acc_iter 15448       Data time: 0.00(0.01)  Forward time: 1.46(1.43)  Batch time: 1.47(1.44)

                                               [Aepochs:  20%|██        | 4/20 [6:11:02<24:44:54, 5568.42s/it]epochs:  20%|██        | 4/20 [6:11:02<24:44:54, 5568.41s/it]epochs:  20%|██        | 4/20 [6:11:02<24:44:55, 5568.44s/it]epochs:  20%|██        | 4/20 [6:11:02<24:44:55, 5568.44s/it]epochs:  20%|██        | 4/20 [6:11:02<24:44:54, 5568.43s/it]epochs:  20%|██        | 4/20 [6:11:02<24:44:55, 5568.44s/it]epochs:  20%|██        | 4/20 [6:11:02<24:44:55, 5568.45s/it]epochs:  20%|██        | 4/20 [6:11:02<24:44:55, 5568.47s/it]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-03 15:26:56,332   INFO  Train:    5/20 ( 25%) [   0/3862 (  0%)]  Loss: 1.672 (1.67)  LR: 5.500e-04  Grad: 14.2712  max=2.7526(module.vfe.pfn_layers.0.linear.weight)  min: -1.5268(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6264, loss_cls=0.1068, loss_bbox=0.6041, matched_ious=0.5017, loss_iou=0.0957, loss_iou_reg=0.2391, d_time=2.13(2.13), f_time=2.26(2.26), b_time=4.39(4.39)  Time cost: 00:04/4:23:07 [6:11:07/70:10:06]  Acc_iter 15449       Data time: 2.13(2.13)  Forward time: 2.26(2.26)  Batch time: 4.39(4.39)
2025-09-03 15:26:57,838   INFO  Train:    5/20 ( 25%) [   1/3862 (  0%)]  Loss: 1.981 (1.83)  LR: 5.500e-04  Grad: 14.3098  max=1.5361(module.vfe.pfn_layers.0.linear.weight)  min: -2.8339(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7505, loss_cls=0.1176, loss_bbox=0.7643, matched_ious=0.4811, loss_iou=0.1029, loss_iou_reg=0.2459, d_time=0.02(1.07), f_time=1.49(1.88), b_time=1.51(2.95)  Time cost: 00:05/3:00:00 [6:11:08/48:00:52]  Acc_iter 15450       Data time: 0.02(1.07)  Forward time: 1.49(1.88)  Batch time: 1.51(2.95)
2025-09-03 15:28:09,892   INFO  Train:    5/20 ( 25%) [  51/3862 (  1%)]  Loss: 2.012 (1.94)  LR: 5.523e-04  Grad: 14.8407  max=1.5111(module.vfe.pfn_layers.0.linear.weight)  min: -3.5926(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6827, loss_cls=0.1174, loss_bbox=0.8060, matched_ious=0.4886, loss_iou=0.0963, loss_iou_reg=0.2386, d_time=0.00(0.05), f_time=1.35(1.45), b_time=1.36(1.50)  Time cost: 01:17/1:34:50 [6:12:21/25:36:35]  Acc_iter 15500       Data time: 0.00(0.05)  Forward time: 1.35(1.45)  Batch time: 1.36(1.50)
2025-09-03 15:29:21,666   INFO  Train:    5/20 ( 25%) [ 101/3862 (  3%)]  Loss: 1.649 (1.93)  LR: 5.546e-04  Grad: 15.2358  max=2.1265(module.vfe.pfn_layers.0.linear.weight)  min: -5.4921(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6883, loss_cls=0.1188, loss_bbox=0.7707, matched_ious=0.4828, loss_iou=0.0963, loss_iou_reg=0.2418, d_time=0.01(0.03), f_time=1.31(1.44), b_time=1.31(1.47)  Time cost: 02:29/1:31:49 [6:13:32/25:06:13]  Acc_iter 15550       Data time: 0.01(0.03)  Forward time: 1.31(1.44)  Batch time: 1.31(1.47)
2025-09-03 15:30:33,098   INFO  Train:    5/20 ( 25%) [ 151/3862 (  4%)]  Loss: 1.802 (1.93)  LR: 5.569e-04  Grad: 17.6936  max=6.8394(module.vfe.pfn_layers.0.linear.weight)  min: -4.8980(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6776, loss_cls=0.1158, loss_bbox=0.8083, matched_ious=0.4833, loss_iou=0.0963, loss_iou_reg=0.2379, d_time=0.01(0.02), f_time=1.35(1.43), b_time=1.36(1.45)  Time cost: 03:40/1:29:52 [6:14:44/24:52:43]  Acc_iter 15600       Data time: 0.01(0.02)  Forward time: 1.35(1.43)  Batch time: 1.36(1.45)
2025-09-03 15:31:49,066   INFO  Train:    5/20 ( 25%) [ 201/3862 (  5%)]  Loss: 2.495 (1.94)  LR: 5.592e-04  Grad: 14.2764  max=1.1913(module.vfe.pfn_layers.0.linear.weight)  min: -0.5258(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7164, loss_cls=0.1227, loss_bbox=0.8030, matched_ious=0.4775, loss_iou=0.0972, loss_iou_reg=0.2439, d_time=0.01(0.02), f_time=1.43(1.45), b_time=1.44(1.47)  Time cost: 04:56/1:29:39 [6:16:00/25:08:22]  Acc_iter 15650       Data time: 0.01(0.02)  Forward time: 1.43(1.45)  Batch time: 1.44(1.47)
2025-09-03 15:33:01,140   INFO  Train:    5/20 ( 25%) [ 251/3862 (  6%)]  Loss: 1.984 (1.94)  LR: 5.615e-04  Grad: 14.3191  max=0.5144(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1248(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6796, loss_cls=0.1183, loss_bbox=0.7805, matched_ious=0.4847, loss_iou=0.0963, loss_iou_reg=0.2402, d_time=0.00(0.02), f_time=1.34(1.45), b_time=1.34(1.47)  Time cost: 06:08/1:28:06 [6:17:12/25:01:29]  Acc_iter 15700       Data time: 0.00(0.02)  Forward time: 1.34(1.45)  Batch time: 1.34(1.47)
2025-09-03 15:34:13,293   INFO  Train:    5/20 ( 25%) [ 301/3862 (  8%)]  Loss: 1.735 (1.93)  LR: 5.638e-04  Grad: 14.4371  max=0.8542(module.vfe.pfn_layers.0.linear.weight)  min: -1.4496(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6896, loss_cls=0.1184, loss_bbox=0.7445, matched_ious=0.4856, loss_iou=0.0969, loss_iou_reg=0.2408, d_time=0.01(0.02), f_time=1.35(1.45), b_time=1.36(1.46)  Time cost: 07:21/1:26:40 [6:18:24/24:56:43]  Acc_iter 15750       Data time: 0.01(0.02)  Forward time: 1.35(1.45)  Batch time: 1.36(1.46)
2025-09-03 15:35:24,036   INFO  Train:    5/20 ( 25%) [ 351/3862 (  9%)]  Loss: 2.362 (1.92)  LR: 5.661e-04  Grad: 14.6561  max=2.7551(module.vfe.pfn_layers.0.linear.weight)  min: -0.5684(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6754, loss_cls=0.1180, loss_bbox=0.7491, matched_ious=0.4885, loss_iou=0.0973, loss_iou_reg=0.2401, d_time=0.01(0.01), f_time=1.45(1.44), b_time=1.46(1.45)  Time cost: 08:31/1:25:04 [6:19:35/24:48:52]  Acc_iter 15800       Data time: 0.01(0.01)  Forward time: 1.45(1.44)  Batch time: 1.46(1.45)
2025-09-03 15:36:34,252   INFO  Train:    5/20 ( 25%) [ 401/3862 ( 10%)]  Loss: 1.858 (1.93)  LR: 5.683e-04  Grad: 15.1284  max=3.9537(module.vfe.pfn_layers.0.linear.weight)  min: -0.5364(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7264, loss_cls=0.1239, loss_bbox=0.8021, matched_ious=0.4834, loss_iou=0.0968, loss_iou_reg=0.2408, d_time=0.00(0.01), f_time=1.47(1.44), b_time=1.48(1.45)  Time cost: 09:42/1:23:30 [6:20:45/24:41:20]  Acc_iter 15850       Data time: 0.00(0.01)  Forward time: 1.47(1.44)  Batch time: 1.48(1.45)
2025-09-03 15:37:50,720   INFO  Train:    5/20 ( 25%) [ 451/3862 ( 12%)]  Loss: 2.138 (1.93)  LR: 5.706e-04  Grad: 12.9419  max=2.5998(module.vfe.pfn_layers.0.linear.weight)  min: -0.9153(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6934, loss_cls=0.1208, loss_bbox=0.7704, matched_ious=0.4934, loss_iou=0.0954, loss_iou_reg=0.2347, d_time=0.01(0.01), f_time=1.49(1.44), b_time=1.50(1.46)  Time cost: 10:58/1:22:49 [6:22:01/24:49:21]  Acc_iter 15900       Data time: 0.01(0.01)  Forward time: 1.49(1.44)  Batch time: 1.50(1.46)
2025-09-03 15:39:02,065   INFO  Train:    5/20 ( 25%) [ 501/3862 ( 13%)]  Loss: 2.417 (1.94)  LR: 5.729e-04  Grad: 12.7749  max=2.0515(module.vfe.pfn_layers.0.linear.weight)  min: -0.4678(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.7150, loss_cls=0.1223, loss_bbox=0.8207, matched_ious=0.4828, loss_iou=0.0966, loss_iou_reg=0.2400, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 12:09/1:21:26 [6:23:13/24:45:06]  Acc_iter 15950       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-03 15:40:14,265   INFO  Train:    5/20 ( 25%) [ 551/3862 ( 14%)]  Loss: 2.234 (1.94)  LR: 5.752e-04  Grad: 13.8271  max=3.8776(module.vfe.pfn_layers.0.linear.weight)  min: -3.4478(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7110, loss_cls=0.1219, loss_bbox=0.7641, matched_ious=0.4838, loss_iou=0.0963, loss_iou_reg=0.2409, d_time=0.01(0.01), f_time=1.55(1.44), b_time=1.55(1.45)  Time cost: 13:22/1:20:10 [6:24:25/24:42:58]  Acc_iter 16000       Data time: 0.01(0.01)  Forward time: 1.55(1.44)  Batch time: 1.55(1.45)
2025-09-03 15:41:25,088   INFO  Train:    5/20 ( 25%) [ 601/3862 ( 16%)]  Loss: 1.760 (1.94)  LR: 5.775e-04  Grad: 12.9244  max=0.7811(module.vfe.pfn_layers.0.linear.weight)  min: -1.5960(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6951, loss_cls=0.1206, loss_bbox=0.7763, matched_ious=0.4783, loss_iou=0.1009, loss_iou_reg=0.2432, d_time=0.00(0.01), f_time=1.39(1.44), b_time=1.40(1.45)  Time cost: 14:32/1:18:48 [6:25:36/24:38:40]  Acc_iter 16050       Data time: 0.00(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.45)
2025-09-03 15:42:36,400   INFO  Train:    5/20 ( 25%) [ 651/3862 ( 17%)]  Loss: 1.941 (1.93)  LR: 5.798e-04  Grad: 13.3458  max=3.2732(module.vfe.pfn_layers.0.linear.weight)  min: -1.8040(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6782, loss_cls=0.1177, loss_bbox=0.7737, matched_ious=0.4864, loss_iou=0.0963, loss_iou_reg=0.2391, d_time=0.01(0.01), f_time=1.46(1.44), b_time=1.46(1.45)  Time cost: 15:44/1:17:29 [6:26:47/24:35:37]  Acc_iter 16100       Data time: 0.01(0.01)  Forward time: 1.46(1.44)  Batch time: 1.46(1.45)
2025-09-03 15:43:51,692   INFO  Train:    5/20 ( 25%) [ 701/3862 ( 18%)]  Loss: 1.704 (1.93)  LR: 5.820e-04  Grad: 8.8921  max=0.7957(module.vfe.pfn_layers.0.linear.weight)  min: -3.2752(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6943, loss_cls=0.1196, loss_bbox=0.7709, matched_ious=0.4833, loss_iou=0.0966, loss_iou_reg=0.2401, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 16:59/1:16:30 [6:28:02/24:38:36]  Acc_iter 16150       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-03 15:45:02,498   INFO  Train:    5/20 ( 25%) [ 751/3862 ( 19%)]  Loss: 2.521 (1.93)  LR: 5.843e-04  Grad: 9.2648  max=2.2452(module.vfe.pfn_layers.0.linear.weight)  min: -3.4390(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7025, loss_cls=0.1208, loss_bbox=0.7810, matched_ious=0.4882, loss_iou=0.0979, loss_iou_reg=0.2364, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 18:10/1:15:10 [6:29:13/24:34:57]  Acc_iter 16200       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-03 15:46:13,985   INFO  Train:    5/20 ( 25%) [ 801/3862 ( 21%)]  Loss: 1.746 (1.93)  LR: 5.866e-04  Grad: 8.8447  max=2.1035(module.vfe.pfn_layers.0.linear.weight)  min: -0.3081(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6663, loss_cls=0.1150, loss_bbox=0.7649, matched_ious=0.4873, loss_iou=0.0955, loss_iou_reg=0.2394, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 19:21/1:13:54 [6:30:25/24:32:28]  Acc_iter 16250       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-03 15:47:26,003   INFO  Train:    5/20 ( 25%) [ 851/3862 ( 22%)]  Loss: 1.792 (1.92)  LR: 5.889e-04  Grad: 9.1985  max=2.6205(module.vfe.pfn_layers.0.linear.weight)  min: -1.4956(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6659, loss_cls=0.1160, loss_bbox=0.7307, matched_ious=0.4939, loss_iou=0.0971, loss_iou_reg=0.2387, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 20:33/1:12:40 [6:31:37/24:30:46]  Acc_iter 16300       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-03 15:48:36,515   INFO  Train:    5/20 ( 25%) [ 901/3862 ( 23%)]  Loss: 1.771 (1.92)  LR: 5.912e-04  Grad: 8.6777  max=1.0684(module.vfe.pfn_layers.0.linear.weight)  min: -1.2963(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6766, loss_cls=0.1184, loss_bbox=0.7567, matched_ious=0.4906, loss_iou=0.0959, loss_iou_reg=0.2379, d_time=0.01(0.01), f_time=1.38(1.43), b_time=1.38(1.45)  Time cost: 21:44/1:11:21 [6:32:47/24:27:26]  Acc_iter 16350       Data time: 0.01(0.01)  Forward time: 1.38(1.43)  Batch time: 1.38(1.45)
2025-09-03 15:49:52,705   INFO  Train:    5/20 ( 25%) [ 951/3862 ( 25%)]  Loss: 1.631 (1.92)  LR: 5.934e-04  Grad: 8.6461  max=0.5739(module.vfe.pfn_layers.0.linear.weight)  min: -0.9995(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6758, loss_cls=0.1165, loss_bbox=0.7666, matched_ious=0.4913, loss_iou=0.0960, loss_iou_reg=0.2365, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 23:00/1:10:21 [6:34:03/24:30:23]  Acc_iter 16400       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-03 15:51:03,809   INFO  Train:    5/20 ( 25%) [1001/3862 ( 26%)]  Loss: 1.681 (1.92)  LR: 5.957e-04  Grad: 8.8669  max=1.6922(module.vfe.pfn_layers.0.linear.weight)  min: -1.1014(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6825, loss_cls=0.1175, loss_bbox=0.8039, matched_ious=0.4864, loss_iou=0.0987, loss_iou_reg=0.2381, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 24:11/1:09:04 [6:35:14/24:27:46]  Acc_iter 16450       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-03 15:52:16,016   INFO  Train:    5/20 ( 25%) [1051/3862 ( 27%)]  Loss: 1.931 (1.92)  LR: 5.980e-04  Grad: 8.8033  max=1.4213(module.vfe.pfn_layers.0.linear.weight)  min: -0.3222(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6819, loss_cls=0.1161, loss_bbox=0.7675, matched_ious=0.4906, loss_iou=0.0956, loss_iou_reg=0.2364, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 25:23/1:07:51 [6:36:27/24:26:20]  Acc_iter 16500       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-03 15:53:27,356   INFO  Train:    5/20 ( 25%) [1101/3862 ( 29%)]  Loss: 1.721 (1.92)  LR: 6.003e-04  Grad: 11.3881  max=0.3169(module.dense_head.decoder.self_attn.in_proj_weight)  min: -7.2586(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.7076, loss_cls=0.1229, loss_bbox=0.7679, matched_ious=0.4891, loss_iou=0.0962, loss_iou_reg=0.2374, d_time=0.00(0.01), f_time=1.36(1.44), b_time=1.37(1.45)  Time cost: 26:35/1:06:36 [6:37:38/24:24:08]  Acc_iter 16550       Data time: 0.00(0.01)  Forward time: 1.36(1.44)  Batch time: 1.37(1.45)
2025-09-03 15:54:38,291   INFO  Train:    5/20 ( 25%) [1151/3862 ( 30%)]  Loss: 1.775 (1.92)  LR: 6.025e-04  Grad: 10.3179  max=4.7052(module.vfe.pfn_layers.0.linear.weight)  min: -0.3722(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6928, loss_cls=0.1174, loss_bbox=0.7593, matched_ious=0.4930, loss_iou=0.0962, loss_iou_reg=0.2348, d_time=0.01(0.01), f_time=1.46(1.44), b_time=1.47(1.45)  Time cost: 27:46/1:05:20 [6:38:49/24:21:40]  Acc_iter 16600       Data time: 0.01(0.01)  Forward time: 1.46(1.44)  Batch time: 1.47(1.45)
2025-09-03 15:55:54,187   INFO  Train:    5/20 ( 25%) [1201/3862 ( 31%)]  Loss: 1.710 (1.92)  LR: 6.048e-04  Grad: 9.0947  max=0.9240(module.vfe.pfn_layers.0.linear.weight)  min: -1.2344(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6614, loss_cls=0.1150, loss_bbox=0.7736, matched_ious=0.4879, loss_iou=0.0954, loss_iou_reg=0.2384, d_time=0.00(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 29:01/1:04:16 [6:40:05/24:23:28]  Acc_iter 16650       Data time: 0.00(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-03 15:57:06,285   INFO  Train:    5/20 ( 25%) [1251/3862 ( 32%)]  Loss: 1.633 (1.92)  LR: 6.071e-04  Grad: 9.6090  max=0.8367(module.vfe.pfn_layers.0.linear.weight)  min: -3.1588(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6778, loss_cls=0.1174, loss_bbox=0.7387, matched_ious=0.4942, loss_iou=0.0952, loss_iou_reg=0.2359, d_time=0.01(0.01), f_time=1.45(1.44), b_time=1.46(1.45)  Time cost: 30:14/1:03:03 [6:41:17/24:21:58]  Acc_iter 16700       Data time: 0.01(0.01)  Forward time: 1.45(1.44)  Batch time: 1.46(1.45)
2025-09-03 15:58:16,994   INFO  Train:    5/20 ( 25%) [1301/3862 ( 34%)]  Loss: 2.046 (1.92)  LR: 6.094e-04  Grad: 9.3540  max=1.5351(module.vfe.pfn_layers.0.linear.weight)  min: -0.9674(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6755, loss_cls=0.1167, loss_bbox=0.7546, matched_ious=0.4912, loss_iou=0.0966, loss_iou_reg=0.2386, d_time=0.00(0.01), f_time=1.38(1.44), b_time=1.38(1.45)  Time cost: 31:24/1:01:47 [6:42:28/24:19:25]  Acc_iter 16750       Data time: 0.00(0.01)  Forward time: 1.38(1.44)  Batch time: 1.38(1.45)
2025-09-03 15:59:28,161   INFO  Train:    5/20 ( 25%) [1351/3862 ( 35%)]  Loss: 2.047 (1.91)  LR: 6.116e-04  Grad: 9.5683  max=1.1004(module.vfe.pfn_layers.0.linear.weight)  min: -2.6574(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6717, loss_cls=0.1191, loss_bbox=0.7443, matched_ious=0.4874, loss_iou=0.0970, loss_iou_reg=0.2410, d_time=0.01(0.01), f_time=1.31(1.44), b_time=1.31(1.45)  Time cost: 32:35/1:00:32 [6:43:39/24:17:19]  Acc_iter 16800       Data time: 0.01(0.01)  Forward time: 1.31(1.44)  Batch time: 1.31(1.45)
2025-09-03 16:00:40,444   INFO  Train:    5/20 ( 25%) [1401/3862 ( 36%)]  Loss: 1.828 (1.91)  LR: 6.139e-04  Grad: 9.2614  max=0.5588(module.vfe.pfn_layers.0.linear.weight)  min: -1.0294(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6822, loss_cls=0.1188, loss_bbox=0.7456, matched_ious=0.4896, loss_iou=0.0957, loss_iou_reg=0.2377, d_time=0.00(0.01), f_time=2.29(1.44), b_time=2.29(1.45)  Time cost: 33:48/59:20 [6:44:51/24:16:04]  Acc_iter 16850       Data time: 0.00(0.01)  Forward time: 2.29(1.44)  Batch time: 2.29(1.45)
2025-09-03 16:01:55,606   INFO  Train:    5/20 ( 25%) [1451/3862 ( 38%)]  Loss: 2.003 (1.91)  LR: 6.162e-04  Grad: 14.2886  max=7.1928(module.vfe.pfn_layers.0.linear.weight)  min: -6.1426(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6895, loss_cls=0.1203, loss_bbox=0.7585, matched_ious=0.4869, loss_iou=0.0949, loss_iou_reg=0.2397, d_time=0.00(0.01), f_time=1.52(1.44), b_time=1.52(1.45)  Time cost: 35:03/58:12 [6:46:06/24:16:49]  Acc_iter 16900       Data time: 0.00(0.01)  Forward time: 1.52(1.44)  Batch time: 1.52(1.45)
2025-09-03 16:03:07,524   INFO  Train:    5/20 ( 25%) [1501/3862 ( 39%)]  Loss: 1.744 (1.91)  LR: 6.184e-04  Grad: 13.1142  max=5.2330(module.vfe.pfn_layers.0.linear.weight)  min: -7.2957(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6903, loss_cls=0.1164, loss_bbox=0.7624, matched_ious=0.4962, loss_iou=0.0938, loss_iou_reg=0.2334, d_time=0.01(0.01), f_time=1.45(1.44), b_time=1.45(1.45)  Time cost: 36:15/56:59 [6:47:18/24:15:16]  Acc_iter 16950       Data time: 0.01(0.01)  Forward time: 1.45(1.44)  Batch time: 1.45(1.45)
2025-09-03 16:04:18,370   INFO  Train:    5/20 ( 25%) [1551/3862 ( 40%)]  Loss: 1.738 (1.91)  LR: 6.207e-04  Grad: 10.1978  max=3.5924(module.vfe.pfn_layers.0.linear.weight)  min: -0.8849(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6819, loss_cls=0.1143, loss_bbox=0.7723, matched_ious=0.4883, loss_iou=0.0972, loss_iou_reg=0.2387, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 37:26/55:44 [6:48:29/24:13:03]  Acc_iter 17000       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-03 16:05:29,589   INFO  Train:    5/20 ( 25%) [1601/3862 ( 41%)]  Loss: 1.916 (1.91)  LR: 6.229e-04  Grad: 13.3098  max=7.7430(module.vfe.pfn_layers.0.linear.weight)  min: -3.2413(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6847, loss_cls=0.1189, loss_bbox=0.7621, matched_ious=0.4883, loss_iou=0.0959, loss_iou_reg=0.2382, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.42(1.45)  Time cost: 38:37/54:30 [6:49:40/24:11:08]  Acc_iter 17050       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.45)
2025-09-03 16:06:41,335   INFO  Train:    5/20 ( 25%) [1651/3862 ( 43%)]  Loss: 2.071 (1.91)  LR: 6.252e-04  Grad: 9.6543  max=0.3445(module.vfe.pfn_layers.0.linear.weight)  min: -1.1415(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6803, loss_cls=0.1178, loss_bbox=0.7486, matched_ious=0.4919, loss_iou=0.0967, loss_iou_reg=0.2366, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 39:49/53:17 [6:50:52/24:09:34]  Acc_iter 17100       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-03 16:07:55,840   INFO  Train:    5/20 ( 25%) [1701/3862 ( 44%)]  Loss: 1.806 (1.91)  LR: 6.274e-04  Grad: 10.7010  max=3.6305(module.vfe.pfn_layers.0.linear.weight)  min: -0.3658(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6743, loss_cls=0.1168, loss_bbox=0.7196, matched_ious=0.4999, loss_iou=0.0943, loss_iou_reg=0.2330, d_time=0.00(0.01), f_time=1.39(1.44), b_time=1.39(1.45)  Time cost: 41:03/52:07 [6:52:06/24:09:40]  Acc_iter 17150       Data time: 0.00(0.01)  Forward time: 1.39(1.44)  Batch time: 1.39(1.45)
2025-09-03 16:09:07,620   INFO  Train:    5/20 ( 25%) [1751/3862 ( 45%)]  Loss: 1.965 (1.91)  LR: 6.297e-04  Grad: 9.8082  max=0.3427(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2883(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6657, loss_cls=0.1138, loss_bbox=0.7315, matched_ious=0.4945, loss_iou=0.0970, loss_iou_reg=0.2365, d_time=0.02(0.01), f_time=1.27(1.44), b_time=1.29(1.45)  Time cost: 42:15/50:54 [6:53:18/24:08:07]  Acc_iter 17200       Data time: 0.02(0.01)  Forward time: 1.27(1.44)  Batch time: 1.29(1.45)
2025-09-03 16:10:18,931   INFO  Train:    5/20 ( 25%) [1801/3862 ( 47%)]  Loss: 1.608 (1.90)  LR: 6.319e-04  Grad: 9.9796  max=1.7072(module.vfe.pfn_layers.0.linear.weight)  min: -0.3741(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6520, loss_cls=0.1113, loss_bbox=0.7420, matched_ious=0.4934, loss_iou=0.0950, loss_iou_reg=0.2365, d_time=0.01(0.01), f_time=1.30(1.44), b_time=1.32(1.45)  Time cost: 43:26/49:41 [6:54:30/24:06:20]  Acc_iter 17250       Data time: 0.01(0.01)  Forward time: 1.30(1.44)  Batch time: 1.32(1.45)
2025-09-03 16:11:28,792   INFO  Train:    5/20 ( 25%) [1851/3862 ( 48%)]  Loss: 1.733 (1.90)  LR: 6.342e-04  Grad: 10.0473  max=0.5113(module.vfe.pfn_layers.0.linear.weight)  min: -1.5553(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6701, loss_cls=0.1161, loss_bbox=0.7418, matched_ious=0.4832, loss_iou=0.0967, loss_iou_reg=0.2405, d_time=0.01(0.01), f_time=1.34(1.44), b_time=1.35(1.45)  Time cost: 44:36/48:26 [6:55:39/24:03:48]  Acc_iter 17300       Data time: 0.01(0.01)  Forward time: 1.34(1.44)  Batch time: 1.35(1.45)
2025-09-03 16:12:41,627   INFO  Train:    5/20 ( 25%) [1901/3862 ( 49%)]  Loss: 1.891 (1.90)  LR: 6.364e-04  Grad: 10.2608  max=1.6809(module.vfe.pfn_layers.0.linear.weight)  min: -1.6086(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6568, loss_cls=0.1153, loss_bbox=0.7545, matched_ious=0.4825, loss_iou=0.0968, loss_iou_reg=0.2411, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.45(1.45)  Time cost: 45:49/47:14 [6:56:52/24:02:53]  Acc_iter 17350       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.45)
2025-09-03 16:13:57,283   INFO  Train:    5/20 ( 25%) [1951/3862 ( 51%)]  Loss: 1.657 (1.90)  LR: 6.387e-04  Grad: 9.9659  max=0.3498(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8731(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6523, loss_cls=0.1139, loss_bbox=0.7539, matched_ious=0.4951, loss_iou=0.0957, loss_iou_reg=0.2374, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.41(1.45)  Time cost: 47:05/46:05 [6:58:08/24:03:24]  Acc_iter 17400       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.41(1.45)
2025-09-03 16:15:08,361   INFO  Train:    5/20 ( 25%) [2001/3862 ( 52%)]  Loss: 1.548 (1.90)  LR: 6.409e-04  Grad: 11.4905  max=4.9696(module.vfe.pfn_layers.0.linear.weight)  min: -2.3437(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6661, loss_cls=0.1136, loss_bbox=0.7545, matched_ious=0.4917, loss_iou=0.0962, loss_iou_reg=0.2384, d_time=0.01(0.01), f_time=1.57(1.44), b_time=1.58(1.45)  Time cost: 48:16/44:52 [6:59:19/24:01:34]  Acc_iter 17450       Data time: 0.01(0.01)  Forward time: 1.57(1.44)  Batch time: 1.58(1.45)
2025-09-03 16:16:19,174   INFO  Train:    5/20 ( 25%) [2051/3862 ( 53%)]  Loss: 1.807 (1.90)  LR: 6.432e-04  Grad: 11.0967  max=0.3547(module.dense_head.decoder.self_attn.in_proj_weight)  min: -4.0085(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6575, loss_cls=0.1144, loss_bbox=0.7477, matched_ious=0.4959, loss_iou=0.0959, loss_iou_reg=0.2370, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.45(1.45)  Time cost: 49:26/43:38 [7:00:30/23:59:37]  Acc_iter 17500       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.45)
2025-09-03 16:17:30,224   INFO  Train:    5/20 ( 25%) [2101/3862 ( 54%)]  Loss: 2.452 (1.90)  LR: 6.454e-04  Grad: 12.3339  max=3.6011(module.vfe.pfn_layers.0.linear.weight)  min: -5.6215(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6678, loss_cls=0.1164, loss_bbox=0.7549, matched_ious=0.4873, loss_iou=0.0963, loss_iou_reg=0.2399, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.43(1.45)  Time cost: 50:37/42:25 [7:01:41/23:57:50]  Acc_iter 17550       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.43(1.45)
2025-09-03 16:18:43,640   INFO  Train:    5/20 ( 25%) [2151/3862 ( 56%)]  Loss: 2.109 (1.90)  LR: 6.476e-04  Grad: 11.6380  max=2.9064(module.vfe.pfn_layers.0.linear.weight)  min: -3.8465(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6679, loss_cls=0.1142, loss_bbox=0.7307, matched_ious=0.4946, loss_iou=0.0956, loss_iou_reg=0.2358, d_time=0.01(0.01), f_time=2.48(1.44), b_time=2.49(1.45)  Time cost: 51:51/41:13 [7:02:54/23:57:09]  Acc_iter 17600       Data time: 0.01(0.01)  Forward time: 2.48(1.44)  Batch time: 2.49(1.45)
2025-09-03 16:19:56,929   INFO  Train:    5/20 ( 25%) [2201/3862 ( 57%)]  Loss: 1.800 (1.90)  LR: 6.499e-04  Grad: 10.7979  max=3.1103(module.vfe.pfn_layers.0.linear.weight)  min: -0.4875(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6589, loss_cls=0.1125, loss_bbox=0.7234, matched_ious=0.4929, loss_iou=0.0960, loss_iou_reg=0.2378, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.38(1.45)  Time cost: 53:04/40:02 [7:04:08/23:56:24]  Acc_iter 17650       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.38(1.45)
2025-09-03 16:21:07,873   INFO  Train:    5/20 ( 25%) [2251/3862 ( 58%)]  Loss: 1.797 (1.89)  LR: 6.521e-04  Grad: 10.4661  max=0.3653(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2339(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6607, loss_cls=0.1126, loss_bbox=0.7418, matched_ious=0.4896, loss_iou=0.0960, loss_iou_reg=0.2399, d_time=0.00(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 54:15/38:48 [7:05:18/23:54:36]  Acc_iter 17700       Data time: 0.00(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-03 16:22:19,488   INFO  Train:    5/20 ( 25%) [2301/3862 ( 60%)]  Loss: 1.862 (1.89)  LR: 6.543e-04  Grad: 10.5510  max=0.3701(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.5595(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6352, loss_cls=0.1112, loss_bbox=0.7017, matched_ious=0.4994, loss_iou=0.0957, loss_iou_reg=0.2349, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 55:27/37:36 [7:06:30/23:53:06]  Acc_iter 17750       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-03 16:23:29,429   INFO  Train:    5/20 ( 25%) [2351/3862 ( 61%)]  Loss: 1.740 (1.89)  LR: 6.566e-04  Grad: 11.9900  max=0.3720(module.dense_head.decoder.self_attn.in_proj_weight)  min: -5.8309(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6623, loss_cls=0.1159, loss_bbox=0.7318, matched_ious=0.4936, loss_iou=0.0956, loss_iou_reg=0.2374, d_time=0.00(0.01), f_time=1.39(1.43), b_time=1.40(1.44)  Time cost: 56:37/36:22 [7:07:40/23:50:55]  Acc_iter 17800       Data time: 0.00(0.01)  Forward time: 1.39(1.43)  Batch time: 1.40(1.44)
2025-09-03 16:24:44,420   INFO  Train:    5/20 ( 25%) [2401/3862 ( 62%)]  Loss: 1.675 (1.89)  LR: 6.588e-04  Grad: 10.7767  max=1.0228(module.vfe.pfn_layers.0.linear.weight)  min: -1.5042(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6634, loss_cls=0.1130, loss_bbox=0.7566, matched_ious=0.4921, loss_iou=0.0948, loss_iou_reg=0.2362, d_time=0.00(0.01), f_time=2.36(1.44), b_time=2.37(1.45)  Time cost: 57:52/35:11 [7:08:55/23:50:51]  Acc_iter 17850       Data time: 0.00(0.01)  Forward time: 2.36(1.44)  Batch time: 2.37(1.45)
2025-09-03 16:25:57,365   INFO  Train:    5/20 ( 25%) [2451/3862 ( 63%)]  Loss: 2.031 (1.89)  LR: 6.610e-04  Grad: 10.7532  max=0.3744(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.4174(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6819, loss_cls=0.1172, loss_bbox=0.7434, matched_ious=0.4922, loss_iou=0.0955, loss_iou_reg=0.2370, d_time=0.01(0.01), f_time=1.50(1.44), b_time=1.51(1.45)  Time cost: 59:05/34:00 [7:10:08/23:49:55]  Acc_iter 17900       Data time: 0.01(0.01)  Forward time: 1.50(1.44)  Batch time: 1.51(1.45)
2025-09-03 16:27:07,967   INFO  Train:    5/20 ( 25%) [2501/3862 ( 65%)]  Loss: 1.817 (1.89)  LR: 6.632e-04  Grad: 11.5014  max=3.1285(module.vfe.pfn_layers.0.linear.weight)  min: -0.4088(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6521, loss_cls=0.1117, loss_bbox=0.7561, matched_ious=0.4947, loss_iou=0.0954, loss_iou_reg=0.2369, d_time=0.01(0.01), f_time=1.50(1.44), b_time=1.50(1.45)  Time cost: 1:00:15/32:46 [7:11:19/23:48:03]  Acc_iter 17950       Data time: 0.01(0.01)  Forward time: 1.50(1.44)  Batch time: 1.50(1.45)
2025-09-03 16:28:18,604   INFO  Train:    5/20 ( 25%) [2551/3862 ( 66%)]  Loss: 1.858 (1.89)  LR: 6.654e-04  Grad: 10.9576  max=1.7168(module.vfe.pfn_layers.0.linear.weight)  min: -0.4129(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6887, loss_cls=0.1177, loss_bbox=0.7607, matched_ious=0.4930, loss_iou=0.0954, loss_iou_reg=0.2364, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.41(1.44)  Time cost: 1:01:26/31:33 [7:12:29/23:46:13]  Acc_iter 18000       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.44)
2025-09-03 16:29:29,605   INFO  Train:    5/20 ( 25%) [2601/3862 ( 67%)]  Loss: 1.963 (1.89)  LR: 6.676e-04  Grad: 10.8840  max=0.5317(module.vfe.pfn_layers.0.linear.weight)  min: -0.4137(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6529, loss_cls=0.1129, loss_bbox=0.7443, matched_ious=0.4924, loss_iou=0.0965, loss_iou_reg=0.2387, d_time=0.00(0.01), f_time=1.41(1.43), b_time=1.42(1.44)  Time cost: 1:02:37/30:20 [7:13:40/23:44:33]  Acc_iter 18050       Data time: 0.00(0.01)  Forward time: 1.41(1.43)  Batch time: 1.42(1.44)
2025-09-03 16:30:45,679   INFO  Train:    5/20 ( 25%) [2651/3862 ( 69%)]  Loss: 1.792 (1.89)  LR: 6.698e-04  Grad: 11.1391  max=1.8473(module.vfe.pfn_layers.0.linear.weight)  min: -0.7074(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6655, loss_cls=0.1145, loss_bbox=0.7286, matched_ious=0.4970, loss_iou=0.0949, loss_iou_reg=0.2358, d_time=0.01(0.01), f_time=1.46(1.44), b_time=1.46(1.45)  Time cost: 1:03:53/29:10 [7:14:56/23:44:47]  Acc_iter 18100       Data time: 0.01(0.01)  Forward time: 1.46(1.44)  Batch time: 1.46(1.45)
2025-09-03 16:31:58,696   INFO  Train:    5/20 ( 25%) [2701/3862 ( 70%)]  Loss: 1.733 (1.89)  LR: 6.720e-04  Grad: 11.1406  max=0.3873(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.5221(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6601, loss_cls=0.1143, loss_bbox=0.7507, matched_ious=0.4924, loss_iou=0.0957, loss_iou_reg=0.2365, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 1:05:06/27:58 [7:16:09/23:43:51]  Acc_iter 18150       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-03 16:33:09,440   INFO  Train:    5/20 ( 25%) [2751/3862 ( 71%)]  Loss: 2.002 (1.89)  LR: 6.742e-04  Grad: 12.5349  max=5.7814(module.vfe.pfn_layers.0.linear.weight)  min: -0.9039(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6709, loss_cls=0.1155, loss_bbox=0.7580, matched_ious=0.4930, loss_iou=0.0957, loss_iou_reg=0.2367, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.42(1.45)  Time cost: 1:06:17/26:45 [7:17:20/23:42:06]  Acc_iter 18200       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.45)
2025-09-03 16:34:20,678   INFO  Train:    5/20 ( 25%) [2801/3862 ( 73%)]  Loss: 2.169 (1.89)  LR: 6.764e-04  Grad: 11.3955  max=0.3907(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.0762(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6580, loss_cls=0.1137, loss_bbox=0.7482, matched_ious=0.4953, loss_iou=0.0954, loss_iou_reg=0.2370, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.44(1.44)  Time cost: 1:07:28/25:32 [7:18:31/23:40:32]  Acc_iter 18250       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.44)
2025-09-03 16:35:32,625   INFO  Train:    5/20 ( 25%) [2851/3862 ( 74%)]  Loss: 1.782 (1.89)  LR: 6.786e-04  Grad: 13.0648  max=1.3863(module.vfe.pfn_layers.0.linear.weight)  min: -6.4284(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6543, loss_cls=0.1132, loss_bbox=0.7603, matched_ious=0.4967, loss_iou=0.0954, loss_iou_reg=0.2361, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.44(1.44)  Time cost: 1:08:40/24:20 [7:19:43/23:39:14]  Acc_iter 18300       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.44(1.44)
2025-09-03 16:36:48,110   INFO  Train:    5/20 ( 25%) [2901/3862 ( 75%)]  Loss: 2.148 (1.89)  LR: 6.808e-04  Grad: 11.7693  max=2.9162(module.vfe.pfn_layers.0.linear.weight)  min: -1.5188(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6550, loss_cls=0.1138, loss_bbox=0.7427, matched_ious=0.5026, loss_iou=0.0943, loss_iou_reg=0.2319, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 1:09:55/23:09 [7:20:59/23:39:07]  Acc_iter 18350       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-03 16:38:00,829   INFO  Train:    5/20 ( 25%) [2951/3862 ( 76%)]  Loss: 1.915 (1.88)  LR: 6.830e-04  Grad: 17.0350  max=10.0767(module.vfe.pfn_layers.0.linear.weight)  min: -3.4589(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6568, loss_cls=0.1127, loss_bbox=0.7244, matched_ious=0.5008, loss_iou=0.0964, loss_iou_reg=0.2338, d_time=0.00(0.01), f_time=1.37(1.44), b_time=1.37(1.45)  Time cost: 1:11:08/21:57 [7:22:11/23:38:03]  Acc_iter 18400       Data time: 0.00(0.01)  Forward time: 1.37(1.44)  Batch time: 1.37(1.45)
2025-09-03 16:39:11,522   INFO  Train:    5/20 ( 25%) [3001/3862 ( 78%)]  Loss: 1.971 (1.88)  LR: 6.852e-04  Grad: 11.3107  max=1.2979(module.vfe.pfn_layers.0.linear.weight)  min: -1.0953(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6574, loss_cls=0.1113, loss_bbox=0.7154, matched_ious=0.5009, loss_iou=0.0960, loss_iou_reg=0.2334, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.42(1.45)  Time cost: 1:12:19/20:44 [7:23:22/23:36:20]  Acc_iter 18450       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.45)
2025-09-03 16:40:22,443   INFO  Train:    5/20 ( 25%) [3051/3862 ( 79%)]  Loss: 2.187 (1.88)  LR: 6.874e-04  Grad: 11.2565  max=0.8124(module.vfe.pfn_layers.0.linear.weight)  min: -0.4786(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6577, loss_cls=0.1135, loss_bbox=0.7324, matched_ious=0.5012, loss_iou=0.0942, loss_iou_reg=0.2346, d_time=0.00(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 1:13:30/19:31 [7:24:33/23:34:41]  Acc_iter 18500       Data time: 0.00(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-03 16:41:33,657   INFO  Train:    5/20 ( 25%) [3101/3862 ( 80%)]  Loss: 1.672 (1.88)  LR: 6.896e-04  Grad: 11.4433  max=0.3976(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3006(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6432, loss_cls=0.1117, loss_bbox=0.7225, matched_ious=0.4998, loss_iou=0.0956, loss_iou_reg=0.2350, d_time=0.01(0.01), f_time=1.39(1.44), b_time=1.40(1.44)  Time cost: 1:14:41/18:19 [7:25:44/23:33:09]  Acc_iter 18550       Data time: 0.01(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.44)
2025-09-03 16:42:50,610   INFO  Train:    5/20 ( 25%) [3151/3862 ( 82%)]  Loss: 1.931 (1.88)  LR: 6.917e-04  Grad: 12.0390  max=0.8459(module.vfe.pfn_layers.0.linear.weight)  min: -2.9501(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6590, loss_cls=0.1132, loss_bbox=0.7489, matched_ious=0.5001, loss_iou=0.0952, loss_iou_reg=0.2342, d_time=0.01(0.01), f_time=1.49(1.44), b_time=1.50(1.45)  Time cost: 1:15:58/17:08 [7:27:01/23:33:25]  Acc_iter 18600       Data time: 0.01(0.01)  Forward time: 1.49(1.44)  Batch time: 1.50(1.45)
2025-09-03 16:44:01,130   INFO  Train:    5/20 ( 25%) [3201/3862 ( 83%)]  Loss: 1.543 (1.88)  LR: 6.939e-04  Grad: 12.2510  max=3.0660(module.vfe.pfn_layers.0.linear.weight)  min: -3.0785(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6619, loss_cls=0.1171, loss_bbox=0.7279, matched_ious=0.4978, loss_iou=0.0953, loss_iou_reg=0.2356, d_time=0.01(0.01), f_time=1.45(1.44), b_time=1.46(1.45)  Time cost: 1:17:08/15:55 [7:28:12/23:31:40]  Acc_iter 18650       Data time: 0.01(0.01)  Forward time: 1.45(1.44)  Batch time: 1.46(1.45)
2025-09-03 16:45:12,328   INFO  Train:    5/20 ( 25%) [3251/3862 ( 84%)]  Loss: 1.712 (1.88)  LR: 6.961e-04  Grad: 11.6385  max=1.2308(module.vfe.pfn_layers.0.linear.weight)  min: -1.0062(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6542, loss_cls=0.1139, loss_bbox=0.7300, matched_ious=0.5004, loss_iou=0.0938, loss_iou_reg=0.2325, d_time=0.01(0.01), f_time=1.30(1.44), b_time=1.30(1.45)  Time cost: 1:18:20/14:43 [7:29:23/23:30:08]  Acc_iter 18700       Data time: 0.01(0.01)  Forward time: 1.30(1.44)  Batch time: 1.30(1.45)
2025-09-03 16:46:23,204   INFO  Train:    5/20 ( 25%) [3301/3862 ( 85%)]  Loss: 1.548 (1.88)  LR: 6.982e-04  Grad: 11.7592  max=1.5430(module.vfe.pfn_layers.0.linear.weight)  min: -0.4376(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6509, loss_cls=0.1135, loss_bbox=0.7221, matched_ious=0.4984, loss_iou=0.0939, loss_iou_reg=0.2349, d_time=0.01(0.01), f_time=1.45(1.44), b_time=1.46(1.44)  Time cost: 1:19:30/13:30 [7:30:34/23:28:31]  Acc_iter 18750       Data time: 0.01(0.01)  Forward time: 1.45(1.44)  Batch time: 1.46(1.44)
2025-09-03 16:47:34,861   INFO  Train:    5/20 ( 25%) [3351/3862 ( 87%)]  Loss: 2.293 (1.88)  LR: 7.004e-04  Grad: 11.9724  max=0.5566(module.vfe.pfn_layers.0.linear.weight)  min: -2.4846(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6439, loss_cls=0.1103, loss_bbox=0.7595, matched_ious=0.4989, loss_iou=0.0964, loss_iou_reg=0.2347, d_time=0.00(0.01), f_time=1.41(1.44), b_time=1.42(1.44)  Time cost: 1:20:42/12:18 [7:31:45/23:27:09]  Acc_iter 18800       Data time: 0.00(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.44)
2025-09-03 16:48:50,314   INFO  Train:    5/20 ( 25%) [3401/3862 ( 88%)]  Loss: 1.689 (1.88)  LR: 7.025e-04  Grad: 12.0920  max=0.4125(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.0631(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6621, loss_cls=0.1138, loss_bbox=0.7343, matched_ious=0.4979, loss_iou=0.0954, loss_iou_reg=0.2337, d_time=0.00(0.01), f_time=1.32(1.44), b_time=1.32(1.45)  Time cost: 1:21:58/11:06 [7:33:01/23:26:52]  Acc_iter 18850       Data time: 0.00(0.01)  Forward time: 1.32(1.44)  Batch time: 1.32(1.45)
2025-09-03 16:50:01,698   INFO  Train:    5/20 ( 25%) [3451/3862 ( 89%)]  Loss: 1.877 (1.88)  LR: 7.047e-04  Grad: 12.0683  max=1.3233(module.vfe.pfn_layers.0.linear.weight)  min: -1.8202(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6492, loss_cls=0.1138, loss_bbox=0.7109, matched_ious=0.5044, loss_iou=0.0953, loss_iou_reg=0.2319, d_time=0.01(0.01), f_time=1.39(1.44), b_time=1.40(1.45)  Time cost: 1:23:09/09:54 [7:34:12/23:25:24]  Acc_iter 18900       Data time: 0.01(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.45)
2025-09-03 16:51:12,554   INFO  Train:    5/20 ( 25%) [3501/3862 ( 91%)]  Loss: 1.866 (1.88)  LR: 7.068e-04  Grad: 12.1796  max=1.5226(module.vfe.pfn_layers.0.linear.weight)  min: -1.9480(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6602, loss_cls=0.1139, loss_bbox=0.7389, matched_ious=0.4983, loss_iou=0.0946, loss_iou_reg=0.2351, d_time=0.00(0.01), f_time=1.41(1.44), b_time=1.41(1.45)  Time cost: 1:24:20/08:41 [7:35:23/23:23:49]  Acc_iter 18950       Data time: 0.00(0.01)  Forward time: 1.41(1.44)  Batch time: 1.41(1.45)
2025-09-03 16:52:24,161   INFO  Train:    5/20 ( 25%) [3551/3862 ( 92%)]  Loss: 1.767 (1.87)  LR: 7.090e-04  Grad: 11.9434  max=0.5088(module.vfe.pfn_layers.0.linear.weight)  min: -0.5717(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6594, loss_cls=0.1128, loss_bbox=0.7430, matched_ious=0.4952, loss_iou=0.0963, loss_iou_reg=0.2364, d_time=0.01(0.01), f_time=1.31(1.44), b_time=1.32(1.44)  Time cost: 1:25:31/07:29 [7:36:35/23:22:26]  Acc_iter 19000       Data time: 0.01(0.01)  Forward time: 1.31(1.44)  Batch time: 1.32(1.44)
2025-09-03 16:53:34,679   INFO  Train:    5/20 ( 25%) [3601/3862 ( 93%)]  Loss: 1.570 (1.87)  LR: 7.111e-04  Grad: 12.0580  max=1.2117(module.vfe.pfn_layers.0.linear.weight)  min: -0.4505(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6459, loss_cls=0.1101, loss_bbox=0.7226, matched_ious=0.4987, loss_iou=0.0955, loss_iou_reg=0.2350, d_time=0.01(0.01), f_time=1.34(1.43), b_time=1.35(1.44)  Time cost: 1:26:42/06:16 [7:37:45/23:20:46]  Acc_iter 19050       Data time: 0.01(0.01)  Forward time: 1.34(1.43)  Batch time: 1.35(1.44)
2025-09-03 16:54:51,858   INFO  Train:    5/20 ( 25%) [3651/3862 ( 95%)]  Loss: 1.848 (1.87)  LR: 7.132e-04  Grad: 12.0887  max=0.5698(module.vfe.pfn_layers.0.linear.weight)  min: -0.4821(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6504, loss_cls=0.1101, loss_bbox=0.7243, matched_ious=0.4985, loss_iou=0.0961, loss_iou_reg=0.2356, d_time=0.00(0.01), f_time=1.45(1.44), b_time=1.46(1.45)  Time cost: 1:27:59/05:05 [7:39:02/23:20:53]  Acc_iter 19100       Data time: 0.00(0.01)  Forward time: 1.45(1.44)  Batch time: 1.46(1.45)
2025-09-03 16:56:02,057   INFO  Train:    5/20 ( 25%) [3701/3862 ( 96%)]  Loss: 1.894 (1.87)  LR: 7.154e-04  Grad: 13.1442  max=3.9515(module.vfe.pfn_layers.0.linear.weight)  min: -0.4559(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6272, loss_cls=0.1107, loss_bbox=0.7112, matched_ious=0.5016, loss_iou=0.0954, loss_iou_reg=0.2350, d_time=0.01(0.01), f_time=1.57(1.44), b_time=1.57(1.45)  Time cost: 1:29:09/03:52 [7:40:13/23:19:08]  Acc_iter 19150       Data time: 0.01(0.01)  Forward time: 1.57(1.44)  Batch time: 1.57(1.45)
2025-09-03 16:57:13,513   INFO  Train:    5/20 ( 25%) [3751/3862 ( 97%)]  Loss: 2.103 (1.87)  LR: 7.175e-04  Grad: 13.2577  max=0.4268(module.dense_head.decoder.self_attn.in_proj_weight)  min: -4.3558(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6649, loss_cls=0.1147, loss_bbox=0.7228, matched_ious=0.4950, loss_iou=0.0959, loss_iou_reg=0.2377, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.42(1.44)  Time cost: 1:30:21/02:40 [7:41:24/23:17:43]  Acc_iter 19200       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.44)
2025-09-03 16:58:24,363   INFO  Train:    5/20 ( 25%) [3801/3862 ( 98%)]  Loss: 1.674 (1.87)  LR: 7.196e-04  Grad: 12.5189  max=1.6064(module.vfe.pfn_layers.0.linear.weight)  min: -1.2701(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6340, loss_cls=0.1115, loss_bbox=0.6934, matched_ious=0.5021, loss_iou=0.0954, loss_iou_reg=0.2349, d_time=0.00(0.01), f_time=1.37(1.44), b_time=1.37(1.44)  Time cost: 1:31:32/01:28 [7:42:35/23:16:10]  Acc_iter 19250       Data time: 0.00(0.01)  Forward time: 1.37(1.44)  Batch time: 1.37(1.44)
2025-09-03 16:59:34,589   INFO  Train:    5/20 ( 25%) [3851/3862 (100%)]  Loss: 1.749 (1.87)  LR: 7.217e-04  Grad: 12.4555  max=1.2929(module.vfe.pfn_layers.0.linear.weight)  min: -0.6219(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6525, loss_cls=0.1128, loss_bbox=0.7125, matched_ious=0.5086, loss_iou=0.0942, loss_iou_reg=0.2286, d_time=0.01(0.01), f_time=1.27(1.43), b_time=1.28(1.44)  Time cost: 1:32:42/00:15 [7:43:45/23:14:27]  Acc_iter 19300       Data time: 0.01(0.01)  Forward time: 1.27(1.43)  Batch time: 1.28(1.44)
2025-09-03 16:59:49,528   INFO  Train:    5/20 ( 25%) [3861/3862 (100%)]  Loss: 2.190 (1.87)  LR: 7.222e-04  Grad: 12.6111  max=1.4197(module.vfe.pfn_layers.0.linear.weight)  min: -2.1100(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6241, loss_cls=0.1035, loss_bbox=0.7285, matched_ious=0.5094, loss_iou=0.0964, loss_iou_reg=0.2322, d_time=0.37(0.01), f_time=1.36(1.43), b_time=1.74(1.44)  Time cost: 1:32:57/00:01 [7:44:00/23:14:20]  Acc_iter 19310       Data time: 0.37(0.01)  Forward time: 1.36(1.43)  Batch time: 1.74(1.44)

                                               [Aepochs:  25%|██▌       | 5/20 [7:44:00<23:13:01, 5572.12s/it]epochs:  25%|██▌       | 5/20 [7:44:00<23:13:02, 5572.15s/it]epochs:  25%|██▌       | 5/20 [7:44:00<23:13:02, 5572.15s/it]epochs:  25%|██▌       | 5/20 [7:44:00<23:13:02, 5572.14s/it]epochs:  25%|██▌       | 5/20 [7:44:01<23:13:02, 5572.16s/it]epochs:  25%|██▌       | 5/20 [7:44:01<23:13:02, 5572.16s/it]epochs:  25%|██▌       | 5/20 [7:44:01<23:13:02, 5572.17s/it]epochs:  25%|██▌       | 5/20 [7:44:01<23:13:02, 5572.20s/it]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-03 16:59:55,602   INFO  Train:    6/20 ( 30%) [   0/3862 (  0%)]  Loss: 1.550 (1.55)  LR: 7.222e-04  Grad: 12.3708  max=0.5331(module.vfe.pfn_layers.0.linear.weight)  min: -0.5490(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5214, loss_cls=0.0936, loss_bbox=0.6197, matched_ious=0.5111, loss_iou=0.0940, loss_iou_reg=0.2217, d_time=1.77(1.77), f_time=2.96(2.96), b_time=4.73(4.73)  Time cost: 00:04/4:51:14 [7:44:06/72:48:36]  Acc_iter 19311       Data time: 1.77(1.77)  Forward time: 2.96(2.96)  Batch time: 4.73(4.73)
2025-09-03 17:00:55,374   INFO  Train:    6/20 ( 30%) [  39/3862 (  1%)]  Loss: 2.468 (1.81)  LR: 7.239e-04  Grad: 12.5814  max=1.1393(module.vfe.pfn_layers.0.linear.weight)  min: -1.6083(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6484, loss_cls=0.1098, loss_bbox=0.7325, matched_ious=0.5066, loss_iou=0.0925, loss_iou_reg=0.2309, d_time=0.01(0.05), f_time=1.42(1.56), b_time=1.43(1.61)  Time cost: 01:04/1:42:24 [7:45:06/25:50:48]  Acc_iter 19350       Data time: 0.01(0.05)  Forward time: 1.42(1.56)  Batch time: 1.43(1.61)
2025-09-03 17:02:07,188   INFO  Train:    6/20 ( 30%) [  89/3862 (  2%)]  Loss: 2.136 (1.79)  LR: 7.260e-04  Grad: 8.2871  max=0.6571(module.vfe.pfn_layers.0.linear.weight)  min: -2.3198(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6366, loss_cls=0.1107, loss_bbox=0.7061, matched_ious=0.5017, loss_iou=0.0951, loss_iou_reg=0.2343, d_time=0.01(0.03), f_time=1.37(1.49), b_time=1.38(1.51)  Time cost: 02:16/1:35:06 [7:46:18/24:17:54]  Acc_iter 19400       Data time: 0.01(0.03)  Forward time: 1.37(1.49)  Batch time: 1.38(1.51)
2025-09-03 17:03:17,591   INFO  Train:    6/20 ( 30%) [ 139/3862 (  4%)]  Loss: 1.606 (1.78)  LR: 7.281e-04  Grad: 7.8475  max=0.6348(module.vfe.pfn_layers.0.linear.weight)  min: -0.2937(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6308, loss_cls=0.1095, loss_bbox=0.7002, matched_ious=0.5068, loss_iou=0.0945, loss_iou_reg=0.2324, d_time=0.01(0.02), f_time=1.46(1.46), b_time=1.47(1.48)  Time cost: 03:26/1:31:31 [7:47:28/23:40:48]  Acc_iter 19450       Data time: 0.01(0.02)  Forward time: 1.46(1.46)  Batch time: 1.47(1.48)
2025-09-03 17:04:29,732   INFO  Train:    6/20 ( 30%) [ 189/3862 (  5%)]  Loss: 1.918 (1.79)  LR: 7.302e-04  Grad: 8.9437  max=3.8894(module.vfe.pfn_layers.0.linear.weight)  min: -0.2952(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6499, loss_cls=0.1131, loss_bbox=0.7239, matched_ious=0.4988, loss_iou=0.0957, loss_iou_reg=0.2358, d_time=0.00(0.02), f_time=1.54(1.45), b_time=1.54(1.47)  Time cost: 04:38/1:29:46 [7:48:40/23:31:22]  Acc_iter 19500       Data time: 0.00(0.02)  Forward time: 1.54(1.45)  Batch time: 1.54(1.47)
2025-09-03 17:05:42,191   INFO  Train:    6/20 ( 30%) [ 239/3862 (  6%)]  Loss: 1.759 (1.79)  LR: 7.323e-04  Grad: 8.0189  max=0.2777(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.3595(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6349, loss_cls=0.1118, loss_bbox=0.7089, matched_ious=0.5029, loss_iou=0.0953, loss_iou_reg=0.2337, d_time=0.01(0.01), f_time=1.48(1.45), b_time=1.49(1.46)  Time cost: 05:51/1:28:20 [7:49:53/23:26:36]  Acc_iter 19550       Data time: 0.01(0.01)  Forward time: 1.48(1.45)  Batch time: 1.49(1.46)
2025-09-03 17:06:58,542   INFO  Train:    6/20 ( 30%) [ 289/3862 (  7%)]  Loss: 1.811 (1.79)  LR: 7.343e-04  Grad: 8.2802  max=1.2223(module.vfe.pfn_layers.0.linear.weight)  min: -1.0383(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6339, loss_cls=0.1077, loss_bbox=0.7053, matched_ious=0.5040, loss_iou=0.0951, loss_iou_reg=0.2318, d_time=0.01(0.01), f_time=1.34(1.46), b_time=1.34(1.47)  Time cost: 07:07/1:27:46 [7:51:09/23:36:04]  Acc_iter 19600       Data time: 0.01(0.01)  Forward time: 1.34(1.46)  Batch time: 1.34(1.47)
2025-09-03 17:08:09,385   INFO  Train:    6/20 ( 30%) [ 339/3862 (  9%)]  Loss: 1.489 (1.79)  LR: 7.364e-04  Grad: 8.6670  max=0.5880(module.vfe.pfn_layers.0.linear.weight)  min: -2.0853(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6395, loss_cls=0.1111, loss_bbox=0.7095, matched_ious=0.5052, loss_iou=0.0950, loss_iou_reg=0.2319, d_time=0.01(0.01), f_time=1.34(1.45), b_time=1.35(1.47)  Time cost: 08:18/1:26:03 [7:52:20/23:26:46]  Acc_iter 19650       Data time: 0.01(0.01)  Forward time: 1.34(1.45)  Batch time: 1.35(1.47)
2025-09-03 17:09:20,378   INFO  Train:    6/20 ( 30%) [ 389/3862 ( 10%)]  Loss: 1.931 (1.79)  LR: 7.385e-04  Grad: 8.8385  max=2.3257(module.vfe.pfn_layers.0.linear.weight)  min: -1.6184(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6364, loss_cls=0.1105, loss_bbox=0.7143, matched_ious=0.5025, loss_iou=0.0954, loss_iou_reg=0.2335, d_time=0.01(0.01), f_time=1.40(1.45), b_time=1.40(1.46)  Time cost: 09:29/1:24:29 [7:53:31/23:19:55]  Acc_iter 19700       Data time: 0.01(0.01)  Forward time: 1.40(1.45)  Batch time: 1.40(1.46)
2025-09-03 17:10:31,954   INFO  Train:    6/20 ( 30%) [ 439/3862 ( 11%)]  Loss: 2.139 (1.79)  LR: 7.406e-04  Grad: 9.3749  max=1.2536(module.vfe.pfn_layers.0.linear.weight)  min: -3.3770(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6437, loss_cls=0.1122, loss_bbox=0.7156, matched_ious=0.4943, loss_iou=0.0957, loss_iou_reg=0.2367, d_time=0.01(0.01), f_time=1.42(1.45), b_time=1.43(1.46)  Time cost: 10:40/1:23:05 [7:54:43/23:15:38]  Acc_iter 19750       Data time: 0.01(0.01)  Forward time: 1.42(1.45)  Batch time: 1.43(1.46)
2025-09-03 17:11:44,273   INFO  Train:    6/20 ( 30%) [ 489/3862 ( 13%)]  Loss: 1.709 (1.79)  LR: 7.427e-04  Grad: 10.6773  max=4.3857(module.vfe.pfn_layers.0.linear.weight)  min: -4.8044(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6261, loss_cls=0.1079, loss_bbox=0.7121, matched_ious=0.5034, loss_iou=0.0967, loss_iou_reg=0.2337, d_time=0.00(0.01), f_time=1.43(1.45), b_time=1.43(1.46)  Time cost: 11:53/1:21:49 [7:55:55/23:13:25]  Acc_iter 19800       Data time: 0.00(0.01)  Forward time: 1.43(1.45)  Batch time: 1.43(1.46)
2025-09-03 17:12:59,874   INFO  Train:    6/20 ( 30%) [ 539/3862 ( 14%)]  Loss: 1.504 (1.79)  LR: 7.447e-04  Grad: 18.3907  max=7.2985(module.vfe.pfn_layers.0.linear.weight)  min: -13.6687(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6493, loss_cls=0.1109, loss_bbox=0.7099, matched_ious=0.5066, loss_iou=0.0945, loss_iou_reg=0.2304, d_time=0.01(0.01), f_time=1.42(1.45), b_time=1.42(1.46)  Time cost: 13:08/1:20:53 [7:57:10/23:17:12]  Acc_iter 19850       Data time: 0.01(0.01)  Forward time: 1.42(1.45)  Batch time: 1.42(1.46)
2025-09-03 17:14:10,379   INFO  Train:    6/20 ( 30%) [ 589/3862 ( 15%)]  Loss: 2.038 (1.78)  LR: 7.468e-04  Grad: 9.1536  max=2.4483(module.vfe.pfn_layers.0.linear.weight)  min: -2.4022(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6151, loss_cls=0.1078, loss_bbox=0.6835, matched_ious=0.5088, loss_iou=0.0938, loss_iou_reg=0.2307, d_time=0.01(0.01), f_time=1.32(1.45), b_time=1.33(1.46)  Time cost: 14:19/1:19:26 [7:58:21/23:11:54]  Acc_iter 19900       Data time: 0.01(0.01)  Forward time: 1.32(1.45)  Batch time: 1.33(1.46)
2025-09-03 17:15:21,332   INFO  Train:    6/20 ( 30%) [ 639/3862 ( 17%)]  Loss: 1.919 (1.78)  LR: 7.488e-04  Grad: 8.5677  max=0.2942(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.3195(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6377, loss_cls=0.1101, loss_bbox=0.6914, matched_ious=0.5103, loss_iou=0.0952, loss_iou_reg=0.2297, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 15:30/1:18:04 [7:59:32/23:07:53]  Acc_iter 19950       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-03 17:16:32,477   INFO  Train:    6/20 ( 30%) [ 689/3862 ( 18%)]  Loss: 1.837 (1.78)  LR: 7.509e-04  Grad: 9.9408  max=1.5254(module.vfe.pfn_layers.0.linear.weight)  min: -3.5243(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6426, loss_cls=0.1118, loss_bbox=0.7141, matched_ious=0.5058, loss_iou=0.0940, loss_iou_reg=0.2329, d_time=0.01(0.01), f_time=1.51(1.44), b_time=1.52(1.45)  Time cost: 16:41/1:16:44 [8:00:43/23:04:34]  Acc_iter 20000       Data time: 0.01(0.01)  Forward time: 1.51(1.44)  Batch time: 1.52(1.45)
2025-09-03 17:17:44,835   INFO  Train:    6/20 ( 30%) [ 739/3862 ( 19%)]  Loss: 1.732 (1.78)  LR: 7.529e-04  Grad: 18.3503  max=11.1450(module.vfe.pfn_layers.0.linear.weight)  min: -9.5766(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6407, loss_cls=0.1117, loss_bbox=0.7165, matched_ious=0.5018, loss_iou=0.0941, loss_iou_reg=0.2343, d_time=0.00(0.01), f_time=1.46(1.44), b_time=1.47(1.45)  Time cost: 17:53/1:15:31 [8:01:55/23:03:05]  Acc_iter 20050       Data time: 0.00(0.01)  Forward time: 1.46(1.44)  Batch time: 1.47(1.45)
2025-09-03 17:19:00,810   INFO  Train:    6/20 ( 30%) [ 789/3862 ( 20%)]  Loss: 1.707 (1.78)  LR: 7.550e-04  Grad: 8.9714  max=1.2388(module.vfe.pfn_layers.0.linear.weight)  min: -1.2931(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6440, loss_cls=0.1123, loss_bbox=0.7017, matched_ious=0.5041, loss_iou=0.0939, loss_iou_reg=0.2316, d_time=0.00(0.01), f_time=1.36(1.45), b_time=1.37(1.46)  Time cost: 19:09/1:14:32 [8:03:11/23:06:00]  Acc_iter 20100       Data time: 0.00(0.01)  Forward time: 1.36(1.45)  Batch time: 1.37(1.46)
2025-09-03 17:20:11,970   INFO  Train:    6/20 ( 30%) [ 839/3862 ( 22%)]  Loss: 1.774 (1.79)  LR: 7.570e-04  Grad: 12.5440  max=6.9677(module.vfe.pfn_layers.0.linear.weight)  min: -0.5417(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6564, loss_cls=0.1124, loss_bbox=0.7514, matched_ious=0.5058, loss_iou=0.0929, loss_iou_reg=0.2299, d_time=0.01(0.01), f_time=1.28(1.44), b_time=1.29(1.45)  Time cost: 20:20/1:13:13 [8:04:23/23:02:58]  Acc_iter 20150       Data time: 0.01(0.01)  Forward time: 1.28(1.44)  Batch time: 1.29(1.45)
2025-09-03 17:21:22,884   INFO  Train:    6/20 ( 30%) [ 889/3862 ( 23%)]  Loss: 1.578 (1.79)  LR: 7.590e-04  Grad: 9.9736  max=2.6685(module.vfe.pfn_layers.0.linear.weight)  min: -3.4907(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6246, loss_cls=0.1096, loss_bbox=0.7100, matched_ious=0.5045, loss_iou=0.0942, loss_iou_reg=0.2322, d_time=0.00(0.01), f_time=1.31(1.44), b_time=1.31(1.45)  Time cost: 21:31/1:11:55 [8:05:33/22:59:52]  Acc_iter 20200       Data time: 0.00(0.01)  Forward time: 1.31(1.44)  Batch time: 1.31(1.45)
2025-09-03 17:22:34,767   INFO  Train:    6/20 ( 30%) [ 939/3862 ( 24%)]  Loss: 1.563 (1.79)  LR: 7.611e-04  Grad: 9.2228  max=1.8170(module.vfe.pfn_layers.0.linear.weight)  min: -0.6755(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6236, loss_cls=0.1073, loss_bbox=0.7177, matched_ious=0.4972, loss_iou=0.0965, loss_iou_reg=0.2371, d_time=0.01(0.01), f_time=1.29(1.44), b_time=1.30(1.45)  Time cost: 22:43/1:10:40 [8:06:45/22:57:58]  Acc_iter 20250       Data time: 0.01(0.01)  Forward time: 1.29(1.44)  Batch time: 1.30(1.45)
2025-09-03 17:23:47,327   INFO  Train:    6/20 ( 30%) [ 989/3862 ( 26%)]  Loss: 1.638 (1.79)  LR: 7.631e-04  Grad: 9.5819  max=0.3099(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.8885(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6378, loss_cls=0.1100, loss_bbox=0.7071, matched_ious=0.5093, loss_iou=0.0938, loss_iou_reg=0.2300, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 23:56/1:09:28 [8:07:58/22:56:47]  Acc_iter 20300       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-03 17:25:00,386   INFO  Train:    6/20 ( 30%) [1039/3862 ( 27%)]  Loss: 2.039 (1.79)  LR: 7.651e-04  Grad: 9.9608  max=0.3120(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.8786(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6340, loss_cls=0.1102, loss_bbox=0.7230, matched_ious=0.5046, loss_iou=0.0940, loss_iou_reg=0.2329, d_time=0.01(0.01), f_time=1.39(1.44), b_time=1.40(1.45)  Time cost: 25:09/1:08:16 [8:09:11/22:56:03]  Acc_iter 20350       Data time: 0.01(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.45)
2025-09-03 17:26:11,573   INFO  Train:    6/20 ( 30%) [1089/3862 ( 28%)]  Loss: 1.810 (1.79)  LR: 7.671e-04  Grad: 9.2135  max=0.3359(module.vfe.pfn_layers.0.linear.weight)  min: -0.6522(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6433, loss_cls=0.1120, loss_bbox=0.7157, matched_ious=0.5074, loss_iou=0.0943, loss_iou_reg=0.2318, d_time=0.01(0.01), f_time=1.46(1.44), b_time=1.46(1.45)  Time cost: 26:20/1:07:00 [8:10:22/22:53:39]  Acc_iter 20400       Data time: 0.01(0.01)  Forward time: 1.46(1.44)  Batch time: 1.46(1.45)
2025-09-03 17:27:21,860   INFO  Train:    6/20 ( 30%) [1139/3862 ( 29%)]  Loss: 1.696 (1.78)  LR: 7.691e-04  Grad: 10.2888  max=0.3122(module.dense_head.decoder.self_attn.in_proj_weight)  min: -3.3324(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6111, loss_cls=0.1083, loss_bbox=0.6882, matched_ious=0.5103, loss_iou=0.0947, loss_iou_reg=0.2304, d_time=0.01(0.01), f_time=1.32(1.44), b_time=1.33(1.45)  Time cost: 27:30/1:05:43 [8:11:32/22:50:36]  Acc_iter 20450       Data time: 0.01(0.01)  Forward time: 1.32(1.44)  Batch time: 1.33(1.45)
2025-09-03 17:28:33,334   INFO  Train:    6/20 ( 30%) [1189/3862 ( 31%)]  Loss: 1.669 (1.79)  LR: 7.711e-04  Grad: 9.4179  max=2.3305(module.vfe.pfn_layers.0.linear.weight)  min: -0.4532(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6442, loss_cls=0.1118, loss_bbox=0.7242, matched_ious=0.5068, loss_iou=0.0923, loss_iou_reg=0.2317, d_time=0.01(0.01), f_time=1.34(1.44), b_time=1.35(1.45)  Time cost: 28:42/1:04:28 [8:12:44/22:48:39]  Acc_iter 20500       Data time: 0.01(0.01)  Forward time: 1.34(1.44)  Batch time: 1.35(1.45)
2025-09-03 17:29:45,053   INFO  Train:    6/20 ( 30%) [1239/3862 ( 32%)]  Loss: 1.705 (1.79)  LR: 7.731e-04  Grad: 9.3936  max=1.9249(module.vfe.pfn_layers.0.linear.weight)  min: -0.4208(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6313, loss_cls=0.1104, loss_bbox=0.7223, matched_ious=0.5080, loss_iou=0.0949, loss_iou_reg=0.2319, d_time=0.01(0.01), f_time=1.46(1.44), b_time=1.47(1.45)  Time cost: 29:53/1:03:14 [8:13:56/22:46:57]  Acc_iter 20550       Data time: 0.01(0.01)  Forward time: 1.46(1.44)  Batch time: 1.47(1.45)
2025-09-03 17:30:59,342   INFO  Train:    6/20 ( 30%) [1289/3862 ( 33%)]  Loss: 1.834 (1.79)  LR: 7.751e-04  Grad: 9.4262  max=0.8172(module.vfe.pfn_layers.0.linear.weight)  min: -0.7331(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6186, loss_cls=0.1069, loss_bbox=0.7101, matched_ious=0.5035, loss_iou=0.0960, loss_iou_reg=0.2346, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.41(1.45)  Time cost: 31:08/1:02:06 [8:15:10/22:47:11]  Acc_iter 20600       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.41(1.45)
2025-09-03 17:32:10,157   INFO  Train:    6/20 ( 30%) [1339/3862 ( 35%)]  Loss: 1.629 (1.78)  LR: 7.770e-04  Grad: 9.4719  max=0.8427(module.vfe.pfn_layers.0.linear.weight)  min: -1.2811(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6207, loss_cls=0.1061, loss_bbox=0.7121, matched_ious=0.5098, loss_iou=0.0927, loss_iou_reg=0.2314, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 32:19/1:00:50 [8:16:21/22:44:51]  Acc_iter 20650       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-03 17:33:21,613   INFO  Train:    6/20 ( 30%) [1389/3862 ( 36%)]  Loss: 1.516 (1.78)  LR: 7.790e-04  Grad: 9.5495  max=1.0347(module.vfe.pfn_layers.0.linear.weight)  min: -1.1169(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6430, loss_cls=0.1084, loss_bbox=0.7164, matched_ious=0.5066, loss_iou=0.0950, loss_iou_reg=0.2324, d_time=0.01(0.01), f_time=1.32(1.44), b_time=1.32(1.45)  Time cost: 33:30/59:37 [8:17:32/22:43:02]  Acc_iter 20700       Data time: 0.01(0.01)  Forward time: 1.32(1.44)  Batch time: 1.32(1.45)
2025-09-03 17:34:34,341   INFO  Train:    6/20 ( 30%) [1439/3862 ( 37%)]  Loss: 1.717 (1.79)  LR: 7.810e-04  Grad: 10.2818  max=3.2950(module.vfe.pfn_layers.0.linear.weight)  min: -2.2443(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6337, loss_cls=0.1099, loss_bbox=0.7237, matched_ious=0.5044, loss_iou=0.0973, loss_iou_reg=0.2321, d_time=0.01(0.01), f_time=1.25(1.44), b_time=1.26(1.45)  Time cost: 34:43/58:25 [8:18:45/22:42:06]  Acc_iter 20750       Data time: 0.01(0.01)  Forward time: 1.25(1.44)  Batch time: 1.26(1.45)
2025-09-03 17:35:48,795   INFO  Train:    6/20 ( 30%) [1489/3862 ( 39%)]  Loss: 1.713 (1.78)  LR: 7.829e-04  Grad: 9.6389  max=0.8840(module.vfe.pfn_layers.0.linear.weight)  min: -0.8030(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6290, loss_cls=0.1107, loss_bbox=0.7140, matched_ious=0.5055, loss_iou=0.0937, loss_iou_reg=0.2326, d_time=0.01(0.01), f_time=2.20(1.44), b_time=2.21(1.45)  Time cost: 35:57/57:16 [8:19:59/22:42:14]  Acc_iter 20800       Data time: 0.01(0.01)  Forward time: 2.20(1.44)  Batch time: 2.21(1.45)
2025-09-03 17:37:03,137   INFO  Train:    6/20 ( 30%) [1539/3862 ( 40%)]  Loss: 1.669 (1.78)  LR: 7.849e-04  Grad: 9.7648  max=0.5248(module.vfe.pfn_layers.0.linear.weight)  min: -1.3556(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6191, loss_cls=0.1076, loss_bbox=0.7055, matched_ious=0.4985, loss_iou=0.0965, loss_iou_reg=0.2359, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 37:12/56:06 [8:21:14/22:42:12]  Acc_iter 20850       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-03 17:38:14,387   INFO  Train:    6/20 ( 30%) [1589/3862 ( 41%)]  Loss: 1.670 (1.78)  LR: 7.868e-04  Grad: 9.7714  max=0.8009(module.vfe.pfn_layers.0.linear.weight)  min: -0.6924(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6279, loss_cls=0.1096, loss_bbox=0.7114, matched_ious=0.5114, loss_iou=0.0945, loss_iou_reg=0.2288, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.41(1.45)  Time cost: 38:23/54:52 [8:22:25/22:40:16]  Acc_iter 20900       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.41(1.45)
2025-09-03 17:39:25,695   INFO  Train:    6/20 ( 30%) [1639/3862 ( 42%)]  Loss: 1.756 (1.78)  LR: 7.888e-04  Grad: 9.9319  max=0.7327(module.vfe.pfn_layers.0.linear.weight)  min: -1.6086(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6252, loss_cls=0.1097, loss_bbox=0.6886, matched_ious=0.5107, loss_iou=0.0939, loss_iou_reg=0.2313, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.38(1.45)  Time cost: 39:34/53:38 [8:23:36/22:38:25]  Acc_iter 20950       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.38(1.45)
2025-09-03 17:40:37,189   INFO  Train:    6/20 ( 30%) [1689/3862 ( 44%)]  Loss: 1.551 (1.78)  LR: 7.907e-04  Grad: 10.0956  max=0.3221(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.7647(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6353, loss_cls=0.1077, loss_bbox=0.7028, matched_ious=0.5072, loss_iou=0.0951, loss_iou_reg=0.2312, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.40(1.45)  Time cost: 40:46/52:25 [8:24:48/22:36:43]  Acc_iter 21000       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.40(1.45)
2025-09-03 17:41:51,295   INFO  Train:    6/20 ( 30%) [1739/3862 ( 45%)]  Loss: 1.740 (1.78)  LR: 7.927e-04  Grad: 10.0001  max=0.8595(module.vfe.pfn_layers.0.linear.weight)  min: -0.8057(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6110, loss_cls=0.1054, loss_bbox=0.6668, matched_ious=0.5017, loss_iou=0.0943, loss_iou_reg=0.2373, d_time=0.02(0.01), f_time=1.43(1.44), b_time=1.45(1.45)  Time cost: 42:00/51:14 [8:26:02/22:36:27]  Acc_iter 21050       Data time: 0.02(0.01)  Forward time: 1.43(1.44)  Batch time: 1.45(1.45)
2025-09-03 17:43:03,706   INFO  Train:    6/20 ( 30%) [1789/3862 ( 46%)]  Loss: 1.797 (1.78)  LR: 7.946e-04  Grad: 10.2066  max=1.3624(module.vfe.pfn_layers.0.linear.weight)  min: -1.5814(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6415, loss_cls=0.1098, loss_bbox=0.7272, matched_ious=0.5053, loss_iou=0.0947, loss_iou_reg=0.2328, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 43:12/50:02 [8:27:14/22:35:14]  Acc_iter 21100       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-03 17:44:14,212   INFO  Train:    6/20 ( 30%) [1839/3862 ( 48%)]  Loss: 1.423 (1.78)  LR: 7.965e-04  Grad: 10.3279  max=1.3795(module.vfe.pfn_layers.0.linear.weight)  min: -1.5857(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6136, loss_cls=0.1051, loss_bbox=0.6818, matched_ious=0.5083, loss_iou=0.0946, loss_iou_reg=0.2325, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.42(1.45)  Time cost: 44:23/48:47 [8:28:25/22:33:03]  Acc_iter 21150       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.45)
2025-09-03 17:45:26,088   INFO  Train:    6/20 ( 30%) [1889/3862 ( 49%)]  Loss: 1.473 (1.78)  LR: 7.984e-04  Grad: 10.8209  max=3.4108(module.vfe.pfn_layers.0.linear.weight)  min: -0.3760(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5925, loss_cls=0.1030, loss_bbox=0.6953, matched_ious=0.5047, loss_iou=0.0957, loss_iou_reg=0.2338, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.44(1.45)  Time cost: 45:35/47:35 [8:29:37/22:31:36]  Acc_iter 21200       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.44(1.45)
2025-09-03 17:46:37,149   INFO  Train:    6/20 ( 30%) [1939/3862 ( 50%)]  Loss: 1.601 (1.78)  LR: 8.003e-04  Grad: 10.2473  max=0.4320(module.vfe.pfn_layers.0.linear.weight)  min: -0.4444(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6126, loss_cls=0.1070, loss_bbox=0.6941, matched_ious=0.5080, loss_iou=0.0938, loss_iou_reg=0.2322, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.45(1.45)  Time cost: 46:46/46:21 [8:30:48/22:29:47]  Acc_iter 21250       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.45)
2025-09-03 17:47:52,593   INFO  Train:    6/20 ( 30%) [1989/3862 ( 52%)]  Loss: 1.862 (1.78)  LR: 8.022e-04  Grad: 12.0519  max=2.7163(module.vfe.pfn_layers.0.linear.weight)  min: -5.2880(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6137, loss_cls=0.1069, loss_bbox=0.7027, matched_ious=0.5106, loss_iou=0.0944, loss_iou_reg=0.2307, d_time=0.00(0.01), f_time=2.26(1.44), b_time=2.26(1.45)  Time cost: 48:01/45:12 [8:32:03/22:30:02]  Acc_iter 21300       Data time: 0.00(0.01)  Forward time: 2.26(1.44)  Batch time: 2.26(1.45)
2025-09-03 17:49:04,702   INFO  Train:    6/20 ( 30%) [2039/3862 ( 53%)]  Loss: 1.871 (1.78)  LR: 8.041e-04  Grad: 10.3920  max=0.6870(module.vfe.pfn_layers.0.linear.weight)  min: -0.3778(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6161, loss_cls=0.1056, loss_bbox=0.7031, matched_ious=0.5076, loss_iou=0.0947, loss_iou_reg=0.2314, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 49:13/43:59 [8:33:15/22:28:42]  Acc_iter 21350       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-03 17:50:15,290   INFO  Train:    6/20 ( 30%) [2089/3862 ( 54%)]  Loss: 1.618 (1.77)  LR: 8.060e-04  Grad: 10.4727  max=0.3345(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0817(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6033, loss_cls=0.1056, loss_bbox=0.6633, matched_ious=0.5045, loss_iou=0.0951, loss_iou_reg=0.2343, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.42(1.45)  Time cost: 50:24/42:45 [8:34:26/22:26:41]  Acc_iter 21400       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.45)
2025-09-03 17:51:27,307   INFO  Train:    6/20 ( 30%) [2139/3862 ( 55%)]  Loss: 1.672 (1.77)  LR: 8.079e-04  Grad: 10.5616  max=0.4496(module.vfe.pfn_layers.0.linear.weight)  min: -0.8720(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6258, loss_cls=0.1070, loss_bbox=0.6958, matched_ious=0.5098, loss_iou=0.0962, loss_iou_reg=0.2310, d_time=0.01(0.01), f_time=1.46(1.44), b_time=1.47(1.45)  Time cost: 51:36/41:32 [8:35:38/22:25:20]  Acc_iter 21450       Data time: 0.01(0.01)  Forward time: 1.46(1.44)  Batch time: 1.47(1.45)
2025-09-03 17:52:37,929   INFO  Train:    6/20 ( 30%) [2189/3862 ( 57%)]  Loss: 1.733 (1.77)  LR: 8.097e-04  Grad: 10.7103  max=1.2205(module.vfe.pfn_layers.0.linear.weight)  min: -0.6520(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6173, loss_cls=0.1079, loss_bbox=0.6782, matched_ious=0.5100, loss_iou=0.0956, loss_iou_reg=0.2311, d_time=0.01(0.01), f_time=1.32(1.44), b_time=1.32(1.45)  Time cost: 52:46/40:19 [8:36:49/22:23:24]  Acc_iter 21500       Data time: 0.01(0.01)  Forward time: 1.32(1.44)  Batch time: 1.32(1.45)
2025-09-03 17:53:53,528   INFO  Train:    6/20 ( 30%) [2239/3862 ( 58%)]  Loss: 1.836 (1.77)  LR: 8.116e-04  Grad: 10.8620  max=0.8201(module.vfe.pfn_layers.0.linear.weight)  min: -1.9389(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6389, loss_cls=0.1118, loss_bbox=0.6991, matched_ious=0.5043, loss_iou=0.0936, loss_iou_reg=0.2323, d_time=0.01(0.01), f_time=2.21(1.44), b_time=2.22(1.45)  Time cost: 54:02/39:09 [8:38:04/22:23:33]  Acc_iter 21550       Data time: 0.01(0.01)  Forward time: 2.21(1.44)  Batch time: 2.22(1.45)
2025-09-03 17:55:04,317   INFO  Train:    6/20 ( 30%) [2289/3862 ( 59%)]  Loss: 1.685 (1.77)  LR: 8.135e-04  Grad: 10.7409  max=0.3429(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.4795(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6069, loss_cls=0.1068, loss_bbox=0.6590, matched_ious=0.5174, loss_iou=0.0933, loss_iou_reg=0.2294, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.42(1.45)  Time cost: 55:13/37:55 [8:39:15/22:21:43]  Acc_iter 21600       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.45)
2025-09-03 17:56:15,090   INFO  Train:    6/20 ( 30%) [2339/3862 ( 61%)]  Loss: 2.072 (1.77)  LR: 8.153e-04  Grad: 10.8005  max=0.3447(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.3882(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6226, loss_cls=0.1057, loss_bbox=0.6756, matched_ious=0.5110, loss_iou=0.0942, loss_iou_reg=0.2306, d_time=0.00(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 56:24/36:42 [8:40:26/22:19:53]  Acc_iter 21650       Data time: 0.00(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-03 17:57:27,660   INFO  Train:    6/20 ( 30%) [2389/3862 ( 62%)]  Loss: 1.436 (1.77)  LR: 8.172e-04  Grad: 10.9798  max=1.3805(module.vfe.pfn_layers.0.linear.weight)  min: -0.4395(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6134, loss_cls=0.1058, loss_bbox=0.6678, matched_ious=0.5108, loss_iou=0.0933, loss_iou_reg=0.2308, d_time=0.01(0.01), f_time=1.33(1.44), b_time=1.34(1.45)  Time cost: 57:36/35:30 [8:41:38/22:18:47]  Acc_iter 21700       Data time: 0.01(0.01)  Forward time: 1.33(1.44)  Batch time: 1.34(1.45)
2025-09-03 17:58:38,254   INFO  Train:    6/20 ( 30%) [2439/3862 ( 63%)]  Loss: 1.927 (1.77)  LR: 8.190e-04  Grad: 10.9796  max=0.6957(module.vfe.pfn_layers.0.linear.weight)  min: -0.3916(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6092, loss_cls=0.1036, loss_bbox=0.6933, matched_ious=0.5082, loss_iou=0.0937, loss_iou_reg=0.2323, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 58:47/34:17 [8:42:49/22:16:55]  Acc_iter 21750       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-03 17:59:55,668   INFO  Train:    6/20 ( 30%) [2489/3862 ( 64%)]  Loss: 1.746 (1.77)  LR: 8.208e-04  Grad: 11.2039  max=0.3463(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.7026(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6479, loss_cls=0.1137, loss_bbox=0.7066, matched_ious=0.5117, loss_iou=0.0940, loss_iou_reg=0.2289, d_time=0.00(0.01), f_time=1.39(1.44), b_time=1.39(1.45)  Time cost: 1:00:04/33:07 [8:44:06/22:17:37]  Acc_iter 21800       Data time: 0.00(0.01)  Forward time: 1.39(1.44)  Batch time: 1.39(1.45)
2025-09-03 18:01:06,995   INFO  Train:    6/20 ( 30%) [2539/3862 ( 66%)]  Loss: 1.691 (1.77)  LR: 8.226e-04  Grad: 11.1417  max=0.3469(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0215(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6158, loss_cls=0.1084, loss_bbox=0.6868, matched_ious=0.5100, loss_iou=0.0944, loss_iou_reg=0.2296, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.38(1.45)  Time cost: 1:01:15/31:54 [8:45:18/22:16:02]  Acc_iter 21850       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.38(1.45)
2025-09-03 18:02:18,111   INFO  Train:    6/20 ( 30%) [2589/3862 ( 67%)]  Loss: 1.619 (1.77)  LR: 8.245e-04  Grad: 11.2982  max=1.1926(module.vfe.pfn_layers.0.linear.weight)  min: -0.4974(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6099, loss_cls=0.1068, loss_bbox=0.6623, matched_ious=0.5104, loss_iou=0.0944, loss_iou_reg=0.2316, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 1:02:27/30:41 [8:46:29/22:14:23]  Acc_iter 21900       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-03 18:03:30,236   INFO  Train:    6/20 ( 30%) [2639/3862 ( 68%)]  Loss: 2.069 (1.77)  LR: 8.263e-04  Grad: 11.6818  max=2.8573(module.vfe.pfn_layers.0.linear.weight)  min: -1.1731(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6021, loss_cls=0.1062, loss_bbox=0.6785, matched_ious=0.5123, loss_iou=0.0940, loss_iou_reg=0.2315, d_time=0.01(0.01), f_time=1.51(1.44), b_time=1.51(1.45)  Time cost: 1:03:39/29:29 [8:47:41/22:13:06]  Acc_iter 21950       Data time: 0.01(0.01)  Forward time: 1.51(1.44)  Batch time: 1.51(1.45)
2025-09-03 18:04:40,779   INFO  Train:    6/20 ( 30%) [2689/3862 ( 70%)]  Loss: 1.686 (1.76)  LR: 8.281e-04  Grad: 11.3329  max=0.3488(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.4141(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6101, loss_cls=0.1021, loss_bbox=0.6786, matched_ious=0.5125, loss_iou=0.0943, loss_iou_reg=0.2306, d_time=0.01(0.01), f_time=1.49(1.44), b_time=1.50(1.45)  Time cost: 1:04:49/28:16 [8:48:51/22:11:17]  Acc_iter 22000       Data time: 0.01(0.01)  Forward time: 1.49(1.44)  Batch time: 1.50(1.45)
2025-09-03 18:05:57,311   INFO  Train:    6/20 ( 30%) [2739/3862 ( 71%)]  Loss: 1.423 (1.76)  LR: 8.299e-04  Grad: 11.4292  max=0.3503(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7920(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6005, loss_cls=0.1007, loss_bbox=0.6952, matched_ious=0.5125, loss_iou=0.0929, loss_iou_reg=0.2297, d_time=0.00(0.01), f_time=1.46(1.44), b_time=1.47(1.45)  Time cost: 1:06:06/27:05 [8:50:08/22:11:30]  Acc_iter 22050       Data time: 0.00(0.01)  Forward time: 1.46(1.44)  Batch time: 1.47(1.45)
2025-09-03 18:07:08,088   INFO  Train:    6/20 ( 30%) [2789/3862 ( 72%)]  Loss: 1.793 (1.76)  LR: 8.317e-04  Grad: 11.5377  max=0.4842(module.vfe.pfn_layers.0.linear.weight)  min: -0.8649(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6013, loss_cls=0.1042, loss_bbox=0.6773, matched_ious=0.5166, loss_iou=0.0941, loss_iou_reg=0.2269, d_time=0.00(0.01), f_time=1.48(1.44), b_time=1.48(1.45)  Time cost: 1:07:17/25:52 [8:51:19/22:09:46]  Acc_iter 22100       Data time: 0.00(0.01)  Forward time: 1.48(1.44)  Batch time: 1.48(1.45)
2025-09-03 18:08:19,472   INFO  Train:    6/20 ( 30%) [2839/3862 ( 74%)]  Loss: 1.653 (1.76)  LR: 8.334e-04  Grad: 12.1253  max=3.1549(module.vfe.pfn_layers.0.linear.weight)  min: -1.8163(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6121, loss_cls=0.1061, loss_bbox=0.6796, matched_ious=0.5127, loss_iou=0.0943, loss_iou_reg=0.2312, d_time=0.01(0.01), f_time=1.47(1.44), b_time=1.49(1.45)  Time cost: 1:08:28/24:39 [8:52:30/22:08:15]  Acc_iter 22150       Data time: 0.01(0.01)  Forward time: 1.47(1.44)  Batch time: 1.49(1.45)
2025-09-03 18:09:31,338   INFO  Train:    6/20 ( 30%) [2889/3862 ( 75%)]  Loss: 1.855 (1.76)  LR: 8.352e-04  Grad: 11.7886  max=1.7431(module.vfe.pfn_layers.0.linear.weight)  min: -0.4071(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6110, loss_cls=0.1066, loss_bbox=0.6824, matched_ious=0.5130, loss_iou=0.0930, loss_iou_reg=0.2296, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 1:09:40/23:27 [8:53:42/22:06:54]  Acc_iter 22200       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-03 18:10:42,843   INFO  Train:    6/20 ( 30%) [2939/3862 ( 76%)]  Loss: 1.349 (1.76)  LR: 8.370e-04  Grad: 11.8211  max=0.9229(module.vfe.pfn_layers.0.linear.weight)  min: -1.0732(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6098, loss_cls=0.1082, loss_bbox=0.6693, matched_ious=0.5100, loss_iou=0.0931, loss_iou_reg=0.2297, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 1:10:51/22:14 [8:54:53/22:05:26]  Acc_iter 22250       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-03 18:11:59,195   INFO  Train:    6/20 ( 30%) [2989/3862 ( 77%)]  Loss: 1.590 (1.76)  LR: 8.387e-04  Grad: 11.7986  max=0.5466(module.vfe.pfn_layers.0.linear.weight)  min: -0.4115(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6288, loss_cls=0.1094, loss_bbox=0.7058, matched_ious=0.5072, loss_iou=0.0946, loss_iou_reg=0.2315, d_time=0.01(0.01), f_time=1.52(1.44), b_time=1.53(1.45)  Time cost: 1:12:08/21:03 [8:56:10/22:05:28]  Acc_iter 22300       Data time: 0.01(0.01)  Forward time: 1.52(1.44)  Batch time: 1.53(1.45)
2025-09-03 18:13:10,668   INFO  Train:    6/20 ( 30%) [3039/3862 ( 79%)]  Loss: 1.890 (1.76)  LR: 8.405e-04  Grad: 11.8555  max=0.3989(module.vfe.pfn_layers.0.linear.weight)  min: -0.4147(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6109, loss_cls=0.1042, loss_bbox=0.6812, matched_ious=0.5143, loss_iou=0.0947, loss_iou_reg=0.2306, d_time=0.01(0.01), f_time=1.34(1.44), b_time=1.35(1.45)  Time cost: 1:13:19/19:51 [8:57:21/22:04:00]  Acc_iter 22350       Data time: 0.01(0.01)  Forward time: 1.34(1.44)  Batch time: 1.35(1.45)
2025-09-03 18:14:22,554   INFO  Train:    6/20 ( 30%) [3089/3862 ( 80%)]  Loss: 1.656 (1.76)  LR: 8.422e-04  Grad: 12.2202  max=2.3014(module.vfe.pfn_layers.0.linear.weight)  min: -1.4128(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6124, loss_cls=0.1043, loss_bbox=0.6673, matched_ious=0.5177, loss_iou=0.0931, loss_iou_reg=0.2263, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 1:14:31/18:38 [8:58:33/22:02:39]  Acc_iter 22400       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-03 18:15:33,669   INFO  Train:    6/20 ( 30%) [3139/3862 ( 81%)]  Loss: 2.141 (1.76)  LR: 8.440e-04  Grad: 12.1227  max=1.5086(module.vfe.pfn_layers.0.linear.weight)  min: -1.0461(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6090, loss_cls=0.1030, loss_bbox=0.6807, matched_ious=0.5152, loss_iou=0.0946, loss_iou_reg=0.2307, d_time=0.01(0.01), f_time=1.36(1.44), b_time=1.37(1.45)  Time cost: 1:15:42/17:25 [8:59:44/22:01:05]  Acc_iter 22450       Data time: 0.01(0.01)  Forward time: 1.36(1.44)  Batch time: 1.37(1.45)
2025-09-03 18:16:44,084   INFO  Train:    6/20 ( 30%) [3189/3862 ( 83%)]  Loss: 1.739 (1.76)  LR: 8.457e-04  Grad: 12.0574  max=0.3716(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7454(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5897, loss_cls=0.1031, loss_bbox=0.6340, matched_ious=0.5145, loss_iou=0.0929, loss_iou_reg=0.2310, d_time=0.01(0.01), f_time=1.32(1.44), b_time=1.32(1.45)  Time cost: 1:16:53/16:13 [9:00:55/21:59:20]  Acc_iter 22500       Data time: 0.01(0.01)  Forward time: 1.32(1.44)  Batch time: 1.32(1.45)
2025-09-03 18:18:00,661   INFO  Train:    6/20 ( 30%) [3239/3862 ( 84%)]  Loss: 1.743 (1.76)  LR: 8.474e-04  Grad: 12.1452  max=0.3923(module.vfe.pfn_layers.0.linear.weight)  min: -0.4238(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6042, loss_cls=0.1073, loss_bbox=0.6656, matched_ious=0.5163, loss_iou=0.0925, loss_iou_reg=0.2281, d_time=0.00(0.01), f_time=1.37(1.44), b_time=1.38(1.45)  Time cost: 1:18:09/15:01 [9:02:11/21:59:19]  Acc_iter 22550       Data time: 0.00(0.01)  Forward time: 1.37(1.44)  Batch time: 1.38(1.45)
2025-09-03 18:19:12,061   INFO  Train:    6/20 ( 30%) [3289/3862 ( 85%)]  Loss: 1.876 (1.76)  LR: 8.491e-04  Grad: 12.1968  max=0.3727(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7615(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5972, loss_cls=0.1030, loss_bbox=0.6975, matched_ious=0.5125, loss_iou=0.0942, loss_iou_reg=0.2304, d_time=0.01(0.01), f_time=1.48(1.44), b_time=1.49(1.45)  Time cost: 1:19:20/13:49 [9:03:23/21:57:51]  Acc_iter 22600       Data time: 0.01(0.01)  Forward time: 1.48(1.44)  Batch time: 1.49(1.45)
2025-09-03 18:20:23,980   INFO  Train:    6/20 ( 30%) [3339/3862 ( 86%)]  Loss: 1.770 (1.76)  LR: 8.508e-04  Grad: 15.6463  max=1.4495(module.vfe.pfn_layers.0.linear.weight)  min: -9.2410(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6206, loss_cls=0.1078, loss_bbox=0.7021, matched_ious=0.5130, loss_iou=0.0948, loss_iou_reg=0.2289, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 1:20:32/12:36 [9:04:35/21:56:31]  Acc_iter 22650       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-03 18:21:34,540   INFO  Train:    6/20 ( 30%) [3389/3862 ( 88%)]  Loss: 1.616 (1.75)  LR: 8.525e-04  Grad: 12.3241  max=0.3746(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.4270(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6135, loss_cls=0.1064, loss_bbox=0.6776, matched_ious=0.5169, loss_iou=0.0926, loss_iou_reg=0.2270, d_time=0.00(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 1:21:43/11:24 [9:05:45/21:54:50]  Acc_iter 22700       Data time: 0.00(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-03 18:22:46,169   INFO  Train:    6/20 ( 30%) [3439/3862 ( 89%)]  Loss: 1.472 (1.75)  LR: 8.542e-04  Grad: 12.5375  max=1.1638(module.vfe.pfn_layers.0.linear.weight)  min: -0.4288(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6104, loss_cls=0.1048, loss_bbox=0.6801, matched_ious=0.5157, loss_iou=0.0939, loss_iou_reg=0.2288, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 1:22:55/10:11 [9:06:57/21:53:27]  Acc_iter 22750       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-03 18:24:01,402   INFO  Train:    6/20 ( 30%) [3489/3862 ( 90%)]  Loss: 1.832 (1.75)  LR: 8.559e-04  Grad: 12.6531  max=0.3772(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.6924(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5958, loss_cls=0.1040, loss_bbox=0.6752, matched_ious=0.5100, loss_iou=0.0944, loss_iou_reg=0.2303, d_time=0.00(0.01), f_time=1.58(1.44), b_time=1.59(1.45)  Time cost: 1:24:10/08:59 [9:08:12/21:53:00]  Acc_iter 22800       Data time: 0.00(0.01)  Forward time: 1.58(1.44)  Batch time: 1.59(1.45)
2025-09-03 18:25:14,302   INFO  Train:    6/20 ( 30%) [3539/3862 ( 92%)]  Loss: 2.033 (1.75)  LR: 8.576e-04  Grad: 16.9951  max=8.6055(module.vfe.pfn_layers.0.linear.weight)  min: -7.4400(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6189, loss_cls=0.1062, loss_bbox=0.6751, matched_ious=0.5171, loss_iou=0.0942, loss_iou_reg=0.2271, d_time=0.01(0.01), f_time=2.38(1.44), b_time=2.38(1.45)  Time cost: 1:25:23/07:47 [9:09:25/21:51:56]  Acc_iter 22850       Data time: 0.01(0.01)  Forward time: 2.38(1.44)  Batch time: 2.38(1.45)
2025-09-03 18:26:25,141   INFO  Train:    6/20 ( 30%) [3589/3862 ( 93%)]  Loss: 1.560 (1.75)  LR: 8.592e-04  Grad: 12.6198  max=0.3809(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.4357(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6036, loss_cls=0.1038, loss_bbox=0.6889, matched_ious=0.5143, loss_iou=0.0942, loss_iou_reg=0.2294, d_time=0.01(0.01), f_time=1.28(1.44), b_time=1.29(1.45)  Time cost: 1:26:34/06:34 [9:10:36/21:50:21]  Acc_iter 22900       Data time: 0.01(0.01)  Forward time: 1.28(1.44)  Batch time: 1.29(1.45)
2025-09-03 18:27:36,650   INFO  Train:    6/20 ( 30%) [3639/3862 ( 94%)]  Loss: 1.938 (1.75)  LR: 8.609e-04  Grad: 12.7415  max=0.6607(module.vfe.pfn_layers.0.linear.weight)  min: -0.7372(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6024, loss_cls=0.1065, loss_bbox=0.6810, matched_ious=0.5128, loss_iou=0.0942, loss_iou_reg=0.2296, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.43(1.45)  Time cost: 1:27:45/05:22 [9:11:47/21:48:56]  Acc_iter 22950       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.43(1.45)
2025-09-03 18:28:47,864   INFO  Train:    6/20 ( 30%) [3689/3862 ( 96%)]  Loss: 1.698 (1.75)  LR: 8.626e-04  Grad: 12.9125  max=0.3857(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.8386(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5993, loss_cls=0.1028, loss_bbox=0.6599, matched_ious=0.5208, loss_iou=0.0931, loss_iou_reg=0.2259, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.42(1.45)  Time cost: 1:28:56/04:10 [9:12:58/21:47:27]  Acc_iter 23000       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.45)
2025-09-03 18:30:03,664   INFO  Train:    6/20 ( 30%) [3739/3862 ( 97%)]  Loss: 1.690 (1.75)  LR: 8.642e-04  Grad: 11.5470  max=0.4824(module.vfe.pfn_layers.0.linear.weight)  min: -1.8438(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6083, loss_cls=0.1061, loss_bbox=0.6755, matched_ious=0.5126, loss_iou=0.0931, loss_iou_reg=0.2300, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.45(1.45)  Time cost: 1:30:12/02:58 [9:14:14/21:47:06]  Acc_iter 23050       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.45(1.45)
2025-09-03 18:31:15,409   INFO  Train:    6/20 ( 30%) [3789/3862 ( 98%)]  Loss: 1.707 (1.75)  LR: 8.658e-04  Grad: 11.5169  max=0.4496(module.vfe.pfn_layers.0.linear.weight)  min: -1.7228(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5957, loss_cls=0.1039, loss_bbox=0.6430, matched_ious=0.5203, loss_iou=0.0945, loss_iou_reg=0.2255, d_time=0.01(0.01), f_time=1.36(1.44), b_time=1.37(1.45)  Time cost: 1:31:24/01:45 [9:15:26/21:45:44]  Acc_iter 23100       Data time: 0.01(0.01)  Forward time: 1.36(1.44)  Batch time: 1.37(1.45)
2025-09-03 18:32:25,867   INFO  Train:    6/20 ( 30%) [3839/3862 ( 99%)]  Loss: 1.593 (1.75)  LR: 8.675e-04  Grad: 11.4952  max=0.7045(module.vfe.pfn_layers.0.linear.weight)  min: -0.3923(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6204, loss_cls=0.1060, loss_bbox=0.6823, matched_ious=0.5134, loss_iou=0.0941, loss_iou_reg=0.2313, d_time=0.00(0.01), f_time=1.33(1.44), b_time=1.33(1.45)  Time cost: 1:32:34/00:33 [9:16:36/21:44:05]  Acc_iter 23150       Data time: 0.00(0.01)  Forward time: 1.33(1.44)  Batch time: 1.33(1.45)
2025-09-03 18:32:55,530   INFO  Train:    6/20 ( 30%) [3861/3862 (100%)]  Loss: 1.706 (1.75)  LR: 8.682e-04  Grad: 11.4970  max=0.5770(module.vfe.pfn_layers.0.linear.weight)  min: -0.4249(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6231, loss_cls=0.1078, loss_bbox=0.6694, matched_ious=0.5124, loss_iou=0.0921, loss_iou_reg=0.2288, d_time=0.00(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 1:33:04/00:01 [9:17:06/21:43:03]  Acc_iter 23172       Data time: 0.00(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)

                                               [Aepochs:  30%|███       | 6/20 [9:17:06<21:41:16, 5576.86s/it]epochs:  30%|███       | 6/20 [9:17:06<21:41:16, 5576.86s/it]epochs:  30%|███       | 6/20 [9:17:07<21:41:16, 5576.87s/it]epochs:  30%|███       | 6/20 [9:17:07<21:41:16, 5576.87s/it]epochs:  30%|███       | 6/20 [9:17:07<21:41:16, 5576.87s/it]epochs:  30%|███       | 6/20 [9:17:07<21:41:16, 5576.87s/it]epochs:  30%|███       | 6/20 [9:17:07<21:41:16, 5576.89s/it]epochs:  30%|███       | 6/20 [9:17:07<21:41:16, 5576.87s/it]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-03 18:33:01,323   INFO  Train:    7/20 ( 35%) [   0/3862 (  0%)]  Loss: 1.625 (1.63)  LR: 8.682e-04  Grad: 11.6498  max=1.1736(module.vfe.pfn_layers.0.linear.weight)  min: -0.3934(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5285, loss_cls=0.0894, loss_bbox=0.6844, matched_ious=0.5214, loss_iou=0.0930, loss_iou_reg=0.2298, d_time=1.91(1.91), f_time=2.67(2.67), b_time=4.58(4.58)  Time cost: 00:04/4:39:07 [9:17:12/65:07:46]  Acc_iter 23173       Data time: 1.91(1.91)  Forward time: 2.67(2.67)  Batch time: 4.58(4.58)
2025-09-03 18:33:39,699   INFO  Train:    7/20 ( 35%) [  27/3862 (  1%)]  Loss: 1.711 (1.68)  LR: 8.691e-04  Grad: 12.7515  max=4.3309(module.vfe.pfn_layers.0.linear.weight)  min: -3.2914(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6046, loss_cls=0.1045, loss_bbox=0.6537, matched_ious=0.5171, loss_iou=0.0936, loss_iou_reg=0.2283, d_time=0.01(0.08), f_time=1.39(1.46), b_time=1.39(1.53)  Time cost: 00:42/1:37:30 [9:17:50/22:53:59]  Acc_iter 23200       Data time: 0.01(0.08)  Forward time: 1.39(1.46)  Batch time: 1.39(1.53)
2025-09-03 18:34:51,887   INFO  Train:    7/20 ( 35%) [  77/3862 (  2%)]  Loss: 1.437 (1.71)  LR: 8.707e-04  Grad: 11.6164  max=0.4938(module.vfe.pfn_layers.0.linear.weight)  min: -0.3957(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6096, loss_cls=0.1036, loss_bbox=0.6973, matched_ious=0.5184, loss_iou=0.0927, loss_iou_reg=0.2270, d_time=0.49(0.04), f_time=1.33(1.44), b_time=1.82(1.48)  Time cost: 01:54/1:32:55 [9:19:03/22:05:32]  Acc_iter 23250       Data time: 0.49(0.04)  Forward time: 1.33(1.44)  Batch time: 1.82(1.48)
2025-09-03 18:36:07,326   INFO  Train:    7/20 ( 35%) [ 127/3862 (  3%)]  Loss: 1.756 (1.73)  LR: 8.723e-04  Grad: 11.7206  max=0.3517(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7879(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6146, loss_cls=0.1067, loss_bbox=0.7026, matched_ious=0.5112, loss_iou=0.0938, loss_iou_reg=0.2295, d_time=0.00(0.03), f_time=1.50(1.46), b_time=1.51(1.49)  Time cost: 03:10/1:32:34 [9:20:18/22:16:52]  Acc_iter 23300       Data time: 0.00(0.03)  Forward time: 1.50(1.46)  Batch time: 1.51(1.49)
2025-09-03 18:37:19,448   INFO  Train:    7/20 ( 35%) [ 177/3862 (  5%)]  Loss: 1.621 (1.72)  LR: 8.739e-04  Grad: 11.7782  max=0.3533(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.4021(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5942, loss_cls=0.1046, loss_bbox=0.6685, matched_ious=0.5197, loss_iou=0.0924, loss_iou_reg=0.2279, d_time=0.01(0.03), f_time=1.50(1.45), b_time=1.50(1.48)  Time cost: 04:22/1:30:33 [9:21:30/22:04:21]  Acc_iter 23350       Data time: 0.01(0.03)  Forward time: 1.50(1.45)  Batch time: 1.50(1.48)
2025-09-03 18:38:30,915   INFO  Train:    7/20 ( 35%) [ 227/3862 (  6%)]  Loss: 1.918 (1.72)  LR: 8.755e-04  Grad: 12.0216  max=0.3558(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.2316(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6049, loss_cls=0.1057, loss_bbox=0.6925, matched_ious=0.5152, loss_iou=0.0936, loss_iou_reg=0.2280, d_time=0.01(0.02), f_time=1.44(1.44), b_time=1.45(1.47)  Time cost: 05:33/1:28:43 [9:22:42/21:54:14]  Acc_iter 23400       Data time: 0.01(0.02)  Forward time: 1.44(1.44)  Batch time: 1.45(1.47)
2025-09-03 18:39:42,720   INFO  Train:    7/20 ( 35%) [ 277/3862 (  7%)]  Loss: 1.898 (1.71)  LR: 8.770e-04  Grad: 12.1110  max=0.9694(module.vfe.pfn_layers.0.linear.weight)  min: -2.0580(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6035, loss_cls=0.1036, loss_bbox=0.6630, matched_ious=0.5134, loss_iou=0.0939, loss_iou_reg=0.2297, d_time=0.01(0.02), f_time=1.46(1.44), b_time=1.47(1.46)  Time cost: 06:45/1:27:12 [9:23:53/21:48:25]  Acc_iter 23450       Data time: 0.01(0.02)  Forward time: 1.46(1.44)  Batch time: 1.47(1.46)
2025-09-03 18:40:55,582   INFO  Train:    7/20 ( 35%) [ 327/3862 (  8%)]  Loss: 1.536 (1.71)  LR: 8.786e-04  Grad: 12.0089  max=0.3605(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8553(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5916, loss_cls=0.1021, loss_bbox=0.6821, matched_ious=0.5130, loss_iou=0.0934, loss_iou_reg=0.2298, d_time=0.01(0.02), f_time=2.26(1.44), b_time=2.26(1.46)  Time cost: 07:58/1:25:58 [9:25:06/21:46:55]  Acc_iter 23500       Data time: 0.01(0.02)  Forward time: 2.26(1.44)  Batch time: 2.26(1.46)
2025-09-03 18:42:11,133   INFO  Train:    7/20 ( 35%) [ 377/3862 ( 10%)]  Loss: 1.946 (1.71)  LR: 8.802e-04  Grad: 12.1173  max=0.3646(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2206(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5976, loss_cls=0.1054, loss_bbox=0.6399, matched_ious=0.5143, loss_iou=0.0942, loss_iou_reg=0.2315, d_time=0.00(0.02), f_time=1.37(1.45), b_time=1.37(1.47)  Time cost: 09:14/1:25:08 [9:26:22/21:51:50]  Acc_iter 23550       Data time: 0.00(0.02)  Forward time: 1.37(1.45)  Batch time: 1.37(1.47)
2025-09-03 18:43:23,665   INFO  Train:    7/20 ( 35%) [ 427/3862 ( 11%)]  Loss: 1.690 (1.71)  LR: 8.817e-04  Grad: 12.2039  max=0.3636(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9737(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6098, loss_cls=0.1044, loss_bbox=0.6737, matched_ious=0.5152, loss_iou=0.0947, loss_iou_reg=0.2296, d_time=0.01(0.01), f_time=1.40(1.45), b_time=1.40(1.46)  Time cost: 10:26/1:23:49 [9:27:34/21:49:01]  Acc_iter 23600       Data time: 0.01(0.01)  Forward time: 1.40(1.45)  Batch time: 1.40(1.46)
2025-09-03 18:44:34,478   INFO  Train:    7/20 ( 35%) [ 477/3862 ( 12%)]  Loss: 1.559 (1.70)  LR: 8.833e-04  Grad: 12.5464  max=0.3662(module.vfe.pfn_layers.0.linear.weight)  min: -2.0974(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5825, loss_cls=0.1011, loss_bbox=0.6377, matched_ious=0.5103, loss_iou=0.0952, loss_iou_reg=0.2313, d_time=0.01(0.01), f_time=1.35(1.45), b_time=1.35(1.46)  Time cost: 11:37/1:22:19 [9:28:45/21:43:19]  Acc_iter 23650       Data time: 0.01(0.01)  Forward time: 1.35(1.45)  Batch time: 1.35(1.46)
2025-09-03 18:45:45,410   INFO  Train:    7/20 ( 35%) [ 527/3862 ( 14%)]  Loss: 1.971 (1.69)  LR: 8.848e-04  Grad: 12.5329  max=0.3678(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.3840(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5707, loss_cls=0.1016, loss_bbox=0.6414, matched_ious=0.5213, loss_iou=0.0926, loss_iou_reg=0.2276, d_time=0.00(0.01), f_time=1.48(1.44), b_time=1.49(1.46)  Time cost: 12:48/1:20:53 [9:29:56/21:38:40]  Acc_iter 23700       Data time: 0.00(0.01)  Forward time: 1.48(1.44)  Batch time: 1.49(1.46)
2025-09-03 18:46:58,242   INFO  Train:    7/20 ( 35%) [ 577/3862 ( 15%)]  Loss: 1.390 (1.69)  LR: 8.863e-04  Grad: 12.3495  max=0.3694(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.4160(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5937, loss_cls=0.1009, loss_bbox=0.6586, matched_ious=0.5239, loss_iou=0.0930, loss_iou_reg=0.2260, d_time=0.00(0.01), f_time=1.31(1.44), b_time=1.31(1.46)  Time cost: 14:01/1:19:41 [9:31:09/21:37:33]  Acc_iter 23750       Data time: 0.00(0.01)  Forward time: 1.31(1.44)  Batch time: 1.31(1.46)
2025-09-03 18:48:14,688   INFO  Train:    7/20 ( 35%) [ 627/3862 ( 16%)]  Loss: 1.521 (1.69)  LR: 8.878e-04  Grad: 12.5161  max=1.4239(module.vfe.pfn_layers.0.linear.weight)  min: -0.4182(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5884, loss_cls=0.1005, loss_bbox=0.6468, matched_ious=0.5219, loss_iou=0.0925, loss_iou_reg=0.2254, d_time=0.00(0.01), f_time=1.32(1.45), b_time=1.32(1.46)  Time cost: 15:17/1:18:47 [9:32:25/21:41:33]  Acc_iter 23800       Data time: 0.00(0.01)  Forward time: 1.32(1.45)  Batch time: 1.32(1.46)
2025-09-03 18:49:26,359   INFO  Train:    7/20 ( 35%) [ 677/3862 ( 18%)]  Loss: 1.826 (1.69)  LR: 8.893e-04  Grad: 12.5024  max=0.8944(module.vfe.pfn_layers.0.linear.weight)  min: -0.4459(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5940, loss_cls=0.1026, loss_bbox=0.6540, matched_ious=0.5214, loss_iou=0.0924, loss_iou_reg=0.2262, d_time=0.01(0.01), f_time=1.51(1.45), b_time=1.51(1.46)  Time cost: 16:29/1:17:27 [9:33:37/21:38:30]  Acc_iter 23850       Data time: 0.01(0.01)  Forward time: 1.51(1.45)  Batch time: 1.51(1.46)
2025-09-03 18:50:37,819   INFO  Train:    7/20 ( 35%) [ 727/3862 ( 19%)]  Loss: 1.653 (1.69)  LR: 8.908e-04  Grad: 12.5863  max=0.4011(module.vfe.pfn_layers.0.linear.weight)  min: -1.1023(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5926, loss_cls=0.1035, loss_bbox=0.6783, matched_ious=0.5211, loss_iou=0.0922, loss_iou_reg=0.2270, d_time=0.01(0.01), f_time=1.34(1.45), b_time=1.34(1.46)  Time cost: 17:40/1:16:08 [9:34:48/21:35:27]  Acc_iter 23900       Data time: 0.01(0.01)  Forward time: 1.34(1.45)  Batch time: 1.34(1.46)
2025-09-03 18:51:49,154   INFO  Train:    7/20 ( 35%) [ 777/3862 ( 20%)]  Loss: 1.525 (1.68)  LR: 8.923e-04  Grad: 12.6403  max=0.3823(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.4227(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5786, loss_cls=0.0998, loss_bbox=0.6312, matched_ious=0.5168, loss_iou=0.0924, loss_iou_reg=0.2282, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.43(1.46)  Time cost: 18:52/1:14:49 [9:36:00/21:32:30]  Acc_iter 23950       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.43(1.46)
2025-09-03 18:53:04,059   INFO  Train:    7/20 ( 35%) [ 827/3862 ( 21%)]  Loss: 1.845 (1.68)  LR: 8.938e-04  Grad: 12.7153  max=0.6739(module.vfe.pfn_layers.0.linear.weight)  min: -0.7064(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5888, loss_cls=0.1014, loss_bbox=0.6840, matched_ious=0.5164, loss_iou=0.0944, loss_iou_reg=0.2279, d_time=0.01(0.01), f_time=2.23(1.45), b_time=2.24(1.46)  Time cost: 20:07/1:13:44 [9:37:15/21:33:35]  Acc_iter 24000       Data time: 0.01(0.01)  Forward time: 2.23(1.45)  Batch time: 2.24(1.46)
2025-09-03 18:54:19,013   INFO  Train:    7/20 ( 35%) [ 877/3862 ( 23%)]  Loss: 1.568 (1.68)  LR: 8.953e-04  Grad: 12.7717  max=0.3851(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8417(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5967, loss_cls=0.1006, loss_bbox=0.6494, matched_ious=0.5209, loss_iou=0.0940, loss_iou_reg=0.2283, d_time=0.00(0.01), f_time=1.38(1.45), b_time=1.38(1.46)  Time cost: 21:22/1:12:38 [9:38:30/21:34:27]  Acc_iter 24050       Data time: 0.00(0.01)  Forward time: 1.38(1.45)  Batch time: 1.38(1.46)
2025-09-03 18:55:29,679   INFO  Train:    7/20 ( 35%) [ 927/3862 ( 24%)]  Loss: 1.815 (1.68)  LR: 8.967e-04  Grad: 13.1337  max=1.2756(module.vfe.pfn_layers.0.linear.weight)  min: -2.3800(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5833, loss_cls=0.1018, loss_bbox=0.6312, matched_ious=0.5251, loss_iou=0.0934, loss_iou_reg=0.2255, d_time=0.01(0.01), f_time=1.38(1.45), b_time=1.39(1.46)  Time cost: 22:32/1:11:18 [9:39:40/21:31:00]  Acc_iter 24100       Data time: 0.01(0.01)  Forward time: 1.38(1.45)  Batch time: 1.39(1.46)
2025-09-03 18:56:40,604   INFO  Train:    7/20 ( 35%) [ 977/3862 ( 25%)]  Loss: 1.912 (1.68)  LR: 8.982e-04  Grad: 12.9315  max=0.3915(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7192(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5947, loss_cls=0.1019, loss_bbox=0.6568, matched_ious=0.5209, loss_iou=0.0940, loss_iou_reg=0.2274, d_time=0.01(0.01), f_time=1.39(1.45), b_time=1.40(1.46)  Time cost: 23:43/1:09:59 [9:40:51/21:28:01]  Acc_iter 24150       Data time: 0.01(0.01)  Forward time: 1.39(1.45)  Batch time: 1.40(1.46)
2025-09-03 18:57:51,888   INFO  Train:    7/20 ( 35%) [1027/3862 ( 27%)]  Loss: 1.685 (1.68)  LR: 8.996e-04  Grad: 12.9561  max=0.3941(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.4319(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5971, loss_cls=0.1053, loss_bbox=0.6455, matched_ious=0.5171, loss_iou=0.0934, loss_iou_reg=0.2289, d_time=0.01(0.01), f_time=1.48(1.44), b_time=1.48(1.45)  Time cost: 24:54/1:08:42 [9:42:03/21:25:31]  Acc_iter 24200       Data time: 0.01(0.01)  Forward time: 1.48(1.44)  Batch time: 1.48(1.45)
2025-09-03 18:59:06,302   INFO  Train:    7/20 ( 35%) [1077/3862 ( 28%)]  Loss: 1.564 (1.68)  LR: 9.011e-04  Grad: 13.5423  max=2.5986(module.vfe.pfn_layers.0.linear.weight)  min: -0.4331(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5651, loss_cls=0.0996, loss_bbox=0.6340, matched_ious=0.5236, loss_iou=0.0938, loss_iou_reg=0.2263, d_time=0.00(0.01), f_time=1.42(1.45), b_time=1.42(1.46)  Time cost: 26:09/1:07:34 [9:43:17/21:25:42]  Acc_iter 24250       Data time: 0.00(0.01)  Forward time: 1.42(1.45)  Batch time: 1.42(1.46)
2025-09-03 19:00:21,015   INFO  Train:    7/20 ( 35%) [1127/3862 ( 29%)]  Loss: 1.913 (1.68)  LR: 9.025e-04  Grad: 13.1866  max=0.4878(module.vfe.pfn_layers.0.linear.weight)  min: -0.9312(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5816, loss_cls=0.1010, loss_bbox=0.6679, matched_ious=0.5243, loss_iou=0.0915, loss_iou_reg=0.2248, d_time=0.01(0.01), f_time=1.41(1.45), b_time=1.42(1.46)  Time cost: 27:24/1:06:26 [9:44:32/21:26:00]  Acc_iter 24300       Data time: 0.01(0.01)  Forward time: 1.41(1.45)  Batch time: 1.42(1.46)
2025-09-03 19:01:32,696   INFO  Train:    7/20 ( 35%) [1177/3862 ( 30%)]  Loss: 1.893 (1.68)  LR: 9.039e-04  Grad: 13.6166  max=3.1476(module.vfe.pfn_layers.0.linear.weight)  min: -0.7703(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5963, loss_cls=0.1028, loss_bbox=0.6710, matched_ious=0.5209, loss_iou=0.0940, loss_iou_reg=0.2257, d_time=0.01(0.01), f_time=1.44(1.45), b_time=1.46(1.46)  Time cost: 28:35/1:05:10 [9:45:43/21:23:53]  Acc_iter 24350       Data time: 0.01(0.01)  Forward time: 1.44(1.45)  Batch time: 1.46(1.46)
2025-09-03 19:02:43,941   INFO  Train:    7/20 ( 35%) [1227/3862 ( 32%)]  Loss: 1.468 (1.68)  LR: 9.053e-04  Grad: 13.3104  max=0.4060(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7550(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.6005, loss_cls=0.1038, loss_bbox=0.6571, matched_ious=0.5193, loss_iou=0.0945, loss_iou_reg=0.2267, d_time=0.01(0.01), f_time=1.42(1.45), b_time=1.43(1.46)  Time cost: 29:46/1:03:54 [9:46:55/21:21:32]  Acc_iter 24400       Data time: 0.01(0.01)  Forward time: 1.42(1.45)  Batch time: 1.43(1.46)
2025-09-03 19:03:55,454   INFO  Train:    7/20 ( 35%) [1277/3862 ( 33%)]  Loss: 1.498 (1.68)  LR: 9.067e-04  Grad: 13.3542  max=0.4068(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.4421(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5757, loss_cls=0.1020, loss_bbox=0.6508, matched_ious=0.5219, loss_iou=0.0923, loss_iou_reg=0.2255, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 30:58/1:02:39 [9:48:06/21:19:28]  Acc_iter 24450       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-03 19:05:10,970   INFO  Train:    7/20 ( 35%) [1327/3862 ( 34%)]  Loss: 1.743 (1.67)  LR: 9.081e-04  Grad: 13.4589  max=0.8263(module.vfe.pfn_layers.0.linear.weight)  min: -0.4455(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5797, loss_cls=0.1023, loss_bbox=0.6205, matched_ious=0.5247, loss_iou=0.0930, loss_iou_reg=0.2262, d_time=0.01(0.01), f_time=2.27(1.45), b_time=2.27(1.46)  Time cost: 32:13/1:01:31 [9:49:22/21:20:07]  Acc_iter 24500       Data time: 0.01(0.01)  Forward time: 2.27(1.45)  Batch time: 2.27(1.46)
2025-09-03 19:06:24,481   INFO  Train:    7/20 ( 35%) [1377/3862 ( 36%)]  Loss: 1.803 (1.68)  LR: 9.095e-04  Grad: 13.6098  max=1.0719(module.vfe.pfn_layers.0.linear.weight)  min: -1.1802(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5988, loss_cls=0.1047, loss_bbox=0.6634, matched_ious=0.5176, loss_iou=0.0937, loss_iou_reg=0.2272, d_time=0.00(0.01), f_time=1.45(1.45), b_time=1.46(1.46)  Time cost: 33:27/1:00:20 [9:50:35/21:19:21]  Acc_iter 24550       Data time: 0.00(0.01)  Forward time: 1.45(1.45)  Batch time: 1.46(1.46)
2025-09-03 19:07:35,387   INFO  Train:    7/20 ( 35%) [1427/3862 ( 37%)]  Loss: 1.966 (1.67)  LR: 9.109e-04  Grad: 13.6025  max=0.4103(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6992(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5676, loss_cls=0.1004, loss_bbox=0.6507, matched_ious=0.5219, loss_iou=0.0930, loss_iou_reg=0.2267, d_time=0.01(0.01), f_time=1.37(1.45), b_time=1.38(1.46)  Time cost: 34:38/59:04 [9:51:46/21:16:56]  Acc_iter 24600       Data time: 0.01(0.01)  Forward time: 1.37(1.45)  Batch time: 1.38(1.46)
2025-09-03 19:08:46,155   INFO  Train:    7/20 ( 35%) [1477/3862 ( 38%)]  Loss: 1.807 (1.67)  LR: 9.122e-04  Grad: 13.6699  max=0.4215(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5949(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5950, loss_cls=0.1027, loss_bbox=0.6775, matched_ious=0.5195, loss_iou=0.0927, loss_iou_reg=0.2257, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.45(1.45)  Time cost: 35:49/57:48 [9:52:57/21:14:32]  Acc_iter 24650       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.45)
2025-09-03 19:09:57,660   INFO  Train:    7/20 ( 35%) [1527/3862 ( 40%)]  Loss: 1.866 (1.67)  LR: 9.136e-04  Grad: 13.7408  max=0.4235(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8809(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5787, loss_cls=0.1003, loss_bbox=0.6479, matched_ious=0.5251, loss_iou=0.0918, loss_iou_reg=0.2244, d_time=0.00(0.01), f_time=1.38(1.44), b_time=1.38(1.45)  Time cost: 37:00/56:33 [9:54:08/21:12:38]  Acc_iter 24700       Data time: 0.00(0.01)  Forward time: 1.38(1.44)  Batch time: 1.38(1.45)
2025-09-03 19:11:14,140   INFO  Train:    7/20 ( 35%) [1577/3862 ( 41%)]  Loss: 1.894 (1.67)  LR: 9.149e-04  Grad: 13.9074  max=1.4360(module.vfe.pfn_layers.0.linear.weight)  min: -0.8670(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5738, loss_cls=0.0995, loss_bbox=0.6386, matched_ious=0.5209, loss_iou=0.0924, loss_iou_reg=0.2284, d_time=0.01(0.01), f_time=2.30(1.45), b_time=2.31(1.46)  Time cost: 38:17/55:26 [9:55:25/21:13:33]  Acc_iter 24750       Data time: 0.01(0.01)  Forward time: 2.30(1.45)  Batch time: 2.31(1.46)
2025-09-03 19:12:27,888   INFO  Train:    7/20 ( 35%) [1627/3862 ( 42%)]  Loss: 1.554 (1.67)  LR: 9.163e-04  Grad: 13.9313  max=1.1408(module.vfe.pfn_layers.0.linear.weight)  min: -0.4559(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5896, loss_cls=0.1047, loss_bbox=0.6563, matched_ious=0.5209, loss_iou=0.0936, loss_iou_reg=0.2262, d_time=0.01(0.01), f_time=1.43(1.45), b_time=1.44(1.46)  Time cost: 39:30/54:14 [9:56:38/21:12:50]  Acc_iter 24800       Data time: 0.01(0.01)  Forward time: 1.43(1.45)  Batch time: 1.44(1.46)
2025-09-03 19:13:39,032   INFO  Train:    7/20 ( 35%) [1677/3862 ( 43%)]  Loss: 1.415 (1.67)  LR: 9.176e-04  Grad: 14.2631  max=0.4277(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.1626(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5857, loss_cls=0.1018, loss_bbox=0.6526, matched_ious=0.5238, loss_iou=0.0927, loss_iou_reg=0.2263, d_time=0.00(0.01), f_time=1.36(1.45), b_time=1.36(1.46)  Time cost: 40:42/52:59 [9:57:50/21:10:45]  Acc_iter 24850       Data time: 0.00(0.01)  Forward time: 1.36(1.45)  Batch time: 1.36(1.46)
2025-09-03 19:14:49,737   INFO  Train:    7/20 ( 35%) [1727/3862 ( 45%)]  Loss: 1.618 (1.67)  LR: 9.189e-04  Grad: 14.1784  max=2.0556(module.vfe.pfn_layers.0.linear.weight)  min: -0.7033(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5802, loss_cls=0.0996, loss_bbox=0.6931, matched_ious=0.5166, loss_iou=0.0933, loss_iou_reg=0.2282, d_time=0.01(0.01), f_time=1.46(1.45), b_time=1.47(1.45)  Time cost: 41:52/51:44 [9:59:00/21:08:31]  Acc_iter 24900       Data time: 0.01(0.01)  Forward time: 1.46(1.45)  Batch time: 1.47(1.45)
2025-09-03 19:16:00,605   INFO  Train:    7/20 ( 35%) [1777/3862 ( 46%)]  Loss: 1.534 (1.67)  LR: 9.202e-04  Grad: 14.0751  max=0.4280(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.4645(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5696, loss_cls=0.1008, loss_bbox=0.6425, matched_ious=0.5260, loss_iou=0.0922, loss_iou_reg=0.2254, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 43:03/50:29 [10:00:11/21:06:23]  Acc_iter 24950       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-03 19:17:18,289   INFO  Train:    7/20 ( 35%) [1827/3862 ( 47%)]  Loss: 1.738 (1.67)  LR: 9.215e-04  Grad: 14.2231  max=0.4317(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1875(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5818, loss_cls=0.1023, loss_bbox=0.6400, matched_ious=0.5203, loss_iou=0.0951, loss_iou_reg=0.2291, d_time=0.01(0.01), f_time=1.39(1.45), b_time=1.39(1.46)  Time cost: 44:21/49:22 [10:01:29/21:07:35]  Acc_iter 25000       Data time: 0.01(0.01)  Forward time: 1.39(1.45)  Batch time: 1.39(1.46)
2025-09-03 19:18:29,616   INFO  Train:    7/20 ( 35%) [1877/3862 ( 49%)]  Loss: 1.670 (1.67)  LR: 9.228e-04  Grad: 14.5282  max=1.0252(module.vfe.pfn_layers.0.linear.weight)  min: -2.8376(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5771, loss_cls=0.1014, loss_bbox=0.6281, matched_ious=0.5264, loss_iou=0.0951, loss_iou_reg=0.2252, d_time=0.00(0.01), f_time=1.35(1.45), b_time=1.35(1.46)  Time cost: 45:32/48:08 [10:02:40/21:05:41]  Acc_iter 25050       Data time: 0.00(0.01)  Forward time: 1.35(1.45)  Batch time: 1.35(1.46)
2025-09-03 19:19:40,776   INFO  Train:    7/20 ( 35%) [1927/3862 ( 50%)]  Loss: 1.465 (1.67)  LR: 9.241e-04  Grad: 14.2766  max=0.4363(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.4693(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5825, loss_cls=0.1005, loss_bbox=0.6730, matched_ious=0.5232, loss_iou=0.0934, loss_iou_reg=0.2248, d_time=0.01(0.01), f_time=1.40(1.45), b_time=1.41(1.45)  Time cost: 46:43/46:53 [10:03:51/21:03:45]  Acc_iter 25100       Data time: 0.01(0.01)  Forward time: 1.40(1.45)  Batch time: 1.41(1.45)
2025-09-03 19:20:51,555   INFO  Train:    7/20 ( 35%) [1977/3862 ( 51%)]  Loss: 2.015 (1.67)  LR: 9.253e-04  Grad: 14.3543  max=0.4401(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.4711(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5628, loss_cls=0.0993, loss_bbox=0.6388, matched_ious=0.5214, loss_iou=0.0917, loss_iou_reg=0.2271, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 47:54/45:39 [10:05:02/21:01:42]  Acc_iter 25150       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-03 19:22:02,600   INFO  Train:    7/20 ( 35%) [2027/3862 ( 52%)]  Loss: 1.618 (1.67)  LR: 9.266e-04  Grad: 14.4664  max=0.5813(module.vfe.pfn_layers.0.linear.weight)  min: -0.7291(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5846, loss_cls=0.1025, loss_bbox=0.6588, matched_ious=0.5149, loss_iou=0.0949, loss_iou_reg=0.2297, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 49:05/44:25 [10:06:13/20:59:48]  Acc_iter 25200       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-03 19:23:18,464   INFO  Train:    7/20 ( 35%) [2077/3862 ( 54%)]  Loss: 1.840 (1.67)  LR: 9.278e-04  Grad: 15.0831  max=2.1612(module.vfe.pfn_layers.0.linear.weight)  min: -2.7938(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5677, loss_cls=0.0982, loss_bbox=0.6382, matched_ious=0.5248, loss_iou=0.0923, loss_iou_reg=0.2255, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 50:21/43:15 [10:07:29/20:59:56]  Acc_iter 25250       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-03 19:24:29,285   INFO  Train:    7/20 ( 35%) [2127/3862 ( 55%)]  Loss: 1.531 (1.67)  LR: 9.291e-04  Grad: 14.8051  max=0.4521(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.2418(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5857, loss_cls=0.1000, loss_bbox=0.6544, matched_ious=0.5200, loss_iou=0.0927, loss_iou_reg=0.2270, d_time=0.00(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 51:32/42:01 [10:08:40/20:57:57]  Acc_iter 25300       Data time: 0.00(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-03 19:25:40,168   INFO  Train:    7/20 ( 35%) [2177/3862 ( 56%)]  Loss: 1.738 (1.67)  LR: 9.303e-04  Grad: 14.6955  max=0.4576(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0862(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5920, loss_cls=0.1010, loss_bbox=0.6637, matched_ious=0.5197, loss_iou=0.0939, loss_iou_reg=0.2273, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 52:43/40:47 [10:09:51/20:56:02]  Acc_iter 25350       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-03 19:26:51,451   INFO  Train:    7/20 ( 35%) [2227/3862 ( 58%)]  Loss: 1.534 (1.67)  LR: 9.315e-04  Grad: 14.7317  max=0.6059(module.vfe.pfn_layers.0.linear.weight)  min: -0.4801(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5694, loss_cls=0.0976, loss_bbox=0.6312, matched_ious=0.5191, loss_iou=0.0943, loss_iou_reg=0.2286, d_time=0.00(0.01), f_time=1.47(1.44), b_time=1.47(1.45)  Time cost: 53:54/39:33 [10:11:02/20:54:19]  Acc_iter 25400       Data time: 0.00(0.01)  Forward time: 1.47(1.44)  Batch time: 1.47(1.45)
2025-09-03 19:28:02,221   INFO  Train:    7/20 ( 35%) [2277/3862 ( 59%)]  Loss: 1.730 (1.67)  LR: 9.327e-04  Grad: 14.7897  max=0.4584(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6166(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5747, loss_cls=0.0991, loss_bbox=0.6470, matched_ious=0.5229, loss_iou=0.0938, loss_iou_reg=0.2270, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.45(1.45)  Time cost: 55:05/38:19 [10:12:13/20:52:25]  Acc_iter 25450       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.45)
2025-09-03 19:29:19,629   INFO  Train:    7/20 ( 35%) [2327/3862 ( 60%)]  Loss: 1.609 (1.66)  LR: 9.339e-04  Grad: 15.2453  max=2.5232(module.vfe.pfn_layers.0.linear.weight)  min: -1.7115(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5843, loss_cls=0.1017, loss_bbox=0.6266, matched_ious=0.5236, loss_iou=0.0932, loss_iou_reg=0.2246, d_time=0.01(0.01), f_time=1.45(1.44), b_time=1.46(1.45)  Time cost: 56:22/37:10 [10:13:30/20:53:00]  Acc_iter 25500       Data time: 0.01(0.01)  Forward time: 1.45(1.44)  Batch time: 1.46(1.45)
2025-09-03 19:30:30,883   INFO  Train:    7/20 ( 35%) [2377/3862 ( 62%)]  Loss: 1.824 (1.66)  LR: 9.351e-04  Grad: 15.0202  max=1.1604(module.vfe.pfn_layers.0.linear.weight)  min: -0.7795(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5583, loss_cls=0.0986, loss_bbox=0.6097, matched_ious=0.5234, loss_iou=0.0936, loss_iou_reg=0.2268, d_time=0.02(0.01), f_time=1.44(1.44), b_time=1.45(1.45)  Time cost: 57:33/35:56 [10:14:42/20:51:17]  Acc_iter 25550       Data time: 0.02(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.45)
2025-09-03 19:31:42,225   INFO  Train:    7/20 ( 35%) [2427/3862 ( 63%)]  Loss: 1.792 (1.66)  LR: 9.363e-04  Grad: 15.0460  max=0.4673(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6622(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5932, loss_cls=0.1022, loss_bbox=0.6643, matched_ious=0.5194, loss_iou=0.0928, loss_iou_reg=0.2267, d_time=0.00(0.01), f_time=1.46(1.44), b_time=1.46(1.45)  Time cost: 58:45/34:43 [10:15:53/20:49:38]  Acc_iter 25600       Data time: 0.00(0.01)  Forward time: 1.46(1.44)  Batch time: 1.46(1.45)
2025-09-03 19:32:53,385   INFO  Train:    7/20 ( 35%) [2477/3862 ( 64%)]  Loss: 1.732 (1.66)  LR: 9.375e-04  Grad: 15.0759  max=0.4786(module.vfe.pfn_layers.0.linear.weight)  min: -0.4881(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5856, loss_cls=0.1022, loss_bbox=0.6586, matched_ious=0.5193, loss_iou=0.0923, loss_iou_reg=0.2276, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.45(1.45)  Time cost: 59:56/33:30 [10:17:04/20:47:55]  Acc_iter 25650       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.45)
2025-09-03 19:34:06,390   INFO  Train:    7/20 ( 35%) [2527/3862 ( 65%)]  Loss: 1.845 (1.66)  LR: 9.386e-04  Grad: 15.2848  max=1.5591(module.vfe.pfn_layers.0.linear.weight)  min: -0.4875(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5882, loss_cls=0.1007, loss_bbox=0.6530, matched_ious=0.5215, loss_iou=0.0941, loss_iou_reg=0.2273, d_time=0.01(0.01), f_time=2.39(1.44), b_time=2.40(1.45)  Time cost: 1:01:09/32:17 [10:18:17/20:46:51]  Acc_iter 25700       Data time: 0.01(0.01)  Forward time: 2.39(1.44)  Batch time: 2.40(1.45)
2025-09-03 19:35:22,937   INFO  Train:    7/20 ( 35%) [2577/3862 ( 67%)]  Loss: 1.700 (1.66)  LR: 9.398e-04  Grad: 15.1987  max=0.4767(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.4876(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5462, loss_cls=0.0960, loss_bbox=0.6085, matched_ious=0.5294, loss_iou=0.0937, loss_iou_reg=0.2242, d_time=0.01(0.01), f_time=1.37(1.44), b_time=1.38(1.45)  Time cost: 1:02:25/31:07 [10:19:34/20:46:58]  Acc_iter 25750       Data time: 0.01(0.01)  Forward time: 1.37(1.44)  Batch time: 1.38(1.45)
2025-09-03 19:36:33,530   INFO  Train:    7/20 ( 35%) [2627/3862 ( 68%)]  Loss: 1.527 (1.66)  LR: 9.409e-04  Grad: 15.6834  max=3.4266(module.vfe.pfn_layers.0.linear.weight)  min: -0.4903(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5885, loss_cls=0.1015, loss_bbox=0.6323, matched_ious=0.5251, loss_iou=0.0926, loss_iou_reg=0.2248, d_time=0.01(0.01), f_time=1.37(1.44), b_time=1.38(1.45)  Time cost: 1:03:36/29:53 [10:20:44/20:45:05]  Acc_iter 25800       Data time: 0.01(0.01)  Forward time: 1.37(1.44)  Batch time: 1.38(1.45)
2025-09-03 19:37:45,570   INFO  Train:    7/20 ( 35%) [2677/3862 ( 69%)]  Loss: 1.526 (1.66)  LR: 9.420e-04  Grad: 15.5113  max=1.6394(module.vfe.pfn_layers.0.linear.weight)  min: -1.6320(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5618, loss_cls=0.0984, loss_bbox=0.6190, matched_ious=0.5301, loss_iou=0.0924, loss_iou_reg=0.2246, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 1:04:48/28:40 [10:21:56/20:43:42]  Acc_iter 25850       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-03 19:38:56,760   INFO  Train:    7/20 ( 35%) [2727/3862 ( 71%)]  Loss: 1.578 (1.66)  LR: 9.431e-04  Grad: 15.4161  max=0.4791(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6571(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5512, loss_cls=0.0946, loss_bbox=0.6503, matched_ious=0.5238, loss_iou=0.0925, loss_iou_reg=0.2243, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 1:05:59/27:27 [10:23:07/20:42:02]  Acc_iter 25900       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-03 19:40:08,879   INFO  Train:    7/20 ( 35%) [2777/3862 ( 72%)]  Loss: 1.827 (1.66)  LR: 9.443e-04  Grad: 15.5008  max=0.4768(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.4996(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5823, loss_cls=0.1009, loss_bbox=0.6496, matched_ious=0.5250, loss_iou=0.0932, loss_iou_reg=0.2256, d_time=0.01(0.01), f_time=1.31(1.44), b_time=1.32(1.45)  Time cost: 1:07:11/26:14 [10:24:19/20:40:41]  Acc_iter 25950       Data time: 0.01(0.01)  Forward time: 1.31(1.44)  Batch time: 1.32(1.45)
2025-09-03 19:41:24,278   INFO  Train:    7/20 ( 35%) [2827/3862 ( 73%)]  Loss: 1.507 (1.66)  LR: 9.454e-04  Grad: 15.6183  max=0.4847(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2942(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5712, loss_cls=0.0988, loss_bbox=0.6455, matched_ious=0.5245, loss_iou=0.0928, loss_iou_reg=0.2255, d_time=0.01(0.01), f_time=1.51(1.44), b_time=1.51(1.45)  Time cost: 1:08:27/25:03 [10:25:35/20:40:20]  Acc_iter 26000       Data time: 0.01(0.01)  Forward time: 1.51(1.44)  Batch time: 1.51(1.45)
2025-09-03 19:42:34,510   INFO  Train:    7/20 ( 35%) [2877/3862 ( 74%)]  Loss: 1.458 (1.66)  LR: 9.464e-04  Grad: 15.8672  max=2.0953(module.vfe.pfn_layers.0.linear.weight)  min: -0.5020(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5761, loss_cls=0.0997, loss_bbox=0.6411, matched_ious=0.5255, loss_iou=0.0920, loss_iou_reg=0.2238, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.43(1.45)  Time cost: 1:09:37/23:49 [10:26:45/20:38:25]  Acc_iter 26050       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.43(1.45)
2025-09-03 19:43:46,036   INFO  Train:    7/20 ( 35%) [2927/3862 ( 76%)]  Loss: 1.532 (1.66)  LR: 9.475e-04  Grad: 15.7001  max=0.6605(module.vfe.pfn_layers.0.linear.weight)  min: -0.5022(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5830, loss_cls=0.0992, loss_bbox=0.6327, matched_ious=0.5234, loss_iou=0.0938, loss_iou_reg=0.2263, d_time=0.00(0.01), f_time=1.39(1.44), b_time=1.39(1.45)  Time cost: 1:10:49/22:36 [10:27:57/20:36:54]  Acc_iter 26100       Data time: 0.00(0.01)  Forward time: 1.39(1.44)  Batch time: 1.39(1.45)
2025-09-03 19:44:56,861   INFO  Train:    7/20 ( 35%) [2977/3862 ( 77%)]  Loss: 1.590 (1.66)  LR: 9.486e-04  Grad: 15.7495  max=0.6059(module.vfe.pfn_layers.0.linear.weight)  min: -0.5050(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5758, loss_cls=0.0988, loss_bbox=0.6198, matched_ious=0.5300, loss_iou=0.0914, loss_iou_reg=0.2225, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 1:11:59/21:23 [10:29:07/20:35:12]  Acc_iter 26150       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-03 19:46:09,474   INFO  Train:    7/20 ( 35%) [3027/3862 ( 78%)]  Loss: 1.656 (1.66)  LR: 9.496e-04  Grad: 15.8029  max=0.4949(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5058(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5516, loss_cls=0.0943, loss_bbox=0.6234, matched_ious=0.5284, loss_iou=0.0910, loss_iou_reg=0.2234, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.41(1.45)  Time cost: 1:13:12/20:11 [10:30:20/20:34:01]  Acc_iter 26200       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.41(1.45)
2025-09-03 19:47:25,657   INFO  Train:    7/20 ( 35%) [3077/3862 ( 80%)]  Loss: 1.724 (1.66)  LR: 9.507e-04  Grad: 15.9010  max=0.4944(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6580(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5838, loss_cls=0.0976, loss_bbox=0.6473, matched_ious=0.5249, loss_iou=0.0928, loss_iou_reg=0.2243, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.42(1.45)  Time cost: 1:14:28/18:59 [10:31:36/20:33:49]  Acc_iter 26250       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.45)
2025-09-03 19:48:37,051   INFO  Train:    7/20 ( 35%) [3127/3862 ( 81%)]  Loss: 1.736 (1.66)  LR: 9.517e-04  Grad: 15.9641  max=0.4907(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5120(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5898, loss_cls=0.1030, loss_bbox=0.6651, matched_ious=0.5237, loss_iou=0.0922, loss_iou_reg=0.2251, d_time=0.01(0.01), f_time=1.45(1.44), b_time=1.46(1.45)  Time cost: 1:15:40/17:46 [10:32:48/20:32:17]  Acc_iter 26300       Data time: 0.01(0.01)  Forward time: 1.45(1.44)  Batch time: 1.46(1.45)
2025-09-03 19:49:48,131   INFO  Train:    7/20 ( 35%) [3177/3862 ( 82%)]  Loss: 1.390 (1.66)  LR: 9.528e-04  Grad: 16.0476  max=0.7951(module.vfe.pfn_layers.0.linear.weight)  min: -0.5141(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.6043, loss_cls=0.1034, loss_bbox=0.6698, matched_ious=0.5157, loss_iou=0.0942, loss_iou_reg=0.2278, d_time=0.01(0.01), f_time=1.47(1.44), b_time=1.48(1.45)  Time cost: 1:16:51/16:33 [10:33:59/20:30:40]  Acc_iter 26350       Data time: 0.01(0.01)  Forward time: 1.47(1.44)  Batch time: 1.48(1.45)
2025-09-03 19:50:58,886   INFO  Train:    7/20 ( 35%) [3227/3862 ( 84%)]  Loss: 1.614 (1.66)  LR: 9.538e-04  Grad: 16.1343  max=0.4989(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8930(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5764, loss_cls=0.1003, loss_bbox=0.6360, matched_ious=0.5316, loss_iou=0.0900, loss_iou_reg=0.2227, d_time=0.00(0.01), f_time=1.38(1.44), b_time=1.38(1.45)  Time cost: 1:18:01/15:21 [10:35:10/20:28:59]  Acc_iter 26400       Data time: 0.00(0.01)  Forward time: 1.38(1.44)  Batch time: 1.38(1.45)
2025-09-03 19:52:10,714   INFO  Train:    7/20 ( 35%) [3277/3862 ( 85%)]  Loss: 1.683 (1.66)  LR: 9.548e-04  Grad: 16.2055  max=0.5021(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5186(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5719, loss_cls=0.0962, loss_bbox=0.6416, matched_ious=0.5240, loss_iou=0.0919, loss_iou_reg=0.2253, d_time=0.01(0.01), f_time=1.39(1.44), b_time=1.40(1.45)  Time cost: 1:19:13/14:08 [10:36:21/20:27:36]  Acc_iter 26450       Data time: 0.01(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.45)
2025-09-03 19:53:27,183   INFO  Train:    7/20 ( 35%) [3327/3862 ( 86%)]  Loss: 1.601 (1.66)  LR: 9.558e-04  Grad: 16.2795  max=0.7691(module.vfe.pfn_layers.0.linear.weight)  min: -0.6930(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5786, loss_cls=0.1017, loss_bbox=0.6711, matched_ious=0.5232, loss_iou=0.0914, loss_iou_reg=0.2240, d_time=0.00(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 1:20:30/12:56 [10:37:38/20:27:24]  Acc_iter 26500       Data time: 0.00(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-03 19:54:38,183   INFO  Train:    7/20 ( 35%) [3377/3862 ( 87%)]  Loss: 1.819 (1.66)  LR: 9.568e-04  Grad: 16.3679  max=0.5010(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1006(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5531, loss_cls=0.0944, loss_bbox=0.6291, matched_ious=0.5260, loss_iou=0.0934, loss_iou_reg=0.2256, d_time=0.01(0.01), f_time=1.49(1.44), b_time=1.50(1.45)  Time cost: 1:21:41/11:43 [10:38:49/20:25:48]  Acc_iter 26550       Data time: 0.01(0.01)  Forward time: 1.49(1.44)  Batch time: 1.50(1.45)
2025-09-03 19:55:49,923   INFO  Train:    7/20 ( 35%) [3427/3862 ( 89%)]  Loss: 2.067 (1.65)  LR: 9.577e-04  Grad: 16.4154  max=0.5003(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6733(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5694, loss_cls=0.0984, loss_bbox=0.6153, matched_ious=0.5267, loss_iou=0.0912, loss_iou_reg=0.2250, d_time=0.01(0.01), f_time=1.46(1.44), b_time=1.46(1.45)  Time cost: 1:22:52/10:31 [10:40:01/20:24:23]  Acc_iter 26600       Data time: 0.01(0.01)  Forward time: 1.46(1.44)  Batch time: 1.46(1.45)
2025-09-03 19:57:01,126   INFO  Train:    7/20 ( 35%) [3477/3862 ( 90%)]  Loss: 1.674 (1.65)  LR: 9.587e-04  Grad: 16.4885  max=0.8755(module.vfe.pfn_layers.0.linear.weight)  min: -0.5222(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5721, loss_cls=0.1001, loss_bbox=0.6469, matched_ious=0.5226, loss_iou=0.0922, loss_iou_reg=0.2262, d_time=0.00(0.01), f_time=1.41(1.44), b_time=1.41(1.45)  Time cost: 1:24:04/09:18 [10:41:12/20:22:51]  Acc_iter 26650       Data time: 0.00(0.01)  Forward time: 1.41(1.44)  Batch time: 1.41(1.45)
2025-09-03 19:58:13,465   INFO  Train:    7/20 ( 35%) [3527/3862 ( 91%)]  Loss: 1.451 (1.65)  LR: 9.596e-04  Grad: 16.5240  max=0.5065(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5284(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5700, loss_cls=0.0985, loss_bbox=0.6122, matched_ious=0.5301, loss_iou=0.0921, loss_iou_reg=0.2228, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 1:25:16/08:05 [10:42:24/20:21:36]  Acc_iter 26700       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-03 19:59:30,912   INFO  Train:    7/20 ( 35%) [3577/3862 ( 93%)]  Loss: 1.412 (1.65)  LR: 9.606e-04  Grad: 16.6292  max=0.5134(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9990(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5464, loss_cls=0.0955, loss_bbox=0.6198, matched_ious=0.5286, loss_iou=0.0919, loss_iou_reg=0.2232, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.44(1.45)  Time cost: 1:26:33/06:53 [10:43:42/20:21:34]  Acc_iter 26750       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.44(1.45)
2025-09-03 20:00:41,747   INFO  Train:    7/20 ( 35%) [3627/3862 ( 94%)]  Loss: 1.785 (1.65)  LR: 9.615e-04  Grad: 16.7559  max=1.5589(module.vfe.pfn_layers.0.linear.weight)  min: -0.9386(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5636, loss_cls=0.0987, loss_bbox=0.6164, matched_ious=0.5309, loss_iou=0.0918, loss_iou_reg=0.2215, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 1:27:44/05:41 [10:44:52/20:19:57]  Acc_iter 26800       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-03 20:01:53,382   INFO  Train:    7/20 ( 35%) [3677/3862 ( 95%)]  Loss: 1.315 (1.65)  LR: 9.624e-04  Grad: 16.7566  max=0.5146(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9448(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5619, loss_cls=0.0967, loss_bbox=0.6168, matched_ious=0.5323, loss_iou=0.0926, loss_iou_reg=0.2203, d_time=0.01(0.01), f_time=1.36(1.44), b_time=1.36(1.45)  Time cost: 1:28:56/04:28 [10:46:04/20:18:32]  Acc_iter 26850       Data time: 0.01(0.01)  Forward time: 1.36(1.44)  Batch time: 1.36(1.45)
2025-09-03 20:03:04,897   INFO  Train:    7/20 ( 35%) [3727/3862 ( 97%)]  Loss: 1.556 (1.65)  LR: 9.633e-04  Grad: 16.9474  max=0.5209(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.4924(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5595, loss_cls=0.0975, loss_bbox=0.6446, matched_ious=0.5265, loss_iou=0.0928, loss_iou_reg=0.2253, d_time=0.01(0.01), f_time=1.37(1.44), b_time=1.38(1.45)  Time cost: 1:30:07/03:15 [10:47:16/20:17:05]  Acc_iter 26900       Data time: 0.01(0.01)  Forward time: 1.37(1.44)  Batch time: 1.38(1.45)
2025-09-03 20:04:18,114   INFO  Train:    7/20 ( 35%) [3777/3862 ( 98%)]  Loss: 1.548 (1.65)  LR: 9.642e-04  Grad: 16.8751  max=0.5205(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5411(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5756, loss_cls=0.0990, loss_bbox=0.6469, matched_ious=0.5309, loss_iou=0.0914, loss_iou_reg=0.2224, d_time=0.00(0.01), f_time=1.45(1.44), b_time=1.45(1.45)  Time cost: 1:31:21/02:03 [10:48:29/20:16:02]  Acc_iter 26950       Data time: 0.00(0.01)  Forward time: 1.45(1.44)  Batch time: 1.45(1.45)
2025-09-03 20:05:32,032   INFO  Train:    7/20 ( 35%) [3827/3862 ( 99%)]  Loss: 1.447 (1.65)  LR: 9.651e-04  Grad: 16.9655  max=0.5845(module.vfe.pfn_layers.0.linear.weight)  min: -0.5438(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5893, loss_cls=0.1004, loss_bbox=0.6558, matched_ious=0.5244, loss_iou=0.0914, loss_iou_reg=0.2230, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 1:32:35/00:50 [10:49:43/20:15:07]  Acc_iter 27000       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-03 20:06:18,614   INFO  Train:    7/20 ( 35%) [3861/3862 (100%)]  Loss: 1.383 (1.65)  LR: 9.657e-04  Grad: 17.0077  max=0.5343(module.vfe.pfn_layers.0.linear.weight)  min: -0.5407(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5765, loss_cls=0.0989, loss_bbox=0.6670, matched_ious=0.5270, loss_iou=0.0909, loss_iou_reg=0.2223, d_time=0.00(0.01), f_time=1.36(1.44), b_time=1.36(1.45)  Time cost: 1:33:21/00:01 [10:50:29/20:13:42]  Acc_iter 27034       Data time: 0.00(0.01)  Forward time: 1.36(1.44)  Batch time: 1.36(1.45)

                                               [Aepochs:  35%|███▌      | 7/20 [10:50:29<20:10:10, 5585.42s/it]epochs:  35%|███▌      | 7/20 [10:50:30<20:10:10, 5585.43s/it]epochs:  35%|███▌      | 7/20 [10:50:30<20:10:10, 5585.43s/it]epochs:  35%|███▌      | 7/20 [10:50:30<20:10:10, 5585.43s/it]epochs:  35%|███▌      | 7/20 [10:50:30<20:10:10, 5585.43s/it]epochs:  35%|███▌      | 7/20 [10:50:30<20:10:10, 5585.43s/it]epochs:  35%|███▌      | 7/20 [10:50:30<20:10:10, 5585.44s/it]epochs:  35%|███▌      | 7/20 [10:50:30<20:10:10, 5585.43s/it]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-03 20:06:24,234   INFO  Train:    8/20 ( 40%) [   0/3862 (  0%)]  Loss: 1.703 (1.70)  LR: 9.657e-04  Grad: 17.1545  max=1.5290(module.vfe.pfn_layers.0.linear.weight)  min: -1.4573(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5931, loss_cls=0.1019, loss_bbox=0.6688, matched_ious=0.5005, loss_iou=0.0987, loss_iou_reg=0.2400, d_time=1.94(1.94), f_time=2.50(2.50), b_time=4.43(4.43)  Time cost: 00:04/4:30:02 [10:50:35/58:30:26]  Acc_iter 27035       Data time: 1.94(1.94)  Forward time: 2.50(2.50)  Batch time: 4.43(4.43)
2025-09-03 20:06:45,470   INFO  Train:    8/20 ( 40%) [  15/3862 (  0%)]  Loss: 1.456 (1.58)  LR: 9.660e-04  Grad: 17.0751  max=0.5254(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1156(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5535, loss_cls=0.0976, loss_bbox=0.6082, matched_ious=0.5344, loss_iou=0.0924, loss_iou_reg=0.2242, d_time=0.00(0.13), f_time=1.40(1.48), b_time=1.41(1.61)  Time cost: 00:25/1:41:54 [10:50:56/22:09:39]  Acc_iter 27050       Data time: 0.00(0.13)  Forward time: 1.40(1.48)  Batch time: 1.41(1.61)
2025-09-03 20:07:56,654   INFO  Train:    8/20 ( 40%) [  65/3862 (  2%)]  Loss: 1.734 (1.62)  LR: 9.669e-04  Grad: 17.1135  max=0.5270(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6910(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5626, loss_cls=0.0978, loss_bbox=0.6512, matched_ious=0.5221, loss_iou=0.0934, loss_iou_reg=0.2258, d_time=0.01(0.04), f_time=1.43(1.43), b_time=1.44(1.47)  Time cost: 01:36/1:32:38 [10:52:07/20:23:16]  Acc_iter 27100       Data time: 0.01(0.04)  Forward time: 1.43(1.43)  Batch time: 1.44(1.47)
2025-09-03 20:09:09,168   INFO  Train:    8/20 ( 40%) [ 115/3862 (  3%)]  Loss: 1.287 (1.63)  LR: 9.677e-04  Grad: 17.1858  max=0.5315(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9965(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5806, loss_cls=0.0999, loss_bbox=0.6392, matched_ious=0.5296, loss_iou=0.0918, loss_iou_reg=0.2234, d_time=0.01(0.02), f_time=1.40(1.44), b_time=1.41(1.46)  Time cost: 02:49/1:31:03 [10:53:20/20:17:11]  Acc_iter 27150       Data time: 0.01(0.02)  Forward time: 1.40(1.44)  Batch time: 1.41(1.46)
2025-09-03 20:10:22,263   INFO  Train:    8/20 ( 40%) [ 165/3862 (  4%)]  Loss: 1.682 (1.64)  LR: 9.686e-04  Grad: 17.2236  max=0.5300(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5530(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5788, loss_cls=0.1006, loss_bbox=0.6738, matched_ious=0.5252, loss_iou=0.0919, loss_iou_reg=0.2246, d_time=0.01(0.02), f_time=1.49(1.44), b_time=1.49(1.46)  Time cost: 04:02/1:29:54 [10:54:33/20:16:57]  Acc_iter 27200       Data time: 0.01(0.02)  Forward time: 1.49(1.44)  Batch time: 1.49(1.46)
2025-09-03 20:11:37,607   INFO  Train:    8/20 ( 40%) [ 215/3862 (  6%)]  Loss: 1.380 (1.63)  LR: 9.694e-04  Grad: 17.3039  max=0.5335(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5503(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5467, loss_cls=0.0968, loss_bbox=0.6251, matched_ious=0.5287, loss_iou=0.0925, loss_iou_reg=0.2229, d_time=0.01(0.02), f_time=1.37(1.45), b_time=1.38(1.47)  Time cost: 05:17/1:29:21 [10:55:48/20:24:55]  Acc_iter 27250       Data time: 0.01(0.02)  Forward time: 1.37(1.45)  Batch time: 1.38(1.47)
2025-09-03 20:12:48,762   INFO  Train:    8/20 ( 40%) [ 265/3862 (  7%)]  Loss: 2.049 (1.63)  LR: 9.702e-04  Grad: 17.3970  max=0.7215(module.vfe.pfn_layers.0.linear.weight)  min: -0.6954(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5647, loss_cls=0.0962, loss_bbox=0.6635, matched_ious=0.5250, loss_iou=0.0920, loss_iou_reg=0.2241, d_time=0.01(0.02), f_time=1.35(1.45), b_time=1.36(1.46)  Time cost: 06:28/1:27:36 [10:56:59/20:16:21]  Acc_iter 27300       Data time: 0.01(0.02)  Forward time: 1.35(1.45)  Batch time: 1.36(1.46)
2025-09-03 20:13:59,795   INFO  Train:    8/20 ( 40%) [ 315/3862 (  8%)]  Loss: 1.504 (1.62)  LR: 9.710e-04  Grad: 17.5574  max=1.7936(module.vfe.pfn_layers.0.linear.weight)  min: -0.8767(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5584, loss_cls=0.0980, loss_bbox=0.6240, matched_ious=0.5278, loss_iou=0.0915, loss_iou_reg=0.2241, d_time=0.00(0.01), f_time=1.34(1.44), b_time=1.35(1.46)  Time cost: 07:39/1:26:00 [10:58:10/20:09:47]  Acc_iter 27350       Data time: 0.00(0.01)  Forward time: 1.34(1.44)  Batch time: 1.35(1.46)
2025-09-03 20:15:11,170   INFO  Train:    8/20 ( 40%) [ 365/3862 (  9%)]  Loss: 1.700 (1.62)  LR: 9.718e-04  Grad: 17.5203  max=0.5377(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5854(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5723, loss_cls=0.0990, loss_bbox=0.6286, matched_ious=0.5319, loss_iou=0.0905, loss_iou_reg=0.2214, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.35(1.45)  Time cost: 08:51/1:24:34 [10:59:22/20:05:27]  Acc_iter 27400       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.35(1.45)
2025-09-03 20:16:24,864   INFO  Train:    8/20 ( 40%) [ 415/3862 ( 11%)]  Loss: 1.749 (1.62)  LR: 9.726e-04  Grad: 17.5678  max=0.5405(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5596(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5696, loss_cls=0.0979, loss_bbox=0.6394, matched_ious=0.5275, loss_iou=0.0935, loss_iou_reg=0.2244, d_time=0.39(0.01), f_time=1.50(1.44), b_time=1.88(1.45)  Time cost: 10:04/1:23:31 [11:00:35/20:06:31]  Acc_iter 27450       Data time: 0.39(0.01)  Forward time: 1.50(1.44)  Batch time: 1.88(1.45)
2025-09-03 20:17:38,859   INFO  Train:    8/20 ( 40%) [ 465/3862 ( 12%)]  Loss: 1.573 (1.62)  LR: 9.734e-04  Grad: 18.9618  max=6.3415(module.vfe.pfn_layers.0.linear.weight)  min: -1.3599(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5836, loss_cls=0.0991, loss_bbox=0.6398, matched_ious=0.5303, loss_iou=0.0902, loss_iou_reg=0.2216, d_time=0.00(0.01), f_time=1.38(1.44), b_time=1.39(1.46)  Time cost: 11:18/1:22:28 [11:01:49/20:07:37]  Acc_iter 27500       Data time: 0.00(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.46)
2025-09-03 20:18:49,529   INFO  Train:    8/20 ( 40%) [ 515/3862 ( 13%)]  Loss: 1.599 (1.62)  LR: 9.742e-04  Grad: 17.6993  max=0.5509(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5642(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5493, loss_cls=0.0953, loss_bbox=0.6272, matched_ious=0.5301, loss_iou=0.0923, loss_iou_reg=0.2210, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 12:29/1:21:01 [11:03:00/20:02:55]  Acc_iter 27550       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-03 20:20:01,069   INFO  Train:    8/20 ( 40%) [ 565/3862 ( 15%)]  Loss: 1.467 (1.62)  LR: 9.749e-04  Grad: 17.7763  max=0.6600(module.vfe.pfn_layers.0.linear.weight)  min: -0.5699(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5723, loss_cls=0.1010, loss_bbox=0.6249, matched_ious=0.5388, loss_iou=0.0890, loss_iou_reg=0.2186, d_time=0.00(0.01), f_time=1.48(1.44), b_time=1.49(1.45)  Time cost: 13:41/1:19:42 [11:04:12/20:00:08]  Acc_iter 27600       Data time: 0.00(0.01)  Forward time: 1.48(1.44)  Batch time: 1.49(1.45)
2025-09-03 20:21:13,619   INFO  Train:    8/20 ( 40%) [ 615/3862 ( 16%)]  Loss: 1.648 (1.62)  LR: 9.757e-04  Grad: 17.8149  max=0.5521(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5700(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5627, loss_cls=0.0956, loss_bbox=0.6434, matched_ious=0.5282, loss_iou=0.0927, loss_iou_reg=0.2246, d_time=0.00(0.01), f_time=1.41(1.44), b_time=1.41(1.45)  Time cost: 14:53/1:18:30 [11:05:24/19:58:57]  Acc_iter 27650       Data time: 0.00(0.01)  Forward time: 1.41(1.44)  Batch time: 1.41(1.45)
2025-09-03 20:22:28,111   INFO  Train:    8/20 ( 40%) [ 665/3862 ( 17%)]  Loss: 1.299 (1.62)  LR: 9.764e-04  Grad: 17.8923  max=0.5543(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5752(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5600, loss_cls=0.0986, loss_bbox=0.6113, matched_ious=0.5304, loss_iou=0.0902, loss_iou_reg=0.2232, d_time=0.58(0.01), f_time=1.46(1.44), b_time=2.04(1.45)  Time cost: 16:08/1:17:27 [11:06:39/20:00:10]  Acc_iter 27700       Data time: 0.58(0.01)  Forward time: 1.46(1.44)  Batch time: 2.04(1.45)
2025-09-03 20:23:42,325   INFO  Train:    8/20 ( 40%) [ 715/3862 ( 19%)]  Loss: 1.804 (1.61)  LR: 9.772e-04  Grad: 17.9473  max=0.5555(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5751(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5537, loss_cls=0.0977, loss_bbox=0.6133, matched_ious=0.5328, loss_iou=0.0922, loss_iou_reg=0.2221, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.44(1.46)  Time cost: 17:22/1:16:21 [11:07:53/20:00:44]  Acc_iter 27750       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.44(1.46)
2025-09-03 20:24:53,647   INFO  Train:    8/20 ( 40%) [ 765/3862 ( 20%)]  Loss: 1.303 (1.61)  LR: 9.779e-04  Grad: 17.9950  max=0.5558(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5789(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5650, loss_cls=0.0979, loss_bbox=0.6309, matched_ious=0.5296, loss_iou=0.0902, loss_iou_reg=0.2232, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 18:33/1:15:02 [11:09:04/19:57:56]  Acc_iter 27800       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-03 20:26:05,386   INFO  Train:    8/20 ( 40%) [ 815/3862 ( 21%)]  Loss: 1.314 (1.61)  LR: 9.786e-04  Grad: 18.0841  max=0.5638(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6353(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5746, loss_cls=0.0995, loss_bbox=0.6311, matched_ious=0.5263, loss_iou=0.0939, loss_iou_reg=0.2243, d_time=0.01(0.01), f_time=1.50(1.44), b_time=1.51(1.45)  Time cost: 19:45/1:13:46 [11:10:16/19:55:46]  Acc_iter 27850       Data time: 0.01(0.01)  Forward time: 1.50(1.44)  Batch time: 1.51(1.45)
2025-09-03 20:27:16,746   INFO  Train:    8/20 ( 40%) [ 865/3862 ( 22%)]  Loss: 1.554 (1.61)  LR: 9.793e-04  Grad: 18.1856  max=1.1571(module.vfe.pfn_layers.0.linear.weight)  min: -0.5796(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5458, loss_cls=0.0970, loss_bbox=0.6164, matched_ious=0.5323, loss_iou=0.0923, loss_iou_reg=0.2218, d_time=0.00(0.01), f_time=1.44(1.44), b_time=1.45(1.45)  Time cost: 20:56/1:12:29 [11:11:27/19:53:20]  Acc_iter 27900       Data time: 0.00(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.45)
2025-09-03 20:28:31,642   INFO  Train:    8/20 ( 40%) [ 915/3862 ( 24%)]  Loss: 1.403 (1.61)  LR: 9.799e-04  Grad: 18.2741  max=1.4298(module.vfe.pfn_layers.0.linear.weight)  min: -0.5836(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5508, loss_cls=0.0957, loss_bbox=0.6202, matched_ious=0.5319, loss_iou=0.0912, loss_iou_reg=0.2230, d_time=0.02(0.01), f_time=1.45(1.44), b_time=1.46(1.45)  Time cost: 22:11/1:11:24 [11:12:42/19:54:14]  Acc_iter 27950       Data time: 0.02(0.01)  Forward time: 1.45(1.44)  Batch time: 1.46(1.45)
2025-09-03 20:29:44,476   INFO  Train:    8/20 ( 40%) [ 965/3862 ( 25%)]  Loss: 1.683 (1.61)  LR: 9.806e-04  Grad: 18.5364  max=1.9013(module.vfe.pfn_layers.0.linear.weight)  min: -1.8499(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5769, loss_cls=0.0984, loss_bbox=0.6302, matched_ious=0.5282, loss_iou=0.0923, loss_iou_reg=0.2228, d_time=0.01(0.01), f_time=1.51(1.44), b_time=1.52(1.45)  Time cost: 23:24/1:10:11 [11:13:55/19:53:09]  Acc_iter 28000       Data time: 0.01(0.01)  Forward time: 1.51(1.44)  Batch time: 1.52(1.45)
2025-09-03 20:30:55,480   INFO  Train:    8/20 ( 40%) [1015/3862 ( 26%)]  Loss: 1.344 (1.61)  LR: 9.813e-04  Grad: 18.3599  max=0.5749(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6957(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5616, loss_cls=0.0974, loss_bbox=0.6160, matched_ious=0.5342, loss_iou=0.0900, loss_iou_reg=0.2200, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.43(1.45)  Time cost: 24:35/1:08:54 [11:15:06/19:50:35]  Acc_iter 28050       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.43(1.45)
2025-09-03 20:32:07,482   INFO  Train:    8/20 ( 40%) [1065/3862 ( 28%)]  Loss: 1.476 (1.61)  LR: 9.819e-04  Grad: 18.4459  max=0.5788(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5939(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5443, loss_cls=0.0956, loss_bbox=0.6205, matched_ious=0.5329, loss_iou=0.0923, loss_iou_reg=0.2217, d_time=0.00(0.01), f_time=1.49(1.44), b_time=1.49(1.45)  Time cost: 25:47/1:07:40 [11:16:18/19:48:54]  Acc_iter 28100       Data time: 0.00(0.01)  Forward time: 1.49(1.44)  Batch time: 1.49(1.45)
2025-09-03 20:33:18,445   INFO  Train:    8/20 ( 40%) [1115/3862 ( 29%)]  Loss: 1.389 (1.60)  LR: 9.826e-04  Grad: 18.4977  max=0.5770(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5970(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5446, loss_cls=0.0940, loss_bbox=0.5970, matched_ious=0.5334, loss_iou=0.0908, loss_iou_reg=0.2205, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 26:58/1:06:23 [11:17:29/19:46:31]  Acc_iter 28150       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-03 20:34:33,824   INFO  Train:    8/20 ( 40%) [1165/3862 ( 30%)]  Loss: 1.344 (1.61)  LR: 9.832e-04  Grad: 18.5614  max=0.5763(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5975(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5831, loss_cls=0.0973, loss_bbox=0.6598, matched_ious=0.5279, loss_iou=0.0928, loss_iou_reg=0.2229, d_time=0.01(0.01), f_time=1.47(1.44), b_time=1.48(1.45)  Time cost: 28:13/1:05:17 [11:18:44/19:47:19]  Acc_iter 28200       Data time: 0.01(0.01)  Forward time: 1.47(1.44)  Batch time: 1.48(1.45)
2025-09-03 20:35:46,206   INFO  Train:    8/20 ( 40%) [1215/3862 ( 31%)]  Loss: 1.716 (1.61)  LR: 9.838e-04  Grad: 18.6371  max=0.5821(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5981(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5430, loss_cls=0.0952, loss_bbox=0.6085, matched_ious=0.5334, loss_iou=0.0915, loss_iou_reg=0.2218, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.44(1.45)  Time cost: 29:26/1:04:04 [11:19:57/19:45:56]  Acc_iter 28250       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.44(1.45)
2025-09-03 20:36:56,530   INFO  Train:    8/20 ( 40%) [1265/3862 ( 33%)]  Loss: 1.484 (1.60)  LR: 9.844e-04  Grad: 18.6935  max=0.5826(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.5970(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5527, loss_cls=0.0960, loss_bbox=0.6027, matched_ious=0.5306, loss_iou=0.0930, loss_iou_reg=0.2232, d_time=0.01(0.01), f_time=1.37(1.44), b_time=1.38(1.45)  Time cost: 30:36/1:02:47 [11:21:07/19:43:14]  Acc_iter 28300       Data time: 0.01(0.01)  Forward time: 1.37(1.44)  Batch time: 1.38(1.45)
2025-09-03 20:38:08,882   INFO  Train:    8/20 ( 40%) [1315/3862 ( 34%)]  Loss: 1.481 (1.60)  LR: 9.850e-04  Grad: 18.8334  max=0.5841(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.7411(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5575, loss_cls=0.0972, loss_bbox=0.6104, matched_ious=0.5355, loss_iou=0.0912, loss_iou_reg=0.2208, d_time=0.01(0.01), f_time=1.46(1.44), b_time=1.47(1.45)  Time cost: 31:48/1:01:34 [11:22:20/19:41:55]  Acc_iter 28350       Data time: 0.01(0.01)  Forward time: 1.46(1.44)  Batch time: 1.47(1.45)
2025-09-03 20:39:19,910   INFO  Train:    8/20 ( 40%) [1365/3862 ( 35%)]  Loss: 1.668 (1.60)  LR: 9.856e-04  Grad: 18.8283  max=0.5866(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8334(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5767, loss_cls=0.1008, loss_bbox=0.6408, matched_ious=0.5272, loss_iou=0.0911, loss_iou_reg=0.2240, d_time=0.01(0.01), f_time=1.39(1.44), b_time=1.40(1.45)  Time cost: 32:59/1:00:19 [11:23:31/19:39:49]  Acc_iter 28400       Data time: 0.01(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.45)
2025-09-03 20:40:36,918   INFO  Train:    8/20 ( 40%) [1415/3862 ( 37%)]  Loss: 1.729 (1.60)  LR: 9.861e-04  Grad: 18.9107  max=0.5844(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6078(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5552, loss_cls=0.0948, loss_bbox=0.6114, matched_ious=0.5327, loss_iou=0.0926, loss_iou_reg=0.2222, d_time=0.01(0.01), f_time=2.31(1.44), b_time=2.32(1.45)  Time cost: 34:16/59:14 [11:24:48/19:41:13]  Acc_iter 28450       Data time: 0.01(0.01)  Forward time: 2.31(1.44)  Batch time: 2.32(1.45)
2025-09-03 20:41:48,498   INFO  Train:    8/20 ( 40%) [1465/3862 ( 38%)]  Loss: 1.436 (1.60)  LR: 9.867e-04  Grad: 21.0214  max=2.3026(module.vfe.pfn_layers.0.linear.weight)  min: -7.8140(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5598, loss_cls=0.0966, loss_bbox=0.6060, matched_ious=0.5360, loss_iou=0.0908, loss_iou_reg=0.2202, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 35:28/58:00 [11:25:59/19:39:26]  Acc_iter 28500       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-03 20:43:00,961   INFO  Train:    8/20 ( 40%) [1515/3862 ( 39%)]  Loss: 1.610 (1.60)  LR: 9.872e-04  Grad: 19.0409  max=0.5942(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6090(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5672, loss_cls=0.0998, loss_bbox=0.6261, matched_ious=0.5289, loss_iou=0.0916, loss_iou_reg=0.2226, d_time=0.00(0.01), f_time=1.54(1.44), b_time=1.54(1.45)  Time cost: 36:40/56:47 [11:27:12/19:38:09]  Acc_iter 28550       Data time: 0.00(0.01)  Forward time: 1.54(1.44)  Batch time: 1.54(1.45)
2025-09-03 20:44:12,425   INFO  Train:    8/20 ( 40%) [1565/3862 ( 41%)]  Loss: 1.979 (1.60)  LR: 9.878e-04  Grad: 19.1786  max=0.5929(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.7140(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5717, loss_cls=0.0997, loss_bbox=0.6363, matched_ious=0.5319, loss_iou=0.0910, loss_iou_reg=0.2210, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 37:52/55:33 [11:28:23/19:36:21]  Acc_iter 28600       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-03 20:45:23,368   INFO  Train:    8/20 ( 40%) [1615/3862 ( 42%)]  Loss: 1.401 (1.60)  LR: 9.883e-04  Grad: 19.1588  max=0.6019(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6177(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5598, loss_cls=0.0981, loss_bbox=0.6491, matched_ious=0.5327, loss_iou=0.0912, loss_iou_reg=0.2203, d_time=0.01(0.01), f_time=1.47(1.44), b_time=1.48(1.45)  Time cost: 39:03/54:18 [11:29:34/19:34:20]  Acc_iter 28650       Data time: 0.01(0.01)  Forward time: 1.47(1.44)  Batch time: 1.48(1.45)
2025-09-03 20:46:40,004   INFO  Train:    8/20 ( 40%) [1665/3862 ( 43%)]  Loss: 1.659 (1.60)  LR: 9.888e-04  Grad: 19.2438  max=0.6040(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6197(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5488, loss_cls=0.0946, loss_bbox=0.6200, matched_ious=0.5382, loss_iou=0.0901, loss_iou_reg=0.2197, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 40:19/53:11 [11:30:51/19:35:08]  Acc_iter 28700       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-03 20:47:51,064   INFO  Train:    8/20 ( 40%) [1715/3862 ( 44%)]  Loss: 1.950 (1.60)  LR: 9.893e-04  Grad: 19.3022  max=0.6045(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6230(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5418, loss_cls=0.0916, loss_bbox=0.6156, matched_ious=0.5318, loss_iou=0.0916, loss_iou_reg=0.2219, d_time=0.01(0.01), f_time=1.36(1.44), b_time=1.37(1.45)  Time cost: 41:31/51:56 [11:32:02/19:33:11]  Acc_iter 28750       Data time: 0.01(0.01)  Forward time: 1.36(1.44)  Batch time: 1.37(1.45)
2025-09-03 20:49:03,979   INFO  Train:    8/20 ( 40%) [1765/3862 ( 46%)]  Loss: 1.875 (1.60)  LR: 9.898e-04  Grad: 19.3770  max=0.6047(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9844(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5585, loss_cls=0.0967, loss_bbox=0.6381, matched_ious=0.5261, loss_iou=0.0918, loss_iou_reg=0.2261, d_time=0.01(0.01), f_time=1.56(1.44), b_time=1.57(1.45)  Time cost: 42:43/50:44 [11:33:15/19:32:08]  Acc_iter 28800       Data time: 0.01(0.01)  Forward time: 1.56(1.44)  Batch time: 1.57(1.45)
2025-09-03 20:50:15,048   INFO  Train:    8/20 ( 40%) [1815/3862 ( 47%)]  Loss: 1.342 (1.60)  LR: 9.903e-04  Grad: 19.4218  max=0.6102(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6255(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5341, loss_cls=0.0925, loss_bbox=0.6025, matched_ious=0.5372, loss_iou=0.0908, loss_iou_reg=0.2190, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 43:55/49:30 [11:34:26/19:30:15]  Acc_iter 28850       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-03 20:51:26,577   INFO  Train:    8/20 ( 40%) [1865/3862 ( 48%)]  Loss: 1.567 (1.60)  LR: 9.908e-04  Grad: 19.5473  max=1.3547(module.vfe.pfn_layers.0.linear.weight)  min: -1.0182(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5783, loss_cls=0.0986, loss_bbox=0.6196, matched_ious=0.5335, loss_iou=0.0917, loss_iou_reg=0.2206, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 45:06/48:16 [11:35:37/19:28:36]  Acc_iter 28900       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-03 20:52:43,092   INFO  Train:    8/20 ( 40%) [1915/3862 ( 50%)]  Loss: 1.812 (1.60)  LR: 9.912e-04  Grad: 19.5732  max=0.6163(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6303(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5411, loss_cls=0.0933, loss_bbox=0.6015, matched_ious=0.5348, loss_iou=0.0914, loss_iou_reg=0.2207, d_time=0.01(0.01), f_time=1.50(1.44), b_time=1.50(1.45)  Time cost: 46:23/47:08 [11:36:54/19:29:04]  Acc_iter 28950       Data time: 0.01(0.01)  Forward time: 1.50(1.44)  Batch time: 1.50(1.45)
2025-09-03 20:53:53,568   INFO  Train:    8/20 ( 40%) [1965/3862 ( 51%)]  Loss: 1.694 (1.60)  LR: 9.917e-04  Grad: 19.6599  max=0.6156(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6332(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5362, loss_cls=0.0947, loss_bbox=0.6037, matched_ious=0.5359, loss_iou=0.0915, loss_iou_reg=0.2213, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 47:33/45:53 [11:38:04/19:26:58]  Acc_iter 29000       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-03 20:55:06,064   INFO  Train:    8/20 ( 40%) [2015/3862 ( 52%)]  Loss: 1.677 (1.60)  LR: 9.921e-04  Grad: 19.7229  max=0.6186(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6347(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5553, loss_cls=0.0973, loss_bbox=0.6058, matched_ious=0.5306, loss_iou=0.0924, loss_iou_reg=0.2217, d_time=0.01(0.01), f_time=1.36(1.44), b_time=1.36(1.45)  Time cost: 48:46/44:40 [11:39:17/19:25:44]  Acc_iter 29050       Data time: 0.01(0.01)  Forward time: 1.36(1.44)  Batch time: 1.36(1.45)
2025-09-03 20:56:17,518   INFO  Train:    8/20 ( 40%) [2065/3862 ( 53%)]  Loss: 1.604 (1.60)  LR: 9.925e-04  Grad: 19.8189  max=0.9940(module.vfe.pfn_layers.0.linear.weight)  min: -0.6362(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5586, loss_cls=0.0971, loss_bbox=0.6113, matched_ious=0.5310, loss_iou=0.0920, loss_iou_reg=0.2224, d_time=0.01(0.01), f_time=1.39(1.44), b_time=1.39(1.45)  Time cost: 49:57/43:27 [11:40:28/19:24:05]  Acc_iter 29100       Data time: 0.01(0.01)  Forward time: 1.39(1.44)  Batch time: 1.39(1.45)
2025-09-03 20:57:29,381   INFO  Train:    8/20 ( 40%) [2115/3862 ( 55%)]  Loss: 1.440 (1.60)  LR: 9.929e-04  Grad: 19.8585  max=0.6256(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6403(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5607, loss_cls=0.0989, loss_bbox=0.6216, matched_ious=0.5348, loss_iou=0.0921, loss_iou_reg=0.2202, d_time=0.00(0.01), f_time=1.34(1.44), b_time=1.35(1.45)  Time cost: 51:09/42:14 [11:41:40/19:22:37]  Acc_iter 29150       Data time: 0.00(0.01)  Forward time: 1.34(1.44)  Batch time: 1.35(1.45)
2025-09-03 20:58:45,396   INFO  Train:    8/20 ( 40%) [2165/3862 ( 56%)]  Loss: 1.601 (1.59)  LR: 9.933e-04  Grad: 19.9409  max=0.6216(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6381(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5404, loss_cls=0.0939, loss_bbox=0.5881, matched_ious=0.5357, loss_iou=0.0907, loss_iou_reg=0.2210, d_time=0.01(0.01), f_time=1.33(1.44), b_time=1.33(1.45)  Time cost: 52:25/41:04 [11:42:56/19:22:42]  Acc_iter 29200       Data time: 0.01(0.01)  Forward time: 1.33(1.44)  Batch time: 1.33(1.45)
2025-09-03 20:59:56,451   INFO  Train:    8/20 ( 40%) [2215/3862 ( 57%)]  Loss: 1.359 (1.59)  LR: 9.937e-04  Grad: 20.1023  max=0.6256(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.7340(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5508, loss_cls=0.0970, loss_bbox=0.6302, matched_ious=0.5335, loss_iou=0.0916, loss_iou_reg=0.2200, d_time=0.01(0.01), f_time=1.29(1.44), b_time=1.30(1.45)  Time cost: 53:36/39:50 [11:44:07/19:20:56]  Acc_iter 29250       Data time: 0.01(0.01)  Forward time: 1.29(1.44)  Batch time: 1.30(1.45)
2025-09-03 21:01:08,176   INFO  Train:    8/20 ( 40%) [2265/3862 ( 59%)]  Loss: 1.724 (1.59)  LR: 9.941e-04  Grad: 20.0816  max=0.6311(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9904(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5460, loss_cls=0.0971, loss_bbox=0.6022, matched_ious=0.5355, loss_iou=0.0914, loss_iou_reg=0.2203, d_time=0.01(0.01), f_time=1.39(1.44), b_time=1.40(1.45)  Time cost: 54:48/38:37 [11:45:19/19:19:25]  Acc_iter 29300       Data time: 0.01(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.45)
2025-09-03 21:02:19,259   INFO  Train:    8/20 ( 40%) [2315/3862 ( 60%)]  Loss: 1.517 (1.59)  LR: 9.944e-04  Grad: 20.1846  max=1.0947(module.vfe.pfn_layers.0.linear.weight)  min: -1.2366(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5307, loss_cls=0.0945, loss_bbox=0.6001, matched_ious=0.5347, loss_iou=0.0916, loss_iou_reg=0.2208, d_time=0.00(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 55:59/37:23 [11:46:30/19:17:43]  Acc_iter 29350       Data time: 0.00(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-03 21:03:29,954   INFO  Train:    8/20 ( 40%) [2365/3862 ( 61%)]  Loss: 1.492 (1.59)  LR: 9.948e-04  Grad: 20.2564  max=0.7950(module.vfe.pfn_layers.0.linear.weight)  min: -0.9010(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5439, loss_cls=0.0963, loss_bbox=0.6105, matched_ious=0.5348, loss_iou=0.0910, loss_iou_reg=0.2212, d_time=0.00(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 57:09/36:10 [11:47:41/19:15:53]  Acc_iter 29400       Data time: 0.00(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-03 21:04:45,795   INFO  Train:    8/20 ( 40%) [2415/3862 ( 63%)]  Loss: 1.672 (1.59)  LR: 9.951e-04  Grad: 20.2738  max=0.6442(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6547(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5364, loss_cls=0.0930, loss_bbox=0.6169, matched_ious=0.5335, loss_iou=0.0934, loss_iou_reg=0.2229, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.38(1.45)  Time cost: 58:25/34:59 [11:48:56/19:15:47]  Acc_iter 29450       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.38(1.45)
2025-09-03 21:05:56,578   INFO  Train:    8/20 ( 40%) [2465/3862 ( 64%)]  Loss: 1.423 (1.59)  LR: 9.955e-04  Grad: 20.3333  max=0.6475(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6568(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5467, loss_cls=0.0964, loss_bbox=0.6080, matched_ious=0.5384, loss_iou=0.0906, loss_iou_reg=0.2182, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 59:36/33:46 [11:50:07/19:14:00]  Acc_iter 29500       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-03 21:07:09,115   INFO  Train:    8/20 ( 40%) [2515/3862 ( 65%)]  Loss: 1.693 (1.59)  LR: 9.958e-04  Grad: 20.4177  max=0.6508(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6562(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5564, loss_cls=0.0981, loss_bbox=0.6186, matched_ious=0.5369, loss_iou=0.0902, loss_iou_reg=0.2191, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 1:00:49/32:33 [11:51:20/19:12:48]  Acc_iter 29550       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-03 21:08:20,783   INFO  Train:    8/20 ( 40%) [2565/3862 ( 66%)]  Loss: 1.567 (1.59)  LR: 9.961e-04  Grad: 20.5377  max=0.6521(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.5434(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5449, loss_cls=0.0973, loss_bbox=0.6017, matched_ious=0.5320, loss_iou=0.0919, loss_iou_reg=0.2225, d_time=0.01(0.01), f_time=1.50(1.44), b_time=1.51(1.45)  Time cost: 1:02:00/31:20 [11:52:31/19:11:20]  Acc_iter 29600       Data time: 0.01(0.01)  Forward time: 1.50(1.44)  Batch time: 1.51(1.45)
2025-09-03 21:09:31,428   INFO  Train:    8/20 ( 40%) [2615/3862 ( 68%)]  Loss: 1.706 (1.59)  LR: 9.964e-04  Grad: 20.5577  max=0.6529(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6630(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5299, loss_cls=0.0931, loss_bbox=0.6064, matched_ious=0.5328, loss_iou=0.0899, loss_iou_reg=0.2219, d_time=0.01(0.01), f_time=1.51(1.44), b_time=1.51(1.45)  Time cost: 1:03:11/30:07 [11:53:42/19:09:34]  Acc_iter 29650       Data time: 0.01(0.01)  Forward time: 1.51(1.44)  Batch time: 1.51(1.45)
2025-09-03 21:10:48,257   INFO  Train:    8/20 ( 40%) [2665/3862 ( 69%)]  Loss: 1.697 (1.59)  LR: 9.967e-04  Grad: 20.6391  max=0.6562(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7120(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5510, loss_cls=0.0976, loss_bbox=0.6118, matched_ious=0.5326, loss_iou=0.0929, loss_iou_reg=0.2228, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.42(1.45)  Time cost: 1:04:28/28:56 [11:54:59/19:09:39]  Acc_iter 29700       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.45)
2025-09-03 21:12:00,380   INFO  Train:    8/20 ( 40%) [2715/3862 ( 70%)]  Loss: 1.601 (1.59)  LR: 9.969e-04  Grad: 20.9889  max=2.7087(module.vfe.pfn_layers.0.linear.weight)  min: -2.0718(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5382, loss_cls=0.0929, loss_bbox=0.6040, matched_ious=0.5360, loss_iou=0.0915, loss_iou_reg=0.2207, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.44(1.45)  Time cost: 1:05:40/27:44 [11:56:11/19:08:19]  Acc_iter 29750       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.44(1.45)
2025-09-03 21:13:11,442   INFO  Train:    8/20 ( 40%) [2765/3862 ( 72%)]  Loss: 1.565 (1.59)  LR: 9.972e-04  Grad: 20.7628  max=0.6547(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6699(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5416, loss_cls=0.0952, loss_bbox=0.6054, matched_ious=0.5292, loss_iou=0.0921, loss_iou_reg=0.2250, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 1:06:51/26:30 [11:57:22/19:06:41]  Acc_iter 29800       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-03 21:14:22,410   INFO  Train:    8/20 ( 40%) [2815/3862 ( 73%)]  Loss: 1.511 (1.59)  LR: 9.975e-04  Grad: 20.8319  max=0.8191(module.vfe.pfn_layers.0.linear.weight)  min: -0.6694(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5266, loss_cls=0.0929, loss_bbox=0.5737, matched_ious=0.5436, loss_iou=0.0898, loss_iou_reg=0.2179, d_time=0.00(0.01), f_time=1.47(1.44), b_time=1.48(1.45)  Time cost: 1:08:02/25:17 [11:58:33/19:05:02]  Acc_iter 29850       Data time: 0.00(0.01)  Forward time: 1.47(1.44)  Batch time: 1.48(1.45)
2025-09-03 21:15:33,411   INFO  Train:    8/20 ( 40%) [2865/3862 ( 74%)]  Loss: 1.946 (1.59)  LR: 9.977e-04  Grad: 20.9219  max=0.6631(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8642(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5558, loss_cls=0.0952, loss_bbox=0.6084, matched_ious=0.5347, loss_iou=0.0915, loss_iou_reg=0.2200, d_time=0.01(0.01), f_time=1.36(1.44), b_time=1.37(1.45)  Time cost: 1:09:13/24:04 [11:59:44/19:03:25]  Acc_iter 29900       Data time: 0.01(0.01)  Forward time: 1.36(1.44)  Batch time: 1.37(1.45)
2025-09-03 21:16:50,022   INFO  Train:    8/20 ( 40%) [2915/3862 ( 75%)]  Loss: 1.564 (1.58)  LR: 9.979e-04  Grad: 20.9770  max=0.6650(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6720(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5414, loss_cls=0.0962, loss_bbox=0.5813, matched_ious=0.5403, loss_iou=0.0883, loss_iou_reg=0.2184, d_time=0.00(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 1:10:29/22:53 [12:01:01/19:03:20]  Acc_iter 29950       Data time: 0.00(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-03 21:18:02,472   INFO  Train:    8/20 ( 40%) [2965/3862 ( 77%)]  Loss: 1.604 (1.58)  LR: 9.981e-04  Grad: 21.2699  max=2.3117(module.vfe.pfn_layers.0.linear.weight)  min: -0.7082(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5257, loss_cls=0.0904, loss_bbox=0.6075, matched_ious=0.5344, loss_iou=0.0916, loss_iou_reg=0.2198, d_time=0.00(0.01), f_time=1.41(1.44), b_time=1.41(1.45)  Time cost: 1:11:42/21:41 [12:02:13/19:02:07]  Acc_iter 30000       Data time: 0.00(0.01)  Forward time: 1.41(1.44)  Batch time: 1.41(1.45)
2025-09-03 21:19:13,273   INFO  Train:    8/20 ( 40%) [3015/3862 ( 78%)]  Loss: 1.404 (1.58)  LR: 9.983e-04  Grad: 21.0666  max=0.6686(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6793(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5458, loss_cls=0.0943, loss_bbox=0.6155, matched_ious=0.5373, loss_iou=0.0912, loss_iou_reg=0.2187, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 1:12:53/20:28 [12:03:24/19:00:27]  Acc_iter 30050       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-03 21:20:24,759   INFO  Train:    8/20 ( 40%) [3065/3862 ( 79%)]  Loss: 1.286 (1.58)  LR: 9.985e-04  Grad: 21.1387  max=0.6719(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6814(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5340, loss_cls=0.0930, loss_bbox=0.6166, matched_ious=0.5431, loss_iou=0.0896, loss_iou_reg=0.2162, d_time=0.01(0.01), f_time=1.36(1.44), b_time=1.36(1.45)  Time cost: 1:14:04/19:15 [12:04:35/18:58:59]  Acc_iter 30100       Data time: 0.01(0.01)  Forward time: 1.36(1.44)  Batch time: 1.36(1.45)
2025-09-03 21:21:36,185   INFO  Train:    8/20 ( 40%) [3115/3862 ( 81%)]  Loss: 1.798 (1.58)  LR: 9.987e-04  Grad: 21.2778  max=0.6715(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.5001(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5488, loss_cls=0.0939, loss_bbox=0.6288, matched_ious=0.5345, loss_iou=0.0915, loss_iou_reg=0.2207, d_time=0.40(0.01), f_time=1.45(1.44), b_time=1.84(1.45)  Time cost: 1:15:16/18:02 [12:05:47/18:57:30]  Acc_iter 30150       Data time: 0.40(0.01)  Forward time: 1.45(1.44)  Batch time: 1.84(1.45)
2025-09-03 21:22:51,870   INFO  Train:    8/20 ( 40%) [3165/3862 ( 82%)]  Loss: 1.839 (1.58)  LR: 9.989e-04  Grad: 21.2738  max=0.7777(module.vfe.pfn_layers.0.linear.weight)  min: -0.6815(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5257, loss_cls=0.0927, loss_bbox=0.5997, matched_ious=0.5379, loss_iou=0.0914, loss_iou_reg=0.2212, d_time=0.01(0.01), f_time=1.48(1.44), b_time=1.48(1.45)  Time cost: 1:16:31/16:50 [12:07:02/18:57:06]  Acc_iter 30200       Data time: 0.01(0.01)  Forward time: 1.48(1.44)  Batch time: 1.48(1.45)
2025-09-03 21:24:04,343   INFO  Train:    8/20 ( 40%) [3215/3862 ( 83%)]  Loss: 1.333 (1.58)  LR: 9.990e-04  Grad: 21.3491  max=0.6795(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6818(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5414, loss_cls=0.0946, loss_bbox=0.6161, matched_ious=0.5276, loss_iou=0.0920, loss_iou_reg=0.2240, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.45(1.45)  Time cost: 1:17:44/15:38 [12:08:15/18:55:53]  Acc_iter 30250       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.45)
2025-09-03 21:25:15,532   INFO  Train:    8/20 ( 40%) [3265/3862 ( 85%)]  Loss: 1.598 (1.58)  LR: 9.992e-04  Grad: 21.4625  max=1.2518(module.vfe.pfn_layers.0.linear.weight)  min: -0.6856(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5428, loss_cls=0.0946, loss_bbox=0.6020, matched_ious=0.5379, loss_iou=0.0920, loss_iou_reg=0.2191, d_time=0.00(0.01), f_time=1.36(1.44), b_time=1.36(1.45)  Time cost: 1:18:55/14:25 [12:09:26/18:54:21]  Acc_iter 30300       Data time: 0.00(0.01)  Forward time: 1.36(1.44)  Batch time: 1.36(1.45)
2025-09-03 21:26:26,998   INFO  Train:    8/20 ( 40%) [3315/3862 ( 86%)]  Loss: 1.447 (1.58)  LR: 9.993e-04  Grad: 21.4837  max=0.6865(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6886(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5139, loss_cls=0.0910, loss_bbox=0.5638, matched_ious=0.5444, loss_iou=0.0907, loss_iou_reg=0.2181, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.43(1.45)  Time cost: 1:20:06/13:12 [12:10:38/18:52:54]  Acc_iter 30350       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.43(1.45)
2025-09-03 21:27:38,112   INFO  Train:    8/20 ( 40%) [3365/3862 ( 87%)]  Loss: 1.579 (1.58)  LR: 9.994e-04  Grad: 21.5851  max=1.0888(module.vfe.pfn_layers.0.linear.weight)  min: -0.6894(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5249, loss_cls=0.0920, loss_bbox=0.5745, matched_ious=0.5371, loss_iou=0.0912, loss_iou_reg=0.2191, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 1:21:18/12:00 [12:11:49/18:51:22]  Acc_iter 30400       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-03 21:28:53,220   INFO  Train:    8/20 ( 40%) [3415/3862 ( 88%)]  Loss: 1.470 (1.58)  LR: 9.995e-04  Grad: 21.6202  max=1.0439(module.vfe.pfn_layers.0.linear.weight)  min: -0.6911(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5405, loss_cls=0.0922, loss_bbox=0.5980, matched_ious=0.5441, loss_iou=0.0908, loss_iou_reg=0.2170, d_time=0.00(0.01), f_time=1.46(1.44), b_time=1.47(1.45)  Time cost: 1:22:33/10:48 [12:13:04/18:50:46]  Acc_iter 30450       Data time: 0.00(0.01)  Forward time: 1.46(1.44)  Batch time: 1.47(1.45)
2025-09-03 21:30:06,302   INFO  Train:    8/20 ( 40%) [3465/3862 ( 90%)]  Loss: 1.590 (1.58)  LR: 9.996e-04  Grad: 21.6910  max=0.6952(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6937(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5509, loss_cls=0.0936, loss_bbox=0.6167, matched_ious=0.5363, loss_iou=0.0920, loss_iou_reg=0.2193, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 1:23:46/09:35 [12:14:17/18:49:42]  Acc_iter 30500       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-03 21:31:17,147   INFO  Train:    8/20 ( 40%) [3515/3862 ( 91%)]  Loss: 1.594 (1.58)  LR: 9.997e-04  Grad: 21.4181  max=0.6854(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6832(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5430, loss_cls=0.0956, loss_bbox=0.6092, matched_ious=0.5392, loss_iou=0.0903, loss_iou_reg=0.2187, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 1:24:57/08:23 [12:15:28/18:48:07]  Acc_iter 30550       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-03 21:32:28,573   INFO  Train:    8/20 ( 40%) [3565/3862 ( 92%)]  Loss: 1.640 (1.58)  LR: 9.998e-04  Grad: 21.4640  max=0.6878(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6827(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5552, loss_cls=0.0962, loss_bbox=0.6142, matched_ious=0.5355, loss_iou=0.0913, loss_iou_reg=0.2205, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.42(1.45)  Time cost: 1:26:08/07:10 [12:16:39/18:46:41]  Acc_iter 30600       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.45)
2025-09-03 21:33:40,817   INFO  Train:    8/20 ( 40%) [3615/3862 ( 94%)]  Loss: 1.235 (1.58)  LR: 9.999e-04  Grad: 21.5204  max=0.6893(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6900(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5317, loss_cls=0.0924, loss_bbox=0.6076, matched_ious=0.5344, loss_iou=0.0910, loss_iou_reg=0.2217, d_time=0.00(0.01), f_time=1.33(1.44), b_time=1.33(1.45)  Time cost: 1:27:20/05:57 [12:17:51/18:45:25]  Acc_iter 30650       Data time: 0.00(0.01)  Forward time: 1.33(1.44)  Batch time: 1.33(1.45)
2025-09-03 21:34:56,256   INFO  Train:    8/20 ( 40%) [3665/3862 ( 95%)]  Loss: 1.546 (1.58)  LR: 9.999e-04  Grad: 21.6607  max=1.6292(module.vfe.pfn_layers.0.linear.weight)  min: -0.6914(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5330, loss_cls=0.0927, loss_bbox=0.6076, matched_ious=0.5392, loss_iou=0.0904, loss_iou_reg=0.2190, d_time=0.01(0.01), f_time=1.45(1.44), b_time=1.46(1.45)  Time cost: 1:28:36/04:45 [12:19:07/18:44:50]  Acc_iter 30700       Data time: 0.01(0.01)  Forward time: 1.45(1.44)  Batch time: 1.46(1.45)
2025-09-03 21:36:08,031   INFO  Train:    8/20 ( 40%) [3715/3862 ( 96%)]  Loss: 1.375 (1.58)  LR: 9.999e-04  Grad: 21.6813  max=0.6943(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7147(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5378, loss_cls=0.0948, loss_bbox=0.6056, matched_ious=0.5423, loss_iou=0.0913, loss_iou_reg=0.2181, d_time=0.00(0.01), f_time=1.39(1.44), b_time=1.39(1.45)  Time cost: 1:29:47/03:33 [12:20:19/18:43:29]  Acc_iter 30750       Data time: 0.00(0.01)  Forward time: 1.39(1.44)  Batch time: 1.39(1.45)
2025-09-03 21:37:19,594   INFO  Train:    8/20 ( 40%) [3765/3862 ( 97%)]  Loss: 1.439 (1.58)  LR: 1.000e-03  Grad: 21.7505  max=0.7000(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0501(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5308, loss_cls=0.0909, loss_bbox=0.6010, matched_ious=0.5429, loss_iou=0.0910, loss_iou_reg=0.2172, d_time=0.00(0.01), f_time=1.52(1.44), b_time=1.53(1.45)  Time cost: 1:30:59/02:20 [12:21:30/18:42:05]  Acc_iter 30800       Data time: 0.00(0.01)  Forward time: 1.52(1.44)  Batch time: 1.53(1.45)
2025-09-03 21:38:30,495   INFO  Train:    8/20 ( 40%) [3815/3862 ( 99%)]  Loss: 1.733 (1.57)  LR: 1.000e-03  Grad: 21.7891  max=0.6964(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6998(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5297, loss_cls=0.0915, loss_bbox=0.5793, matched_ious=0.5392, loss_iou=0.0921, loss_iou_reg=0.2211, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 1:32:10/01:08 [12:22:41/18:40:33]  Acc_iter 30850       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-03 21:39:35,586   INFO  Train:    8/20 ( 40%) [3861/3862 (100%)]  Loss: 1.563 (1.57)  LR: 1.000e-03  Grad: 22.1557  max=3.1193(module.vfe.pfn_layers.0.linear.weight)  min: -1.8523(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5306, loss_cls=0.0950, loss_bbox=0.5998, matched_ious=0.5330, loss_iou=0.0900, loss_iou_reg=0.2218, d_time=0.00(0.01), f_time=1.29(1.44), b_time=1.30(1.45)  Time cost: 1:33:15/00:01 [12:23:46/18:39:08]  Acc_iter 30896       Data time: 0.00(0.01)  Forward time: 1.29(1.44)  Batch time: 1.30(1.45)

                                               [Aepochs:  40%|████      | 8/20 [12:23:46<18:37:49, 5589.11s/it]epochs:  40%|████      | 8/20 [12:23:47<18:37:49, 5589.12s/it]epochs:  40%|████      | 8/20 [12:23:47<18:37:49, 5589.11s/it]epochs:  40%|████      | 8/20 [12:23:47<18:37:49, 5589.11s/it]epochs:  40%|████      | 8/20 [12:23:47<18:37:49, 5589.11s/it]epochs:  40%|████      | 8/20 [12:23:47<18:37:49, 5589.12s/it]epochs:  40%|████      | 8/20 [12:23:47<18:37:49, 5589.13s/it]epochs:  40%|████      | 8/20 [12:23:47<18:37:49, 5589.12s/it]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-03 21:39:41,866   INFO  Train:    9/20 ( 45%) [   0/3862 (  0%)]  Loss: 1.677 (1.68)  LR: 1.000e-03  Grad: 21.8482  max=0.6998(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6982(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5447, loss_cls=0.0965, loss_bbox=0.6949, matched_ious=0.5029, loss_iou=0.1084, loss_iou_reg=0.2321, d_time=2.04(2.04), f_time=2.96(2.96), b_time=5.00(5.00)  Time cost: 00:04/5:10:17 [12:23:52/62:03:31]  Acc_iter 30897       Data time: 2.04(2.04)  Forward time: 2.96(2.96)  Batch time: 5.00(5.00)
2025-09-03 21:39:46,304   INFO  Train:    9/20 ( 45%) [   3/3862 (  0%)]  Loss: 1.926 (1.70)  LR: 1.000e-03  Grad: 21.8698  max=0.6964(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6980(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5356, loss_cls=0.0905, loss_bbox=0.7781, matched_ious=0.5457, loss_iou=0.0882, loss_iou_reg=0.2110, d_time=0.01(0.52), f_time=1.39(1.84), b_time=1.39(2.36)  Time cost: 00:09/2:28:52 [12:23:57/29:47:45]  Acc_iter 30900       Data time: 0.01(0.52)  Forward time: 1.39(1.84)  Batch time: 1.39(2.36)
2025-09-03 21:41:02,443   INFO  Train:    9/20 ( 45%) [  53/3862 (  1%)]  Loss: 1.668 (1.58)  LR: 1.000e-03  Grad: 21.9357  max=0.7011(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6996(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5549, loss_cls=0.0950, loss_bbox=0.6147, matched_ious=0.5387, loss_iou=0.0902, loss_iou_reg=0.2183, d_time=0.00(0.05), f_time=1.43(1.54), b_time=1.43(1.58)  Time cost: 01:25/1:40:23 [12:25:13/20:20:05]  Acc_iter 30950       Data time: 0.00(0.05)  Forward time: 1.43(1.54)  Batch time: 1.43(1.58)
2025-09-03 21:42:14,270   INFO  Train:    9/20 ( 45%) [ 103/3862 (  3%)]  Loss: 1.721 (1.58)  LR: 1.000e-03  Grad: 22.3748  max=0.9737(module.vfe.pfn_layers.0.linear.weight)  min: -3.4157(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5398, loss_cls=0.0928, loss_bbox=0.6270, matched_ious=0.5346, loss_iou=0.0906, loss_iou_reg=0.2216, d_time=0.01(0.03), f_time=1.43(1.49), b_time=1.44(1.51)  Time cost: 02:37/1:34:42 [12:26:25/19:25:06]  Acc_iter 31000       Data time: 0.01(0.03)  Forward time: 1.43(1.49)  Batch time: 1.44(1.51)
2025-09-03 21:43:25,709   INFO  Train:    9/20 ( 45%) [ 153/3862 (  4%)]  Loss: 1.570 (1.56)  LR: 1.000e-03  Grad: 22.0416  max=0.7084(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7069(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5254, loss_cls=0.0915, loss_bbox=0.6117, matched_ious=0.5367, loss_iou=0.0921, loss_iou_reg=0.2187, d_time=0.00(0.02), f_time=1.41(1.47), b_time=1.42(1.49)  Time cost: 03:48/1:31:47 [12:27:36/19:03:05]  Acc_iter 31050       Data time: 0.00(0.02)  Forward time: 1.41(1.47)  Batch time: 1.42(1.49)
2025-09-03 21:44:36,089   INFO  Train:    9/20 ( 45%) [ 203/3862 (  5%)]  Loss: 1.757 (1.56)  LR: 1.000e-03  Grad: 22.1258  max=0.7091(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7109(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5422, loss_cls=0.0934, loss_bbox=0.6037, matched_ious=0.5426, loss_iou=0.0893, loss_iou_reg=0.2162, d_time=0.00(0.02), f_time=1.42(1.45), b_time=1.43(1.47)  Time cost: 04:59/1:29:23 [12:28:47/18:47:18]  Acc_iter 31100       Data time: 0.00(0.02)  Forward time: 1.42(1.45)  Batch time: 1.43(1.47)
2025-09-03 21:45:49,091   INFO  Train:    9/20 ( 45%) [ 253/3862 (  7%)]  Loss: 1.649 (1.56)  LR: 9.999e-04  Grad: 22.1627  max=0.7083(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7117(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5443, loss_cls=0.0937, loss_bbox=0.6177, matched_ious=0.5378, loss_iou=0.0907, loss_iou_reg=0.2197, d_time=0.37(0.02), f_time=1.39(1.45), b_time=1.76(1.47)  Time cost: 06:12/1:28:06 [12:30:00/18:45:11]  Acc_iter 31150       Data time: 0.37(0.02)  Forward time: 1.39(1.45)  Batch time: 1.76(1.47)
2025-09-03 21:47:04,666   INFO  Train:    9/20 ( 45%) [ 303/3862 (  8%)]  Loss: 1.312 (1.56)  LR: 9.999e-04  Grad: 22.2265  max=0.7524(module.vfe.pfn_layers.0.linear.weight)  min: -0.7134(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5322, loss_cls=0.0939, loss_bbox=0.6018, matched_ious=0.5406, loss_iou=0.0903, loss_iou_reg=0.2178, d_time=0.00(0.02), f_time=1.39(1.46), b_time=1.40(1.47)  Time cost: 07:27/1:27:20 [12:31:15/18:49:52]  Acc_iter 31200       Data time: 0.00(0.02)  Forward time: 1.39(1.46)  Batch time: 1.40(1.47)
2025-09-03 21:48:16,463   INFO  Train:    9/20 ( 45%) [ 353/3862 (  9%)]  Loss: 1.409 (1.55)  LR: 9.999e-04  Grad: 22.2767  max=0.7092(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7137(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5386, loss_cls=0.0946, loss_bbox=0.5825, matched_ious=0.5444, loss_iou=0.0901, loss_iou_reg=0.2167, d_time=0.01(0.01), f_time=1.44(1.45), b_time=1.45(1.47)  Time cost: 08:39/1:25:48 [12:32:27/18:44:41]  Acc_iter 31250       Data time: 0.01(0.01)  Forward time: 1.44(1.45)  Batch time: 1.45(1.47)
2025-09-03 21:49:27,863   INFO  Train:    9/20 ( 45%) [ 403/3862 ( 10%)]  Loss: 1.999 (1.55)  LR: 9.998e-04  Grad: 22.4544  max=0.7124(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.9963(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5346, loss_cls=0.0924, loss_bbox=0.5850, matched_ious=0.5394, loss_iou=0.0914, loss_iou_reg=0.2192, d_time=0.00(0.01), f_time=1.41(1.45), b_time=1.42(1.46)  Time cost: 09:50/1:24:18 [12:33:38/18:39:44]  Acc_iter 31300       Data time: 0.00(0.01)  Forward time: 1.41(1.45)  Batch time: 1.42(1.46)
2025-09-03 21:50:39,018   INFO  Train:    9/20 ( 45%) [ 453/3862 ( 12%)]  Loss: 1.483 (1.55)  LR: 9.998e-04  Grad: 22.4688  max=0.7141(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3369(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5314, loss_cls=0.0927, loss_bbox=0.5850, matched_ious=0.5381, loss_iou=0.0907, loss_iou_reg=0.2189, d_time=0.00(0.01), f_time=1.43(1.45), b_time=1.44(1.46)  Time cost: 11:01/1:22:50 [12:34:50/18:35:13]  Acc_iter 31350       Data time: 0.00(0.01)  Forward time: 1.43(1.45)  Batch time: 1.44(1.46)
2025-09-03 21:51:52,860   INFO  Train:    9/20 ( 45%) [ 503/3862 ( 13%)]  Loss: 1.763 (1.54)  LR: 9.997e-04  Grad: 22.6794  max=0.7208(module.dense_head.decoder.self_attn.in_proj_weight)  min: -3.0975(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5163, loss_cls=0.0902, loss_bbox=0.5934, matched_ious=0.5471, loss_iou=0.0906, loss_iou_reg=0.2159, d_time=0.01(0.01), f_time=1.37(1.45), b_time=1.38(1.46)  Time cost: 12:15/1:21:43 [12:36:03/18:35:25]  Acc_iter 31400       Data time: 0.01(0.01)  Forward time: 1.37(1.45)  Batch time: 1.38(1.46)
2025-09-03 21:53:07,538   INFO  Train:    9/20 ( 45%) [ 553/3862 ( 14%)]  Loss: 1.513 (1.54)  LR: 9.996e-04  Grad: 22.5399  max=0.7189(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7239(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5216, loss_cls=0.0896, loss_bbox=0.5927, matched_ious=0.5486, loss_iou=0.0894, loss_iou_reg=0.2151, d_time=0.00(0.01), f_time=1.47(1.45), b_time=1.47(1.46)  Time cost: 13:30/1:20:41 [12:37:18/18:36:31]  Acc_iter 31450       Data time: 0.00(0.01)  Forward time: 1.47(1.45)  Batch time: 1.47(1.46)
2025-09-03 21:54:19,123   INFO  Train:    9/20 ( 45%) [ 603/3862 ( 16%)]  Loss: 1.496 (1.54)  LR: 9.996e-04  Grad: 22.6135  max=0.7216(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7252(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5508, loss_cls=0.0949, loss_bbox=0.5987, matched_ious=0.5410, loss_iou=0.0905, loss_iou_reg=0.2171, d_time=0.01(0.01), f_time=1.39(1.45), b_time=1.39(1.46)  Time cost: 14:42/1:19:19 [12:38:30/18:33:19]  Acc_iter 31500       Data time: 0.01(0.01)  Forward time: 1.39(1.45)  Batch time: 1.39(1.46)
2025-09-03 21:55:30,918   INFO  Train:    9/20 ( 45%) [ 653/3862 ( 17%)]  Loss: 1.471 (1.54)  LR: 9.995e-04  Grad: 22.6795  max=0.7223(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7228(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5263, loss_cls=0.0917, loss_bbox=0.5816, matched_ious=0.5434, loss_iou=0.0900, loss_iou_reg=0.2172, d_time=0.01(0.01), f_time=1.37(1.45), b_time=1.37(1.46)  Time cost: 15:53/1:18:00 [12:39:42/18:30:40]  Acc_iter 31550       Data time: 0.01(0.01)  Forward time: 1.37(1.45)  Batch time: 1.37(1.46)
2025-09-03 21:56:42,202   INFO  Train:    9/20 ( 45%) [ 703/3862 ( 18%)]  Loss: 1.385 (1.53)  LR: 9.994e-04  Grad: 22.7381  max=0.7248(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7235(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5046, loss_cls=0.0878, loss_bbox=0.5609, matched_ious=0.5482, loss_iou=0.0907, loss_iou_reg=0.2149, d_time=0.01(0.01), f_time=1.46(1.45), b_time=1.47(1.46)  Time cost: 17:05/1:16:40 [12:40:53/18:27:41]  Acc_iter 31600       Data time: 0.01(0.01)  Forward time: 1.46(1.45)  Batch time: 1.47(1.46)
2025-09-03 21:57:58,649   INFO  Train:    9/20 ( 45%) [ 753/3862 ( 19%)]  Loss: 1.351 (1.53)  LR: 9.993e-04  Grad: 22.7871  max=0.7272(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7295(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5176, loss_cls=0.0915, loss_bbox=0.5856, matched_ious=0.5479, loss_iou=0.0894, loss_iou_reg=0.2151, d_time=0.01(0.01), f_time=2.22(1.45), b_time=2.23(1.46)  Time cost: 18:21/1:15:42 [12:42:09/18:30:08]  Acc_iter 31650       Data time: 0.01(0.01)  Forward time: 2.22(1.45)  Batch time: 2.23(1.46)
2025-09-03 21:59:11,234   INFO  Train:    9/20 ( 45%) [ 803/3862 ( 21%)]  Loss: 1.301 (1.53)  LR: 9.993e-04  Grad: 22.8529  max=0.7298(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8148(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5237, loss_cls=0.0906, loss_bbox=0.5678, matched_ious=0.5423, loss_iou=0.0912, loss_iou_reg=0.2186, d_time=0.02(0.01), f_time=1.37(1.45), b_time=1.39(1.46)  Time cost: 19:34/1:14:27 [12:43:22/18:28:29]  Acc_iter 31700       Data time: 0.02(0.01)  Forward time: 1.37(1.45)  Batch time: 1.39(1.46)
2025-09-03 22:00:22,510   INFO  Train:    9/20 ( 45%) [ 853/3862 ( 22%)]  Loss: 1.593 (1.53)  LR: 9.992e-04  Grad: 23.1093  max=0.7320(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.2841(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5176, loss_cls=0.0906, loss_bbox=0.5843, matched_ious=0.5395, loss_iou=0.0915, loss_iou_reg=0.2198, d_time=0.01(0.01), f_time=1.36(1.45), b_time=1.37(1.46)  Time cost: 20:45/1:13:08 [12:44:33/18:25:43]  Acc_iter 31750       Data time: 0.01(0.01)  Forward time: 1.36(1.45)  Batch time: 1.37(1.46)
2025-09-03 22:01:34,032   INFO  Train:    9/20 ( 45%) [ 903/3862 ( 23%)]  Loss: 1.379 (1.52)  LR: 9.991e-04  Grad: 22.9500  max=0.7364(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7316(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5275, loss_cls=0.0921, loss_bbox=0.5662, matched_ious=0.5459, loss_iou=0.0903, loss_iou_reg=0.2167, d_time=0.00(0.01), f_time=1.44(1.45), b_time=1.45(1.46)  Time cost: 21:56/1:11:50 [12:45:45/18:23:20]  Acc_iter 31800       Data time: 0.00(0.01)  Forward time: 1.44(1.45)  Batch time: 1.45(1.46)
2025-09-03 22:02:45,447   INFO  Train:    9/20 ( 45%) [ 953/3862 ( 25%)]  Loss: 1.778 (1.52)  LR: 9.990e-04  Grad: 23.0213  max=0.7411(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7369(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5213, loss_cls=0.0893, loss_bbox=0.5815, matched_ious=0.5373, loss_iou=0.0913, loss_iou_reg=0.2195, d_time=0.01(0.01), f_time=1.42(1.45), b_time=1.43(1.46)  Time cost: 23:08/1:10:33 [12:46:56/18:20:59]  Acc_iter 31850       Data time: 0.01(0.01)  Forward time: 1.42(1.45)  Batch time: 1.43(1.46)
2025-09-03 22:04:01,528   INFO  Train:    9/20 ( 45%) [1003/3862 ( 26%)]  Loss: 1.397 (1.52)  LR: 9.988e-04  Grad: 23.1344  max=0.7421(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1628(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5232, loss_cls=0.0918, loss_bbox=0.5777, matched_ious=0.5432, loss_iou=0.0905, loss_iou_reg=0.2184, d_time=0.01(0.01), f_time=1.52(1.45), b_time=1.53(1.46)  Time cost: 24:24/1:09:30 [12:48:12/18:22:16]  Acc_iter 31900       Data time: 0.01(0.01)  Forward time: 1.52(1.45)  Batch time: 1.53(1.46)
2025-09-03 22:05:14,271   INFO  Train:    9/20 ( 45%) [1053/3862 ( 27%)]  Loss: 1.465 (1.52)  LR: 9.987e-04  Grad: 23.2113  max=0.8970(module.vfe.pfn_layers.0.linear.weight)  min: -0.7370(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5143, loss_cls=0.0912, loss_bbox=0.6155, matched_ious=0.5376, loss_iou=0.0932, loss_iou_reg=0.2211, d_time=0.01(0.01), f_time=1.49(1.45), b_time=1.50(1.46)  Time cost: 25:37/1:08:16 [12:49:25/18:20:55]  Acc_iter 31950       Data time: 0.01(0.01)  Forward time: 1.49(1.45)  Batch time: 1.50(1.46)
2025-09-03 22:06:25,649   INFO  Train:    9/20 ( 45%) [1103/3862 ( 29%)]  Loss: 1.369 (1.52)  LR: 9.986e-04  Grad: 23.2498  max=0.7485(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7387(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5125, loss_cls=0.0889, loss_bbox=0.5864, matched_ious=0.5423, loss_iou=0.0906, loss_iou_reg=0.2189, d_time=0.01(0.01), f_time=1.41(1.45), b_time=1.42(1.46)  Time cost: 26:48/1:07:00 [12:50:36/18:18:39]  Acc_iter 32000       Data time: 0.01(0.01)  Forward time: 1.41(1.45)  Batch time: 1.42(1.46)
2025-09-03 22:07:37,140   INFO  Train:    9/20 ( 45%) [1153/3862 ( 30%)]  Loss: 1.498 (1.52)  LR: 9.985e-04  Grad: 23.3196  max=0.7503(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7412(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5224, loss_cls=0.0899, loss_bbox=0.5828, matched_ious=0.5403, loss_iou=0.0908, loss_iou_reg=0.2183, d_time=0.01(0.01), f_time=1.51(1.45), b_time=1.51(1.46)  Time cost: 28:00/1:05:43 [12:51:48/18:16:32]  Acc_iter 32050       Data time: 0.01(0.01)  Forward time: 1.51(1.45)  Batch time: 1.51(1.46)
2025-09-03 22:08:48,076   INFO  Train:    9/20 ( 45%) [1203/3862 ( 31%)]  Loss: 1.350 (1.52)  LR: 9.983e-04  Grad: 23.3801  max=0.7512(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7429(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5372, loss_cls=0.0937, loss_bbox=0.5877, matched_ious=0.5490, loss_iou=0.0882, loss_iou_reg=0.2140, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 29:11/1:04:27 [12:52:59/18:14:10]  Acc_iter 32100       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-03 22:10:06,649   INFO  Train:    9/20 ( 45%) [1253/3862 ( 32%)]  Loss: 1.649 (1.52)  LR: 9.982e-04  Grad: 23.4520  max=0.7551(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7504(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5408, loss_cls=0.0935, loss_bbox=0.5817, matched_ious=0.5382, loss_iou=0.0936, loss_iou_reg=0.2208, d_time=0.00(0.01), f_time=1.39(1.45), b_time=1.40(1.46)  Time cost: 30:29/1:03:26 [12:54:17/18:16:27]  Acc_iter 32150       Data time: 0.00(0.01)  Forward time: 1.39(1.45)  Batch time: 1.40(1.46)
2025-09-03 22:11:17,349   INFO  Train:    9/20 ( 45%) [1303/3862 ( 34%)]  Loss: 1.655 (1.52)  LR: 9.981e-04  Grad: 23.5291  max=1.0239(module.vfe.pfn_layers.0.linear.weight)  min: -0.7477(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5245, loss_cls=0.0903, loss_bbox=0.5819, matched_ious=0.5515, loss_iou=0.0878, loss_iou_reg=0.2144, d_time=0.01(0.01), f_time=1.31(1.45), b_time=1.31(1.46)  Time cost: 31:40/1:02:09 [12:55:28/18:13:57]  Acc_iter 32200       Data time: 0.01(0.01)  Forward time: 1.31(1.45)  Batch time: 1.31(1.46)
2025-09-03 22:12:28,110   INFO  Train:    9/20 ( 45%) [1353/3862 ( 35%)]  Loss: 1.783 (1.52)  LR: 9.979e-04  Grad: 23.5665  max=0.7611(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7533(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5321, loss_cls=0.0914, loss_bbox=0.5969, matched_ious=0.5370, loss_iou=0.0896, loss_iou_reg=0.2192, d_time=0.01(0.01), f_time=1.41(1.45), b_time=1.41(1.46)  Time cost: 32:51/1:00:52 [12:56:39/18:11:34]  Acc_iter 32250       Data time: 0.01(0.01)  Forward time: 1.41(1.45)  Batch time: 1.41(1.46)
2025-09-03 22:13:39,234   INFO  Train:    9/20 ( 45%) [1403/3862 ( 36%)]  Loss: 1.696 (1.52)  LR: 9.977e-04  Grad: 23.6482  max=0.7611(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7522(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5213, loss_cls=0.0915, loss_bbox=0.5985, matched_ious=0.5437, loss_iou=0.0901, loss_iou_reg=0.2165, d_time=0.02(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 34:02/59:36 [12:57:50/18:09:28]  Acc_iter 32300       Data time: 0.02(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-03 22:14:51,232   INFO  Train:    9/20 ( 45%) [1453/3862 ( 38%)]  Loss: 1.405 (1.52)  LR: 9.976e-04  Grad: 23.6906  max=0.7643(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7532(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5139, loss_cls=0.0902, loss_bbox=0.5866, matched_ious=0.5420, loss_iou=0.0886, loss_iou_reg=0.2184, d_time=0.01(0.01), f_time=1.45(1.44), b_time=1.45(1.45)  Time cost: 35:14/58:22 [12:59:02/18:07:53]  Acc_iter 32350       Data time: 0.01(0.01)  Forward time: 1.45(1.44)  Batch time: 1.45(1.45)
2025-09-03 22:16:08,312   INFO  Train:    9/20 ( 45%) [1503/3862 ( 39%)]  Loss: 1.436 (1.52)  LR: 9.974e-04  Grad: 23.7771  max=0.7631(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7540(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5284, loss_cls=0.0932, loss_bbox=0.5800, matched_ious=0.5447, loss_iou=0.0893, loss_iou_reg=0.2167, d_time=0.00(0.01), f_time=1.35(1.45), b_time=1.36(1.46)  Time cost: 36:31/57:16 [13:00:19/18:08:51]  Acc_iter 32400       Data time: 0.00(0.01)  Forward time: 1.35(1.45)  Batch time: 1.36(1.46)
2025-09-03 22:17:19,882   INFO  Train:    9/20 ( 45%) [1553/3862 ( 40%)]  Loss: 1.351 (1.52)  LR: 9.972e-04  Grad: 23.8428  max=1.1849(module.vfe.pfn_layers.0.linear.weight)  min: -0.7578(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5179, loss_cls=0.0906, loss_bbox=0.5824, matched_ious=0.5471, loss_iou=0.0902, loss_iou_reg=0.2147, d_time=0.01(0.01), f_time=1.41(1.45), b_time=1.41(1.46)  Time cost: 37:42/56:02 [13:01:30/18:07:01]  Acc_iter 32450       Data time: 0.01(0.01)  Forward time: 1.41(1.45)  Batch time: 1.41(1.46)
2025-09-03 22:18:31,244   INFO  Train:    9/20 ( 45%) [1603/3862 ( 42%)]  Loss: 1.515 (1.52)  LR: 9.971e-04  Grad: 23.8952  max=0.7728(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7614(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5400, loss_cls=0.0940, loss_bbox=0.6009, matched_ious=0.5430, loss_iou=0.0904, loss_iou_reg=0.2174, d_time=0.01(0.01), f_time=1.45(1.45), b_time=1.46(1.46)  Time cost: 38:54/54:47 [13:02:42/18:05:08]  Acc_iter 32500       Data time: 0.01(0.01)  Forward time: 1.45(1.45)  Batch time: 1.46(1.46)
2025-09-03 22:19:43,100   INFO  Train:    9/20 ( 45%) [1653/3862 ( 43%)]  Loss: 1.885 (1.52)  LR: 9.969e-04  Grad: 23.9635  max=0.7716(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7639(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5305, loss_cls=0.0923, loss_bbox=0.5713, matched_ious=0.5487, loss_iou=0.0906, loss_iou_reg=0.2148, d_time=0.00(0.01), f_time=1.46(1.45), b_time=1.47(1.45)  Time cost: 40:06/53:33 [13:03:54/18:03:31]  Acc_iter 32550       Data time: 0.00(0.01)  Forward time: 1.46(1.45)  Batch time: 1.47(1.45)
2025-09-03 22:20:55,834   INFO  Train:    9/20 ( 45%) [1703/3862 ( 44%)]  Loss: 1.752 (1.52)  LR: 9.967e-04  Grad: 24.1758  max=0.7743(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.3269(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5293, loss_cls=0.0929, loss_bbox=0.5871, matched_ious=0.5430, loss_iou=0.0908, loss_iou_reg=0.2184, d_time=0.01(0.01), f_time=1.32(1.45), b_time=1.33(1.45)  Time cost: 41:18/52:20 [13:05:06/18:02:18]  Acc_iter 32600       Data time: 0.01(0.01)  Forward time: 1.32(1.45)  Batch time: 1.33(1.45)
2025-09-03 22:22:12,489   INFO  Train:    9/20 ( 45%) [1753/3862 ( 45%)]  Loss: 1.448 (1.52)  LR: 9.965e-04  Grad: 24.0794  max=0.7747(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7668(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5383, loss_cls=0.0930, loss_bbox=0.6060, matched_ious=0.5439, loss_iou=0.0889, loss_iou_reg=0.2159, d_time=0.01(0.01), f_time=1.45(1.45), b_time=1.46(1.46)  Time cost: 42:35/51:12 [13:06:23/18:02:45]  Acc_iter 32650       Data time: 0.01(0.01)  Forward time: 1.45(1.45)  Batch time: 1.46(1.46)
2025-09-03 22:23:23,294   INFO  Train:    9/20 ( 45%) [1803/3862 ( 47%)]  Loss: 1.526 (1.52)  LR: 9.963e-04  Grad: 24.1349  max=0.7808(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7684(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5170, loss_cls=0.0891, loss_bbox=0.5933, matched_ious=0.5430, loss_iou=0.0906, loss_iou_reg=0.2176, d_time=0.00(0.01), f_time=1.47(1.45), b_time=1.47(1.46)  Time cost: 43:46/49:57 [13:07:34/18:00:42]  Acc_iter 32700       Data time: 0.00(0.01)  Forward time: 1.47(1.45)  Batch time: 1.47(1.46)
2025-09-03 22:24:34,455   INFO  Train:    9/20 ( 45%) [1853/3862 ( 48%)]  Loss: 1.507 (1.52)  LR: 9.961e-04  Grad: 24.1727  max=0.7811(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7681(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5252, loss_cls=0.0889, loss_bbox=0.5859, matched_ious=0.5462, loss_iou=0.0904, loss_iou_reg=0.2156, d_time=0.01(0.01), f_time=1.46(1.45), b_time=1.47(1.46)  Time cost: 44:57/48:42 [13:08:45/17:58:50]  Acc_iter 32750       Data time: 0.01(0.01)  Forward time: 1.46(1.45)  Batch time: 1.47(1.46)
2025-09-03 22:25:46,449   INFO  Train:    9/20 ( 45%) [1903/3862 ( 49%)]  Loss: 1.414 (1.52)  LR: 9.958e-04  Grad: 24.2804  max=0.7861(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3838(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5104, loss_cls=0.0878, loss_bbox=0.5515, matched_ious=0.5480, loss_iou=0.0892, loss_iou_reg=0.2159, d_time=0.01(0.01), f_time=1.43(1.45), b_time=1.43(1.45)  Time cost: 46:09/47:29 [13:09:57/17:57:20]  Acc_iter 32800       Data time: 0.01(0.01)  Forward time: 1.43(1.45)  Batch time: 1.43(1.45)
2025-09-03 22:26:58,411   INFO  Train:    9/20 ( 45%) [1953/3862 ( 51%)]  Loss: 1.800 (1.52)  LR: 9.956e-04  Grad: 24.2825  max=0.7884(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7683(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5133, loss_cls=0.0895, loss_bbox=0.5769, matched_ious=0.5437, loss_iou=0.0902, loss_iou_reg=0.2171, d_time=0.00(0.01), f_time=1.45(1.45), b_time=1.45(1.45)  Time cost: 47:21/46:15 [13:11:09/17:55:50]  Acc_iter 32850       Data time: 0.00(0.01)  Forward time: 1.45(1.45)  Batch time: 1.45(1.45)
2025-09-03 22:28:15,267   INFO  Train:    9/20 ( 45%) [2003/3862 ( 52%)]  Loss: 1.876 (1.52)  LR: 9.954e-04  Grad: 24.3805  max=0.7881(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7740(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5346, loss_cls=0.0930, loss_bbox=0.6026, matched_ious=0.5429, loss_iou=0.0906, loss_iou_reg=0.2171, d_time=0.01(0.01), f_time=1.48(1.45), b_time=1.48(1.46)  Time cost: 48:38/45:07 [13:12:26/17:56:09]  Acc_iter 32900       Data time: 0.01(0.01)  Forward time: 1.48(1.45)  Batch time: 1.48(1.46)
2025-09-03 22:29:25,942   INFO  Train:    9/20 ( 45%) [2053/3862 ( 53%)]  Loss: 1.559 (1.52)  LR: 9.952e-04  Grad: 24.4273  max=0.7912(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7756(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5151, loss_cls=0.0896, loss_bbox=0.6112, matched_ious=0.5452, loss_iou=0.0899, loss_iou_reg=0.2154, d_time=0.01(0.01), f_time=1.34(1.45), b_time=1.35(1.46)  Time cost: 49:48/43:52 [13:13:37/17:54:10]  Acc_iter 32950       Data time: 0.01(0.01)  Forward time: 1.34(1.45)  Batch time: 1.35(1.46)
2025-09-03 22:30:36,795   INFO  Train:    9/20 ( 45%) [2103/3862 ( 54%)]  Loss: 1.229 (1.52)  LR: 9.949e-04  Grad: 24.4897  max=0.8756(module.vfe.pfn_layers.0.linear.weight)  min: -0.7764(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4945, loss_cls=0.0853, loss_bbox=0.5617, matched_ious=0.5504, loss_iou=0.0895, loss_iou_reg=0.2143, d_time=0.00(0.01), f_time=1.45(1.45), b_time=1.45(1.45)  Time cost: 50:59/42:38 [13:14:47/17:52:17]  Acc_iter 33000       Data time: 0.00(0.01)  Forward time: 1.45(1.45)  Batch time: 1.45(1.45)
2025-09-03 22:31:47,988   INFO  Train:    9/20 ( 45%) [2153/3862 ( 56%)]  Loss: 1.734 (1.52)  LR: 9.947e-04  Grad: 24.5760  max=0.7977(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7806(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5226, loss_cls=0.0908, loss_bbox=0.5887, matched_ious=0.5362, loss_iou=0.0909, loss_iou_reg=0.2200, d_time=0.02(0.01), f_time=1.40(1.44), b_time=1.42(1.45)  Time cost: 52:10/41:24 [13:15:59/17:50:33]  Acc_iter 33050       Data time: 0.02(0.01)  Forward time: 1.40(1.44)  Batch time: 1.42(1.45)
2025-09-03 22:32:59,607   INFO  Train:    9/20 ( 45%) [2203/3862 ( 57%)]  Loss: 1.591 (1.51)  LR: 9.944e-04  Grad: 25.1585  max=3.7630(module.vfe.pfn_layers.0.linear.weight)  min: -0.7812(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5165, loss_cls=0.0890, loss_bbox=0.5900, matched_ious=0.5455, loss_iou=0.0909, loss_iou_reg=0.2150, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 53:22/40:10 [13:17:10/17:48:59]  Acc_iter 33100       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-03 22:34:16,070   INFO  Train:    9/20 ( 45%) [2253/3862 ( 58%)]  Loss: 1.526 (1.51)  LR: 9.942e-04  Grad: 24.6754  max=0.8039(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7867(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5191, loss_cls=0.0896, loss_bbox=0.5897, matched_ious=0.5430, loss_iou=0.0913, loss_iou_reg=0.2172, d_time=0.00(0.01), f_time=1.48(1.45), b_time=1.49(1.45)  Time cost: 54:39/39:00 [13:18:27/17:49:01]  Acc_iter 33150       Data time: 0.00(0.01)  Forward time: 1.48(1.45)  Batch time: 1.49(1.45)
2025-09-03 22:35:26,842   INFO  Train:    9/20 ( 45%) [2303/3862 ( 60%)]  Loss: 1.483 (1.51)  LR: 9.939e-04  Grad: 24.7516  max=0.8047(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7862(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5263, loss_cls=0.0912, loss_bbox=0.5700, matched_ious=0.5433, loss_iou=0.0897, loss_iou_reg=0.2162, d_time=0.01(0.01), f_time=1.36(1.44), b_time=1.37(1.45)  Time cost: 55:49/37:46 [13:19:37/17:47:11]  Acc_iter 33200       Data time: 0.01(0.01)  Forward time: 1.36(1.44)  Batch time: 1.37(1.45)
2025-09-03 22:36:37,843   INFO  Train:    9/20 ( 45%) [2353/3862 ( 61%)]  Loss: 1.547 (1.51)  LR: 9.937e-04  Grad: 24.7850  max=0.8078(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7891(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5219, loss_cls=0.0897, loss_bbox=0.6156, matched_ious=0.5430, loss_iou=0.0904, loss_iou_reg=0.2179, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.42(1.45)  Time cost: 57:00/36:32 [13:20:48/17:45:27]  Acc_iter 33250       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.45)
2025-09-03 22:37:49,305   INFO  Train:    9/20 ( 45%) [2403/3862 ( 62%)]  Loss: 1.413 (1.51)  LR: 9.934e-04  Grad: 24.8742  max=0.8110(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7895(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5122, loss_cls=0.0875, loss_bbox=0.5874, matched_ious=0.5494, loss_iou=0.0894, loss_iou_reg=0.2133, d_time=0.01(0.01), f_time=1.47(1.44), b_time=1.47(1.45)  Time cost: 58:12/35:19 [13:22:00/17:43:52]  Acc_iter 33300       Data time: 0.01(0.01)  Forward time: 1.47(1.44)  Batch time: 1.47(1.45)
2025-09-03 22:39:01,786   INFO  Train:    9/20 ( 45%) [2453/3862 ( 64%)]  Loss: 1.653 (1.51)  LR: 9.931e-04  Grad: 24.9271  max=0.8149(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7912(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5202, loss_cls=0.0878, loss_bbox=0.5813, matched_ious=0.5470, loss_iou=0.0899, loss_iou_reg=0.2148, d_time=0.00(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 59:24/34:06 [13:23:12/17:42:37]  Acc_iter 33350       Data time: 0.00(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-03 22:40:18,751   INFO  Train:    9/20 ( 45%) [2503/3862 ( 65%)]  Loss: 1.411 (1.51)  LR: 9.928e-04  Grad: 24.9984  max=0.8126(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7968(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5088, loss_cls=0.0882, loss_bbox=0.5737, matched_ious=0.5480, loss_iou=0.0888, loss_iou_reg=0.2146, d_time=0.01(0.01), f_time=1.37(1.45), b_time=1.37(1.45)  Time cost: 1:00:41/32:56 [13:24:29/17:42:40]  Acc_iter 33400       Data time: 0.01(0.01)  Forward time: 1.37(1.45)  Batch time: 1.37(1.45)
2025-09-03 22:41:29,797   INFO  Train:    9/20 ( 45%) [2553/3862 ( 66%)]  Loss: 1.386 (1.51)  LR: 9.925e-04  Grad: 25.0662  max=0.8177(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7981(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5048, loss_cls=0.0864, loss_bbox=0.5650, matched_ious=0.5475, loss_iou=0.0898, loss_iou_reg=0.2149, d_time=0.00(0.01), f_time=1.39(1.44), b_time=1.39(1.45)  Time cost: 1:01:52/31:42 [13:25:40/17:40:58]  Acc_iter 33450       Data time: 0.00(0.01)  Forward time: 1.39(1.44)  Batch time: 1.39(1.45)
2025-09-03 22:42:41,287   INFO  Train:    9/20 ( 45%) [2603/3862 ( 67%)]  Loss: 1.652 (1.51)  LR: 9.922e-04  Grad: 25.1213  max=0.8180(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8006(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5344, loss_cls=0.0904, loss_bbox=0.6011, matched_ious=0.5434, loss_iou=0.0900, loss_iou_reg=0.2184, d_time=0.01(0.01), f_time=1.36(1.44), b_time=1.37(1.45)  Time cost: 1:03:04/30:29 [13:26:52/17:39:26]  Acc_iter 33500       Data time: 0.01(0.01)  Forward time: 1.36(1.44)  Batch time: 1.37(1.45)
2025-09-03 22:43:53,097   INFO  Train:    9/20 ( 45%) [2653/3862 ( 69%)]  Loss: 1.168 (1.51)  LR: 9.919e-04  Grad: 25.2137  max=0.8233(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8049(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5101, loss_cls=0.0883, loss_bbox=0.5770, matched_ious=0.5472, loss_iou=0.0887, loss_iou_reg=0.2155, d_time=0.01(0.01), f_time=1.51(1.44), b_time=1.52(1.45)  Time cost: 1:04:16/29:16 [13:28:04/17:37:59]  Acc_iter 33550       Data time: 0.01(0.01)  Forward time: 1.51(1.44)  Batch time: 1.52(1.45)
2025-09-03 22:45:04,518   INFO  Train:    9/20 ( 45%) [2703/3862 ( 70%)]  Loss: 1.903 (1.51)  LR: 9.916e-04  Grad: 25.4525  max=1.7661(module.vfe.pfn_layers.0.linear.weight)  min: -2.7890(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5209, loss_cls=0.0913, loss_bbox=0.6054, matched_ious=0.5451, loss_iou=0.0887, loss_iou_reg=0.2163, d_time=0.00(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 1:05:27/28:03 [13:29:15/17:36:27]  Acc_iter 33600       Data time: 0.00(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-03 22:46:21,312   INFO  Train:    9/20 ( 45%) [2753/3862 ( 71%)]  Loss: 1.597 (1.51)  LR: 9.913e-04  Grad: 25.3062  max=0.8247(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8062(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5056, loss_cls=0.0887, loss_bbox=0.5712, matched_ious=0.5465, loss_iou=0.0910, loss_iou_reg=0.2155, d_time=0.00(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 1:06:44/26:52 [13:30:32/17:36:20]  Acc_iter 33650       Data time: 0.00(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-03 22:47:32,448   INFO  Train:    9/20 ( 45%) [2803/3862 ( 73%)]  Loss: 1.568 (1.51)  LR: 9.910e-04  Grad: 25.3478  max=0.8291(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8055(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5098, loss_cls=0.0891, loss_bbox=0.5796, matched_ious=0.5464, loss_iou=0.0904, loss_iou_reg=0.2147, d_time=0.01(0.01), f_time=1.45(1.44), b_time=1.45(1.45)  Time cost: 1:07:55/25:39 [13:31:43/17:34:43]  Acc_iter 33700       Data time: 0.01(0.01)  Forward time: 1.45(1.44)  Batch time: 1.45(1.45)
2025-09-03 22:48:43,511   INFO  Train:    9/20 ( 45%) [2853/3862 ( 74%)]  Loss: 1.540 (1.51)  LR: 9.907e-04  Grad: 25.5968  max=2.5479(module.vfe.pfn_layers.0.linear.weight)  min: -1.5473(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5190, loss_cls=0.0876, loss_bbox=0.5753, matched_ious=0.5506, loss_iou=0.0897, loss_iou_reg=0.2146, d_time=0.01(0.01), f_time=1.46(1.44), b_time=1.46(1.45)  Time cost: 1:09:06/24:25 [13:32:54/17:33:06]  Acc_iter 33750       Data time: 0.01(0.01)  Forward time: 1.46(1.44)  Batch time: 1.46(1.45)
2025-09-03 22:49:55,845   INFO  Train:    9/20 ( 45%) [2903/3862 ( 75%)]  Loss: 1.151 (1.51)  LR: 9.903e-04  Grad: 25.4759  max=0.8267(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8094(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5031, loss_cls=0.0881, loss_bbox=0.5708, matched_ious=0.5500, loss_iou=0.0906, loss_iou_reg=0.2132, d_time=0.01(0.01), f_time=1.46(1.44), b_time=1.46(1.45)  Time cost: 1:10:18/23:13 [13:34:06/17:31:49]  Acc_iter 33800       Data time: 0.01(0.01)  Forward time: 1.46(1.44)  Batch time: 1.46(1.45)
2025-09-03 22:51:07,438   INFO  Train:    9/20 ( 45%) [2953/3862 ( 76%)]  Loss: 1.461 (1.51)  LR: 9.900e-04  Grad: 25.5305  max=0.8300(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8120(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5121, loss_cls=0.0879, loss_bbox=0.5798, matched_ious=0.5485, loss_iou=0.0892, loss_iou_reg=0.2152, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.44(1.45)  Time cost: 1:11:30/22:00 [13:35:18/17:30:20]  Acc_iter 33850       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.44(1.45)
2025-09-03 22:52:24,170   INFO  Train:    9/20 ( 45%) [3003/3862 ( 78%)]  Loss: 1.656 (1.51)  LR: 9.897e-04  Grad: 25.6403  max=0.8312(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.7456(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5036, loss_cls=0.0874, loss_bbox=0.5523, matched_ious=0.5541, loss_iou=0.0896, loss_iou_reg=0.2135, d_time=0.01(0.01), f_time=1.56(1.44), b_time=1.57(1.45)  Time cost: 1:12:47/20:48 [13:36:35/17:30:07]  Acc_iter 33900       Data time: 0.01(0.01)  Forward time: 1.56(1.44)  Batch time: 1.57(1.45)
2025-09-03 22:53:34,860   INFO  Train:    9/20 ( 45%) [3053/3862 ( 79%)]  Loss: 1.479 (1.51)  LR: 9.893e-04  Grad: 25.6493  max=0.8345(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8173(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5044, loss_cls=0.0890, loss_bbox=0.5629, matched_ious=0.5526, loss_iou=0.0900, loss_iou_reg=0.2134, d_time=0.00(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 1:13:57/19:35 [13:37:45/17:28:26]  Acc_iter 33950       Data time: 0.00(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-03 22:54:46,368   INFO  Train:    9/20 ( 45%) [3103/3862 ( 80%)]  Loss: 1.631 (1.51)  LR: 9.890e-04  Grad: 25.6989  max=0.8402(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8206(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5120, loss_cls=0.0885, loss_bbox=0.5593, matched_ious=0.5506, loss_iou=0.0896, loss_iou_reg=0.2138, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 1:15:09/18:22 [13:38:57/17:26:58]  Acc_iter 34000       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-03 22:55:58,029   INFO  Train:    9/20 ( 45%) [3153/3862 ( 82%)]  Loss: 1.288 (1.51)  LR: 9.886e-04  Grad: 25.7663  max=0.8428(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8268(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5001, loss_cls=0.0877, loss_bbox=0.5745, matched_ious=0.5490, loss_iou=0.0905, loss_iou_reg=0.2150, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 1:16:20/17:09 [13:40:09/17:25:32]  Acc_iter 34050       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-03 22:57:09,071   INFO  Train:    9/20 ( 45%) [3203/3862 ( 83%)]  Loss: 1.383 (1.51)  LR: 9.883e-04  Grad: 25.8051  max=0.8429(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8269(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5249, loss_cls=0.0897, loss_bbox=0.5947, matched_ious=0.5467, loss_iou=0.0900, loss_iou_reg=0.2150, d_time=0.00(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 1:17:32/15:56 [13:41:20/17:23:58]  Acc_iter 34100       Data time: 0.00(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-03 22:58:26,174   INFO  Train:    9/20 ( 45%) [3253/3862 ( 84%)]  Loss: 1.360 (1.51)  LR: 9.879e-04  Grad: 25.8567  max=0.8418(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8286(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5049, loss_cls=0.0889, loss_bbox=0.5810, matched_ious=0.5472, loss_iou=0.0903, loss_iou_reg=0.2153, d_time=0.01(0.01), f_time=1.37(1.44), b_time=1.38(1.45)  Time cost: 1:18:49/14:45 [13:42:37/17:23:45]  Acc_iter 34150       Data time: 0.01(0.01)  Forward time: 1.37(1.44)  Batch time: 1.38(1.45)
2025-09-03 22:59:37,549   INFO  Train:    9/20 ( 45%) [3303/3862 ( 86%)]  Loss: 1.467 (1.51)  LR: 9.875e-04  Grad: 25.9249  max=0.8408(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8311(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5114, loss_cls=0.0896, loss_bbox=0.5652, matched_ious=0.5460, loss_iou=0.0902, loss_iou_reg=0.2167, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.42(1.45)  Time cost: 1:20:00/13:32 [13:43:48/17:22:15]  Acc_iter 34200       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.45)
2025-09-03 23:00:48,623   INFO  Train:    9/20 ( 45%) [3353/3862 ( 87%)]  Loss: 1.517 (1.50)  LR: 9.871e-04  Grad: 25.9718  max=0.8467(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8341(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4992, loss_cls=0.0840, loss_bbox=0.5830, matched_ious=0.5469, loss_iou=0.0899, loss_iou_reg=0.2159, d_time=0.00(0.01), f_time=1.44(1.44), b_time=1.45(1.45)  Time cost: 1:21:11/12:19 [13:44:59/17:20:43]  Acc_iter 34250       Data time: 0.00(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.45)
2025-09-03 23:02:00,635   INFO  Train:    9/20 ( 45%) [3403/3862 ( 88%)]  Loss: 1.252 (1.50)  LR: 9.868e-04  Grad: 26.0467  max=1.1403(module.vfe.pfn_layers.0.linear.weight)  min: -0.8381(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5178, loss_cls=0.0894, loss_bbox=0.5831, matched_ious=0.5488, loss_iou=0.0908, loss_iou_reg=0.2150, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.44(1.45)  Time cost: 1:22:23/11:06 [13:46:11/17:19:22]  Acc_iter 34300       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.44(1.45)
2025-09-03 23:03:12,865   INFO  Train:    9/20 ( 45%) [3453/3862 ( 89%)]  Loss: 1.408 (1.50)  LR: 9.864e-04  Grad: 26.1003  max=0.8495(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8369(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5219, loss_cls=0.0888, loss_bbox=0.5943, matched_ious=0.5485, loss_iou=0.0893, loss_iou_reg=0.2153, d_time=0.39(0.01), f_time=2.14(1.44), b_time=2.52(1.45)  Time cost: 1:23:35/09:53 [13:47:23/17:18:05]  Acc_iter 34350       Data time: 0.39(0.01)  Forward time: 2.14(1.44)  Batch time: 2.52(1.45)
2025-09-03 23:04:27,679   INFO  Train:    9/20 ( 45%) [3503/3862 ( 91%)]  Loss: 1.475 (1.50)  LR: 9.860e-04  Grad: 26.1097  max=0.8529(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8360(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5098, loss_cls=0.0889, loss_bbox=0.5680, matched_ious=0.5484, loss_iou=0.0913, loss_iou_reg=0.2161, d_time=0.01(0.01), f_time=1.29(1.44), b_time=1.30(1.45)  Time cost: 1:24:50/08:41 [13:48:38/17:17:19]  Acc_iter 34400       Data time: 0.01(0.01)  Forward time: 1.29(1.44)  Batch time: 1.30(1.45)
2025-09-03 23:05:39,436   INFO  Train:    9/20 ( 45%) [3553/3862 ( 92%)]  Loss: 1.514 (1.50)  LR: 9.856e-04  Grad: 26.2094  max=0.8516(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8423(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5137, loss_cls=0.0906, loss_bbox=0.5679, matched_ious=0.5524, loss_iou=0.0900, loss_iou_reg=0.2123, d_time=0.00(0.01), f_time=1.45(1.44), b_time=1.45(1.45)  Time cost: 1:26:02/07:28 [13:49:50/17:15:56]  Acc_iter 34450       Data time: 0.00(0.01)  Forward time: 1.45(1.44)  Batch time: 1.45(1.45)
2025-09-03 23:06:51,292   INFO  Train:    9/20 ( 45%) [3603/3862 ( 93%)]  Loss: 1.354 (1.50)  LR: 9.852e-04  Grad: 26.2595  max=0.8566(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8444(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5113, loss_cls=0.0885, loss_bbox=0.5557, matched_ious=0.5545, loss_iou=0.0891, loss_iou_reg=0.2094, d_time=0.00(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 1:27:14/06:16 [13:51:02/17:14:34]  Acc_iter 34500       Data time: 0.00(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-03 23:08:02,156   INFO  Train:    9/20 ( 45%) [3653/3862 ( 95%)]  Loss: 1.320 (1.50)  LR: 9.847e-04  Grad: 26.3113  max=0.8597(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8467(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5264, loss_cls=0.0902, loss_bbox=0.5869, matched_ious=0.5546, loss_iou=0.0877, loss_iou_reg=0.2114, d_time=0.01(0.01), f_time=1.46(1.44), b_time=1.47(1.45)  Time cost: 1:28:25/05:03 [13:52:13/17:13:01]  Acc_iter 34550       Data time: 0.01(0.01)  Forward time: 1.46(1.44)  Batch time: 1.47(1.45)
2025-09-03 23:09:14,350   INFO  Train:    9/20 ( 45%) [3703/3862 ( 96%)]  Loss: 1.467 (1.50)  LR: 9.843e-04  Grad: 26.3965  max=0.8671(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8480(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5206, loss_cls=0.0884, loss_bbox=0.5717, matched_ious=0.5493, loss_iou=0.0909, loss_iou_reg=0.2129, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 1:29:37/03:50 [13:53:25/17:11:44]  Acc_iter 34600       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-03 23:10:29,431   INFO  Train:    9/20 ( 45%) [3753/3862 ( 97%)]  Loss: 1.348 (1.50)  LR: 9.839e-04  Grad: 26.4293  max=0.8655(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8490(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5099, loss_cls=0.0900, loss_bbox=0.5812, matched_ious=0.5465, loss_iou=0.0898, loss_iou_reg=0.2154, d_time=0.00(0.01), f_time=1.34(1.44), b_time=1.34(1.45)  Time cost: 1:30:52/02:38 [13:54:40/17:11:00]  Acc_iter 34650       Data time: 0.00(0.01)  Forward time: 1.34(1.44)  Batch time: 1.34(1.45)
2025-09-03 23:11:40,059   INFO  Train:    9/20 ( 45%) [3803/3862 ( 98%)]  Loss: 1.471 (1.50)  LR: 9.835e-04  Grad: 26.4958  max=0.8697(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8504(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4918, loss_cls=0.0854, loss_bbox=0.5504, matched_ious=0.5511, loss_iou=0.0887, loss_iou_reg=0.2154, d_time=0.00(0.01), f_time=1.35(1.44), b_time=1.35(1.45)  Time cost: 1:32:03/01:25 [13:55:51/17:09:25]  Acc_iter 34700       Data time: 0.00(0.01)  Forward time: 1.35(1.44)  Batch time: 1.35(1.45)
2025-09-03 23:12:51,731   INFO  Train:    9/20 ( 45%) [3853/3862 (100%)]  Loss: 1.829 (1.50)  LR: 9.830e-04  Grad: 26.5603  max=0.8703(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8536(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5066, loss_cls=0.0867, loss_bbox=0.5701, matched_ious=0.5485, loss_iou=0.0899, loss_iou_reg=0.2144, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 1:33:14/00:13 [13:57:02/17:08:02]  Acc_iter 34750       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-03 23:13:02,447   INFO  Train:    9/20 ( 45%) [3861/3862 (100%)]  Loss: 1.722 (1.50)  LR: 9.830e-04  Grad: 26.5562  max=0.8698(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8543(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5065, loss_cls=0.0867, loss_bbox=0.5746, matched_ious=0.5519, loss_iou=0.0911, loss_iou_reg=0.2138, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 1:33:25/00:01 [13:57:13/17:07:40]  Acc_iter 34758       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)

                                               [Aepochs:  45%|████▌     | 9/20 [13:57:13<17:05:41, 5594.66s/it]epochs:  45%|████▌     | 9/20 [13:57:13<17:05:41, 5594.64s/it]epochs:  45%|████▌     | 9/20 [13:57:13<17:05:41, 5594.65s/it]epochs:  45%|████▌     | 9/20 [13:57:13<17:05:41, 5594.66s/it]epochs:  45%|████▌     | 9/20 [13:57:13<17:05:41, 5594.65s/it]epochs:  45%|████▌     | 9/20 [13:57:13<17:05:41, 5594.66s/it]epochs:  45%|████▌     | 9/20 [13:57:13<17:05:41, 5594.68s/it]epochs:  45%|████▌     | 9/20 [13:57:14<17:05:41, 5594.67s/it]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-03 23:13:08,053   INFO  Train:   10/20 ( 50%) [   0/3862 (  0%)]  Loss: 1.253 (1.25)  LR: 9.830e-04  Grad: 26.5485  max=0.8705(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8533(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4657, loss_cls=0.0834, loss_bbox=0.4186, matched_ious=0.5842, loss_iou=0.0879, loss_iou_reg=0.1977, d_time=1.86(1.86), f_time=2.54(2.54), b_time=4.40(4.40)  Time cost: 00:04/4:22:36 [13:57:19/48:08:36]  Acc_iter 34759       Data time: 1.86(1.86)  Forward time: 2.54(2.54)  Batch time: 4.40(4.40)
2025-09-03 23:14:06,643   INFO  Train:   10/20 ( 50%) [  41/3862 (  1%)]  Loss: 1.502 (1.45)  LR: 9.826e-04  Grad: 26.6097  max=0.8683(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8578(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4996, loss_cls=0.0844, loss_bbox=0.5677, matched_ious=0.5445, loss_iou=0.0901, loss_iou_reg=0.2168, d_time=0.01(0.05), f_time=1.45(1.45), b_time=1.45(1.50)  Time cost: 01:02/1:35:01 [13:58:17/17:35:26]  Acc_iter 34800       Data time: 0.01(0.05)  Forward time: 1.45(1.45)  Batch time: 1.45(1.50)
2025-09-03 23:15:20,419   INFO  Train:   10/20 ( 50%) [  91/3862 (  2%)]  Loss: 1.143 (1.46)  LR: 9.822e-04  Grad: 26.6688  max=0.8738(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8592(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5065, loss_cls=0.0882, loss_bbox=0.5675, matched_ious=0.5493, loss_iou=0.0895, loss_iou_reg=0.2127, d_time=0.01(0.03), f_time=1.40(1.46), b_time=1.41(1.49)  Time cost: 02:16/1:33:12 [13:59:31/17:27:51]  Acc_iter 34850       Data time: 0.01(0.03)  Forward time: 1.40(1.46)  Batch time: 1.41(1.49)
2025-09-03 23:16:34,929   INFO  Train:   10/20 ( 50%) [ 141/3862 (  4%)]  Loss: 1.261 (1.46)  LR: 9.817e-04  Grad: 26.7375  max=0.8736(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8648(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4961, loss_cls=0.0846, loss_bbox=0.5632, matched_ious=0.5494, loss_iou=0.0906, loss_iou_reg=0.2152, d_time=0.01(0.02), f_time=1.40(1.47), b_time=1.41(1.49)  Time cost: 03:30/1:32:07 [14:00:46/17:28:22]  Acc_iter 34900       Data time: 0.01(0.02)  Forward time: 1.40(1.47)  Batch time: 1.41(1.49)
2025-09-03 23:17:46,469   INFO  Train:   10/20 ( 50%) [ 191/3862 (  5%)]  Loss: 1.540 (1.46)  LR: 9.812e-04  Grad: 26.8390  max=0.8752(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8797(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5070, loss_cls=0.0872, loss_bbox=0.5698, matched_ious=0.5469, loss_iou=0.0897, loss_iou_reg=0.2155, d_time=0.01(0.02), f_time=1.44(1.45), b_time=1.45(1.47)  Time cost: 04:42/1:30:01 [14:01:57/17:17:04]  Acc_iter 34950       Data time: 0.01(0.02)  Forward time: 1.44(1.45)  Batch time: 1.45(1.47)
2025-09-03 23:18:59,164   INFO  Train:   10/20 ( 50%) [ 241/3862 (  6%)]  Loss: 1.226 (1.46)  LR: 9.808e-04  Grad: 26.8708  max=0.8773(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8669(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4931, loss_cls=0.0863, loss_bbox=0.5679, matched_ious=0.5461, loss_iou=0.0910, loss_iou_reg=0.2163, d_time=0.01(0.02), f_time=1.42(1.45), b_time=1.42(1.47)  Time cost: 05:55/1:28:34 [14:03:10/17:13:18]  Acc_iter 35000       Data time: 0.01(0.02)  Forward time: 1.42(1.45)  Batch time: 1.42(1.47)
2025-09-03 23:20:09,652   INFO  Train:   10/20 ( 50%) [ 291/3862 (  8%)]  Loss: 1.461 (1.45)  LR: 9.803e-04  Grad: 26.9152  max=0.8833(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8661(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4926, loss_cls=0.0856, loss_bbox=0.5325, matched_ious=0.5528, loss_iou=0.0901, loss_iou_reg=0.2144, d_time=0.00(0.01), f_time=1.38(1.44), b_time=1.39(1.46)  Time cost: 07:05/1:26:45 [14:04:20/17:05:06]  Acc_iter 35050       Data time: 0.00(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.46)
2025-09-03 23:21:25,362   INFO  Train:   10/20 ( 50%) [ 341/3862 (  9%)]  Loss: 1.526 (1.45)  LR: 9.798e-04  Grad: 26.9739  max=0.8841(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8694(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4933, loss_cls=0.0849, loss_bbox=0.5625, matched_ious=0.5544, loss_iou=0.0894, loss_iou_reg=0.2125, d_time=0.00(0.01), f_time=2.96(1.45), b_time=2.96(1.47)  Time cost: 08:21/1:26:01 [14:05:36/17:09:40]  Acc_iter 35100       Data time: 0.00(0.01)  Forward time: 2.96(1.45)  Batch time: 2.96(1.47)
2025-09-03 23:22:38,600   INFO  Train:   10/20 ( 50%) [ 391/3862 ( 10%)]  Loss: 1.424 (1.45)  LR: 9.794e-04  Grad: 27.0250  max=0.8840(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8744(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4983, loss_cls=0.0859, loss_bbox=0.5564, matched_ious=0.5540, loss_iou=0.0902, loss_iou_reg=0.2130, d_time=0.00(0.01), f_time=1.28(1.45), b_time=1.29(1.47)  Time cost: 09:34/1:24:48 [14:06:49/17:08:20]  Acc_iter 35150       Data time: 0.00(0.01)  Forward time: 1.28(1.45)  Batch time: 1.29(1.47)
2025-09-03 23:23:49,856   INFO  Train:   10/20 ( 50%) [ 441/3862 ( 11%)]  Loss: 1.683 (1.45)  LR: 9.789e-04  Grad: 27.1004  max=0.8871(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8746(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4958, loss_cls=0.0878, loss_bbox=0.5567, matched_ious=0.5517, loss_iou=0.0886, loss_iou_reg=0.2137, d_time=0.01(0.01), f_time=1.39(1.45), b_time=1.39(1.46)  Time cost: 10:45/1:23:18 [14:08:00/17:03:53]  Acc_iter 35200       Data time: 0.01(0.01)  Forward time: 1.39(1.45)  Batch time: 1.39(1.46)
2025-09-03 23:25:01,321   INFO  Train:   10/20 ( 50%) [ 491/3862 ( 13%)]  Loss: 1.503 (1.45)  LR: 9.784e-04  Grad: 27.1546  max=0.8948(module.vfe.pfn_layers.0.linear.weight)  min: -0.8769(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4930, loss_cls=0.0858, loss_bbox=0.5667, matched_ious=0.5517, loss_iou=0.0902, loss_iou_reg=0.2142, d_time=0.00(0.01), f_time=1.50(1.45), b_time=1.50(1.46)  Time cost: 11:57/1:21:54 [14:09:12/17:00:23]  Acc_iter 35250       Data time: 0.00(0.01)  Forward time: 1.50(1.45)  Batch time: 1.50(1.46)
2025-09-03 23:26:12,442   INFO  Train:   10/20 ( 50%) [ 541/3862 ( 14%)]  Loss: 1.539 (1.45)  LR: 9.779e-04  Grad: 27.1979  max=0.8898(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8770(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4879, loss_cls=0.0851, loss_bbox=0.5639, matched_ious=0.5521, loss_iou=0.0904, loss_iou_reg=0.2129, d_time=0.00(0.01), f_time=1.45(1.44), b_time=1.46(1.46)  Time cost: 13:08/1:20:31 [14:10:23/16:56:53]  Acc_iter 35300       Data time: 0.00(0.01)  Forward time: 1.45(1.44)  Batch time: 1.46(1.46)
2025-09-03 23:27:27,860   INFO  Train:   10/20 ( 50%) [ 591/3862 ( 15%)]  Loss: 1.530 (1.45)  LR: 9.774e-04  Grad: 27.2783  max=0.8886(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8805(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5005, loss_cls=0.0880, loss_bbox=0.5608, matched_ious=0.5504, loss_iou=0.0892, loss_iou_reg=0.2143, d_time=0.01(0.01), f_time=1.50(1.45), b_time=1.50(1.46)  Time cost: 14:23/1:19:33 [14:11:38/16:58:50]  Acc_iter 35350       Data time: 0.01(0.01)  Forward time: 1.50(1.45)  Batch time: 1.50(1.46)
2025-09-03 23:28:40,323   INFO  Train:   10/20 ( 50%) [ 641/3862 ( 17%)]  Loss: 1.627 (1.45)  LR: 9.769e-04  Grad: 27.2925  max=0.8930(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8799(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4827, loss_cls=0.0838, loss_bbox=0.5516, matched_ious=0.5534, loss_iou=0.0891, loss_iou_reg=0.2122, d_time=0.00(0.01), f_time=1.31(1.45), b_time=1.31(1.46)  Time cost: 15:36/1:18:17 [14:12:51/16:57:04]  Acc_iter 35400       Data time: 0.00(0.01)  Forward time: 1.31(1.45)  Batch time: 1.31(1.46)
2025-09-03 23:29:52,016   INFO  Train:   10/20 ( 50%) [ 691/3862 ( 18%)]  Loss: 1.405 (1.44)  LR: 9.764e-04  Grad: 27.3774  max=0.8962(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8850(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4834, loss_cls=0.0843, loss_bbox=0.5383, matched_ious=0.5555, loss_iou=0.0877, loss_iou_reg=0.2121, d_time=0.00(0.01), f_time=1.51(1.45), b_time=1.52(1.46)  Time cost: 16:48/1:16:59 [14:14:03/16:54:37]  Acc_iter 35450       Data time: 0.00(0.01)  Forward time: 1.51(1.45)  Batch time: 1.52(1.46)
2025-09-03 23:31:03,317   INFO  Train:   10/20 ( 50%) [ 741/3862 ( 19%)]  Loss: 1.379 (1.44)  LR: 9.759e-04  Grad: 27.4716  max=0.8982(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.6177(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4924, loss_cls=0.0857, loss_bbox=0.5350, matched_ious=0.5545, loss_iou=0.0893, loss_iou_reg=0.2117, d_time=0.01(0.01), f_time=1.36(1.44), b_time=1.37(1.46)  Time cost: 17:59/1:15:39 [14:15:14/16:51:58]  Acc_iter 35500       Data time: 0.01(0.01)  Forward time: 1.36(1.44)  Batch time: 1.37(1.46)
2025-09-03 23:32:14,205   INFO  Train:   10/20 ( 50%) [ 791/3862 ( 20%)]  Loss: 1.475 (1.44)  LR: 9.753e-04  Grad: 27.4814  max=0.8993(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8900(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4818, loss_cls=0.0827, loss_bbox=0.5658, matched_ious=0.5495, loss_iou=0.0912, loss_iou_reg=0.2145, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.42(1.45)  Time cost: 19:10/1:14:20 [14:16:25/16:49:08]  Acc_iter 35550       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.45)
2025-09-03 23:33:31,117   INFO  Train:   10/20 ( 50%) [ 841/3862 ( 22%)]  Loss: 1.770 (1.45)  LR: 9.748e-04  Grad: 27.5331  max=0.9050(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8883(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5282, loss_cls=0.0893, loss_bbox=0.6018, matched_ious=0.5451, loss_iou=0.0888, loss_iou_reg=0.2158, d_time=0.01(0.01), f_time=2.25(1.45), b_time=2.25(1.46)  Time cost: 20:27/1:13:22 [14:17:42/16:51:28]  Acc_iter 35600       Data time: 0.01(0.01)  Forward time: 2.25(1.45)  Batch time: 2.25(1.46)
2025-09-03 23:34:43,566   INFO  Train:   10/20 ( 50%) [ 891/3862 ( 23%)]  Loss: 1.555 (1.45)  LR: 9.743e-04  Grad: 28.0868  max=4.4254(module.vfe.pfn_layers.0.linear.weight)  min: -2.7325(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5064, loss_cls=0.0876, loss_bbox=0.5532, matched_ious=0.5488, loss_iou=0.0896, loss_iou_reg=0.2151, d_time=0.01(0.01), f_time=1.35(1.45), b_time=1.36(1.46)  Time cost: 21:39/1:12:08 [14:18:54/16:49:55]  Acc_iter 35650       Data time: 0.01(0.01)  Forward time: 1.35(1.45)  Batch time: 1.36(1.46)
2025-09-03 23:35:55,777   INFO  Train:   10/20 ( 50%) [ 941/3862 ( 24%)]  Loss: 1.476 (1.45)  LR: 9.737e-04  Grad: 19.2360  max=0.6286(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6221(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4990, loss_cls=0.0856, loss_bbox=0.5631, matched_ious=0.5499, loss_iou=0.0898, loss_iou_reg=0.2144, d_time=0.01(0.01), f_time=1.33(1.45), b_time=1.34(1.46)  Time cost: 22:51/1:10:53 [14:20:06/16:48:14]  Acc_iter 35700       Data time: 0.01(0.01)  Forward time: 1.33(1.45)  Batch time: 1.34(1.46)
2025-09-03 23:37:07,106   INFO  Train:   10/20 ( 50%) [ 991/3862 ( 26%)]  Loss: 1.498 (1.45)  LR: 9.732e-04  Grad: 19.2930  max=0.6318(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6228(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5085, loss_cls=0.0892, loss_bbox=0.5762, matched_ious=0.5490, loss_iou=0.0897, loss_iou_reg=0.2135, d_time=0.01(0.01), f_time=1.40(1.45), b_time=1.41(1.46)  Time cost: 24:03/1:09:36 [14:21:18/16:45:59]  Acc_iter 35750       Data time: 0.01(0.01)  Forward time: 1.40(1.45)  Batch time: 1.41(1.46)
2025-09-03 23:38:18,455   INFO  Train:   10/20 ( 50%) [1041/3862 ( 27%)]  Loss: 1.572 (1.45)  LR: 9.726e-04  Grad: 19.3805  max=0.6319(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6283(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4945, loss_cls=0.0856, loss_bbox=0.5732, matched_ious=0.5507, loss_iou=0.0908, loss_iou_reg=0.2143, d_time=0.00(0.01), f_time=1.33(1.44), b_time=1.34(1.45)  Time cost: 25:14/1:08:20 [14:22:29/16:43:51]  Acc_iter 35800       Data time: 0.00(0.01)  Forward time: 1.33(1.44)  Batch time: 1.34(1.45)
2025-09-03 23:39:35,412   INFO  Train:   10/20 ( 50%) [1091/3862 ( 28%)]  Loss: 1.493 (1.45)  LR: 9.721e-04  Grad: 19.3825  max=0.6349(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6293(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5051, loss_cls=0.0870, loss_bbox=0.5706, matched_ious=0.5466, loss_iou=0.0896, loss_iou_reg=0.2163, d_time=0.01(0.01), f_time=1.39(1.45), b_time=1.40(1.46)  Time cost: 26:31/1:07:18 [14:23:46/16:45:21]  Acc_iter 35850       Data time: 0.01(0.01)  Forward time: 1.39(1.45)  Batch time: 1.40(1.46)
2025-09-03 23:40:47,485   INFO  Train:   10/20 ( 50%) [1141/3862 ( 30%)]  Loss: 1.230 (1.45)  LR: 9.715e-04  Grad: 19.4634  max=0.6378(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6318(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4967, loss_cls=0.0870, loss_bbox=0.5432, matched_ious=0.5521, loss_iou=0.0914, loss_iou_reg=0.2129, d_time=0.00(0.01), f_time=1.50(1.45), b_time=1.51(1.46)  Time cost: 27:43/1:06:03 [14:24:58/16:43:39]  Acc_iter 35900       Data time: 0.00(0.01)  Forward time: 1.50(1.45)  Batch time: 1.51(1.46)
2025-09-03 23:41:59,619   INFO  Train:   10/20 ( 50%) [1191/3862 ( 31%)]  Loss: 1.226 (1.45)  LR: 9.710e-04  Grad: 19.5469  max=1.0587(module.vfe.pfn_layers.0.linear.weight)  min: -0.6337(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5032, loss_cls=0.0874, loss_bbox=0.5423, matched_ious=0.5518, loss_iou=0.0891, loss_iou_reg=0.2141, d_time=0.01(0.01), f_time=1.46(1.45), b_time=1.47(1.46)  Time cost: 28:55/1:04:49 [14:26:10/16:42:02]  Acc_iter 35950       Data time: 0.01(0.01)  Forward time: 1.46(1.45)  Batch time: 1.47(1.46)
2025-09-03 23:43:10,550   INFO  Train:   10/20 ( 50%) [1241/3862 ( 32%)]  Loss: 1.606 (1.45)  LR: 9.704e-04  Grad: 19.6017  max=0.6409(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6365(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4869, loss_cls=0.0849, loss_bbox=0.5477, matched_ious=0.5485, loss_iou=0.0892, loss_iou_reg=0.2166, d_time=0.01(0.01), f_time=1.40(1.45), b_time=1.41(1.45)  Time cost: 30:06/1:03:32 [14:27:21/16:39:47]  Acc_iter 36000       Data time: 0.01(0.01)  Forward time: 1.40(1.45)  Batch time: 1.41(1.45)
2025-09-03 23:44:21,767   INFO  Train:   10/20 ( 50%) [1291/3862 ( 33%)]  Loss: 1.470 (1.45)  LR: 9.698e-04  Grad: 19.6345  max=0.6461(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6376(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5112, loss_cls=0.0885, loss_bbox=0.5615, matched_ious=0.5533, loss_iou=0.0886, loss_iou_reg=0.2114, d_time=0.01(0.01), f_time=1.47(1.44), b_time=1.48(1.45)  Time cost: 31:17/1:02:16 [14:28:32/16:37:46]  Acc_iter 36050       Data time: 0.01(0.01)  Forward time: 1.47(1.44)  Batch time: 1.48(1.45)
2025-09-03 23:45:37,831   INFO  Train:   10/20 ( 50%) [1341/3862 ( 35%)]  Loss: 1.169 (1.45)  LR: 9.692e-04  Grad: 19.6890  max=0.6445(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6394(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5148, loss_cls=0.0878, loss_bbox=0.5559, matched_ious=0.5551, loss_iou=0.0886, loss_iou_reg=0.2103, d_time=0.01(0.01), f_time=1.42(1.45), b_time=1.42(1.46)  Time cost: 32:33/1:01:10 [14:29:48/16:38:18]  Acc_iter 36100       Data time: 0.01(0.01)  Forward time: 1.42(1.45)  Batch time: 1.42(1.46)
2025-09-03 23:46:49,329   INFO  Train:   10/20 ( 50%) [1391/3862 ( 36%)]  Loss: 1.315 (1.45)  LR: 9.686e-04  Grad: 19.7185  max=0.6486(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6399(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5048, loss_cls=0.0876, loss_bbox=0.5595, matched_ious=0.5562, loss_iou=0.0892, loss_iou_reg=0.2100, d_time=0.01(0.01), f_time=1.47(1.45), b_time=1.48(1.46)  Time cost: 33:45/59:55 [14:31:00/16:36:27]  Acc_iter 36150       Data time: 0.01(0.01)  Forward time: 1.47(1.45)  Batch time: 1.48(1.46)
2025-09-03 23:48:01,550   INFO  Train:   10/20 ( 50%) [1441/3862 ( 37%)]  Loss: 1.286 (1.45)  LR: 9.680e-04  Grad: 20.0038  max=2.1032(module.vfe.pfn_layers.0.linear.weight)  min: -2.1401(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.5119, loss_cls=0.0885, loss_bbox=0.5772, matched_ious=0.5478, loss_iou=0.0894, loss_iou_reg=0.2145, d_time=0.00(0.01), f_time=1.38(1.45), b_time=1.38(1.45)  Time cost: 34:57/58:41 [14:32:12/16:34:59]  Acc_iter 36200       Data time: 0.00(0.01)  Forward time: 1.38(1.45)  Batch time: 1.38(1.45)
2025-09-03 23:49:13,161   INFO  Train:   10/20 ( 50%) [1491/3862 ( 39%)]  Loss: 1.511 (1.45)  LR: 9.674e-04  Grad: 19.8069  max=0.6554(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6394(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5178, loss_cls=0.0889, loss_bbox=0.5665, matched_ious=0.5517, loss_iou=0.0889, loss_iou_reg=0.2116, d_time=0.01(0.01), f_time=1.47(1.44), b_time=1.49(1.45)  Time cost: 36:09/57:27 [14:33:24/16:33:15]  Acc_iter 36250       Data time: 0.01(0.01)  Forward time: 1.47(1.44)  Batch time: 1.49(1.45)
2025-09-03 23:50:24,233   INFO  Train:   10/20 ( 50%) [1541/3862 ( 40%)]  Loss: 1.306 (1.45)  LR: 9.668e-04  Grad: 19.9022  max=0.6552(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6466(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4906, loss_cls=0.0857, loss_bbox=0.5685, matched_ious=0.5529, loss_iou=0.0881, loss_iou_reg=0.2117, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 37:20/56:12 [14:34:35/16:31:20]  Acc_iter 36300       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-03 23:51:40,696   INFO  Train:   10/20 ( 50%) [1591/3862 ( 41%)]  Loss: 1.539 (1.45)  LR: 9.662e-04  Grad: 19.9439  max=0.6583(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6456(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4806, loss_cls=0.0837, loss_bbox=0.5498, matched_ious=0.5484, loss_iou=0.0902, loss_iou_reg=0.2177, d_time=0.01(0.01), f_time=1.45(1.45), b_time=1.45(1.46)  Time cost: 38:36/55:04 [14:35:51/16:31:45]  Acc_iter 36350       Data time: 0.01(0.01)  Forward time: 1.45(1.45)  Batch time: 1.45(1.46)
2025-09-03 23:52:53,200   INFO  Train:   10/20 ( 50%) [1641/3862 ( 42%)]  Loss: 1.609 (1.45)  LR: 9.656e-04  Grad: 19.9925  max=0.6601(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6509(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5022, loss_cls=0.0874, loss_bbox=0.5612, matched_ious=0.5529, loss_iou=0.0906, loss_iou_reg=0.2140, d_time=0.00(0.01), f_time=1.33(1.45), b_time=1.34(1.46)  Time cost: 39:49/53:51 [14:37:04/16:30:26]  Acc_iter 36400       Data time: 0.00(0.01)  Forward time: 1.33(1.45)  Batch time: 1.34(1.46)
2025-09-03 23:54:04,941   INFO  Train:   10/20 ( 50%) [1691/3862 ( 44%)]  Loss: 1.417 (1.45)  LR: 9.650e-04  Grad: 20.0708  max=0.6775(module.vfe.pfn_layers.0.linear.weight)  min: -0.6711(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4933, loss_cls=0.0838, loss_bbox=0.5597, matched_ious=0.5547, loss_iou=0.0889, loss_iou_reg=0.2111, d_time=0.01(0.01), f_time=1.42(1.45), b_time=1.42(1.45)  Time cost: 41:00/52:37 [14:38:16/16:28:49]  Acc_iter 36450       Data time: 0.01(0.01)  Forward time: 1.42(1.45)  Batch time: 1.42(1.45)
2025-09-03 23:55:15,194   INFO  Train:   10/20 ( 50%) [1741/3862 ( 45%)]  Loss: 1.178 (1.45)  LR: 9.644e-04  Grad: 20.1309  max=0.6628(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8500(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4997, loss_cls=0.0874, loss_bbox=0.5713, matched_ious=0.5502, loss_iou=0.0890, loss_iou_reg=0.2143, d_time=0.01(0.01), f_time=1.26(1.44), b_time=1.27(1.45)  Time cost: 42:11/51:21 [14:39:26/16:26:38]  Acc_iter 36500       Data time: 0.01(0.01)  Forward time: 1.26(1.44)  Batch time: 1.27(1.45)
2025-09-03 23:56:26,407   INFO  Train:   10/20 ( 50%) [1791/3862 ( 46%)]  Loss: 1.400 (1.45)  LR: 9.637e-04  Grad: 20.1439  max=0.6625(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6559(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4931, loss_cls=0.0842, loss_bbox=0.5626, matched_ious=0.5508, loss_iou=0.0898, loss_iou_reg=0.2142, d_time=0.00(0.01), f_time=1.44(1.44), b_time=1.45(1.45)  Time cost: 43:22/50:07 [14:40:37/16:24:53]  Acc_iter 36550       Data time: 0.00(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.45)
2025-09-03 23:57:42,939   INFO  Train:   10/20 ( 50%) [1841/3862 ( 48%)]  Loss: 1.389 (1.45)  LR: 9.631e-04  Grad: 20.2408  max=0.6636(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6606(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4768, loss_cls=0.0823, loss_bbox=0.5551, matched_ious=0.5531, loss_iou=0.0891, loss_iou_reg=0.2132, d_time=0.01(0.01), f_time=1.41(1.45), b_time=1.41(1.45)  Time cost: 44:38/48:59 [14:41:54/16:25:07]  Acc_iter 36600       Data time: 0.01(0.01)  Forward time: 1.41(1.45)  Batch time: 1.41(1.45)
2025-09-03 23:58:54,982   INFO  Train:   10/20 ( 50%) [1891/3862 ( 49%)]  Loss: 1.263 (1.45)  LR: 9.625e-04  Grad: 20.2586  max=0.6673(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6641(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4893, loss_cls=0.0853, loss_bbox=0.5714, matched_ious=0.5520, loss_iou=0.0899, loss_iou_reg=0.2133, d_time=0.00(0.01), f_time=1.33(1.44), b_time=1.34(1.45)  Time cost: 45:51/47:45 [14:43:06/16:23:40]  Acc_iter 36650       Data time: 0.00(0.01)  Forward time: 1.33(1.44)  Batch time: 1.34(1.45)
2025-09-04 00:00:05,544   INFO  Train:   10/20 ( 50%) [1941/3862 ( 50%)]  Loss: 1.262 (1.45)  LR: 9.618e-04  Grad: 20.3165  max=0.6677(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6644(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5002, loss_cls=0.0865, loss_bbox=0.5599, matched_ious=0.5513, loss_iou=0.0887, loss_iou_reg=0.2125, d_time=0.00(0.01), f_time=1.32(1.44), b_time=1.32(1.45)  Time cost: 47:01/46:31 [14:44:16/16:21:42]  Acc_iter 36700       Data time: 0.00(0.01)  Forward time: 1.32(1.44)  Batch time: 1.32(1.45)
2025-09-04 00:01:16,069   INFO  Train:   10/20 ( 50%) [1991/3862 ( 52%)]  Loss: 1.610 (1.45)  LR: 9.612e-04  Grad: 20.3822  max=0.6670(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6709(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4899, loss_cls=0.0832, loss_bbox=0.5448, matched_ious=0.5578, loss_iou=0.0884, loss_iou_reg=0.2117, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.38(1.45)  Time cost: 48:12/45:16 [14:45:27/16:19:47]  Acc_iter 36750       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.38(1.45)
2025-09-04 00:02:26,908   INFO  Train:   10/20 ( 50%) [2041/3862 ( 53%)]  Loss: 1.258 (1.45)  LR: 9.605e-04  Grad: 20.4682  max=1.1811(module.vfe.pfn_layers.0.linear.weight)  min: -0.6749(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4996, loss_cls=0.0851, loss_bbox=0.5462, matched_ious=0.5543, loss_iou=0.0894, loss_iou_reg=0.2122, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.35(1.45)  Time cost: 49:22/44:02 [14:46:38/16:17:59]  Acc_iter 36800       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.35(1.45)
2025-09-04 00:03:43,991   INFO  Train:   10/20 ( 50%) [2091/3862 ( 54%)]  Loss: 1.387 (1.45)  LR: 9.598e-04  Grad: 20.5185  max=0.6696(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3294(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4773, loss_cls=0.0838, loss_bbox=0.5600, matched_ious=0.5539, loss_iou=0.0897, loss_iou_reg=0.2127, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.43(1.45)  Time cost: 50:40/42:53 [14:47:55/16:18:14]  Acc_iter 36850       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.43(1.45)
2025-09-04 00:04:56,077   INFO  Train:   10/20 ( 50%) [2141/3862 ( 55%)]  Loss: 1.359 (1.45)  LR: 9.592e-04  Grad: 20.5442  max=0.6745(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6759(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5047, loss_cls=0.0852, loss_bbox=0.5745, matched_ious=0.5528, loss_iou=0.0898, loss_iou_reg=0.2129, d_time=0.00(0.01), f_time=1.34(1.44), b_time=1.34(1.45)  Time cost: 51:52/41:40 [14:49:07/16:16:51]  Acc_iter 36900       Data time: 0.00(0.01)  Forward time: 1.34(1.44)  Batch time: 1.34(1.45)
2025-09-04 00:06:07,455   INFO  Train:   10/20 ( 50%) [2191/3862 ( 57%)]  Loss: 1.431 (1.45)  LR: 9.585e-04  Grad: 20.5784  max=0.6787(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6783(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4913, loss_cls=0.0848, loss_bbox=0.5509, matched_ious=0.5569, loss_iou=0.0890, loss_iou_reg=0.2114, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 53:03/40:26 [14:50:18/16:15:15]  Acc_iter 36950       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-04 00:07:19,049   INFO  Train:   10/20 ( 50%) [2241/3862 ( 58%)]  Loss: 1.473 (1.45)  LR: 9.578e-04  Grad: 20.6506  max=0.6782(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6822(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5025, loss_cls=0.0859, loss_bbox=0.5642, matched_ious=0.5499, loss_iou=0.0904, loss_iou_reg=0.2149, d_time=0.01(0.01), f_time=1.39(1.44), b_time=1.40(1.45)  Time cost: 54:15/39:13 [14:51:30/16:13:44]  Acc_iter 37000       Data time: 0.01(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.45)
2025-09-04 00:08:30,428   INFO  Train:   10/20 ( 50%) [2291/3862 ( 59%)]  Loss: 1.417 (1.45)  LR: 9.571e-04  Grad: 20.6987  max=0.6796(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6841(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5084, loss_cls=0.0883, loss_bbox=0.5552, matched_ious=0.5583, loss_iou=0.0880, loss_iou_reg=0.2110, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 55:26/38:00 [14:52:41/16:12:10]  Acc_iter 37050       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-04 00:09:47,945   INFO  Train:   10/20 ( 50%) [2341/3862 ( 61%)]  Loss: 1.430 (1.45)  LR: 9.564e-04  Grad: 20.7335  max=0.6824(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6875(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4926, loss_cls=0.0867, loss_bbox=0.5417, matched_ious=0.5564, loss_iou=0.0897, loss_iou_reg=0.2122, d_time=0.53(0.01), f_time=1.54(1.44), b_time=2.07(1.45)  Time cost: 56:43/36:50 [14:53:59/16:12:22]  Acc_iter 37100       Data time: 0.53(0.01)  Forward time: 1.54(1.44)  Batch time: 2.07(1.45)
2025-09-04 00:10:58,940   INFO  Train:   10/20 ( 50%) [2391/3862 ( 62%)]  Loss: 1.533 (1.45)  LR: 9.558e-04  Grad: 20.8165  max=0.6853(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8314(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4917, loss_cls=0.0858, loss_bbox=0.5366, matched_ious=0.5578, loss_iou=0.0893, loss_iou_reg=0.2117, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.43(1.45)  Time cost: 57:54/35:36 [14:55:10/16:10:42]  Acc_iter 37150       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.43(1.45)
2025-09-04 00:12:10,509   INFO  Train:   10/20 ( 50%) [2441/3862 ( 63%)]  Loss: 1.654 (1.45)  LR: 9.551e-04  Grad: 20.8370  max=0.6892(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6918(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5000, loss_cls=0.0843, loss_bbox=0.5697, matched_ious=0.5516, loss_iou=0.0893, loss_iou_reg=0.2138, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 59:06/34:23 [14:56:21/16:09:11]  Acc_iter 37200       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-04 00:13:21,553   INFO  Train:   10/20 ( 50%) [2491/3862 ( 65%)]  Loss: 1.440 (1.45)  LR: 9.543e-04  Grad: 20.8907  max=0.6929(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6924(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4996, loss_cls=0.0855, loss_bbox=0.5658, matched_ious=0.5502, loss_iou=0.0899, loss_iou_reg=0.2155, d_time=0.01(0.01), f_time=1.37(1.44), b_time=1.37(1.45)  Time cost: 1:00:17/33:10 [14:57:32/16:07:34]  Acc_iter 37250       Data time: 0.01(0.01)  Forward time: 1.37(1.44)  Batch time: 1.37(1.45)
2025-09-04 00:14:32,469   INFO  Train:   10/20 ( 50%) [2541/3862 ( 66%)]  Loss: 1.808 (1.45)  LR: 9.536e-04  Grad: 20.9603  max=0.6919(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6952(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4797, loss_cls=0.0835, loss_bbox=0.5593, matched_ious=0.5500, loss_iou=0.0892, loss_iou_reg=0.2146, d_time=0.01(0.01), f_time=1.27(1.44), b_time=1.28(1.45)  Time cost: 1:01:28/31:56 [14:58:43/16:05:55]  Acc_iter 37300       Data time: 0.01(0.01)  Forward time: 1.27(1.44)  Batch time: 1.28(1.45)
2025-09-04 00:15:50,266   INFO  Train:   10/20 ( 50%) [2591/3862 ( 67%)]  Loss: 1.433 (1.45)  LR: 9.529e-04  Grad: 20.9767  max=0.6946(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6971(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4890, loss_cls=0.0864, loss_bbox=0.5532, matched_ious=0.5511, loss_iou=0.0900, loss_iou_reg=0.2126, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.44(1.45)  Time cost: 1:02:46/30:46 [15:00:01/16:06:03]  Acc_iter 37350       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.44(1.45)
2025-09-04 00:17:02,605   INFO  Train:   10/20 ( 50%) [2641/3862 ( 68%)]  Loss: 1.173 (1.44)  LR: 9.522e-04  Grad: 21.1642  max=1.4397(module.vfe.pfn_layers.0.linear.weight)  min: -0.8557(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4740, loss_cls=0.0839, loss_bbox=0.5515, matched_ious=0.5509, loss_iou=0.0913, loss_iou_reg=0.2141, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.38(1.45)  Time cost: 1:03:58/29:34 [15:01:13/16:04:45]  Acc_iter 37400       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.38(1.45)
2025-09-04 00:18:14,207   INFO  Train:   10/20 ( 50%) [2691/3862 ( 70%)]  Loss: 1.304 (1.44)  LR: 9.515e-04  Grad: 21.1156  max=0.6959(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7053(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4827, loss_cls=0.0836, loss_bbox=0.5428, matched_ious=0.5587, loss_iou=0.0885, loss_iou_reg=0.2111, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 1:05:10/28:20 [15:02:25/16:03:17]  Acc_iter 37450       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-04 00:19:24,626   INFO  Train:   10/20 ( 50%) [2741/3862 ( 71%)]  Loss: 1.324 (1.44)  LR: 9.507e-04  Grad: 21.2062  max=0.6993(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7083(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4937, loss_cls=0.0839, loss_bbox=0.5322, matched_ious=0.5549, loss_iou=0.0890, loss_iou_reg=0.2136, d_time=0.00(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 1:06:20/27:07 [15:03:35/16:01:33]  Acc_iter 37500       Data time: 0.00(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-04 00:20:35,872   INFO  Train:   10/20 ( 50%) [2791/3862 ( 72%)]  Loss: 1.320 (1.44)  LR: 9.500e-04  Grad: 21.2389  max=0.7026(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7086(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4738, loss_cls=0.0819, loss_bbox=0.5533, matched_ious=0.5580, loss_iou=0.0895, loss_iou_reg=0.2103, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 1:07:31/25:54 [15:04:46/16:00:01]  Acc_iter 37550       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-04 00:21:53,975   INFO  Train:   10/20 ( 50%) [2841/3862 ( 74%)]  Loss: 1.387 (1.44)  LR: 9.493e-04  Grad: 21.2791  max=0.7041(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7107(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4961, loss_cls=0.0857, loss_bbox=0.5550, matched_ious=0.5557, loss_iou=0.0897, loss_iou_reg=0.2128, d_time=0.01(0.01), f_time=1.39(1.44), b_time=1.39(1.45)  Time cost: 1:08:50/24:43 [15:06:05/16:00:06]  Acc_iter 37600       Data time: 0.01(0.01)  Forward time: 1.39(1.44)  Batch time: 1.39(1.45)
2025-09-04 00:23:06,308   INFO  Train:   10/20 ( 50%) [2891/3862 ( 75%)]  Loss: 1.375 (1.44)  LR: 9.485e-04  Grad: 21.3554  max=0.7085(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7149(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4864, loss_cls=0.0848, loss_bbox=0.5575, matched_ious=0.5478, loss_iou=0.0907, loss_iou_reg=0.2175, d_time=0.03(0.01), f_time=1.69(1.44), b_time=1.72(1.45)  Time cost: 1:10:02/23:30 [15:07:17/15:58:49]  Acc_iter 37650       Data time: 0.03(0.01)  Forward time: 1.69(1.44)  Batch time: 1.72(1.45)
2025-09-04 00:24:16,964   INFO  Train:   10/20 ( 50%) [2941/3862 ( 76%)]  Loss: 1.595 (1.44)  LR: 9.478e-04  Grad: 21.3825  max=0.7098(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7175(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4897, loss_cls=0.0832, loss_bbox=0.5413, matched_ious=0.5600, loss_iou=0.0882, loss_iou_reg=0.2095, d_time=0.01(0.01), f_time=1.36(1.44), b_time=1.37(1.45)  Time cost: 1:11:12/22:17 [15:08:28/15:57:09]  Acc_iter 37700       Data time: 0.01(0.01)  Forward time: 1.36(1.44)  Batch time: 1.37(1.45)
2025-09-04 00:25:27,892   INFO  Train:   10/20 ( 50%) [2991/3862 ( 77%)]  Loss: 1.294 (1.44)  LR: 9.470e-04  Grad: 21.4609  max=0.7082(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7485(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4774, loss_cls=0.0839, loss_bbox=0.5328, matched_ious=0.5572, loss_iou=0.0881, loss_iou_reg=0.2118, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 1:12:23/21:04 [15:09:39/15:55:34]  Acc_iter 37750       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-04 00:26:38,192   INFO  Train:   10/20 ( 50%) [3041/3862 ( 79%)]  Loss: 1.303 (1.44)  LR: 9.462e-04  Grad: 21.5200  max=0.7109(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7258(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4905, loss_cls=0.0847, loss_bbox=0.5462, matched_ious=0.5522, loss_iou=0.0907, loss_iou_reg=0.2132, d_time=0.01(0.01), f_time=1.47(1.44), b_time=1.48(1.45)  Time cost: 1:13:34/19:51 [15:10:49/15:53:52]  Acc_iter 37800       Data time: 0.01(0.01)  Forward time: 1.47(1.44)  Batch time: 1.48(1.45)
2025-09-04 00:27:56,077   INFO  Train:   10/20 ( 50%) [3091/3862 ( 80%)]  Loss: 1.265 (1.44)  LR: 9.455e-04  Grad: 21.5749  max=0.7128(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7272(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4830, loss_cls=0.0813, loss_bbox=0.5431, matched_ious=0.5587, loss_iou=0.0892, loss_iou_reg=0.2125, d_time=0.01(0.01), f_time=1.45(1.44), b_time=1.46(1.45)  Time cost: 1:14:52/18:40 [15:12:07/15:53:47]  Acc_iter 37850       Data time: 0.01(0.01)  Forward time: 1.45(1.44)  Batch time: 1.46(1.45)
2025-09-04 00:29:07,855   INFO  Train:   10/20 ( 50%) [3141/3862 ( 81%)]  Loss: 1.495 (1.44)  LR: 9.447e-04  Grad: 21.6418  max=0.7153(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7291(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.5010, loss_cls=0.0852, loss_bbox=0.5637, matched_ious=0.5565, loss_iou=0.0900, loss_iou_reg=0.2115, d_time=0.00(0.01), f_time=1.36(1.44), b_time=1.36(1.45)  Time cost: 1:16:03/17:27 [15:13:18/15:52:24]  Acc_iter 37900       Data time: 0.00(0.01)  Forward time: 1.36(1.44)  Batch time: 1.36(1.45)
2025-09-04 00:30:18,464   INFO  Train:   10/20 ( 50%) [3191/3862 ( 83%)]  Loss: 1.496 (1.44)  LR: 9.439e-04  Grad: 21.6889  max=0.7185(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7353(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4873, loss_cls=0.0829, loss_bbox=0.5545, matched_ious=0.5571, loss_iou=0.0886, loss_iou_reg=0.2094, d_time=0.00(0.01), f_time=1.37(1.44), b_time=1.37(1.45)  Time cost: 1:17:14/16:14 [15:14:29/15:50:46]  Acc_iter 37950       Data time: 0.00(0.01)  Forward time: 1.37(1.44)  Batch time: 1.37(1.45)
2025-09-04 00:31:29,517   INFO  Train:   10/20 ( 50%) [3241/3862 ( 84%)]  Loss: 1.348 (1.44)  LR: 9.432e-04  Grad: 21.7306  max=0.7201(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7335(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4821, loss_cls=0.0828, loss_bbox=0.5204, matched_ious=0.5629, loss_iou=0.0881, loss_iou_reg=0.2102, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 1:18:25/15:01 [15:15:40/15:49:15]  Acc_iter 38000       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-04 00:32:40,371   INFO  Train:   10/20 ( 50%) [3291/3862 ( 85%)]  Loss: 1.281 (1.44)  LR: 9.424e-04  Grad: 21.7639  max=0.7196(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7370(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4934, loss_cls=0.0812, loss_bbox=0.5473, matched_ious=0.5579, loss_iou=0.0883, loss_iou_reg=0.2109, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 1:19:36/13:48 [15:16:51/15:47:42]  Acc_iter 38050       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-04 00:33:59,555   INFO  Train:   10/20 ( 50%) [3341/3862 ( 87%)]  Loss: 1.281 (1.44)  LR: 9.416e-04  Grad: 21.8335  max=0.7223(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7396(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4852, loss_cls=0.0845, loss_bbox=0.5609, matched_ious=0.5578, loss_iou=0.0884, loss_iou_reg=0.2108, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 1:20:55/12:36 [15:18:10/15:47:47]  Acc_iter 38100       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-04 00:35:10,729   INFO  Train:   10/20 ( 50%) [3391/3862 ( 88%)]  Loss: 1.704 (1.44)  LR: 9.408e-04  Grad: 21.8731  max=0.7237(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7409(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4749, loss_cls=0.0816, loss_bbox=0.5436, matched_ious=0.5601, loss_iou=0.0887, loss_iou_reg=0.2095, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.45(1.45)  Time cost: 1:22:06/11:24 [15:19:21/15:46:18]  Acc_iter 38150       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.45)
2025-09-04 00:36:21,939   INFO  Train:   10/20 ( 50%) [3441/3862 ( 89%)]  Loss: 1.575 (1.44)  LR: 9.400e-04  Grad: 21.9037  max=0.7299(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7401(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4788, loss_cls=0.0802, loss_bbox=0.5499, matched_ious=0.5581, loss_iou=0.0881, loss_iou_reg=0.2125, d_time=0.00(0.01), f_time=1.29(1.44), b_time=1.29(1.45)  Time cost: 1:23:17/10:11 [15:20:33/15:44:49]  Acc_iter 38200       Data time: 0.00(0.01)  Forward time: 1.29(1.44)  Batch time: 1.29(1.45)
2025-09-04 00:37:33,313   INFO  Train:   10/20 ( 50%) [3491/3862 ( 90%)]  Loss: 1.335 (1.44)  LR: 9.392e-04  Grad: 21.9596  max=0.7339(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7444(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4684, loss_cls=0.0822, loss_bbox=0.5388, matched_ious=0.5560, loss_iou=0.0898, loss_iou_reg=0.2129, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 1:24:29/08:58 [15:21:44/15:43:23]  Acc_iter 38250       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-04 00:38:45,560   INFO  Train:   10/20 ( 50%) [3541/3862 ( 92%)]  Loss: 1.320 (1.44)  LR: 9.384e-04  Grad: 22.0046  max=0.7341(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7465(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4837, loss_cls=0.0850, loss_bbox=0.5414, matched_ious=0.5576, loss_iou=0.0876, loss_iou_reg=0.2104, d_time=0.00(0.01), f_time=1.51(1.44), b_time=1.52(1.45)  Time cost: 1:25:41/07:45 [15:22:56/15:42:06]  Acc_iter 38300       Data time: 0.00(0.01)  Forward time: 1.51(1.44)  Batch time: 1.52(1.45)
2025-09-04 00:40:01,104   INFO  Train:   10/20 ( 50%) [3591/3862 ( 93%)]  Loss: 1.523 (1.44)  LR: 9.375e-04  Grad: 22.0970  max=0.7372(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7503(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4757, loss_cls=0.0824, loss_bbox=0.5364, matched_ious=0.5617, loss_iou=0.0869, loss_iou_reg=0.2096, d_time=0.01(0.01), f_time=1.52(1.44), b_time=1.54(1.45)  Time cost: 1:26:57/06:33 [15:24:12/15:41:26]  Acc_iter 38350       Data time: 0.01(0.01)  Forward time: 1.52(1.44)  Batch time: 1.54(1.45)
2025-09-04 00:41:12,299   INFO  Train:   10/20 ( 50%) [3641/3862 ( 94%)]  Loss: 1.354 (1.44)  LR: 9.367e-04  Grad: 22.1319  max=0.7433(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7515(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4784, loss_cls=0.0815, loss_bbox=0.5382, matched_ious=0.5644, loss_iou=0.0878, loss_iou_reg=0.2083, d_time=0.01(0.01), f_time=1.52(1.44), b_time=1.52(1.45)  Time cost: 1:28:08/05:20 [15:25:23/15:39:58]  Acc_iter 38400       Data time: 0.01(0.01)  Forward time: 1.52(1.44)  Batch time: 1.52(1.45)
2025-09-04 00:42:22,915   INFO  Train:   10/20 ( 50%) [3691/3862 ( 96%)]  Loss: 1.207 (1.44)  LR: 9.359e-04  Grad: 22.1718  max=0.7410(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7536(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4707, loss_cls=0.0793, loss_bbox=0.5216, matched_ious=0.5572, loss_iou=0.0899, loss_iou_reg=0.2113, d_time=0.00(0.01), f_time=1.41(1.44), b_time=1.41(1.45)  Time cost: 1:29:18/04:08 [15:26:34/15:38:25]  Acc_iter 38450       Data time: 0.00(0.01)  Forward time: 1.41(1.44)  Batch time: 1.41(1.45)
2025-09-04 00:43:34,273   INFO  Train:   10/20 ( 50%) [3741/3862 ( 97%)]  Loss: 1.416 (1.43)  LR: 9.350e-04  Grad: 22.2409  max=0.7431(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7561(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4778, loss_cls=0.0831, loss_bbox=0.5335, matched_ious=0.5570, loss_iou=0.0888, loss_iou_reg=0.2124, d_time=0.01(0.01), f_time=1.39(1.44), b_time=1.40(1.45)  Time cost: 1:30:30/02:55 [15:27:45/15:36:59]  Acc_iter 38500       Data time: 0.01(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.45)
2025-09-04 00:44:48,758   INFO  Train:   10/20 ( 50%) [3791/3862 ( 98%)]  Loss: 1.304 (1.43)  LR: 9.342e-04  Grad: 22.2974  max=0.7467(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7608(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4813, loss_cls=0.0836, loss_bbox=0.5408, matched_ious=0.5540, loss_iou=0.0891, loss_iou_reg=0.2122, d_time=0.00(0.01), f_time=2.13(1.44), b_time=2.14(1.45)  Time cost: 1:31:44/01:43 [15:28:59/15:36:07]  Acc_iter 38550       Data time: 0.00(0.01)  Forward time: 2.13(1.44)  Batch time: 2.14(1.45)
2025-09-04 00:46:02,728   INFO  Train:   10/20 ( 50%) [3841/3862 ( 99%)]  Loss: 1.546 (1.43)  LR: 9.334e-04  Grad: 22.3275  max=0.7494(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7618(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4808, loss_cls=0.0826, loss_bbox=0.5513, matched_ious=0.5571, loss_iou=0.0885, loss_iou_reg=0.2100, d_time=0.00(0.01), f_time=1.30(1.44), b_time=1.31(1.45)  Time cost: 1:32:58/00:30 [15:30:13/15:35:08]  Acc_iter 38600       Data time: 0.00(0.01)  Forward time: 1.30(1.44)  Batch time: 1.31(1.45)
2025-09-04 00:46:29,716   INFO  Train:   10/20 ( 50%) [3861/3862 (100%)]  Loss: 1.208 (1.43)  LR: 9.330e-04  Grad: 22.4462  max=0.7548(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.4187(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4679, loss_cls=0.0811, loss_bbox=0.4859, matched_ious=0.5640, loss_iou=0.0877, loss_iou_reg=0.2095, d_time=0.00(0.01), f_time=1.31(1.44), b_time=1.31(1.45)  Time cost: 1:33:25/00:01 [15:30:40/15:34:18]  Acc_iter 38620       Data time: 0.00(0.01)  Forward time: 1.31(1.44)  Batch time: 1.31(1.45)

                                               [Aepochs:  50%|█████     | 10/20 [15:30:41<15:33:05, 5598.55s/it]epochs:  50%|█████     | 10/20 [15:30:41<15:33:05, 5598.55s/it]epochs:  50%|█████     | 10/20 [15:30:41<15:33:05, 5598.55s/it]epochs:  50%|█████     | 10/20 [15:30:41<15:33:05, 5598.56s/it]epochs:  50%|█████     | 10/20 [15:30:41<15:33:05, 5598.57s/it]epochs:  50%|█████     | 10/20 [15:30:41<15:33:05, 5598.56s/it]epochs:  50%|█████     | 10/20 [15:30:41<15:33:05, 5598.57s/it]epochs:  50%|█████     | 10/20 [15:30:41<15:33:05, 5598.56s/it]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-04 00:46:35,544   INFO  Train:   11/20 ( 55%) [   0/3862 (  0%)]  Loss: 1.518 (1.52)  LR: 9.330e-04  Grad: 22.3916  max=0.7537(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7624(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4605, loss_cls=0.0860, loss_bbox=0.6622, matched_ious=0.5597, loss_iou=0.0940, loss_iou_reg=0.2158, d_time=1.73(1.73), f_time=2.89(2.89), b_time=4.62(4.62)  Time cost: 00:04/4:37:21 [15:30:46/46:13:35]  Acc_iter 38621       Data time: 1.73(1.73)  Forward time: 2.89(2.89)  Batch time: 4.62(4.62)
2025-09-04 00:47:17,431   INFO  Train:   11/20 ( 55%) [  29/3862 (  1%)]  Loss: 1.435 (1.44)  LR: 9.325e-04  Grad: 22.4001  max=0.7517(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7647(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4915, loss_cls=0.0837, loss_bbox=0.5595, matched_ious=0.5582, loss_iou=0.0880, loss_iou_reg=0.2097, d_time=0.03(0.07), f_time=1.45(1.48), b_time=1.48(1.55)  Time cost: 00:46/1:38:22 [15:31:28/16:30:30]  Acc_iter 38650       Data time: 0.03(0.07)  Forward time: 1.45(1.48)  Batch time: 1.48(1.55)
2025-09-04 00:48:29,343   INFO  Train:   11/20 ( 55%) [  79/3862 (  2%)]  Loss: 1.207 (1.37)  LR: 9.317e-04  Grad: 22.4535  max=0.7564(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7684(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4496, loss_cls=0.0763, loss_bbox=0.5024, matched_ious=0.5623, loss_iou=0.0893, loss_iou_reg=0.2106, d_time=0.01(0.03), f_time=1.55(1.45), b_time=1.55(1.48)  Time cost: 01:58/1:33:05 [15:32:40/15:48:21]  Acc_iter 38700       Data time: 0.01(0.03)  Forward time: 1.55(1.45)  Batch time: 1.55(1.48)
2025-09-04 00:49:40,342   INFO  Train:   11/20 ( 55%) [ 129/3862 (  3%)]  Loss: 1.577 (1.37)  LR: 9.308e-04  Grad: 19.0658  max=0.6425(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6511(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4723, loss_cls=0.0815, loss_bbox=0.5296, matched_ious=0.5584, loss_iou=0.0891, loss_iou_reg=0.2103, d_time=0.01(0.02), f_time=1.37(1.44), b_time=1.38(1.46)  Time cost: 03:09/1:30:30 [15:33:51/15:33:12]  Acc_iter 38750       Data time: 0.01(0.02)  Forward time: 1.37(1.44)  Batch time: 1.38(1.46)
2025-09-04 00:50:56,170   INFO  Train:   11/20 ( 55%) [ 179/3862 (  5%)]  Loss: 1.309 (1.38)  LR: 9.299e-04  Grad: 19.0760  max=0.6408(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6500(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4853, loss_cls=0.0834, loss_bbox=0.5344, matched_ious=0.5635, loss_iou=0.0874, loss_iou_reg=0.2076, d_time=0.66(0.02), f_time=1.31(1.45), b_time=1.97(1.47)  Time cost: 04:24/1:30:20 [15:35:07/15:42:59]  Acc_iter 38800       Data time: 0.66(0.02)  Forward time: 1.31(1.45)  Batch time: 1.97(1.47)
2025-09-04 00:52:11,047   INFO  Train:   11/20 ( 55%) [ 229/3862 (  6%)]  Loss: 1.400 (1.38)  LR: 9.291e-04  Grad: 19.1376  max=0.6452(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6563(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4718, loss_cls=0.0813, loss_bbox=0.5368, matched_ious=0.5615, loss_iou=0.0876, loss_iou_reg=0.2109, d_time=0.00(0.02), f_time=1.46(1.46), b_time=1.46(1.48)  Time cost: 05:39/1:29:27 [15:36:22/15:45:20]  Acc_iter 38850       Data time: 0.00(0.02)  Forward time: 1.46(1.46)  Batch time: 1.46(1.48)
2025-09-04 00:53:21,459   INFO  Train:   11/20 ( 55%) [ 279/3862 (  7%)]  Loss: 1.056 (1.38)  LR: 9.282e-04  Grad: 19.1884  max=0.6449(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6569(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4802, loss_cls=0.0826, loss_bbox=0.5355, matched_ious=0.5578, loss_iou=0.0882, loss_iou_reg=0.2106, d_time=0.00(0.02), f_time=1.36(1.45), b_time=1.37(1.47)  Time cost: 06:50/1:27:29 [15:37:32/15:36:13]  Acc_iter 38900       Data time: 0.00(0.02)  Forward time: 1.36(1.45)  Batch time: 1.37(1.47)
2025-09-04 00:54:32,372   INFO  Train:   11/20 ( 55%) [ 329/3862 (  9%)]  Loss: 1.294 (1.38)  LR: 9.273e-04  Grad: 19.2503  max=0.7513(module.vfe.pfn_layers.0.linear.weight)  min: -0.6585(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4652, loss_cls=0.0797, loss_bbox=0.5056, matched_ious=0.5628, loss_iou=0.0887, loss_iou_reg=0.2094, d_time=0.01(0.01), f_time=1.39(1.44), b_time=1.40(1.46)  Time cost: 08:01/1:25:51 [15:38:43/15:30:28]  Acc_iter 38950       Data time: 0.01(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.46)
2025-09-04 00:55:44,256   INFO  Train:   11/20 ( 55%) [ 379/3862 ( 10%)]  Loss: 1.344 (1.38)  LR: 9.264e-04  Grad: 19.2848  max=0.6459(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6646(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4758, loss_cls=0.0825, loss_bbox=0.5378, matched_ious=0.5560, loss_iou=0.0898, loss_iou_reg=0.2100, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.42(1.46)  Time cost: 09:13/1:24:28 [15:39:55/15:27:32]  Acc_iter 39000       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.46)
2025-09-04 00:56:58,496   INFO  Train:   11/20 ( 55%) [ 429/3862 ( 11%)]  Loss: 1.067 (1.38)  LR: 9.256e-04  Grad: 19.3300  max=0.6540(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6639(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4869, loss_cls=0.0847, loss_bbox=0.5304, matched_ious=0.5590, loss_iou=0.0899, loss_iou_reg=0.2107, d_time=0.00(0.01), f_time=1.42(1.45), b_time=1.43(1.46)  Time cost: 10:27/1:23:27 [15:41:09/15:28:31]  Acc_iter 39050       Data time: 0.00(0.01)  Forward time: 1.42(1.45)  Batch time: 1.43(1.46)
2025-09-04 00:58:11,783   INFO  Train:   11/20 ( 55%) [ 479/3862 ( 12%)]  Loss: 1.494 (1.39)  LR: 9.247e-04  Grad: 19.3740  max=0.6735(module.vfe.pfn_layers.0.linear.weight)  min: -0.6682(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4771, loss_cls=0.0813, loss_bbox=0.5488, matched_ious=0.5603, loss_iou=0.0886, loss_iou_reg=0.2101, d_time=0.01(0.01), f_time=1.49(1.45), b_time=1.50(1.46)  Time cost: 11:40/1:22:17 [15:42:22/15:27:45]  Acc_iter 39100       Data time: 0.01(0.01)  Forward time: 1.49(1.45)  Batch time: 1.50(1.46)
2025-09-04 00:59:22,989   INFO  Train:   11/20 ( 55%) [ 529/3862 ( 14%)]  Loss: 1.606 (1.39)  LR: 9.238e-04  Grad: 19.4250  max=0.6609(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6720(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4843, loss_cls=0.0846, loss_bbox=0.5320, matched_ious=0.5567, loss_iou=0.0889, loss_iou_reg=0.2121, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.45(1.46)  Time cost: 12:51/1:20:53 [15:43:34/15:24:26]  Acc_iter 39150       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.46)
2025-09-04 01:00:34,292   INFO  Train:   11/20 ( 55%) [ 579/3862 ( 15%)]  Loss: 1.808 (1.39)  LR: 9.229e-04  Grad: 19.4491  max=0.6629(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6697(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4671, loss_cls=0.0795, loss_bbox=0.5316, matched_ious=0.5600, loss_iou=0.0886, loss_iou_reg=0.2100, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 14:03/1:19:32 [15:44:45/15:21:34]  Acc_iter 39200       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-04 01:01:45,930   INFO  Train:   11/20 ( 55%) [ 629/3862 ( 16%)]  Loss: 1.504 (1.38)  LR: 9.220e-04  Grad: 20.1800  max=3.7986(module.vfe.pfn_layers.0.linear.weight)  min: -2.4749(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4587, loss_cls=0.0787, loss_bbox=0.5242, matched_ious=0.5659, loss_iou=0.0862, loss_iou_reg=0.2063, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 15:14/1:18:14 [15:45:57/15:19:19]  Acc_iter 39250       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-04 01:02:59,871   INFO  Train:   11/20 ( 55%) [ 679/3862 ( 18%)]  Loss: 1.259 (1.39)  LR: 9.211e-04  Grad: 19.5668  max=0.6673(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6717(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4900, loss_cls=0.0852, loss_bbox=0.5430, matched_ious=0.5615, loss_iou=0.0885, loss_iou_reg=0.2078, d_time=0.01(0.01), f_time=1.29(1.44), b_time=1.29(1.45)  Time cost: 16:28/1:17:07 [15:47:10/15:19:21]  Acc_iter 39300       Data time: 0.01(0.01)  Forward time: 1.29(1.44)  Batch time: 1.29(1.45)
2025-09-04 01:04:13,066   INFO  Train:   11/20 ( 55%) [ 729/3862 ( 19%)]  Loss: 1.313 (1.39)  LR: 9.201e-04  Grad: 19.5999  max=0.6678(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6741(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4830, loss_cls=0.0811, loss_bbox=0.5377, matched_ious=0.5599, loss_iou=0.0889, loss_iou_reg=0.2108, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 17:41/1:15:57 [15:48:24/15:18:35]  Acc_iter 39350       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-04 01:05:24,220   INFO  Train:   11/20 ( 55%) [ 779/3862 ( 20%)]  Loss: 1.290 (1.39)  LR: 9.192e-04  Grad: 21.1039  max=6.9271(module.vfe.pfn_layers.0.linear.weight)  min: -2.0542(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4679, loss_cls=0.0795, loss_bbox=0.5377, matched_ious=0.5596, loss_iou=0.0887, loss_iou_reg=0.2102, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 18:52/1:14:38 [15:49:35/15:16:05]  Acc_iter 39400       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-04 01:06:35,362   INFO  Train:   11/20 ( 55%) [ 829/3862 ( 21%)]  Loss: 1.454 (1.38)  LR: 9.183e-04  Grad: 19.7136  max=0.6723(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6808(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4632, loss_cls=0.0789, loss_bbox=0.5071, matched_ious=0.5665, loss_iou=0.0880, loss_iou_reg=0.2079, d_time=0.00(0.01), f_time=1.32(1.44), b_time=1.32(1.45)  Time cost: 20:04/1:13:20 [15:50:46/15:13:45]  Acc_iter 39450       Data time: 0.00(0.01)  Forward time: 1.32(1.44)  Batch time: 1.32(1.45)
2025-09-04 01:07:46,242   INFO  Train:   11/20 ( 55%) [ 879/3862 ( 23%)]  Loss: 1.230 (1.39)  LR: 9.174e-04  Grad: 19.7754  max=0.9026(module.vfe.pfn_layers.0.linear.weight)  min: -0.6831(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4851, loss_cls=0.0827, loss_bbox=0.5659, matched_ious=0.5559, loss_iou=0.0894, loss_iou_reg=0.2115, d_time=0.00(0.01), f_time=1.46(1.44), b_time=1.47(1.45)  Time cost: 21:15/1:12:01 [15:51:57/15:11:21]  Acc_iter 39500       Data time: 0.00(0.01)  Forward time: 1.46(1.44)  Batch time: 1.47(1.45)
2025-09-04 01:09:01,378   INFO  Train:   11/20 ( 55%) [ 929/3862 ( 24%)]  Loss: 1.240 (1.39)  LR: 9.164e-04  Grad: 19.7853  max=0.6780(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6870(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4812, loss_cls=0.0829, loss_bbox=0.5412, matched_ious=0.5620, loss_iou=0.0889, loss_iou_reg=0.2083, d_time=0.00(0.01), f_time=1.34(1.44), b_time=1.35(1.45)  Time cost: 22:30/1:10:58 [15:53:12/15:11:58]  Acc_iter 39550       Data time: 0.00(0.01)  Forward time: 1.34(1.44)  Batch time: 1.35(1.45)
2025-09-04 01:10:13,895   INFO  Train:   11/20 ( 55%) [ 979/3862 ( 25%)]  Loss: 1.252 (1.39)  LR: 9.155e-04  Grad: 19.8536  max=0.6786(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6893(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4747, loss_cls=0.0806, loss_bbox=0.5344, matched_ious=0.5549, loss_iou=0.0907, loss_iou_reg=0.2126, d_time=0.01(0.01), f_time=1.45(1.44), b_time=1.45(1.45)  Time cost: 23:42/1:09:45 [15:54:25/15:10:43]  Acc_iter 39600       Data time: 0.01(0.01)  Forward time: 1.45(1.44)  Batch time: 1.45(1.45)
2025-09-04 01:11:25,272   INFO  Train:   11/20 ( 55%) [1029/3862 ( 27%)]  Loss: 1.410 (1.39)  LR: 9.145e-04  Grad: 19.9318  max=0.6817(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6928(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4865, loss_cls=0.0820, loss_bbox=0.5397, matched_ious=0.5584, loss_iou=0.0894, loss_iou_reg=0.2112, d_time=0.01(0.01), f_time=1.48(1.44), b_time=1.48(1.45)  Time cost: 24:54/1:08:29 [15:55:36/15:08:46]  Acc_iter 39650       Data time: 0.01(0.01)  Forward time: 1.48(1.44)  Batch time: 1.48(1.45)
2025-09-04 01:12:36,773   INFO  Train:   11/20 ( 55%) [1079/3862 ( 28%)]  Loss: 1.429 (1.39)  LR: 9.136e-04  Grad: 19.9855  max=0.6875(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6921(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4493, loss_cls=0.0786, loss_bbox=0.5378, matched_ious=0.5584, loss_iou=0.0891, loss_iou_reg=0.2118, d_time=0.00(0.01), f_time=1.38(1.44), b_time=1.38(1.45)  Time cost: 26:05/1:07:14 [15:56:47/15:06:58]  Acc_iter 39700       Data time: 0.00(0.01)  Forward time: 1.38(1.44)  Batch time: 1.38(1.45)
2025-09-04 01:13:48,644   INFO  Train:   11/20 ( 55%) [1129/3862 ( 29%)]  Loss: 1.241 (1.39)  LR: 9.126e-04  Grad: 20.0041  max=0.6904(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6955(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4749, loss_cls=0.0814, loss_bbox=0.5345, matched_ious=0.5579, loss_iou=0.0882, loss_iou_reg=0.2118, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 27:17/1:06:00 [15:57:59/15:05:25]  Acc_iter 39750       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-04 01:15:03,265   INFO  Train:   11/20 ( 55%) [1179/3862 ( 31%)]  Loss: 1.595 (1.39)  LR: 9.117e-04  Grad: 20.0415  max=0.6930(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6964(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4787, loss_cls=0.0835, loss_bbox=0.5703, matched_ious=0.5577, loss_iou=0.0896, loss_iou_reg=0.2113, d_time=0.42(0.01), f_time=1.40(1.44), b_time=1.82(1.45)  Time cost: 28:32/1:04:52 [15:59:14/15:05:22]  Acc_iter 39800       Data time: 0.42(0.01)  Forward time: 1.40(1.44)  Batch time: 1.82(1.45)
2025-09-04 01:16:15,034   INFO  Train:   11/20 ( 55%) [1229/3862 ( 32%)]  Loss: 1.473 (1.39)  LR: 9.107e-04  Grad: 20.0781  max=0.6935(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.6954(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4748, loss_cls=0.0806, loss_bbox=0.5251, matched_ious=0.5624, loss_iou=0.0871, loss_iou_reg=0.2099, d_time=0.00(0.01), f_time=1.37(1.44), b_time=1.37(1.45)  Time cost: 29:43/1:03:38 [16:00:26/15:03:45]  Acc_iter 39850       Data time: 0.00(0.01)  Forward time: 1.37(1.44)  Batch time: 1.37(1.45)
2025-09-04 01:17:26,768   INFO  Train:   11/20 ( 55%) [1279/3862 ( 33%)]  Loss: 1.323 (1.39)  LR: 9.097e-04  Grad: 20.1296  max=0.6953(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7033(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4714, loss_cls=0.0812, loss_bbox=0.5472, matched_ious=0.5600, loss_iou=0.0882, loss_iou_reg=0.2089, d_time=0.00(0.01), f_time=1.52(1.44), b_time=1.53(1.45)  Time cost: 30:55/1:02:24 [16:01:37/15:02:10]  Acc_iter 39900       Data time: 0.00(0.01)  Forward time: 1.52(1.44)  Batch time: 1.53(1.45)
2025-09-04 01:18:38,212   INFO  Train:   11/20 ( 55%) [1329/3862 ( 34%)]  Loss: 1.588 (1.39)  LR: 9.088e-04  Grad: 20.2035  max=0.6938(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7061(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4766, loss_cls=0.0811, loss_bbox=0.5488, matched_ious=0.5626, loss_iou=0.0881, loss_iou_reg=0.2084, d_time=0.00(0.01), f_time=1.34(1.44), b_time=1.35(1.45)  Time cost: 32:06/1:01:09 [16:02:49/15:00:29]  Acc_iter 39950       Data time: 0.00(0.01)  Forward time: 1.34(1.44)  Batch time: 1.35(1.45)
2025-09-04 01:19:50,573   INFO  Train:   11/20 ( 55%) [1379/3862 ( 36%)]  Loss: 1.271 (1.39)  LR: 9.078e-04  Grad: 20.2458  max=0.6958(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7056(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4701, loss_cls=0.0797, loss_bbox=0.5235, matched_ious=0.5554, loss_iou=0.0889, loss_iou_reg=0.2112, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 33:19/59:57 [16:04:01/14:59:14]  Acc_iter 40000       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-04 01:21:05,813   INFO  Train:   11/20 ( 55%) [1429/3862 ( 37%)]  Loss: 1.482 (1.39)  LR: 9.068e-04  Grad: 20.3150  max=0.7033(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7076(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4709, loss_cls=0.0821, loss_bbox=0.5404, matched_ious=0.5599, loss_iou=0.0883, loss_iou_reg=0.2097, d_time=0.01(0.01), f_time=1.53(1.44), b_time=1.53(1.45)  Time cost: 34:34/58:49 [16:05:16/14:59:14]  Acc_iter 40050       Data time: 0.01(0.01)  Forward time: 1.53(1.44)  Batch time: 1.53(1.45)
2025-09-04 01:22:17,843   INFO  Train:   11/20 ( 55%) [1479/3862 ( 38%)]  Loss: 1.595 (1.39)  LR: 9.058e-04  Grad: 20.3284  max=0.7067(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7094(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4791, loss_cls=0.0838, loss_bbox=0.5310, matched_ious=0.5612, loss_iou=0.0878, loss_iou_reg=0.2100, d_time=0.00(0.01), f_time=1.47(1.44), b_time=1.47(1.45)  Time cost: 35:46/57:36 [16:06:28/14:57:49]  Acc_iter 40100       Data time: 0.00(0.01)  Forward time: 1.47(1.44)  Batch time: 1.47(1.45)
2025-09-04 01:23:28,263   INFO  Train:   11/20 ( 55%) [1529/3862 ( 40%)]  Loss: 1.613 (1.39)  LR: 9.048e-04  Grad: 20.4089  max=0.7081(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7143(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4884, loss_cls=0.0825, loss_bbox=0.5403, matched_ious=0.5536, loss_iou=0.0902, loss_iou_reg=0.2131, d_time=0.01(0.01), f_time=1.47(1.44), b_time=1.48(1.45)  Time cost: 36:57/56:20 [16:07:39/14:55:46]  Acc_iter 40150       Data time: 0.01(0.01)  Forward time: 1.47(1.44)  Batch time: 1.48(1.45)
2025-09-04 01:24:40,043   INFO  Train:   11/20 ( 55%) [1579/3862 ( 41%)]  Loss: 1.492 (1.39)  LR: 9.038e-04  Grad: 20.4528  max=0.7100(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7202(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4549, loss_cls=0.0791, loss_bbox=0.5333, matched_ious=0.5666, loss_iou=0.0873, loss_iou_reg=0.2071, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 38:08/55:07 [16:08:51/14:54:18]  Acc_iter 40200       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-04 01:25:50,762   INFO  Train:   11/20 ( 55%) [1629/3862 ( 42%)]  Loss: 1.441 (1.39)  LR: 9.028e-04  Grad: 20.5261  max=0.7129(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7203(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4838, loss_cls=0.0822, loss_bbox=0.5411, matched_ious=0.5625, loss_iou=0.0881, loss_iou_reg=0.2086, d_time=0.00(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 39:19/53:52 [16:10:01/14:52:26]  Acc_iter 40250       Data time: 0.00(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-04 01:27:06,506   INFO  Train:   11/20 ( 55%) [1679/3862 ( 43%)]  Loss: 1.187 (1.39)  LR: 9.018e-04  Grad: 20.5434  max=0.7136(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7228(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4673, loss_cls=0.0816, loss_bbox=0.5239, matched_ious=0.5641, loss_iou=0.0879, loss_iou_reg=0.2086, d_time=0.00(0.01), f_time=1.41(1.44), b_time=1.41(1.45)  Time cost: 40:35/52:44 [16:11:17/14:52:28]  Acc_iter 40300       Data time: 0.00(0.01)  Forward time: 1.41(1.44)  Batch time: 1.41(1.45)
2025-09-04 01:28:18,350   INFO  Train:   11/20 ( 55%) [1729/3862 ( 45%)]  Loss: 1.673 (1.39)  LR: 9.008e-04  Grad: 20.5860  max=0.7132(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7195(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4576, loss_cls=0.0797, loss_bbox=0.5482, matched_ious=0.5601, loss_iou=0.0897, loss_iou_reg=0.2111, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.43(1.45)  Time cost: 41:47/51:31 [16:12:29/14:51:02]  Acc_iter 40350       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.43(1.45)
2025-09-04 01:29:29,324   INFO  Train:   11/20 ( 55%) [1779/3862 ( 46%)]  Loss: 1.634 (1.39)  LR: 8.998e-04  Grad: 20.6497  max=0.7164(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7251(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4686, loss_cls=0.0803, loss_bbox=0.5295, matched_ious=0.5616, loss_iou=0.0883, loss_iou_reg=0.2084, d_time=0.01(0.01), f_time=1.34(1.44), b_time=1.35(1.45)  Time cost: 42:58/50:16 [16:13:40/14:49:19]  Acc_iter 40400       Data time: 0.01(0.01)  Forward time: 1.34(1.44)  Batch time: 1.35(1.45)
2025-09-04 01:30:41,150   INFO  Train:   11/20 ( 55%) [1829/3862 ( 47%)]  Loss: 1.400 (1.39)  LR: 8.988e-04  Grad: 20.7099  max=0.7199(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7285(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4580, loss_cls=0.0787, loss_bbox=0.5068, matched_ious=0.5640, loss_iou=0.0881, loss_iou_reg=0.2082, d_time=0.00(0.01), f_time=1.34(1.44), b_time=1.35(1.45)  Time cost: 44:09/49:03 [16:14:52/14:47:54]  Acc_iter 40450       Data time: 0.00(0.01)  Forward time: 1.34(1.44)  Batch time: 1.35(1.45)
2025-09-04 01:31:52,490   INFO  Train:   11/20 ( 55%) [1879/3862 ( 49%)]  Loss: 1.148 (1.39)  LR: 8.977e-04  Grad: 20.7885  max=0.8247(module.vfe.pfn_layers.0.linear.weight)  min: -1.3213(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4651, loss_cls=0.0800, loss_bbox=0.5299, matched_ious=0.5643, loss_iou=0.0876, loss_iou_reg=0.2077, d_time=0.01(0.01), f_time=1.33(1.44), b_time=1.34(1.45)  Time cost: 45:21/47:50 [16:16:03/14:46:21]  Acc_iter 40500       Data time: 0.01(0.01)  Forward time: 1.33(1.44)  Batch time: 1.34(1.45)
2025-09-04 01:33:08,529   INFO  Train:   11/20 ( 55%) [1929/3862 ( 50%)]  Loss: 1.656 (1.39)  LR: 8.967e-04  Grad: 20.7928  max=0.7283(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7336(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4609, loss_cls=0.0791, loss_bbox=0.5229, matched_ious=0.5631, loss_iou=0.0887, loss_iou_reg=0.2078, d_time=0.00(0.01), f_time=1.37(1.44), b_time=1.37(1.45)  Time cost: 46:37/46:41 [16:17:19/14:46:19]  Acc_iter 40550       Data time: 0.00(0.01)  Forward time: 1.37(1.44)  Batch time: 1.37(1.45)
2025-09-04 01:34:19,500   INFO  Train:   11/20 ( 55%) [1979/3862 ( 51%)]  Loss: 1.230 (1.39)  LR: 8.957e-04  Grad: 20.8396  max=0.7328(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7365(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4611, loss_cls=0.0802, loss_bbox=0.5249, matched_ious=0.5620, loss_iou=0.0887, loss_iou_reg=0.2090, d_time=0.00(0.01), f_time=1.37(1.44), b_time=1.37(1.45)  Time cost: 47:48/45:27 [16:18:30/14:44:38]  Acc_iter 40600       Data time: 0.00(0.01)  Forward time: 1.37(1.44)  Batch time: 1.37(1.45)
2025-09-04 01:35:30,794   INFO  Train:   11/20 ( 55%) [2029/3862 ( 53%)]  Loss: 1.726 (1.39)  LR: 8.946e-04  Grad: 20.9097  max=0.7285(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7367(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4850, loss_cls=0.0825, loss_bbox=0.5543, matched_ious=0.5631, loss_iou=0.0869, loss_iou_reg=0.2068, d_time=0.01(0.01), f_time=1.32(1.44), b_time=1.33(1.45)  Time cost: 48:59/44:14 [16:19:41/14:43:05]  Acc_iter 40650       Data time: 0.01(0.01)  Forward time: 1.32(1.44)  Batch time: 1.33(1.45)
2025-09-04 01:36:43,436   INFO  Train:   11/20 ( 55%) [2079/3862 ( 54%)]  Loss: 1.332 (1.39)  LR: 8.936e-04  Grad: 20.9425  max=0.7334(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7387(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4715, loss_cls=0.0824, loss_bbox=0.5157, matched_ious=0.5613, loss_iou=0.0875, loss_iou_reg=0.2095, d_time=0.01(0.01), f_time=1.36(1.44), b_time=1.37(1.45)  Time cost: 50:12/43:02 [16:20:54/14:41:57]  Acc_iter 40700       Data time: 0.01(0.01)  Forward time: 1.36(1.44)  Batch time: 1.37(1.45)
2025-09-04 01:37:55,141   INFO  Train:   11/20 ( 55%) [2129/3862 ( 55%)]  Loss: 1.194 (1.39)  LR: 8.926e-04  Grad: 21.6626  max=4.4634(module.vfe.pfn_layers.0.linear.weight)  min: -0.8751(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4672, loss_cls=0.0781, loss_bbox=0.5361, matched_ious=0.5575, loss_iou=0.0908, loss_iou_reg=0.2125, d_time=0.01(0.01), f_time=1.34(1.44), b_time=1.35(1.45)  Time cost: 51:23/41:49 [16:22:06/14:40:33]  Acc_iter 40750       Data time: 0.01(0.01)  Forward time: 1.34(1.44)  Batch time: 1.35(1.45)
2025-09-04 01:39:12,480   INFO  Train:   11/20 ( 55%) [2179/3862 ( 56%)]  Loss: 1.351 (1.39)  LR: 8.915e-04  Grad: 21.0535  max=0.7348(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7449(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4735, loss_cls=0.0813, loss_bbox=0.5257, matched_ious=0.5649, loss_iou=0.0879, loss_iou_reg=0.2090, d_time=0.01(0.01), f_time=1.53(1.44), b_time=1.54(1.45)  Time cost: 52:41/40:40 [16:23:23/14:40:43]  Acc_iter 40800       Data time: 0.01(0.01)  Forward time: 1.53(1.44)  Batch time: 1.54(1.45)
2025-09-04 01:40:24,216   INFO  Train:   11/20 ( 55%) [2229/3862 ( 58%)]  Loss: 1.545 (1.39)  LR: 8.904e-04  Grad: 21.0833  max=0.7423(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7445(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4615, loss_cls=0.0799, loss_bbox=0.5200, matched_ious=0.5632, loss_iou=0.0882, loss_iou_reg=0.2084, d_time=0.00(0.01), f_time=1.39(1.44), b_time=1.39(1.45)  Time cost: 53:52/39:27 [16:24:35/14:39:18]  Acc_iter 40850       Data time: 0.00(0.01)  Forward time: 1.39(1.44)  Batch time: 1.39(1.45)
2025-09-04 01:41:35,494   INFO  Train:   11/20 ( 55%) [2279/3862 ( 59%)]  Loss: 1.893 (1.39)  LR: 8.894e-04  Grad: 21.1824  max=1.3374(module.vfe.pfn_layers.0.linear.weight)  min: -0.7509(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4793, loss_cls=0.0831, loss_bbox=0.5156, matched_ious=0.5620, loss_iou=0.0886, loss_iou_reg=0.2087, d_time=0.00(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 55:04/38:14 [16:25:46/14:37:46]  Acc_iter 40900       Data time: 0.00(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-04 01:42:47,487   INFO  Train:   11/20 ( 55%) [2329/3862 ( 60%)]  Loss: 1.717 (1.39)  LR: 8.883e-04  Grad: 21.1889  max=0.7419(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9242(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4644, loss_cls=0.0794, loss_bbox=0.5366, matched_ious=0.5582, loss_iou=0.0878, loss_iou_reg=0.2102, d_time=0.00(0.01), f_time=1.37(1.44), b_time=1.37(1.45)  Time cost: 56:16/37:01 [16:26:58/14:36:26]  Acc_iter 40950       Data time: 0.00(0.01)  Forward time: 1.37(1.44)  Batch time: 1.37(1.45)
2025-09-04 01:43:58,772   INFO  Train:   11/20 ( 55%) [2379/3862 ( 62%)]  Loss: 1.204 (1.38)  LR: 8.873e-04  Grad: 21.3167  max=1.7501(module.vfe.pfn_layers.0.linear.weight)  min: -0.7577(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4615, loss_cls=0.0800, loss_bbox=0.5349, matched_ious=0.5628, loss_iou=0.0876, loss_iou_reg=0.2090, d_time=0.00(0.01), f_time=1.49(1.44), b_time=1.49(1.45)  Time cost: 57:27/35:48 [16:28:09/14:34:56]  Acc_iter 41000       Data time: 0.00(0.01)  Forward time: 1.49(1.44)  Batch time: 1.49(1.45)
2025-09-04 01:45:14,239   INFO  Train:   11/20 ( 55%) [2429/3862 ( 63%)]  Loss: 1.199 (1.38)  LR: 8.862e-04  Grad: 21.2808  max=0.7437(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7575(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4681, loss_cls=0.0785, loss_bbox=0.5359, matched_ious=0.5620, loss_iou=0.0886, loss_iou_reg=0.2089, d_time=0.00(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 58:43/34:37 [16:29:25/14:34:29]  Acc_iter 41050       Data time: 0.00(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-04 01:46:24,834   INFO  Train:   11/20 ( 55%) [2479/3862 ( 64%)]  Loss: 1.337 (1.38)  LR: 8.851e-04  Grad: 21.3154  max=0.7485(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7580(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4641, loss_cls=0.0796, loss_bbox=0.5114, matched_ious=0.5603, loss_iou=0.0890, loss_iou_reg=0.2102, d_time=0.00(0.01), f_time=1.37(1.44), b_time=1.38(1.45)  Time cost: 59:53/33:24 [16:30:35/14:32:49]  Acc_iter 41100       Data time: 0.00(0.01)  Forward time: 1.37(1.44)  Batch time: 1.38(1.45)
2025-09-04 01:47:37,400   INFO  Train:   11/20 ( 55%) [2529/3862 ( 65%)]  Loss: 1.152 (1.38)  LR: 8.840e-04  Grad: 21.3821  max=0.7538(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7607(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4576, loss_cls=0.0769, loss_bbox=0.5164, matched_ious=0.5652, loss_iou=0.0886, loss_iou_reg=0.2063, d_time=0.01(0.01), f_time=1.46(1.44), b_time=1.46(1.45)  Time cost: 1:01:06/32:11 [16:31:48/14:31:38]  Acc_iter 41150       Data time: 0.01(0.01)  Forward time: 1.46(1.44)  Batch time: 1.46(1.45)
2025-09-04 01:48:47,491   INFO  Train:   11/20 ( 55%) [2579/3862 ( 67%)]  Loss: 1.573 (1.38)  LR: 8.829e-04  Grad: 21.4355  max=0.7552(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7641(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4637, loss_cls=0.0802, loss_bbox=0.5194, matched_ious=0.5648, loss_iou=0.0883, loss_iou_reg=0.2085, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 1:02:16/30:57 [16:32:58/14:29:53]  Acc_iter 41200       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-04 01:49:58,736   INFO  Train:   11/20 ( 55%) [2629/3862 ( 68%)]  Loss: 1.180 (1.38)  LR: 8.818e-04  Grad: 21.4445  max=0.7586(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7635(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4833, loss_cls=0.0846, loss_bbox=0.5415, matched_ious=0.5574, loss_iou=0.0893, loss_iou_reg=0.2107, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.43(1.45)  Time cost: 1:03:27/29:45 [16:34:09/14:28:24]  Acc_iter 41250       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.43(1.45)
2025-09-04 01:51:15,281   INFO  Train:   11/20 ( 55%) [2679/3862 ( 69%)]  Loss: 1.482 (1.38)  LR: 8.807e-04  Grad: 21.7573  max=0.7631(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.7189(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4618, loss_cls=0.0797, loss_bbox=0.5269, matched_ious=0.5614, loss_iou=0.0872, loss_iou_reg=0.2095, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 1:04:44/28:34 [16:35:26/14:28:08]  Acc_iter 41300       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-04 01:52:26,767   INFO  Train:   11/20 ( 55%) [2729/3862 ( 71%)]  Loss: 1.009 (1.38)  LR: 8.796e-04  Grad: 21.5830  max=0.7611(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7695(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4644, loss_cls=0.0802, loss_bbox=0.5100, matched_ious=0.5670, loss_iou=0.0875, loss_iou_reg=0.2068, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 1:05:55/27:21 [16:36:37/14:26:42]  Acc_iter 41350       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-04 01:53:38,590   INFO  Train:   11/20 ( 55%) [2779/3862 ( 72%)]  Loss: 1.355 (1.38)  LR: 8.785e-04  Grad: 21.5957  max=0.7658(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7701(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4625, loss_cls=0.0799, loss_bbox=0.5349, matched_ious=0.5621, loss_iou=0.0876, loss_iou_reg=0.2108, d_time=0.01(0.01), f_time=1.33(1.44), b_time=1.33(1.45)  Time cost: 1:07:07/26:08 [16:37:49/14:25:22]  Acc_iter 41400       Data time: 0.01(0.01)  Forward time: 1.33(1.44)  Batch time: 1.33(1.45)
2025-09-04 01:54:49,615   INFO  Train:   11/20 ( 55%) [2829/3862 ( 73%)]  Loss: 1.323 (1.38)  LR: 8.774e-04  Grad: 21.6583  max=0.7671(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7711(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4702, loss_cls=0.0793, loss_bbox=0.5396, matched_ious=0.5615, loss_iou=0.0881, loss_iou_reg=0.2082, d_time=0.00(0.01), f_time=1.34(1.44), b_time=1.35(1.45)  Time cost: 1:08:18/24:55 [16:39:00/14:23:52]  Acc_iter 41450       Data time: 0.00(0.01)  Forward time: 1.34(1.44)  Batch time: 1.35(1.45)
2025-09-04 01:56:01,162   INFO  Train:   11/20 ( 55%) [2879/3862 ( 75%)]  Loss: 1.628 (1.38)  LR: 8.763e-04  Grad: 21.7013  max=0.7698(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7740(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4695, loss_cls=0.0818, loss_bbox=0.5379, matched_ious=0.5668, loss_iou=0.0870, loss_iou_reg=0.2066, d_time=0.00(0.01), f_time=1.44(1.44), b_time=1.44(1.45)  Time cost: 1:09:29/23:43 [16:40:12/14:22:29]  Acc_iter 41500       Data time: 0.00(0.01)  Forward time: 1.44(1.44)  Batch time: 1.44(1.45)
2025-09-04 01:57:18,083   INFO  Train:   11/20 ( 55%) [2929/3862 ( 76%)]  Loss: 1.184 (1.38)  LR: 8.752e-04  Grad: 21.7599  max=0.7717(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7743(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4318, loss_cls=0.0766, loss_bbox=0.4852, matched_ious=0.5696, loss_iou=0.0882, loss_iou_reg=0.2066, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.42(1.45)  Time cost: 1:10:46/22:32 [16:41:29/14:22:11]  Acc_iter 41550       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.45)
2025-09-04 01:58:29,549   INFO  Train:   11/20 ( 55%) [2979/3862 ( 77%)]  Loss: 1.698 (1.38)  LR: 8.741e-04  Grad: 21.7906  max=0.7724(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7785(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4607, loss_cls=0.0803, loss_bbox=0.5411, matched_ious=0.5607, loss_iou=0.0896, loss_iou_reg=0.2102, d_time=0.02(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 1:11:58/21:19 [16:42:40/14:20:47]  Acc_iter 41600       Data time: 0.02(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-04 01:59:41,448   INFO  Train:   11/20 ( 55%) [3029/3862 ( 78%)]  Loss: 1.110 (1.38)  LR: 8.729e-04  Grad: 21.8521  max=0.7767(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7828(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4669, loss_cls=0.0789, loss_bbox=0.5062, matched_ious=0.5664, loss_iou=0.0892, loss_iou_reg=0.2070, d_time=0.01(0.01), f_time=1.34(1.44), b_time=1.34(1.45)  Time cost: 1:13:10/20:06 [16:43:52/14:19:28]  Acc_iter 41650       Data time: 0.01(0.01)  Forward time: 1.34(1.44)  Batch time: 1.34(1.45)
2025-09-04 02:00:52,370   INFO  Train:   11/20 ( 55%) [3079/3862 ( 80%)]  Loss: 1.338 (1.38)  LR: 8.718e-04  Grad: 21.9044  max=0.7797(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8967(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4576, loss_cls=0.0790, loss_bbox=0.5250, matched_ious=0.5650, loss_iou=0.0882, loss_iou_reg=0.2088, d_time=0.00(0.01), f_time=1.49(1.44), b_time=1.49(1.45)  Time cost: 1:14:21/18:54 [16:45:03/14:17:58]  Acc_iter 41700       Data time: 0.00(0.01)  Forward time: 1.49(1.44)  Batch time: 1.49(1.45)
2025-09-04 02:02:04,265   INFO  Train:   11/20 ( 55%) [3129/3862 ( 81%)]  Loss: 1.417 (1.38)  LR: 8.707e-04  Grad: 21.9159  max=0.7802(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7866(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4711, loss_cls=0.0820, loss_bbox=0.5142, matched_ious=0.5632, loss_iou=0.0880, loss_iou_reg=0.2090, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 1:15:33/17:41 [16:46:15/14:16:39]  Acc_iter 41750       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-04 02:03:20,808   INFO  Train:   11/20 ( 55%) [3179/3862 ( 82%)]  Loss: 1.241 (1.38)  LR: 8.695e-04  Grad: 21.9656  max=0.7858(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7860(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4690, loss_cls=0.0807, loss_bbox=0.5024, matched_ious=0.5656, loss_iou=0.0872, loss_iou_reg=0.2063, d_time=0.01(0.01), f_time=1.36(1.44), b_time=1.36(1.45)  Time cost: 1:16:49/16:30 [16:47:31/14:16:13]  Acc_iter 41800       Data time: 0.01(0.01)  Forward time: 1.36(1.44)  Batch time: 1.36(1.45)
2025-09-04 02:04:32,112   INFO  Train:   11/20 ( 55%) [3229/3862 ( 84%)]  Loss: 1.135 (1.38)  LR: 8.684e-04  Grad: 22.0277  max=0.7839(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7900(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4657, loss_cls=0.0795, loss_bbox=0.5096, matched_ious=0.5710, loss_iou=0.0870, loss_iou_reg=0.2057, d_time=0.00(0.01), f_time=1.48(1.44), b_time=1.49(1.45)  Time cost: 1:18:00/15:17 [16:48:43/14:14:48]  Acc_iter 41850       Data time: 0.00(0.01)  Forward time: 1.48(1.44)  Batch time: 1.49(1.45)
2025-09-04 02:05:44,293   INFO  Train:   11/20 ( 55%) [3279/3862 ( 85%)]  Loss: 1.708 (1.38)  LR: 8.672e-04  Grad: 22.0720  max=0.7852(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7943(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4622, loss_cls=0.0796, loss_bbox=0.5298, matched_ious=0.5635, loss_iou=0.0890, loss_iou_reg=0.2085, d_time=0.00(0.01), f_time=1.52(1.44), b_time=1.52(1.45)  Time cost: 1:19:13/14:04 [16:49:55/14:13:32]  Acc_iter 41900       Data time: 0.00(0.01)  Forward time: 1.52(1.44)  Batch time: 1.52(1.45)
2025-09-04 02:06:55,388   INFO  Train:   11/20 ( 55%) [3329/3862 ( 86%)]  Loss: 1.653 (1.38)  LR: 8.661e-04  Grad: 22.1180  max=0.7897(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.7970(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4705, loss_cls=0.0801, loss_bbox=0.5319, matched_ious=0.5650, loss_iou=0.0865, loss_iou_reg=0.2064, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 1:20:24/12:52 [16:51:06/14:12:05]  Acc_iter 41950       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-04 02:08:06,751   INFO  Train:   11/20 ( 55%) [3379/3862 ( 87%)]  Loss: 1.432 (1.38)  LR: 8.649e-04  Grad: 22.1742  max=0.7933(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8012(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4602, loss_cls=0.0811, loss_bbox=0.5274, matched_ious=0.5691, loss_iou=0.0874, loss_iou_reg=0.2037, d_time=0.01(0.01), f_time=1.33(1.44), b_time=1.33(1.45)  Time cost: 1:21:35/11:39 [16:52:17/14:10:42]  Acc_iter 42000       Data time: 0.01(0.01)  Forward time: 1.33(1.44)  Batch time: 1.33(1.45)
2025-09-04 02:09:22,956   INFO  Train:   11/20 ( 55%) [3429/3862 ( 89%)]  Loss: 1.414 (1.38)  LR: 8.638e-04  Grad: 22.2008  max=0.7937(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8026(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4597, loss_cls=0.0794, loss_bbox=0.5355, matched_ious=0.5596, loss_iou=0.0878, loss_iou_reg=0.2089, d_time=0.01(0.01), f_time=1.49(1.44), b_time=1.49(1.45)  Time cost: 1:22:51/10:27 [16:53:34/14:10:08]  Acc_iter 42050       Data time: 0.01(0.01)  Forward time: 1.49(1.44)  Batch time: 1.49(1.45)
2025-09-04 02:10:35,188   INFO  Train:   11/20 ( 55%) [3479/3862 ( 90%)]  Loss: 1.276 (1.38)  LR: 8.626e-04  Grad: 22.2403  max=0.7930(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8032(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4661, loss_cls=0.0819, loss_bbox=0.5130, matched_ious=0.5630, loss_iou=0.0879, loss_iou_reg=0.2082, d_time=0.00(0.01), f_time=2.29(1.44), b_time=2.30(1.45)  Time cost: 1:24:03/09:15 [16:54:46/14:08:53]  Acc_iter 42100       Data time: 0.00(0.01)  Forward time: 2.29(1.44)  Batch time: 2.30(1.45)
2025-09-04 02:11:46,470   INFO  Train:   11/20 ( 55%) [3529/3862 ( 91%)]  Loss: 1.753 (1.38)  LR: 8.614e-04  Grad: 22.3163  max=0.7957(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8058(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4347, loss_cls=0.0732, loss_bbox=0.4997, matched_ious=0.5687, loss_iou=0.0877, loss_iou_reg=0.2062, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 1:25:15/08:02 [16:55:57/14:07:29]  Acc_iter 42150       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-04 02:12:57,735   INFO  Train:   11/20 ( 55%) [3579/3862 ( 93%)]  Loss: 1.454 (1.38)  LR: 8.603e-04  Grad: 22.3245  max=0.8022(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8083(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4602, loss_cls=0.0785, loss_bbox=0.5270, matched_ious=0.5620, loss_iou=0.0891, loss_iou_reg=0.2090, d_time=0.01(0.01), f_time=1.46(1.44), b_time=1.47(1.45)  Time cost: 1:26:26/06:49 [16:57:08/14:06:05]  Acc_iter 42200       Data time: 0.01(0.01)  Forward time: 1.46(1.44)  Batch time: 1.47(1.45)
2025-09-04 02:14:11,207   INFO  Train:   11/20 ( 55%) [3629/3862 ( 94%)]  Loss: 1.480 (1.38)  LR: 8.591e-04  Grad: 22.3790  max=0.7991(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8084(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4557, loss_cls=0.0774, loss_bbox=0.5228, matched_ious=0.5620, loss_iou=0.0875, loss_iou_reg=0.2096, d_time=0.01(0.01), f_time=3.15(1.44), b_time=3.16(1.45)  Time cost: 1:27:39/05:37 [16:58:22/14:05:02]  Acc_iter 42250       Data time: 0.01(0.01)  Forward time: 3.15(1.44)  Batch time: 3.16(1.45)
2025-09-04 02:15:26,879   INFO  Train:   11/20 ( 55%) [3679/3862 ( 95%)]  Loss: 1.294 (1.38)  LR: 8.579e-04  Grad: 22.4300  max=0.8028(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8115(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4672, loss_cls=0.0797, loss_bbox=0.5215, matched_ious=0.5665, loss_iou=0.0869, loss_iou_reg=0.2068, d_time=0.00(0.01), f_time=1.35(1.44), b_time=1.35(1.45)  Time cost: 1:28:55/04:25 [16:59:37/14:04:21]  Acc_iter 42300       Data time: 0.00(0.01)  Forward time: 1.35(1.44)  Batch time: 1.35(1.45)
2025-09-04 02:16:39,342   INFO  Train:   11/20 ( 55%) [3729/3862 ( 97%)]  Loss: 1.650 (1.38)  LR: 8.567e-04  Grad: 22.4677  max=0.8033(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8128(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4601, loss_cls=0.0802, loss_bbox=0.5152, matched_ious=0.5656, loss_iou=0.0885, loss_iou_reg=0.2083, d_time=0.00(0.01), f_time=1.44(1.44), b_time=1.45(1.45)  Time cost: 1:30:08/03:12 [17:00:50/14:03:08]  Acc_iter 42350       Data time: 0.00(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.45)
2025-09-04 02:17:51,111   INFO  Train:   11/20 ( 55%) [3779/3862 ( 98%)]  Loss: 1.369 (1.38)  LR: 8.555e-04  Grad: 22.5267  max=0.8093(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8165(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4777, loss_cls=0.0803, loss_bbox=0.5253, matched_ious=0.5668, loss_iou=0.0862, loss_iou_reg=0.2073, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.44(1.45)  Time cost: 1:31:19/02:00 [17:02:02/14:01:49]  Acc_iter 42400       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.44(1.45)
2025-09-04 02:19:03,094   INFO  Train:   11/20 ( 55%) [3829/3862 ( 99%)]  Loss: 1.347 (1.38)  LR: 8.543e-04  Grad: 22.6781  max=1.8807(module.vfe.pfn_layers.0.linear.weight)  min: -1.4622(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4788, loss_cls=0.0811, loss_bbox=0.5477, matched_ious=0.5633, loss_iou=0.0882, loss_iou_reg=0.2078, d_time=0.00(0.01), f_time=1.37(1.44), b_time=1.38(1.45)  Time cost: 1:32:31/00:47 [17:03:14/14:00:32]  Acc_iter 42450       Data time: 0.00(0.01)  Forward time: 1.37(1.44)  Batch time: 1.38(1.45)
2025-09-04 02:19:46,922   INFO  Train:   11/20 ( 55%) [3861/3862 (100%)]  Loss: 1.552 (1.38)  LR: 8.536e-04  Grad: 22.5897  max=0.8112(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8166(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4609, loss_cls=0.0755, loss_bbox=0.5290, matched_ious=0.5706, loss_iou=0.0877, loss_iou_reg=0.2047, d_time=0.00(0.01), f_time=1.32(1.44), b_time=1.32(1.45)  Time cost: 1:33:15/00:01 [17:03:58/13:59:22]  Acc_iter 42482       Data time: 0.00(0.01)  Forward time: 1.32(1.44)  Batch time: 1.32(1.45)

                                               [Aepochs:  55%|█████▌    | 11/20 [17:03:58<13:59:43, 5598.12s/it]epochs:  55%|█████▌    | 11/20 [17:03:58<13:59:43, 5598.15s/it]epochs:  55%|█████▌    | 11/20 [17:03:58<13:59:43, 5598.13s/it]epochs:  55%|█████▌    | 11/20 [17:03:58<13:59:43, 5598.13s/it]epochs:  55%|█████▌    | 11/20 [17:03:58<13:59:43, 5598.13s/it]epochs:  55%|█████▌    | 11/20 [17:03:58<13:59:43, 5598.14s/it]epochs:  55%|█████▌    | 11/20 [17:03:58<13:59:43, 5598.14s/it]epochs:  55%|█████▌    | 11/20 [17:03:58<13:59:43, 5598.13s/it]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-04 02:19:52,165   INFO  Train:   12/20 ( 60%) [   0/3862 (  0%)]  Loss: 1.283 (1.28)  LR: 8.536e-04  Grad: 22.6020  max=0.8117(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8172(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4595, loss_cls=0.0834, loss_bbox=0.4497, matched_ious=0.5868, loss_iou=0.0957, loss_iou_reg=0.1949, d_time=1.82(1.82), f_time=2.22(2.22), b_time=4.05(4.05)  Time cost: 00:03/4:03:09 [17:04:03/36:28:25]  Acc_iter 42483       Data time: 1.82(1.82)  Forward time: 2.22(2.22)  Batch time: 4.05(4.05)
2025-09-04 02:20:18,439   INFO  Train:   12/20 ( 60%) [  17/3862 (  0%)]  Loss: 1.273 (1.33)  LR: 8.531e-04  Grad: 22.6114  max=0.8121(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8208(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4561, loss_cls=0.0778, loss_bbox=0.4999, matched_ious=0.5629, loss_iou=0.0900, loss_iou_reg=0.2083, d_time=0.01(0.16), f_time=1.42(1.52), b_time=1.42(1.68)  Time cost: 00:30/1:46:57 [17:04:29/16:06:21]  Acc_iter 42500       Data time: 0.01(0.16)  Forward time: 1.42(1.52)  Batch time: 1.42(1.68)
2025-09-04 02:21:33,508   INFO  Train:   12/20 ( 60%) [  67/3862 (  2%)]  Loss: 1.443 (1.35)  LR: 8.519e-04  Grad: 22.6805  max=0.8108(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8233(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4585, loss_cls=0.0793, loss_bbox=0.5182, matched_ious=0.5651, loss_iou=0.0882, loss_iou_reg=0.2083, d_time=0.01(0.07), f_time=1.40(1.48), b_time=1.41(1.55)  Time cost: 01:45/1:37:46 [17:05:44/14:53:49]  Acc_iter 42550       Data time: 0.01(0.07)  Forward time: 1.40(1.48)  Batch time: 1.41(1.55)
2025-09-04 02:22:45,178   INFO  Train:   12/20 ( 60%) [ 117/3862 (  3%)]  Loss: 1.451 (1.34)  LR: 8.507e-04  Grad: 22.7044  max=0.8167(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8207(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4523, loss_cls=0.0768, loss_bbox=0.5102, matched_ious=0.5692, loss_iou=0.0874, loss_iou_reg=0.2058, d_time=0.01(0.04), f_time=1.37(1.46), b_time=1.37(1.50)  Time cost: 02:56/1:33:30 [17:06:56/14:24:57]  Acc_iter 42600       Data time: 0.01(0.04)  Forward time: 1.37(1.46)  Batch time: 1.37(1.50)
2025-09-04 02:23:56,748   INFO  Train:   12/20 ( 60%) [ 167/3862 (  4%)]  Loss: 1.514 (1.33)  LR: 8.495e-04  Grad: 22.7925  max=0.8180(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8270(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4458, loss_cls=0.0778, loss_bbox=0.4898, matched_ious=0.5697, loss_iou=0.0872, loss_iou_reg=0.2061, d_time=0.00(0.03), f_time=1.46(1.45), b_time=1.46(1.48)  Time cost: 04:08/1:31:02 [17:08:07/14:12:17]  Acc_iter 42650       Data time: 0.00(0.03)  Forward time: 1.46(1.45)  Batch time: 1.46(1.48)
2025-09-04 02:25:07,719   INFO  Train:   12/20 ( 60%) [ 217/3862 (  6%)]  Loss: 1.153 (1.33)  LR: 8.483e-04  Grad: 22.7884  max=0.8202(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8276(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4486, loss_cls=0.0798, loss_bbox=0.5007, matched_ious=0.5685, loss_iou=0.0876, loss_iou_reg=0.2073, d_time=0.00(0.03), f_time=1.43(1.44), b_time=1.44(1.47)  Time cost: 05:19/1:28:59 [17:09:18/14:03:16]  Acc_iter 42700       Data time: 0.00(0.03)  Forward time: 1.43(1.44)  Batch time: 1.44(1.47)
2025-09-04 02:26:20,537   INFO  Train:   12/20 ( 60%) [ 267/3862 (  7%)]  Loss: 1.384 (1.33)  LR: 8.471e-04  Grad: 22.8434  max=0.8246(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8314(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4584, loss_cls=0.0786, loss_bbox=0.5238, matched_ious=0.5658, loss_iou=0.0864, loss_iou_reg=0.2079, d_time=0.01(0.02), f_time=1.47(1.44), b_time=1.47(1.46)  Time cost: 06:32/1:27:40 [17:10:31/14:01:08]  Acc_iter 42750       Data time: 0.01(0.02)  Forward time: 1.47(1.44)  Batch time: 1.47(1.46)
2025-09-04 02:27:35,919   INFO  Train:   12/20 ( 60%) [ 317/3862 (  8%)]  Loss: 1.207 (1.33)  LR: 8.459e-04  Grad: 22.8987  max=0.8249(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8342(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4470, loss_cls=0.0760, loss_bbox=0.4957, matched_ious=0.5688, loss_iou=0.0883, loss_iou_reg=0.2068, d_time=0.01(0.02), f_time=1.45(1.45), b_time=1.45(1.47)  Time cost: 07:47/1:26:51 [17:11:47/14:03:56]  Acc_iter 42800       Data time: 0.01(0.02)  Forward time: 1.45(1.45)  Batch time: 1.45(1.47)
2025-09-04 02:28:48,173   INFO  Train:   12/20 ( 60%) [ 367/3862 ( 10%)]  Loss: 1.506 (1.33)  LR: 8.447e-04  Grad: 23.0141  max=1.7789(module.vfe.pfn_layers.0.linear.weight)  min: -0.8374(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4566, loss_cls=0.0805, loss_bbox=0.5096, matched_ious=0.5625, loss_iou=0.0892, loss_iou_reg=0.2098, d_time=0.01(0.02), f_time=1.45(1.45), b_time=1.46(1.47)  Time cost: 08:59/1:25:26 [17:12:59/14:00:45]  Acc_iter 42850       Data time: 0.01(0.02)  Forward time: 1.45(1.45)  Batch time: 1.46(1.47)
2025-09-04 02:29:59,427   INFO  Train:   12/20 ( 60%) [ 417/3862 ( 11%)]  Loss: 1.539 (1.33)  LR: 8.434e-04  Grad: 22.9778  max=0.8333(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8378(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4577, loss_cls=0.0790, loss_bbox=0.5172, matched_ious=0.5721, loss_iou=0.0866, loss_iou_reg=0.2053, d_time=0.01(0.02), f_time=1.40(1.44), b_time=1.41(1.46)  Time cost: 10:11/1:23:55 [17:14:10/13:56:40]  Acc_iter 42900       Data time: 0.01(0.02)  Forward time: 1.40(1.44)  Batch time: 1.41(1.46)
2025-09-04 02:31:11,036   INFO  Train:   12/20 ( 60%) [ 467/3862 ( 12%)]  Loss: 1.126 (1.33)  LR: 8.422e-04  Grad: 23.0124  max=0.8350(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8411(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4486, loss_cls=0.0746, loss_bbox=0.5191, matched_ious=0.5725, loss_iou=0.0863, loss_iou_reg=0.2031, d_time=0.02(0.02), f_time=1.41(1.44), b_time=1.43(1.46)  Time cost: 11:22/1:22:32 [17:15:22/13:53:38]  Acc_iter 42950       Data time: 0.02(0.02)  Forward time: 1.41(1.44)  Batch time: 1.43(1.46)
2025-09-04 02:32:24,629   INFO  Train:   12/20 ( 60%) [ 517/3862 ( 13%)]  Loss: 1.447 (1.33)  LR: 8.409e-04  Grad: 23.0673  max=0.8360(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8407(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4570, loss_cls=0.0803, loss_bbox=0.5012, matched_ious=0.5680, loss_iou=0.0866, loss_iou_reg=0.2069, d_time=0.01(0.02), f_time=1.35(1.45), b_time=1.36(1.46)  Time cost: 12:36/1:21:23 [17:16:35/13:53:09]  Acc_iter 43000       Data time: 0.01(0.02)  Forward time: 1.35(1.45)  Batch time: 1.36(1.46)
2025-09-04 02:33:40,257   INFO  Train:   12/20 ( 60%) [ 567/3862 ( 15%)]  Loss: 1.158 (1.33)  LR: 8.397e-04  Grad: 23.1169  max=0.8500(module.vfe.pfn_layers.0.linear.weight)  min: -0.8427(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4558, loss_cls=0.0771, loss_bbox=0.5027, matched_ious=0.5708, loss_iou=0.0863, loss_iou_reg=0.2056, d_time=0.00(0.02), f_time=1.43(1.45), b_time=1.43(1.47)  Time cost: 13:51/1:20:25 [17:17:51/13:54:34]  Acc_iter 43050       Data time: 0.00(0.02)  Forward time: 1.43(1.45)  Batch time: 1.43(1.47)
2025-09-04 02:34:51,918   INFO  Train:   12/20 ( 60%) [ 617/3862 ( 16%)]  Loss: 1.193 (1.33)  LR: 8.385e-04  Grad: 23.1552  max=0.8400(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0174(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4479, loss_cls=0.0776, loss_bbox=0.5245, matched_ious=0.5711, loss_iou=0.0878, loss_iou_reg=0.2037, d_time=0.01(0.01), f_time=1.47(1.45), b_time=1.47(1.46)  Time cost: 15:03/1:19:04 [17:19:03/13:51:54]  Acc_iter 43100       Data time: 0.01(0.01)  Forward time: 1.47(1.45)  Batch time: 1.47(1.46)
2025-09-04 02:36:03,545   INFO  Train:   12/20 ( 60%) [ 667/3862 ( 17%)]  Loss: 1.287 (1.34)  LR: 8.372e-04  Grad: 23.2326  max=0.8419(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0256(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4764, loss_cls=0.0804, loss_bbox=0.5314, matched_ious=0.5607, loss_iou=0.0894, loss_iou_reg=0.2102, d_time=0.01(0.01), f_time=1.49(1.45), b_time=1.50(1.46)  Time cost: 16:15/1:17:44 [17:20:14/13:49:26]  Acc_iter 43150       Data time: 0.01(0.01)  Forward time: 1.49(1.45)  Batch time: 1.50(1.46)
2025-09-04 02:37:15,408   INFO  Train:   12/20 ( 60%) [ 717/3862 ( 19%)]  Loss: 1.234 (1.34)  LR: 8.360e-04  Grad: 23.2378  max=0.8465(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8477(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4502, loss_cls=0.0776, loss_bbox=0.5084, matched_ious=0.5650, loss_iou=0.0894, loss_iou_reg=0.2086, d_time=0.00(0.01), f_time=1.57(1.45), b_time=1.57(1.46)  Time cost: 17:27/1:16:26 [17:21:26/13:47:20]  Acc_iter 43200       Data time: 0.00(0.01)  Forward time: 1.57(1.45)  Batch time: 1.57(1.46)
2025-09-04 02:38:28,997   INFO  Train:   12/20 ( 60%) [ 767/3862 ( 20%)]  Loss: 1.067 (1.34)  LR: 8.347e-04  Grad: 23.2857  max=0.8464(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8521(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4559, loss_cls=0.0787, loss_bbox=0.4986, matched_ious=0.5679, loss_iou=0.0881, loss_iou_reg=0.2063, d_time=0.01(0.01), f_time=1.34(1.45), b_time=1.35(1.46)  Time cost: 18:40/1:15:15 [17:22:40/13:46:36]  Acc_iter 43250       Data time: 0.01(0.01)  Forward time: 1.34(1.45)  Batch time: 1.35(1.46)
2025-09-04 02:39:44,320   INFO  Train:   12/20 ( 60%) [ 817/3862 ( 21%)]  Loss: 1.056 (1.34)  LR: 8.334e-04  Grad: 23.3245  max=0.8459(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8519(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4550, loss_cls=0.0791, loss_bbox=0.5179, matched_ious=0.5671, loss_iou=0.0874, loss_iou_reg=0.2075, d_time=0.01(0.01), f_time=1.43(1.45), b_time=1.44(1.46)  Time cost: 19:55/1:14:11 [17:23:55/13:47:02]  Acc_iter 43300       Data time: 0.01(0.01)  Forward time: 1.43(1.45)  Batch time: 1.44(1.46)
2025-09-04 02:40:56,325   INFO  Train:   12/20 ( 60%) [ 867/3862 ( 22%)]  Loss: 1.390 (1.34)  LR: 8.322e-04  Grad: 23.3976  max=0.9476(module.vfe.pfn_layers.0.linear.weight)  min: -0.8558(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4414, loss_cls=0.0775, loss_bbox=0.4838, matched_ious=0.5655, loss_iou=0.0884, loss_iou_reg=0.2090, d_time=0.00(0.01), f_time=1.42(1.45), b_time=1.43(1.46)  Time cost: 21:07/1:12:54 [17:25:07/13:45:06]  Acc_iter 43350       Data time: 0.00(0.01)  Forward time: 1.42(1.45)  Batch time: 1.43(1.46)
2025-09-04 02:42:07,115   INFO  Train:   12/20 ( 60%) [ 917/3862 ( 24%)]  Loss: 1.440 (1.34)  LR: 8.309e-04  Grad: 23.4131  max=0.8581(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8546(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4788, loss_cls=0.0805, loss_bbox=0.5538, matched_ious=0.5631, loss_iou=0.0874, loss_iou_reg=0.2083, d_time=0.01(0.01), f_time=1.36(1.45), b_time=1.36(1.46)  Time cost: 22:18/1:11:34 [17:26:18/13:42:30]  Acc_iter 43400       Data time: 0.01(0.01)  Forward time: 1.36(1.45)  Batch time: 1.36(1.46)
2025-09-04 02:43:17,992   INFO  Train:   12/20 ( 60%) [ 967/3862 ( 25%)]  Loss: 1.618 (1.34)  LR: 8.296e-04  Grad: 23.4716  max=0.8555(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8573(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4513, loss_cls=0.0779, loss_bbox=0.5121, matched_ious=0.5714, loss_iou=0.0888, loss_iou_reg=0.2051, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.35(1.46)  Time cost: 23:29/1:10:15 [17:27:29/13:40:06]  Acc_iter 43450       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.35(1.46)
2025-09-04 02:44:33,148   INFO  Train:   12/20 ( 60%) [1017/3862 ( 26%)]  Loss: 1.490 (1.34)  LR: 8.284e-04  Grad: 23.5198  max=0.8585(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8606(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4412, loss_cls=0.0764, loss_bbox=0.5063, matched_ious=0.5691, loss_iou=0.0883, loss_iou_reg=0.2063, d_time=0.01(0.01), f_time=2.16(1.45), b_time=2.17(1.46)  Time cost: 24:44/1:09:09 [17:28:44/13:40:11]  Acc_iter 43500       Data time: 0.01(0.01)  Forward time: 2.16(1.45)  Batch time: 2.17(1.46)
2025-09-04 02:45:47,222   INFO  Train:   12/20 ( 60%) [1067/3862 ( 28%)]  Loss: 1.567 (1.34)  LR: 8.271e-04  Grad: 23.5886  max=0.8649(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2375(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4491, loss_cls=0.0752, loss_bbox=0.4948, matched_ious=0.5699, loss_iou=0.0892, loss_iou_reg=0.2056, d_time=0.00(0.01), f_time=1.35(1.45), b_time=1.35(1.46)  Time cost: 25:58/1:07:59 [17:29:58/13:39:34]  Acc_iter 43550       Data time: 0.00(0.01)  Forward time: 1.35(1.45)  Batch time: 1.35(1.46)
2025-09-04 02:46:57,961   INFO  Train:   12/20 ( 60%) [1117/3862 ( 29%)]  Loss: 1.396 (1.34)  LR: 8.258e-04  Grad: 23.5924  max=0.8659(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8605(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4482, loss_cls=0.0768, loss_bbox=0.5007, matched_ious=0.5669, loss_iou=0.0884, loss_iou_reg=0.2083, d_time=0.00(0.01), f_time=1.40(1.45), b_time=1.40(1.46)  Time cost: 27:09/1:06:41 [17:31:09/13:37:14]  Acc_iter 43600       Data time: 0.00(0.01)  Forward time: 1.40(1.45)  Batch time: 1.40(1.46)
2025-09-04 02:48:09,261   INFO  Train:   12/20 ( 60%) [1167/3862 ( 30%)]  Loss: 1.578 (1.34)  LR: 8.245e-04  Grad: 23.6218  max=0.8650(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8619(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4582, loss_cls=0.0774, loss_bbox=0.5223, matched_ious=0.5679, loss_iou=0.0876, loss_iou_reg=0.2072, d_time=0.01(0.01), f_time=1.43(1.45), b_time=1.43(1.46)  Time cost: 28:20/1:05:24 [17:32:20/13:35:16]  Acc_iter 43650       Data time: 0.01(0.01)  Forward time: 1.43(1.45)  Batch time: 1.43(1.46)
2025-09-04 02:49:20,896   INFO  Train:   12/20 ( 60%) [1217/3862 ( 32%)]  Loss: 1.159 (1.34)  LR: 8.232e-04  Grad: 23.6627  max=0.8653(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8651(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4572, loss_cls=0.0780, loss_bbox=0.4965, matched_ious=0.5738, loss_iou=0.0869, loss_iou_reg=0.2036, d_time=0.01(0.01), f_time=1.45(1.44), b_time=1.45(1.46)  Time cost: 29:32/1:04:09 [17:33:32/13:33:31]  Acc_iter 43700       Data time: 0.01(0.01)  Forward time: 1.45(1.44)  Batch time: 1.45(1.46)
2025-09-04 02:50:35,612   INFO  Train:   12/20 ( 60%) [1267/3862 ( 33%)]  Loss: 1.388 (1.34)  LR: 8.219e-04  Grad: 23.7234  max=0.8717(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8687(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4514, loss_cls=0.0774, loss_bbox=0.5147, matched_ious=0.5649, loss_iou=0.0861, loss_iou_reg=0.2082, d_time=0.00(0.01), f_time=1.51(1.45), b_time=1.51(1.46)  Time cost: 30:47/1:03:00 [17:34:46/13:33:09]  Acc_iter 43750       Data time: 0.00(0.01)  Forward time: 1.51(1.45)  Batch time: 1.51(1.46)
2025-09-04 02:51:49,021   INFO  Train:   12/20 ( 60%) [1317/3862 ( 34%)]  Loss: 1.229 (1.34)  LR: 8.206e-04  Grad: 23.7900  max=0.8719(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8965(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4299, loss_cls=0.0749, loss_bbox=0.5131, matched_ious=0.5686, loss_iou=0.0871, loss_iou_reg=0.2064, d_time=0.00(0.01), f_time=1.48(1.45), b_time=1.49(1.46)  Time cost: 32:00/1:01:48 [17:36:00/13:32:11]  Acc_iter 43800       Data time: 0.00(0.01)  Forward time: 1.48(1.45)  Batch time: 1.49(1.46)
2025-09-04 02:53:00,336   INFO  Train:   12/20 ( 60%) [1367/3862 ( 35%)]  Loss: 1.192 (1.33)  LR: 8.193e-04  Grad: 23.8118  max=0.8789(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8735(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4395, loss_cls=0.0760, loss_bbox=0.4836, matched_ious=0.5699, loss_iou=0.0867, loss_iou_reg=0.2060, d_time=0.00(0.01), f_time=1.45(1.45), b_time=1.45(1.46)  Time cost: 33:11/1:00:32 [17:37:11/13:30:20]  Acc_iter 43850       Data time: 0.00(0.01)  Forward time: 1.45(1.45)  Batch time: 1.45(1.46)
2025-09-04 02:54:11,778   INFO  Train:   12/20 ( 60%) [1417/3862 ( 37%)]  Loss: 1.341 (1.33)  LR: 8.180e-04  Grad: 23.8539  max=0.8760(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8776(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4523, loss_cls=0.0786, loss_bbox=0.5019, matched_ious=0.5646, loss_iou=0.0873, loss_iou_reg=0.2089, d_time=0.00(0.01), f_time=1.38(1.44), b_time=1.39(1.46)  Time cost: 34:23/59:17 [17:38:22/13:28:35]  Acc_iter 43900       Data time: 0.00(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.46)
2025-09-04 02:55:24,017   INFO  Train:   12/20 ( 60%) [1467/3862 ( 38%)]  Loss: 1.226 (1.33)  LR: 8.167e-04  Grad: 23.8965  max=0.8730(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8794(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4396, loss_cls=0.0770, loss_bbox=0.4868, matched_ious=0.5693, loss_iou=0.0879, loss_iou_reg=0.2067, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 35:35/58:04 [17:39:35/13:27:11]  Acc_iter 43950       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-04 02:56:41,951   INFO  Train:   12/20 ( 60%) [1517/3862 ( 39%)]  Loss: 1.064 (1.33)  LR: 8.154e-04  Grad: 23.9517  max=0.8746(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8847(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4524, loss_cls=0.0778, loss_bbox=0.5288, matched_ious=0.5681, loss_iou=0.0883, loss_iou_reg=0.2057, d_time=0.00(0.01), f_time=1.48(1.45), b_time=1.48(1.46)  Time cost: 36:53/56:59 [17:40:53/13:27:52]  Acc_iter 44000       Data time: 0.00(0.01)  Forward time: 1.48(1.45)  Batch time: 1.48(1.46)
2025-09-04 02:57:54,016   INFO  Train:   12/20 ( 60%) [1567/3862 ( 41%)]  Loss: 1.374 (1.33)  LR: 8.141e-04  Grad: 23.9823  max=0.8802(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8820(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4452, loss_cls=0.0749, loss_bbox=0.5109, matched_ious=0.5728, loss_iou=0.0881, loss_iou_reg=0.2041, d_time=0.02(0.01), f_time=1.47(1.45), b_time=1.49(1.46)  Time cost: 38:05/55:45 [17:42:05/13:26:21]  Acc_iter 44050       Data time: 0.02(0.01)  Forward time: 1.47(1.45)  Batch time: 1.49(1.46)
2025-09-04 02:59:05,010   INFO  Train:   12/20 ( 60%) [1617/3862 ( 42%)]  Loss: 1.176 (1.33)  LR: 8.128e-04  Grad: 24.0411  max=0.8799(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8860(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4473, loss_cls=0.0757, loss_bbox=0.5167, matched_ious=0.5715, loss_iou=0.0861, loss_iou_reg=0.2052, d_time=0.00(0.01), f_time=1.37(1.45), b_time=1.38(1.46)  Time cost: 39:16/54:29 [17:43:16/13:24:30]  Acc_iter 44100       Data time: 0.00(0.01)  Forward time: 1.37(1.45)  Batch time: 1.38(1.46)
2025-09-04 03:00:16,783   INFO  Train:   12/20 ( 60%) [1667/3862 ( 43%)]  Loss: 1.088 (1.33)  LR: 8.114e-04  Grad: 24.0637  max=0.8883(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8870(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4389, loss_cls=0.0754, loss_bbox=0.4756, matched_ious=0.5738, loss_iou=0.0855, loss_iou_reg=0.2023, d_time=0.01(0.01), f_time=1.46(1.45), b_time=1.47(1.46)  Time cost: 40:28/53:15 [17:44:27/13:22:56]  Acc_iter 44150       Data time: 0.01(0.01)  Forward time: 1.46(1.45)  Batch time: 1.47(1.46)
2025-09-04 03:01:28,496   INFO  Train:   12/20 ( 60%) [1717/3862 ( 44%)]  Loss: 1.280 (1.33)  LR: 8.101e-04  Grad: 24.1333  max=0.8867(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8890(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4523, loss_cls=0.0768, loss_bbox=0.5103, matched_ious=0.5761, loss_iou=0.0863, loss_iou_reg=0.2018, d_time=0.01(0.01), f_time=1.33(1.45), b_time=1.34(1.46)  Time cost: 41:40/52:01 [17:45:39/13:21:22]  Acc_iter 44200       Data time: 0.01(0.01)  Forward time: 1.33(1.45)  Batch time: 1.34(1.46)
2025-09-04 03:02:46,473   INFO  Train:   12/20 ( 60%) [1767/3862 ( 46%)]  Loss: 1.196 (1.33)  LR: 8.088e-04  Grad: 24.1404  max=0.8923(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8895(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4375, loss_cls=0.0754, loss_bbox=0.4927, matched_ious=0.5696, loss_iou=0.0875, loss_iou_reg=0.2050, d_time=0.01(0.01), f_time=1.43(1.45), b_time=1.44(1.46)  Time cost: 42:58/50:54 [17:46:57/13:21:47]  Acc_iter 44250       Data time: 0.01(0.01)  Forward time: 1.43(1.45)  Batch time: 1.44(1.46)
2025-09-04 03:03:58,241   INFO  Train:   12/20 ( 60%) [1817/3862 ( 47%)]  Loss: 1.406 (1.33)  LR: 8.074e-04  Grad: 24.1882  max=0.8946(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8944(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4523, loss_cls=0.0761, loss_bbox=0.5104, matched_ious=0.5697, loss_iou=0.0884, loss_iou_reg=0.2065, d_time=0.01(0.01), f_time=1.41(1.45), b_time=1.42(1.46)  Time cost: 44:09/49:40 [17:48:09/13:20:13]  Acc_iter 44300       Data time: 0.01(0.01)  Forward time: 1.41(1.45)  Batch time: 1.42(1.46)
2025-09-04 03:05:10,099   INFO  Train:   12/20 ( 60%) [1867/3862 ( 48%)]  Loss: 1.183 (1.33)  LR: 8.061e-04  Grad: 24.2257  max=0.8948(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.8950(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4431, loss_cls=0.0768, loss_bbox=0.5003, matched_ious=0.5662, loss_iou=0.0885, loss_iou_reg=0.2060, d_time=0.01(0.01), f_time=1.31(1.45), b_time=1.32(1.46)  Time cost: 45:21/48:26 [17:49:21/13:18:42]  Acc_iter 44350       Data time: 0.01(0.01)  Forward time: 1.31(1.45)  Batch time: 1.32(1.46)
2025-09-04 03:06:21,005   INFO  Train:   12/20 ( 60%) [1917/3862 ( 50%)]  Loss: 1.255 (1.33)  LR: 8.048e-04  Grad: 24.2632  max=0.8972(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9002(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4279, loss_cls=0.0760, loss_bbox=0.4852, matched_ious=0.5720, loss_iou=0.0868, loss_iou_reg=0.2061, d_time=0.01(0.01), f_time=1.48(1.45), b_time=1.49(1.46)  Time cost: 46:32/47:11 [17:50:32/13:16:56]  Acc_iter 44400       Data time: 0.01(0.01)  Forward time: 1.48(1.45)  Batch time: 1.49(1.46)
2025-09-04 03:07:32,479   INFO  Train:   12/20 ( 60%) [1967/3862 ( 51%)]  Loss: 1.157 (1.33)  LR: 8.034e-04  Grad: 24.3295  max=0.8965(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9018(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4588, loss_cls=0.0800, loss_bbox=0.5066, matched_ious=0.5686, loss_iou=0.0871, loss_iou_reg=0.2072, d_time=0.00(0.01), f_time=1.40(1.45), b_time=1.41(1.46)  Time cost: 47:44/45:57 [17:51:43/13:15:21]  Acc_iter 44450       Data time: 0.00(0.01)  Forward time: 1.40(1.45)  Batch time: 1.41(1.46)
2025-09-04 03:08:49,564   INFO  Train:   12/20 ( 60%) [2017/3862 ( 52%)]  Loss: 1.158 (1.33)  LR: 8.021e-04  Grad: 24.3742  max=0.8988(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9064(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4421, loss_cls=0.0751, loss_bbox=0.5114, matched_ious=0.5726, loss_iou=0.0878, loss_iou_reg=0.2043, d_time=0.00(0.01), f_time=1.38(1.45), b_time=1.39(1.46)  Time cost: 49:01/44:49 [17:53:00/13:15:19]  Acc_iter 44500       Data time: 0.00(0.01)  Forward time: 1.38(1.45)  Batch time: 1.39(1.46)
2025-09-04 03:10:00,657   INFO  Train:   12/20 ( 60%) [2067/3862 ( 54%)]  Loss: 1.260 (1.33)  LR: 8.007e-04  Grad: 24.3996  max=0.9032(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9060(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4340, loss_cls=0.0764, loss_bbox=0.4972, matched_ious=0.5711, loss_iou=0.0883, loss_iou_reg=0.2056, d_time=0.00(0.01), f_time=1.44(1.45), b_time=1.44(1.46)  Time cost: 50:12/43:34 [17:54:11/13:13:38]  Acc_iter 44550       Data time: 0.00(0.01)  Forward time: 1.44(1.45)  Batch time: 1.44(1.46)
2025-09-04 03:11:12,160   INFO  Train:   12/20 ( 60%) [2117/3862 ( 55%)]  Loss: 1.125 (1.33)  LR: 7.994e-04  Grad: 24.4445  max=0.9078(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9084(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4530, loss_cls=0.0775, loss_bbox=0.5364, matched_ious=0.5671, loss_iou=0.0880, loss_iou_reg=0.2065, d_time=0.01(0.01), f_time=1.39(1.45), b_time=1.39(1.46)  Time cost: 51:23/42:20 [17:55:23/13:12:04]  Acc_iter 44600       Data time: 0.01(0.01)  Forward time: 1.39(1.45)  Batch time: 1.39(1.46)
2025-09-04 03:12:23,373   INFO  Train:   12/20 ( 60%) [2167/3862 ( 56%)]  Loss: 1.336 (1.33)  LR: 7.980e-04  Grad: 24.5026  max=0.9050(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9097(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4382, loss_cls=0.0778, loss_bbox=0.4755, matched_ious=0.5749, loss_iou=0.0861, loss_iou_reg=0.2038, d_time=0.01(0.01), f_time=1.45(1.45), b_time=1.46(1.46)  Time cost: 52:34/41:06 [17:56:34/13:10:28]  Acc_iter 44650       Data time: 0.01(0.01)  Forward time: 1.45(1.45)  Batch time: 1.46(1.46)
2025-09-04 03:13:35,096   INFO  Train:   12/20 ( 60%) [2217/3862 ( 57%)]  Loss: 1.346 (1.33)  LR: 7.966e-04  Grad: 24.5308  max=0.9081(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9106(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4505, loss_cls=0.0762, loss_bbox=0.5206, matched_ious=0.5730, loss_iou=0.0859, loss_iou_reg=0.2029, d_time=0.01(0.01), f_time=1.49(1.44), b_time=1.50(1.45)  Time cost: 53:46/39:53 [17:57:46/13:09:00]  Acc_iter 44700       Data time: 0.01(0.01)  Forward time: 1.49(1.44)  Batch time: 1.50(1.45)
2025-09-04 03:14:52,292   INFO  Train:   12/20 ( 60%) [2267/3862 ( 59%)]  Loss: 1.287 (1.33)  LR: 7.953e-04  Grad: 24.5950  max=0.9078(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9121(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4411, loss_cls=0.0743, loss_bbox=0.5071, matched_ious=0.5707, loss_iou=0.0878, loss_iou_reg=0.2061, d_time=0.01(0.01), f_time=1.37(1.45), b_time=1.38(1.46)  Time cost: 55:03/38:43 [17:59:03/13:08:51]  Acc_iter 44750       Data time: 0.01(0.01)  Forward time: 1.37(1.45)  Batch time: 1.38(1.46)
2025-09-04 03:16:03,395   INFO  Train:   12/20 ( 60%) [2317/3862 ( 60%)]  Loss: 1.191 (1.33)  LR: 7.939e-04  Grad: 24.6045  max=0.9136(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9134(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4352, loss_cls=0.0759, loss_bbox=0.4926, matched_ious=0.5703, loss_iou=0.0875, loss_iou_reg=0.2048, d_time=0.00(0.01), f_time=1.44(1.45), b_time=1.44(1.46)  Time cost: 56:15/37:29 [18:00:14/13:07:14]  Acc_iter 44800       Data time: 0.00(0.01)  Forward time: 1.44(1.45)  Batch time: 1.44(1.46)
2025-09-04 03:17:15,146   INFO  Train:   12/20 ( 60%) [2367/3862 ( 61%)]  Loss: 1.571 (1.33)  LR: 7.925e-04  Grad: 24.6360  max=0.9148(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9162(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4405, loss_cls=0.0742, loss_bbox=0.4948, matched_ious=0.5709, loss_iou=0.0876, loss_iou_reg=0.2057, d_time=0.01(0.01), f_time=1.39(1.45), b_time=1.40(1.46)  Time cost: 57:26/36:16 [18:01:26/13:05:46]  Acc_iter 44850       Data time: 0.01(0.01)  Forward time: 1.39(1.45)  Batch time: 1.40(1.46)
2025-09-04 03:18:26,313   INFO  Train:   12/20 ( 60%) [2417/3862 ( 63%)]  Loss: 1.283 (1.33)  LR: 7.912e-04  Grad: 24.6989  max=0.9240(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9173(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4623, loss_cls=0.0789, loss_bbox=0.5186, matched_ious=0.5704, loss_iou=0.0876, loss_iou_reg=0.2047, d_time=0.01(0.01), f_time=1.42(1.45), b_time=1.42(1.46)  Time cost: 58:37/35:02 [18:02:37/13:04:12]  Acc_iter 44900       Data time: 0.01(0.01)  Forward time: 1.42(1.45)  Batch time: 1.42(1.46)
2025-09-04 03:19:37,818   INFO  Train:   12/20 ( 60%) [2467/3862 ( 64%)]  Loss: 1.238 (1.33)  LR: 7.898e-04  Grad: 24.7792  max=1.3982(module.vfe.pfn_layers.0.linear.weight)  min: -0.9168(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4364, loss_cls=0.0753, loss_bbox=0.4945, matched_ious=0.5711, loss_iou=0.0868, loss_iou_reg=0.2063, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.43(1.45)  Time cost: 59:49/33:48 [18:03:48/13:02:43]  Acc_iter 44950       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.43(1.45)
2025-09-04 03:20:54,921   INFO  Train:   12/20 ( 60%) [2517/3862 ( 65%)]  Loss: 1.383 (1.33)  LR: 7.884e-04  Grad: 24.7786  max=0.9262(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9199(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4587, loss_cls=0.0792, loss_bbox=0.5253, matched_ious=0.5743, loss_iou=0.0849, loss_iou_reg=0.2039, d_time=0.00(0.01), f_time=1.37(1.45), b_time=1.38(1.46)  Time cost: 1:01:06/32:38 [18:05:06/13:02:27]  Acc_iter 45000       Data time: 0.00(0.01)  Forward time: 1.37(1.45)  Batch time: 1.38(1.46)
2025-09-04 03:22:06,616   INFO  Train:   12/20 ( 60%) [2567/3862 ( 66%)]  Loss: 1.019 (1.33)  LR: 7.870e-04  Grad: 24.8152  max=0.9229(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9219(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4486, loss_cls=0.0784, loss_bbox=0.5178, matched_ious=0.5679, loss_iou=0.0880, loss_iou_reg=0.2063, d_time=0.00(0.01), f_time=1.45(1.45), b_time=1.45(1.46)  Time cost: 1:02:18/31:25 [18:06:17/13:01:00]  Acc_iter 45050       Data time: 0.00(0.01)  Forward time: 1.45(1.45)  Batch time: 1.45(1.46)
2025-09-04 03:23:17,151   INFO  Train:   12/20 ( 60%) [2617/3862 ( 68%)]  Loss: 1.168 (1.33)  LR: 7.856e-04  Grad: 24.8383  max=0.9264(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9237(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4537, loss_cls=0.0776, loss_bbox=0.5031, matched_ious=0.5647, loss_iou=0.0882, loss_iou_reg=0.2081, d_time=0.01(0.01), f_time=1.36(1.45), b_time=1.37(1.45)  Time cost: 1:03:28/30:11 [18:07:28/12:59:19]  Acc_iter 45100       Data time: 0.01(0.01)  Forward time: 1.36(1.45)  Batch time: 1.37(1.45)
2025-09-04 03:24:28,248   INFO  Train:   12/20 ( 60%) [2667/3862 ( 69%)]  Loss: 1.353 (1.33)  LR: 7.842e-04  Grad: 24.8872  max=0.9288(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9300(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4378, loss_cls=0.0736, loss_bbox=0.4922, matched_ious=0.5753, loss_iou=0.0872, loss_iou_reg=0.2020, d_time=0.00(0.01), f_time=1.53(1.44), b_time=1.53(1.45)  Time cost: 1:04:39/28:57 [18:08:39/12:57:47]  Acc_iter 45150       Data time: 0.00(0.01)  Forward time: 1.53(1.44)  Batch time: 1.53(1.45)
2025-09-04 03:25:40,224   INFO  Train:   12/20 ( 60%) [2717/3862 ( 70%)]  Loss: 1.169 (1.33)  LR: 7.828e-04  Grad: 24.9393  max=0.9293(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9327(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4581, loss_cls=0.0777, loss_bbox=0.5171, matched_ious=0.5683, loss_iou=0.0862, loss_iou_reg=0.2069, d_time=0.01(0.01), f_time=1.49(1.44), b_time=1.50(1.45)  Time cost: 1:05:51/27:44 [18:09:51/12:56:26]  Acc_iter 45200       Data time: 0.01(0.01)  Forward time: 1.49(1.44)  Batch time: 1.50(1.45)
2025-09-04 03:26:56,097   INFO  Train:   12/20 ( 60%) [2767/3862 ( 72%)]  Loss: 1.649 (1.33)  LR: 7.814e-04  Grad: 24.9811  max=0.9284(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9331(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4574, loss_cls=0.0785, loss_bbox=0.5253, matched_ious=0.5647, loss_iou=0.0894, loss_iou_reg=0.2067, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.44(1.46)  Time cost: 1:07:07/26:33 [18:11:07/12:55:50]  Acc_iter 45250       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.46)
2025-09-04 03:28:07,430   INFO  Train:   12/20 ( 60%) [2817/3862 ( 73%)]  Loss: 1.374 (1.33)  LR: 7.800e-04  Grad: 25.0076  max=0.9309(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9337(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4419, loss_cls=0.0747, loss_bbox=0.5278, matched_ious=0.5668, loss_iou=0.0874, loss_iou_reg=0.2063, d_time=0.00(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 1:08:19/25:20 [18:12:18/12:54:21]  Acc_iter 45300       Data time: 0.00(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-04 03:29:18,729   INFO  Train:   12/20 ( 60%) [2867/3862 ( 74%)]  Loss: 1.106 (1.33)  LR: 7.786e-04  Grad: 25.0613  max=0.9335(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9352(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4412, loss_cls=0.0740, loss_bbox=0.5221, matched_ious=0.5785, loss_iou=0.0852, loss_iou_reg=0.2000, d_time=0.00(0.01), f_time=1.39(1.44), b_time=1.40(1.45)  Time cost: 1:09:30/24:06 [18:13:29/12:52:52]  Acc_iter 45350       Data time: 0.00(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.45)
2025-09-04 03:30:29,801   INFO  Train:   12/20 ( 60%) [2917/3862 ( 76%)]  Loss: 1.164 (1.33)  LR: 7.772e-04  Grad: 25.0948  max=0.9362(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9385(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4402, loss_cls=0.0767, loss_bbox=0.5089, matched_ious=0.5719, loss_iou=0.0863, loss_iou_reg=0.2042, d_time=0.01(0.01), f_time=1.34(1.44), b_time=1.34(1.45)  Time cost: 1:10:41/22:53 [18:14:40/12:51:22]  Acc_iter 45400       Data time: 0.01(0.01)  Forward time: 1.34(1.44)  Batch time: 1.34(1.45)
2025-09-04 03:31:42,063   INFO  Train:   12/20 ( 60%) [2967/3862 ( 77%)]  Loss: 1.387 (1.33)  LR: 7.758e-04  Grad: 25.1466  max=0.9369(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9397(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4599, loss_cls=0.0779, loss_bbox=0.5307, matched_ious=0.5633, loss_iou=0.0879, loss_iou_reg=0.2084, d_time=0.01(0.01), f_time=1.49(1.44), b_time=1.50(1.45)  Time cost: 1:11:53/21:40 [18:15:53/12:50:04]  Acc_iter 45450       Data time: 0.01(0.01)  Forward time: 1.49(1.44)  Batch time: 1.50(1.45)
2025-09-04 03:32:58,662   INFO  Train:   12/20 ( 60%) [3017/3862 ( 78%)]  Loss: 1.340 (1.33)  LR: 7.744e-04  Grad: 25.1887  max=0.9337(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9435(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4466, loss_cls=0.0758, loss_bbox=0.4973, matched_ious=0.5729, loss_iou=0.0871, loss_iou_reg=0.2046, d_time=0.00(0.01), f_time=1.27(1.44), b_time=1.28(1.45)  Time cost: 1:13:10/20:29 [18:17:09/12:49:33]  Acc_iter 45500       Data time: 0.00(0.01)  Forward time: 1.27(1.44)  Batch time: 1.28(1.45)
2025-09-04 03:34:09,895   INFO  Train:   12/20 ( 60%) [3067/3862 ( 79%)]  Loss: 1.163 (1.33)  LR: 7.730e-04  Grad: 25.2236  max=0.9446(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9407(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4325, loss_cls=0.0755, loss_bbox=0.4933, matched_ious=0.5729, loss_iou=0.0875, loss_iou_reg=0.2049, d_time=0.01(0.01), f_time=1.39(1.44), b_time=1.40(1.45)  Time cost: 1:14:21/19:16 [18:18:21/12:48:05]  Acc_iter 45550       Data time: 0.01(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.45)
2025-09-04 03:35:21,635   INFO  Train:   12/20 ( 60%) [3117/3862 ( 81%)]  Loss: 1.502 (1.33)  LR: 7.715e-04  Grad: 25.2575  max=0.9428(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9438(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4430, loss_cls=0.0748, loss_bbox=0.4912, matched_ious=0.5757, loss_iou=0.0857, loss_iou_reg=0.2026, d_time=0.00(0.01), f_time=1.54(1.44), b_time=1.55(1.45)  Time cost: 1:15:33/18:03 [18:19:32/12:46:42]  Acc_iter 45600       Data time: 0.00(0.01)  Forward time: 1.54(1.44)  Batch time: 1.55(1.45)
2025-09-04 03:36:32,986   INFO  Train:   12/20 ( 60%) [3167/3862 ( 82%)]  Loss: 1.237 (1.33)  LR: 7.701e-04  Grad: 25.3194  max=0.9425(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9469(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4298, loss_cls=0.0751, loss_bbox=0.4964, matched_ious=0.5721, loss_iou=0.0869, loss_iou_reg=0.2053, d_time=0.01(0.01), f_time=1.45(1.44), b_time=1.46(1.45)  Time cost: 1:16:44/16:50 [18:20:44/12:45:16]  Acc_iter 45650       Data time: 0.01(0.01)  Forward time: 1.45(1.44)  Batch time: 1.46(1.45)
2025-09-04 03:37:45,488   INFO  Train:   12/20 ( 60%) [3217/3862 ( 83%)]  Loss: 1.337 (1.33)  LR: 7.687e-04  Grad: 25.3524  max=0.9462(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9501(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4389, loss_cls=0.0768, loss_bbox=0.4979, matched_ious=0.5737, loss_iou=0.0871, loss_iou_reg=0.2032, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 1:17:57/15:37 [18:21:56/12:44:02]  Acc_iter 45700       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-04 03:39:02,704   INFO  Train:   12/20 ( 60%) [3267/3862 ( 85%)]  Loss: 1.213 (1.33)  LR: 7.673e-04  Grad: 25.3641  max=0.9490(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9494(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4410, loss_cls=0.0759, loss_bbox=0.5090, matched_ious=0.5769, loss_iou=0.0862, loss_iou_reg=0.2023, d_time=0.00(0.01), f_time=1.42(1.45), b_time=1.42(1.45)  Time cost: 1:19:14/14:25 [18:23:13/12:43:33]  Acc_iter 45750       Data time: 0.00(0.01)  Forward time: 1.42(1.45)  Batch time: 1.42(1.45)
2025-09-04 03:40:14,168   INFO  Train:   12/20 ( 60%) [3317/3862 ( 86%)]  Loss: 1.266 (1.33)  LR: 7.658e-04  Grad: 25.4072  max=0.9494(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9518(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4491, loss_cls=0.0762, loss_bbox=0.4942, matched_ious=0.5721, loss_iou=0.0879, loss_iou_reg=0.2052, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 1:20:25/13:12 [18:24:25/12:42:08]  Acc_iter 45800       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-04 03:41:25,137   INFO  Train:   12/20 ( 60%) [3367/3862 ( 87%)]  Loss: 1.564 (1.32)  LR: 7.644e-04  Grad: 25.4529  max=0.9534(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9589(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4284, loss_cls=0.0726, loss_bbox=0.4986, matched_ious=0.5754, loss_iou=0.0858, loss_iou_reg=0.2033, d_time=0.01(0.01), f_time=1.37(1.44), b_time=1.38(1.45)  Time cost: 1:21:36/11:59 [18:25:36/12:40:39]  Acc_iter 45850       Data time: 0.01(0.01)  Forward time: 1.37(1.44)  Batch time: 1.38(1.45)
2025-09-04 03:42:37,512   INFO  Train:   12/20 ( 60%) [3417/3862 ( 88%)]  Loss: 1.106 (1.32)  LR: 7.629e-04  Grad: 25.4844  max=0.9540(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9582(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4401, loss_cls=0.0736, loss_bbox=0.4920, matched_ious=0.5723, loss_iou=0.0887, loss_iou_reg=0.2047, d_time=0.01(0.01), f_time=1.48(1.44), b_time=1.49(1.45)  Time cost: 1:22:49/10:46 [18:26:48/12:39:23]  Acc_iter 45900       Data time: 0.01(0.01)  Forward time: 1.48(1.44)  Batch time: 1.49(1.45)
2025-09-04 03:43:48,913   INFO  Train:   12/20 ( 60%) [3467/3862 ( 90%)]  Loss: 1.052 (1.32)  LR: 7.615e-04  Grad: 25.5253  max=0.9535(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9602(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4356, loss_cls=0.0773, loss_bbox=0.4898, matched_ious=0.5698, loss_iou=0.0872, loss_iou_reg=0.2059, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 1:24:00/09:34 [18:28:00/12:37:59]  Acc_iter 45950       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-04 03:45:05,238   INFO  Train:   12/20 ( 60%) [3517/3862 ( 91%)]  Loss: 1.614 (1.32)  LR: 7.601e-04  Grad: 25.5813  max=0.9545(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9619(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4290, loss_cls=0.0739, loss_bbox=0.4811, matched_ious=0.5775, loss_iou=0.0865, loss_iou_reg=0.2033, d_time=0.00(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 1:25:16/08:21 [18:29:16/12:37:19]  Acc_iter 46000       Data time: 0.00(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-04 03:46:16,093   INFO  Train:   12/20 ( 60%) [3567/3862 ( 92%)]  Loss: 1.485 (1.32)  LR: 7.586e-04  Grad: 25.6113  max=0.9611(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9620(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4355, loss_cls=0.0751, loss_bbox=0.4748, matched_ious=0.5771, loss_iou=0.0871, loss_iou_reg=0.2033, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 1:26:27/07:08 [18:30:27/12:35:50]  Acc_iter 46050       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-04 03:47:27,263   INFO  Train:   12/20 ( 60%) [3617/3862 ( 94%)]  Loss: 1.306 (1.32)  LR: 7.572e-04  Grad: 25.6867  max=0.9616(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0204(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4488, loss_cls=0.0747, loss_bbox=0.5136, matched_ious=0.5690, loss_iou=0.0870, loss_iou_reg=0.2048, d_time=0.01(0.01), f_time=1.33(1.44), b_time=1.34(1.45)  Time cost: 1:27:38/05:56 [18:31:38/12:34:24]  Acc_iter 46100       Data time: 0.01(0.01)  Forward time: 1.33(1.44)  Batch time: 1.34(1.45)
2025-09-04 03:48:38,758   INFO  Train:   12/20 ( 60%) [3667/3862 ( 95%)]  Loss: 1.006 (1.32)  LR: 7.557e-04  Grad: 25.6847  max=0.9630(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9640(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4568, loss_cls=0.0765, loss_bbox=0.5106, matched_ious=0.5701, loss_iou=0.0878, loss_iou_reg=0.2051, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.43(1.45)  Time cost: 1:28:50/04:43 [18:32:49/12:33:01]  Acc_iter 46150       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.43(1.45)
2025-09-04 03:49:51,417   INFO  Train:   12/20 ( 60%) [3717/3862 ( 96%)]  Loss: 1.203 (1.32)  LR: 7.542e-04  Grad: 25.7416  max=0.9628(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9698(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4349, loss_cls=0.0742, loss_bbox=0.5062, matched_ious=0.5728, loss_iou=0.0878, loss_iou_reg=0.2042, d_time=0.03(0.01), f_time=1.54(1.44), b_time=1.57(1.45)  Time cost: 1:30:03/03:30 [18:34:02/12:31:49]  Acc_iter 46200       Data time: 0.03(0.01)  Forward time: 1.54(1.44)  Batch time: 1.57(1.45)
2025-09-04 03:51:07,027   INFO  Train:   12/20 ( 60%) [3767/3862 ( 98%)]  Loss: 1.542 (1.32)  LR: 7.528e-04  Grad: 25.7714  max=0.9663(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9730(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4466, loss_cls=0.0769, loss_bbox=0.5085, matched_ious=0.5677, loss_iou=0.0880, loss_iou_reg=0.2062, d_time=0.01(0.01), f_time=1.34(1.44), b_time=1.35(1.45)  Time cost: 1:31:18/02:18 [18:35:18/12:31:00]  Acc_iter 46250       Data time: 0.01(0.01)  Forward time: 1.34(1.44)  Batch time: 1.35(1.45)
2025-09-04 03:52:17,931   INFO  Train:   12/20 ( 60%) [3817/3862 ( 99%)]  Loss: 1.283 (1.32)  LR: 7.513e-04  Grad: 25.8290  max=0.9686(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9750(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4596, loss_cls=0.0765, loss_bbox=0.5112, matched_ious=0.5736, loss_iou=0.0882, loss_iou_reg=0.2036, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 1:32:29/01:05 [18:36:29/12:29:33]  Acc_iter 46300       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-04 03:53:19,546   INFO  Train:   12/20 ( 60%) [3861/3862 (100%)]  Loss: 1.216 (1.32)  LR: 7.500e-04  Grad: 25.8823  max=0.9693(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9769(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4399, loss_cls=0.0735, loss_bbox=0.5027, matched_ious=0.5688, loss_iou=0.0893, loss_iou_reg=0.2063, d_time=0.00(0.01), f_time=1.34(1.44), b_time=1.35(1.45)  Time cost: 1:33:31/00:01 [18:37:30/12:28:10]  Acc_iter 46344       Data time: 0.00(0.01)  Forward time: 1.34(1.44)  Batch time: 1.35(1.45)

                                               [Aepochs:  60%|██████    | 12/20 [18:37:30<12:27:00, 5602.56s/it]epochs:  60%|██████    | 12/20 [18:37:30<12:27:00, 5602.54s/it]epochs:  60%|██████    | 12/20 [18:37:31<12:27:00, 5602.54s/it]epochs:  60%|██████    | 12/20 [18:37:31<12:27:00, 5602.54s/it]epochs:  60%|██████    | 12/20 [18:37:31<12:27:00, 5602.56s/it]epochs:  60%|██████    | 12/20 [18:37:31<12:27:00, 5602.55s/it]epochs:  60%|██████    | 12/20 [18:37:31<12:27:00, 5602.55s/it]epochs:  60%|██████    | 12/20 [18:37:31<12:27:00, 5602.55s/it]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-04 03:53:25,499   INFO  Train:   13/20 ( 65%) [   0/3862 (  0%)]  Loss: 1.098 (1.10)  LR: 7.500e-04  Grad: 25.8714  max=0.9690(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9757(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3213, loss_cls=0.0633, loss_bbox=0.4185, matched_ious=0.5889, loss_iou=0.0921, loss_iou_reg=0.2024, d_time=1.95(1.95), f_time=2.78(2.78), b_time=4.72(4.72)  Time cost: 00:04/4:44:24 [18:37:36/37:55:12]  Acc_iter 46345       Data time: 1.95(1.95)  Forward time: 2.78(2.78)  Batch time: 4.72(4.72)
2025-09-04 03:53:32,649   INFO  Train:   13/20 ( 65%) [   5/3862 (  0%)]  Loss: 1.225 (1.24)  LR: 7.499e-04  Grad: 25.8383  max=0.9682(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9733(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4475, loss_cls=0.0745, loss_bbox=0.4650, matched_ious=0.5748, loss_iou=0.0825, loss_iou_reg=0.2046, d_time=0.00(0.33), f_time=1.48(1.65), b_time=1.49(1.98)  Time cost: 00:11/2:03:59 [18:37:43/16:33:04]  Acc_iter 46350       Data time: 0.00(0.33)  Forward time: 1.48(1.65)  Batch time: 1.49(1.98)
2025-09-04 03:54:45,478   INFO  Train:   13/20 ( 65%) [  55/3862 (  1%)]  Loss: 1.322 (1.29)  LR: 7.484e-04  Grad: 25.8986  max=0.9745(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9781(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4355, loss_cls=0.0748, loss_bbox=0.4915, matched_ious=0.5716, loss_iou=0.0881, loss_iou_reg=0.2056, d_time=0.00(0.04), f_time=1.50(1.47), b_time=1.50(1.51)  Time cost: 01:24/1:35:37 [18:38:56/12:54:42]  Acc_iter 46400       Data time: 0.00(0.04)  Forward time: 1.50(1.47)  Batch time: 1.50(1.51)
2025-09-04 03:56:00,009   INFO  Train:   13/20 ( 65%) [ 105/3862 (  3%)]  Loss: 1.139 (1.30)  LR: 7.469e-04  Grad: 25.9488  max=0.9749(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9797(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4446, loss_cls=0.0768, loss_bbox=0.4940, matched_ious=0.5711, loss_iou=0.0869, loss_iou_reg=0.2040, d_time=0.00(0.02), f_time=2.30(1.48), b_time=2.30(1.50)  Time cost: 02:38/1:33:53 [18:40:11/12:49:26]  Acc_iter 46450       Data time: 0.00(0.02)  Forward time: 2.30(1.48)  Batch time: 2.30(1.50)
2025-09-04 03:57:15,293   INFO  Train:   13/20 ( 65%) [ 155/3862 (  4%)]  Loss: 1.387 (1.29)  LR: 7.454e-04  Grad: 25.9706  max=0.9765(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9803(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4323, loss_cls=0.0751, loss_bbox=0.4775, matched_ious=0.5724, loss_iou=0.0860, loss_iou_reg=0.2058, d_time=0.01(0.02), f_time=1.50(1.48), b_time=1.50(1.50)  Time cost: 03:54/1:32:45 [18:41:26/12:49:14]  Acc_iter 46500       Data time: 0.01(0.02)  Forward time: 1.50(1.48)  Batch time: 1.50(1.50)
2025-09-04 03:58:26,867   INFO  Train:   13/20 ( 65%) [ 205/3862 (  5%)]  Loss: 1.351 (1.29)  LR: 7.440e-04  Grad: 26.0352  max=0.9757(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9840(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4327, loss_cls=0.0739, loss_bbox=0.4893, matched_ious=0.5732, loss_iou=0.0862, loss_iou_reg=0.2045, d_time=0.00(0.02), f_time=1.52(1.47), b_time=1.52(1.49)  Time cost: 05:05/1:30:28 [18:42:37/12:39:18]  Acc_iter 46550       Data time: 0.00(0.02)  Forward time: 1.52(1.47)  Batch time: 1.52(1.49)
2025-09-04 03:59:37,722   INFO  Train:   13/20 ( 65%) [ 255/3862 (  7%)]  Loss: 1.270 (1.29)  LR: 7.425e-04  Grad: 26.0592  max=0.9790(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9853(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4296, loss_cls=0.0723, loss_bbox=0.5054, matched_ious=0.5730, loss_iou=0.0882, loss_iou_reg=0.2038, d_time=0.01(0.02), f_time=1.43(1.46), b_time=1.44(1.47)  Time cost: 06:16/1:28:26 [18:43:48/12:31:21]  Acc_iter 46600       Data time: 0.01(0.02)  Forward time: 1.43(1.46)  Batch time: 1.44(1.47)
2025-09-04 04:00:49,566   INFO  Train:   13/20 ( 65%) [ 305/3862 (  8%)]  Loss: 1.353 (1.29)  LR: 7.410e-04  Grad: 26.1076  max=0.9820(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9877(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4307, loss_cls=0.0764, loss_bbox=0.4989, matched_ious=0.5704, loss_iou=0.0879, loss_iou_reg=0.2055, d_time=0.01(0.01), f_time=1.40(1.45), b_time=1.41(1.47)  Time cost: 07:28/1:26:53 [18:45:00/12:27:15]  Acc_iter 46650       Data time: 0.01(0.01)  Forward time: 1.40(1.45)  Batch time: 1.41(1.47)
2025-09-04 04:02:03,466   INFO  Train:   13/20 ( 65%) [ 355/3862 (  9%)]  Loss: 1.220 (1.30)  LR: 7.395e-04  Grad: 26.1488  max=0.9817(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9880(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4499, loss_cls=0.0747, loss_bbox=0.4944, matched_ious=0.5752, loss_iou=0.0859, loss_iou_reg=0.2025, d_time=0.00(0.01), f_time=1.40(1.46), b_time=1.41(1.47)  Time cost: 08:42/1:25:46 [18:46:14/12:26:55]  Acc_iter 46700       Data time: 0.00(0.01)  Forward time: 1.40(1.46)  Batch time: 1.41(1.47)
2025-09-04 04:03:18,358   INFO  Train:   13/20 ( 65%) [ 405/3862 ( 10%)]  Loss: 1.304 (1.30)  LR: 7.380e-04  Grad: 26.1977  max=0.9865(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9913(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4312, loss_cls=0.0751, loss_bbox=0.4953, matched_ious=0.5684, loss_iou=0.0862, loss_iou_reg=0.2074, d_time=0.01(0.01), f_time=1.42(1.46), b_time=1.43(1.47)  Time cost: 09:57/1:24:45 [18:47:29/12:27:36]  Acc_iter 46750       Data time: 0.01(0.01)  Forward time: 1.42(1.46)  Batch time: 1.43(1.47)
2025-09-04 04:04:29,401   INFO  Train:   13/20 ( 65%) [ 455/3862 ( 12%)]  Loss: 1.235 (1.29)  LR: 7.365e-04  Grad: 26.2279  max=0.9852(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9912(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4245, loss_cls=0.0735, loss_bbox=0.4890, matched_ious=0.5755, loss_iou=0.0871, loss_iou_reg=0.2031, d_time=0.00(0.01), f_time=1.39(1.45), b_time=1.39(1.47)  Time cost: 11:08/1:23:13 [18:48:40/12:23:34]  Acc_iter 46800       Data time: 0.00(0.01)  Forward time: 1.39(1.45)  Batch time: 1.39(1.47)
2025-09-04 04:05:41,545   INFO  Train:   13/20 ( 65%) [ 505/3862 ( 13%)]  Loss: 1.716 (1.29)  LR: 7.350e-04  Grad: 26.2674  max=0.9899(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9953(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4269, loss_cls=0.0718, loss_bbox=0.4944, matched_ious=0.5710, loss_iou=0.0879, loss_iou_reg=0.2066, d_time=0.00(0.01), f_time=1.27(1.45), b_time=1.28(1.46)  Time cost: 12:20/1:21:52 [18:49:52/12:21:13]  Acc_iter 46850       Data time: 0.00(0.01)  Forward time: 1.27(1.45)  Batch time: 1.28(1.46)
2025-09-04 04:06:52,624   INFO  Train:   13/20 ( 65%) [ 555/3862 ( 14%)]  Loss: 1.516 (1.30)  LR: 7.335e-04  Grad: 26.2873  max=0.9918(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9945(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4412, loss_cls=0.0755, loss_bbox=0.5135, matched_ious=0.5684, loss_iou=0.0890, loss_iou_reg=0.2062, d_time=0.00(0.01), f_time=1.48(1.45), b_time=1.48(1.46)  Time cost: 13:31/1:20:26 [18:51:03/12:18:06]  Acc_iter 46900       Data time: 0.00(0.01)  Forward time: 1.48(1.45)  Batch time: 1.48(1.46)
2025-09-04 04:08:06,338   INFO  Train:   13/20 ( 65%) [ 605/3862 ( 16%)]  Loss: 1.012 (1.30)  LR: 7.320e-04  Grad: 26.3315  max=0.9903(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9955(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4359, loss_cls=0.0743, loss_bbox=0.4972, matched_ious=0.5734, loss_iou=0.0875, loss_iou_reg=0.2036, d_time=0.00(0.01), f_time=1.42(1.45), b_time=1.43(1.46)  Time cost: 14:45/1:19:17 [18:52:17/12:17:29]  Acc_iter 46950       Data time: 0.00(0.01)  Forward time: 1.42(1.45)  Batch time: 1.43(1.46)
2025-09-04 04:09:21,842   INFO  Train:   13/20 ( 65%) [ 655/3862 ( 17%)]  Loss: 1.307 (1.29)  LR: 7.305e-04  Grad: 26.3883  max=0.9949(module.dense_head.decoder.self_attn.in_proj_weight)  min: -0.9991(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4205, loss_cls=0.0720, loss_bbox=0.4635, matched_ious=0.5780, loss_iou=0.0867, loss_iou_reg=0.2017, d_time=0.01(0.01), f_time=1.29(1.46), b_time=1.30(1.47)  Time cost: 16:00/1:18:16 [18:53:32/12:18:10]  Acc_iter 47000       Data time: 0.01(0.01)  Forward time: 1.29(1.46)  Batch time: 1.30(1.47)
2025-09-04 04:10:32,550   INFO  Train:   13/20 ( 65%) [ 705/3862 ( 18%)]  Loss: 1.188 (1.29)  LR: 7.290e-04  Grad: 26.4299  max=0.9932(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0021(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4416, loss_cls=0.0757, loss_bbox=0.5007, matched_ious=0.5765, loss_iou=0.0849, loss_iou_reg=0.2022, d_time=0.01(0.01), f_time=1.31(1.45), b_time=1.32(1.46)  Time cost: 17:11/1:16:52 [18:54:43/12:15:09]  Acc_iter 47050       Data time: 0.01(0.01)  Forward time: 1.31(1.45)  Batch time: 1.32(1.46)
2025-09-04 04:11:44,206   INFO  Train:   13/20 ( 65%) [ 755/3862 ( 20%)]  Loss: 1.276 (1.29)  LR: 7.275e-04  Grad: 26.4468  max=0.9936(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0034(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4330, loss_cls=0.0725, loss_bbox=0.5168, matched_ious=0.5679, loss_iou=0.0877, loss_iou_reg=0.2075, d_time=0.00(0.01), f_time=1.32(1.45), b_time=1.32(1.46)  Time cost: 18:23/1:15:33 [18:55:55/12:13:00]  Acc_iter 47100       Data time: 0.00(0.01)  Forward time: 1.32(1.45)  Batch time: 1.32(1.46)
2025-09-04 04:12:55,127   INFO  Train:   13/20 ( 65%) [ 805/3862 ( 21%)]  Loss: 1.324 (1.30)  LR: 7.260e-04  Grad: 26.4933  max=1.0034(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0066(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4476, loss_cls=0.0768, loss_bbox=0.5284, matched_ious=0.5702, loss_iou=0.0871, loss_iou_reg=0.2041, d_time=0.01(0.01), f_time=1.38(1.45), b_time=1.39(1.46)  Time cost: 19:34/1:14:12 [18:57:06/12:10:31]  Acc_iter 47150       Data time: 0.01(0.01)  Forward time: 1.38(1.45)  Batch time: 1.39(1.46)
2025-09-04 04:14:08,729   INFO  Train:   13/20 ( 65%) [ 855/3862 ( 22%)]  Loss: 1.104 (1.30)  LR: 7.245e-04  Grad: 26.5339  max=0.9999(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0088(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4285, loss_cls=0.0740, loss_bbox=0.4870, matched_ious=0.5768, loss_iou=0.0861, loss_iou_reg=0.2023, d_time=0.01(0.01), f_time=1.37(1.45), b_time=1.37(1.46)  Time cost: 20:47/1:13:02 [18:58:19/12:09:45]  Acc_iter 47200       Data time: 0.01(0.01)  Forward time: 1.37(1.45)  Batch time: 1.37(1.46)
2025-09-04 04:15:23,046   INFO  Train:   13/20 ( 65%) [ 905/3862 ( 23%)]  Loss: 1.313 (1.30)  LR: 7.230e-04  Grad: 26.5656  max=1.0021(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0095(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4309, loss_cls=0.0725, loss_bbox=0.4967, matched_ious=0.5759, loss_iou=0.0856, loss_iou_reg=0.2019, d_time=0.01(0.01), f_time=1.46(1.45), b_time=1.46(1.46)  Time cost: 22:01/1:11:54 [18:59:34/12:09:20]  Acc_iter 47250       Data time: 0.01(0.01)  Forward time: 1.46(1.45)  Batch time: 1.46(1.46)
2025-09-04 04:16:34,718   INFO  Train:   13/20 ( 65%) [ 955/3862 ( 25%)]  Loss: 1.508 (1.29)  LR: 7.215e-04  Grad: 26.6268  max=1.0093(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0115(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4187, loss_cls=0.0740, loss_bbox=0.4952, matched_ious=0.5743, loss_iou=0.0866, loss_iou_reg=0.2041, d_time=0.01(0.01), f_time=1.43(1.45), b_time=1.43(1.46)  Time cost: 23:13/1:10:37 [19:00:45/12:07:27]  Acc_iter 47300       Data time: 0.01(0.01)  Forward time: 1.43(1.45)  Batch time: 1.43(1.46)
2025-09-04 04:17:46,762   INFO  Train:   13/20 ( 65%) [1005/3862 ( 26%)]  Loss: 1.095 (1.30)  LR: 7.199e-04  Grad: 26.6549  max=1.0102(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0133(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4345, loss_cls=0.0735, loss_bbox=0.4993, matched_ious=0.5711, loss_iou=0.0876, loss_iou_reg=0.2058, d_time=0.00(0.01), f_time=1.44(1.45), b_time=1.44(1.46)  Time cost: 24:25/1:09:22 [19:01:57/12:05:49]  Acc_iter 47350       Data time: 0.00(0.01)  Forward time: 1.44(1.45)  Batch time: 1.44(1.46)
2025-09-04 04:18:57,884   INFO  Train:   13/20 ( 65%) [1055/3862 ( 27%)]  Loss: 1.181 (1.29)  LR: 7.184e-04  Grad: 26.6936  max=1.0168(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0124(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4140, loss_cls=0.0704, loss_bbox=0.4759, matched_ious=0.5769, loss_iou=0.0866, loss_iou_reg=0.2026, d_time=0.00(0.01), f_time=1.53(1.45), b_time=1.53(1.46)  Time cost: 25:36/1:08:05 [19:03:09/12:03:47]  Acc_iter 47400       Data time: 0.00(0.01)  Forward time: 1.53(1.45)  Batch time: 1.53(1.46)
2025-09-04 04:20:11,501   INFO  Train:   13/20 ( 65%) [1105/3862 ( 29%)]  Loss: 1.115 (1.29)  LR: 7.169e-04  Grad: 26.7414  max=1.0160(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0151(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4240, loss_cls=0.0743, loss_bbox=0.4788, matched_ious=0.5744, loss_iou=0.0861, loss_iou_reg=0.2040, d_time=0.01(0.01), f_time=1.37(1.45), b_time=1.37(1.46)  Time cost: 26:50/1:06:54 [19:04:22/12:02:58]  Acc_iter 47450       Data time: 0.01(0.01)  Forward time: 1.37(1.45)  Batch time: 1.37(1.46)
2025-09-04 04:21:24,973   INFO  Train:   13/20 ( 65%) [1155/3862 ( 30%)]  Loss: 1.384 (1.29)  LR: 7.154e-04  Grad: 26.7845  max=1.0191(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0165(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4489, loss_cls=0.0768, loss_bbox=0.5196, matched_ious=0.5715, loss_iou=0.0865, loss_iou_reg=0.2048, d_time=0.01(0.01), f_time=1.49(1.45), b_time=1.49(1.46)  Time cost: 28:03/1:05:43 [19:05:36/12:02:02]  Acc_iter 47500       Data time: 0.01(0.01)  Forward time: 1.49(1.45)  Batch time: 1.49(1.46)
2025-09-04 04:22:36,171   INFO  Train:   13/20 ( 65%) [1205/3862 ( 31%)]  Loss: 1.564 (1.29)  LR: 7.138e-04  Grad: 26.8187  max=1.0220(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0171(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4092, loss_cls=0.0695, loss_bbox=0.4939, matched_ious=0.5769, loss_iou=0.0879, loss_iou_reg=0.2030, d_time=0.01(0.01), f_time=1.31(1.45), b_time=1.32(1.46)  Time cost: 29:15/1:04:26 [19:06:47/12:00:09]  Acc_iter 47550       Data time: 0.01(0.01)  Forward time: 1.31(1.45)  Batch time: 1.32(1.46)
2025-09-04 04:23:47,678   INFO  Train:   13/20 ( 65%) [1255/3862 ( 32%)]  Loss: 1.428 (1.29)  LR: 7.123e-04  Grad: 26.8373  max=1.0249(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0201(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4239, loss_cls=0.0725, loss_bbox=0.4907, matched_ious=0.5752, loss_iou=0.0876, loss_iou_reg=0.2039, d_time=0.01(0.01), f_time=1.44(1.44), b_time=1.45(1.45)  Time cost: 30:26/1:03:11 [19:07:58/11:58:26]  Acc_iter 47600       Data time: 0.01(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.45)
2025-09-04 04:24:58,815   INFO  Train:   13/20 ( 65%) [1305/3862 ( 34%)]  Loss: 1.278 (1.29)  LR: 7.108e-04  Grad: 26.8873  max=1.0263(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0239(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4344, loss_cls=0.0753, loss_bbox=0.4927, matched_ious=0.5758, loss_iou=0.0865, loss_iou_reg=0.2021, d_time=0.00(0.01), f_time=1.41(1.44), b_time=1.41(1.45)  Time cost: 31:37/1:01:55 [19:09:09/11:56:38]  Acc_iter 47650       Data time: 0.00(0.01)  Forward time: 1.41(1.44)  Batch time: 1.41(1.45)
2025-09-04 04:26:13,579   INFO  Train:   13/20 ( 65%) [1355/3862 ( 35%)]  Loss: 1.474 (1.29)  LR: 7.092e-04  Grad: 26.9192  max=1.0291(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0244(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4213, loss_cls=0.0729, loss_bbox=0.4712, matched_ious=0.5768, loss_iou=0.0876, loss_iou_reg=0.2036, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 32:52/1:00:46 [19:10:24/11:56:11]  Acc_iter 47700       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-04 04:27:27,184   INFO  Train:   13/20 ( 65%) [1405/3862 ( 36%)]  Loss: 1.371 (1.29)  LR: 7.077e-04  Grad: 26.9568  max=1.0295(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0247(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4312, loss_cls=0.0752, loss_bbox=0.4893, matched_ious=0.5751, loss_iou=0.0857, loss_iou_reg=0.2020, d_time=0.01(0.01), f_time=1.49(1.45), b_time=1.49(1.46)  Time cost: 34:06/59:35 [19:11:38/11:55:17]  Acc_iter 47750       Data time: 0.01(0.01)  Forward time: 1.49(1.45)  Batch time: 1.49(1.46)
2025-09-04 04:28:39,972   INFO  Train:   13/20 ( 65%) [1455/3862 ( 38%)]  Loss: 1.373 (1.29)  LR: 7.061e-04  Grad: 26.9775  max=1.0350(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0265(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4167, loss_cls=0.0729, loss_bbox=0.4545, matched_ious=0.5789, loss_iou=0.0865, loss_iou_reg=0.2022, d_time=0.00(0.01), f_time=1.45(1.45), b_time=1.46(1.46)  Time cost: 35:18/58:22 [19:12:51/11:54:05]  Acc_iter 47800       Data time: 0.00(0.01)  Forward time: 1.45(1.45)  Batch time: 1.46(1.46)
2025-09-04 04:29:51,170   INFO  Train:   13/20 ( 65%) [1505/3862 ( 39%)]  Loss: 1.227 (1.29)  LR: 7.046e-04  Grad: 27.0365  max=1.0372(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0286(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4239, loss_cls=0.0720, loss_bbox=0.4959, matched_ious=0.5735, loss_iou=0.0884, loss_iou_reg=0.2056, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 36:30/57:07 [19:14:02/11:52:21]  Acc_iter 47850       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-04 04:31:02,586   INFO  Train:   13/20 ( 65%) [1555/3862 ( 40%)]  Loss: 1.715 (1.29)  LR: 7.031e-04  Grad: 27.0664  max=1.0398(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0308(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4339, loss_cls=0.0756, loss_bbox=0.5058, matched_ious=0.5766, loss_iou=0.0864, loss_iou_reg=0.2018, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 37:41/55:53 [19:15:13/11:50:44]  Acc_iter 47900       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-04 04:32:18,131   INFO  Train:   13/20 ( 65%) [1605/3862 ( 42%)]  Loss: 1.022 (1.29)  LR: 7.015e-04  Grad: 27.1060  max=1.0396(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0329(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4240, loss_cls=0.0718, loss_bbox=0.4816, matched_ious=0.5775, loss_iou=0.0880, loss_iou_reg=0.2024, d_time=0.00(0.01), f_time=2.21(1.45), b_time=2.22(1.46)  Time cost: 38:57/54:44 [19:16:29/11:50:24]  Acc_iter 47950       Data time: 0.00(0.01)  Forward time: 2.21(1.45)  Batch time: 2.22(1.46)
2025-09-04 04:33:31,471   INFO  Train:   13/20 ( 65%) [1655/3862 ( 43%)]  Loss: 1.129 (1.29)  LR: 7.000e-04  Grad: 27.1292  max=1.0434(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0339(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4251, loss_cls=0.0733, loss_bbox=0.4797, matched_ious=0.5713, loss_iou=0.0873, loss_iou_reg=0.2060, d_time=0.01(0.01), f_time=1.44(1.45), b_time=1.44(1.46)  Time cost: 40:10/53:32 [19:17:42/11:49:21]  Acc_iter 48000       Data time: 0.01(0.01)  Forward time: 1.44(1.45)  Batch time: 1.44(1.46)
2025-09-04 04:34:43,562   INFO  Train:   13/20 ( 65%) [1705/3862 ( 44%)]  Loss: 1.438 (1.29)  LR: 6.984e-04  Grad: 27.1605  max=1.0427(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0358(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4357, loss_cls=0.0746, loss_bbox=0.4999, matched_ious=0.5741, loss_iou=0.0874, loss_iou_reg=0.2021, d_time=0.00(0.01), f_time=1.48(1.45), b_time=1.49(1.46)  Time cost: 41:22/52:18 [19:18:54/11:47:56]  Acc_iter 48050       Data time: 0.00(0.01)  Forward time: 1.48(1.45)  Batch time: 1.49(1.46)
2025-09-04 04:35:54,761   INFO  Train:   13/20 ( 65%) [1755/3862 ( 45%)]  Loss: 1.284 (1.29)  LR: 6.968e-04  Grad: 27.2174  max=1.0442(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0382(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4241, loss_cls=0.0730, loss_bbox=0.4758, matched_ious=0.5726, loss_iou=0.0868, loss_iou_reg=0.2056, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 42:33/51:04 [19:20:05/11:46:18]  Acc_iter 48100       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-04 04:37:05,884   INFO  Train:   13/20 ( 65%) [1805/3862 ( 47%)]  Loss: 0.9916 (1.29)  LR: 6.953e-04  Grad: 27.2686  max=1.0459(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0433(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4206, loss_cls=0.0710, loss_bbox=0.4837, matched_ious=0.5765, loss_iou=0.0872, loss_iou_reg=0.2013, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 43:44/49:49 [19:21:17/11:44:40]  Acc_iter 48150       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-04 04:38:21,424   INFO  Train:   13/20 ( 65%) [1855/3862 ( 48%)]  Loss: 1.338 (1.29)  LR: 6.937e-04  Grad: 27.2748  max=1.0498(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0423(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4265, loss_cls=0.0723, loss_bbox=0.5128, matched_ious=0.5739, loss_iou=0.0878, loss_iou_reg=0.2047, d_time=0.01(0.01), f_time=1.35(1.45), b_time=1.35(1.46)  Time cost: 45:00/48:40 [19:22:32/11:44:12]  Acc_iter 48200       Data time: 0.01(0.01)  Forward time: 1.35(1.45)  Batch time: 1.35(1.46)
2025-09-04 04:39:33,732   INFO  Train:   13/20 ( 65%) [1905/3862 ( 49%)]  Loss: 1.221 (1.29)  LR: 6.922e-04  Grad: 27.3314  max=1.0525(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0452(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4129, loss_cls=0.0695, loss_bbox=0.4833, matched_ious=0.5797, loss_iou=0.0858, loss_iou_reg=0.2015, d_time=0.01(0.01), f_time=1.44(1.45), b_time=1.45(1.45)  Time cost: 46:12/47:26 [19:23:44/11:42:53]  Acc_iter 48250       Data time: 0.01(0.01)  Forward time: 1.44(1.45)  Batch time: 1.45(1.45)
2025-09-04 04:40:45,361   INFO  Train:   13/20 ( 65%) [1955/3862 ( 51%)]  Loss: 1.072 (1.29)  LR: 6.906e-04  Grad: 27.3885  max=1.0519(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0471(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4292, loss_cls=0.0724, loss_bbox=0.4923, matched_ious=0.5786, loss_iou=0.0868, loss_iou_reg=0.2015, d_time=0.02(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 47:24/46:13 [19:24:56/11:41:24]  Acc_iter 48300       Data time: 0.02(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-04 04:41:56,615   INFO  Train:   13/20 ( 65%) [2005/3862 ( 52%)]  Loss: 1.296 (1.29)  LR: 6.890e-04  Grad: 27.4101  max=1.0543(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0492(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4251, loss_cls=0.0734, loss_bbox=0.4757, matched_ious=0.5760, loss_iou=0.0852, loss_iou_reg=0.2032, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 48:35/44:58 [19:26:07/11:39:50]  Acc_iter 48350       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-04 04:43:07,519   INFO  Train:   13/20 ( 65%) [2055/3862 ( 53%)]  Loss: 1.436 (1.29)  LR: 6.875e-04  Grad: 27.4462  max=1.0556(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0520(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4244, loss_cls=0.0723, loss_bbox=0.4751, matched_ious=0.5776, loss_iou=0.0871, loss_iou_reg=0.2022, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 49:46/43:44 [19:27:18/11:38:12]  Acc_iter 48400       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-04 04:44:24,182   INFO  Train:   13/20 ( 65%) [2105/3862 ( 55%)]  Loss: 1.202 (1.28)  LR: 6.859e-04  Grad: 27.4800  max=1.0576(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0551(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4281, loss_cls=0.0746, loss_bbox=0.4796, matched_ious=0.5812, loss_iou=0.0855, loss_iou_reg=0.1993, d_time=0.00(0.01), f_time=1.44(1.45), b_time=1.44(1.45)  Time cost: 51:03/42:35 [19:28:35/11:37:55]  Acc_iter 48450       Data time: 0.00(0.01)  Forward time: 1.44(1.45)  Batch time: 1.44(1.45)
2025-09-04 04:45:36,406   INFO  Train:   13/20 ( 65%) [2155/3862 ( 56%)]  Loss: 1.326 (1.28)  LR: 6.843e-04  Grad: 27.4979  max=1.0600(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0552(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4256, loss_cls=0.0739, loss_bbox=0.4838, matched_ious=0.5741, loss_iou=0.0879, loss_iou_reg=0.2033, d_time=0.01(0.01), f_time=1.38(1.45), b_time=1.39(1.45)  Time cost: 52:15/41:22 [19:29:47/11:36:36]  Acc_iter 48500       Data time: 0.01(0.01)  Forward time: 1.38(1.45)  Batch time: 1.39(1.45)
2025-09-04 04:46:48,429   INFO  Train:   13/20 ( 65%) [2205/3862 ( 57%)]  Loss: 0.9790 (1.28)  LR: 6.827e-04  Grad: 27.5599  max=1.0598(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0566(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4177, loss_cls=0.0712, loss_bbox=0.4795, matched_ious=0.5806, loss_iou=0.0862, loss_iou_reg=0.2009, d_time=0.00(0.01), f_time=1.32(1.44), b_time=1.32(1.45)  Time cost: 53:27/40:09 [19:30:59/11:35:14]  Acc_iter 48550       Data time: 0.00(0.01)  Forward time: 1.32(1.44)  Batch time: 1.32(1.45)
2025-09-04 04:47:59,962   INFO  Train:   13/20 ( 65%) [2255/3862 ( 58%)]  Loss: 1.192 (1.28)  LR: 6.812e-04  Grad: 27.5954  max=1.0591(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0596(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4377, loss_cls=0.0752, loss_bbox=0.4859, matched_ious=0.5817, loss_iou=0.0864, loss_iou_reg=0.1998, d_time=0.01(0.01), f_time=1.45(1.44), b_time=1.45(1.45)  Time cost: 54:38/38:55 [19:32:11/11:33:47]  Acc_iter 48600       Data time: 0.01(0.01)  Forward time: 1.45(1.44)  Batch time: 1.45(1.45)
2025-09-04 04:49:11,544   INFO  Train:   13/20 ( 65%) [2305/3862 ( 60%)]  Loss: 1.342 (1.28)  LR: 6.796e-04  Grad: 27.6467  max=1.0658(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0608(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4326, loss_cls=0.0751, loss_bbox=0.4924, matched_ious=0.5812, loss_iou=0.0855, loss_iou_reg=0.2001, d_time=0.02(0.01), f_time=1.45(1.44), b_time=1.46(1.45)  Time cost: 55:50/37:42 [19:33:22/11:32:20]  Acc_iter 48650       Data time: 0.02(0.01)  Forward time: 1.45(1.44)  Batch time: 1.46(1.45)
2025-09-04 04:50:27,213   INFO  Train:   13/20 ( 65%) [2355/3862 ( 61%)]  Loss: 1.453 (1.28)  LR: 6.780e-04  Grad: 27.6705  max=1.0704(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0636(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4249, loss_cls=0.0733, loss_bbox=0.4865, matched_ious=0.5823, loss_iou=0.0865, loss_iou_reg=0.1999, d_time=0.01(0.01), f_time=1.45(1.45), b_time=1.46(1.45)  Time cost: 57:06/36:31 [19:34:38/11:31:44]  Acc_iter 48700       Data time: 0.01(0.01)  Forward time: 1.45(1.45)  Batch time: 1.46(1.45)
2025-09-04 04:51:39,727   INFO  Train:   13/20 ( 65%) [2405/3862 ( 62%)]  Loss: 1.198 (1.28)  LR: 6.764e-04  Grad: 27.7223  max=1.0713(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0663(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4177, loss_cls=0.0708, loss_bbox=0.4758, matched_ious=0.5723, loss_iou=0.0871, loss_iou_reg=0.2049, d_time=0.00(0.01), f_time=1.49(1.45), b_time=1.50(1.45)  Time cost: 58:18/35:18 [19:35:50/11:30:29]  Acc_iter 48750       Data time: 0.00(0.01)  Forward time: 1.49(1.45)  Batch time: 1.50(1.45)
2025-09-04 04:52:52,191   INFO  Train:   13/20 ( 65%) [2455/3862 ( 64%)]  Loss: 1.333 (1.28)  LR: 6.748e-04  Grad: 27.7455  max=1.0749(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0694(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4165, loss_cls=0.0701, loss_bbox=0.4816, matched_ious=0.5790, loss_iou=0.0870, loss_iou_reg=0.2024, d_time=0.01(0.01), f_time=1.50(1.45), b_time=1.51(1.45)  Time cost: 59:31/34:05 [19:37:03/11:29:14]  Acc_iter 48800       Data time: 0.01(0.01)  Forward time: 1.50(1.45)  Batch time: 1.51(1.45)
2025-09-04 04:54:04,106   INFO  Train:   13/20 ( 65%) [2505/3862 ( 65%)]  Loss: 1.480 (1.28)  LR: 6.732e-04  Grad: 27.7833  max=1.0753(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0687(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4414, loss_cls=0.0735, loss_bbox=0.4823, matched_ious=0.5780, loss_iou=0.0868, loss_iou_reg=0.2014, d_time=0.01(0.01), f_time=1.39(1.44), b_time=1.40(1.45)  Time cost: 1:00:43/32:52 [19:38:15/11:27:52]  Acc_iter 48850       Data time: 0.01(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.45)
2025-09-04 04:55:15,597   INFO  Train:   13/20 ( 65%) [2555/3862 ( 66%)]  Loss: 1.268 (1.28)  LR: 6.716e-04  Grad: 27.8345  max=1.0723(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0737(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4196, loss_cls=0.0726, loss_bbox=0.5123, matched_ious=0.5759, loss_iou=0.0871, loss_iou_reg=0.2025, d_time=0.00(0.01), f_time=1.30(1.44), b_time=1.31(1.45)  Time cost: 1:01:54/31:39 [19:39:26/11:26:26]  Acc_iter 48900       Data time: 0.00(0.01)  Forward time: 1.30(1.44)  Batch time: 1.31(1.45)
2025-09-04 04:56:30,810   INFO  Train:   13/20 ( 65%) [2605/3862 ( 67%)]  Loss: 1.162 (1.28)  LR: 6.700e-04  Grad: 27.8805  max=1.0752(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0736(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4203, loss_cls=0.0717, loss_bbox=0.4657, matched_ious=0.5849, loss_iou=0.0852, loss_iou_reg=0.1996, d_time=0.00(0.01), f_time=1.46(1.44), b_time=1.46(1.45)  Time cost: 1:03:09/30:27 [19:40:41/11:25:41]  Acc_iter 48950       Data time: 0.00(0.01)  Forward time: 1.46(1.44)  Batch time: 1.46(1.45)
2025-09-04 04:57:43,509   INFO  Train:   13/20 ( 65%) [2655/3862 ( 69%)]  Loss: 1.272 (1.28)  LR: 6.685e-04  Grad: 27.9569  max=1.0778(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.9414(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4296, loss_cls=0.0739, loss_bbox=0.5080, matched_ious=0.5802, loss_iou=0.0862, loss_iou_reg=0.2013, d_time=0.00(0.01), f_time=1.42(1.45), b_time=1.43(1.45)  Time cost: 1:04:22/29:15 [19:41:54/11:24:28]  Acc_iter 49000       Data time: 0.00(0.01)  Forward time: 1.42(1.45)  Batch time: 1.43(1.45)
2025-09-04 04:58:54,933   INFO  Train:   13/20 ( 65%) [2705/3862 ( 70%)]  Loss: 1.230 (1.28)  LR: 6.669e-04  Grad: 27.9194  max=1.0762(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0764(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4135, loss_cls=0.0698, loss_bbox=0.4559, matched_ious=0.5842, loss_iou=0.0856, loss_iou_reg=0.1995, d_time=0.00(0.01), f_time=1.39(1.44), b_time=1.40(1.45)  Time cost: 1:05:33/28:01 [19:43:06/11:23:02]  Acc_iter 49050       Data time: 0.00(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.45)
2025-09-04 05:00:06,164   INFO  Train:   13/20 ( 65%) [2755/3862 ( 71%)]  Loss: 1.406 (1.28)  LR: 6.653e-04  Grad: 27.9668  max=1.0798(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0798(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4203, loss_cls=0.0699, loss_bbox=0.4869, matched_ious=0.5789, loss_iou=0.0865, loss_iou_reg=0.2008, d_time=0.01(0.01), f_time=1.33(1.44), b_time=1.34(1.45)  Time cost: 1:06:45/26:48 [19:44:17/11:21:35]  Acc_iter 49100       Data time: 0.01(0.01)  Forward time: 1.33(1.44)  Batch time: 1.34(1.45)
2025-09-04 05:01:17,280   INFO  Train:   13/20 ( 65%) [2805/3862 ( 73%)]  Loss: 0.9998 (1.28)  LR: 6.637e-04  Grad: 27.9979  max=1.0825(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0827(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4183, loss_cls=0.0716, loss_bbox=0.4870, matched_ious=0.5822, loss_iou=0.0866, loss_iou_reg=0.2016, d_time=0.01(0.01), f_time=1.47(1.44), b_time=1.48(1.45)  Time cost: 1:07:56/25:35 [19:45:28/11:20:07]  Acc_iter 49150       Data time: 0.01(0.01)  Forward time: 1.47(1.44)  Batch time: 1.48(1.45)
2025-09-04 05:02:33,806   INFO  Train:   13/20 ( 65%) [2855/3862 ( 74%)]  Loss: 1.310 (1.28)  LR: 6.621e-04  Grad: 28.0394  max=1.0816(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0851(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4083, loss_cls=0.0699, loss_bbox=0.4712, matched_ious=0.5824, loss_iou=0.0853, loss_iou_reg=0.1993, d_time=0.00(0.01), f_time=1.50(1.44), b_time=1.50(1.45)  Time cost: 1:09:12/24:24 [19:46:44/11:19:32]  Acc_iter 49200       Data time: 0.00(0.01)  Forward time: 1.50(1.44)  Batch time: 1.50(1.45)
2025-09-04 05:03:46,238   INFO  Train:   13/20 ( 65%) [2905/3862 ( 75%)]  Loss: 1.198 (1.28)  LR: 6.605e-04  Grad: 28.0500  max=1.0862(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0853(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4233, loss_cls=0.0738, loss_bbox=0.4984, matched_ious=0.5766, loss_iou=0.0871, loss_iou_reg=0.2027, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 1:10:25/23:11 [19:47:57/11:18:17]  Acc_iter 49250       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-04 05:04:57,917   INFO  Train:   13/20 ( 65%) [2955/3862 ( 77%)]  Loss: 0.9788 (1.28)  LR: 6.588e-04  Grad: 28.1340  max=1.0847(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0857(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4199, loss_cls=0.0720, loss_bbox=0.4934, matched_ious=0.5769, loss_iou=0.0855, loss_iou_reg=0.2018, d_time=0.01(0.01), f_time=1.50(1.44), b_time=1.50(1.45)  Time cost: 1:11:36/21:58 [19:49:09/11:16:55]  Acc_iter 49300       Data time: 0.01(0.01)  Forward time: 1.50(1.44)  Batch time: 1.50(1.45)
2025-09-04 05:06:09,587   INFO  Train:   13/20 ( 65%) [3005/3862 ( 78%)]  Loss: 1.154 (1.28)  LR: 6.572e-04  Grad: 28.1576  max=1.0889(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0870(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4140, loss_cls=0.0702, loss_bbox=0.4628, matched_ious=0.5810, loss_iou=0.0865, loss_iou_reg=0.2014, d_time=0.01(0.01), f_time=1.59(1.44), b_time=1.60(1.45)  Time cost: 1:12:48/20:45 [19:50:20/11:15:32]  Acc_iter 49350       Data time: 0.01(0.01)  Forward time: 1.59(1.44)  Batch time: 1.60(1.45)
2025-09-04 05:07:20,723   INFO  Train:   13/20 ( 65%) [3055/3862 ( 79%)]  Loss: 1.371 (1.28)  LR: 6.556e-04  Grad: 28.1799  max=1.0893(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0894(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4134, loss_cls=0.0718, loss_bbox=0.4757, matched_ious=0.5762, loss_iou=0.0857, loss_iou_reg=0.2031, d_time=0.00(0.01), f_time=1.44(1.44), b_time=1.44(1.45)  Time cost: 1:13:59/19:32 [19:51:31/11:14:06]  Acc_iter 49400       Data time: 0.00(0.01)  Forward time: 1.44(1.44)  Batch time: 1.44(1.45)
2025-09-04 05:08:37,607   INFO  Train:   13/20 ( 65%) [3105/3862 ( 80%)]  Loss: 1.233 (1.28)  LR: 6.540e-04  Grad: 28.2058  max=1.0908(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0887(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4230, loss_cls=0.0721, loss_bbox=0.4689, matched_ious=0.5847, loss_iou=0.0848, loss_iou_reg=0.1985, d_time=0.01(0.01), f_time=1.37(1.45), b_time=1.37(1.45)  Time cost: 1:15:16/18:20 [19:52:48/11:13:31]  Acc_iter 49450       Data time: 0.01(0.01)  Forward time: 1.37(1.45)  Batch time: 1.37(1.45)
2025-09-04 05:09:49,644   INFO  Train:   13/20 ( 65%) [3155/3862 ( 82%)]  Loss: 1.284 (1.28)  LR: 6.524e-04  Grad: 28.2823  max=1.0899(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0940(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4089, loss_cls=0.0725, loss_bbox=0.4731, matched_ious=0.5771, loss_iou=0.0871, loss_iou_reg=0.2037, d_time=0.00(0.01), f_time=1.33(1.45), b_time=1.34(1.45)  Time cost: 1:16:28/17:07 [19:54:00/11:12:13]  Acc_iter 49500       Data time: 0.00(0.01)  Forward time: 1.33(1.45)  Batch time: 1.34(1.45)
2025-09-04 05:11:00,226   INFO  Train:   13/20 ( 65%) [3205/3862 ( 83%)]  Loss: 1.414 (1.28)  LR: 6.508e-04  Grad: 28.3064  max=1.0909(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0937(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4099, loss_cls=0.0710, loss_bbox=0.4801, matched_ious=0.5780, loss_iou=0.0869, loss_iou_reg=0.2020, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.38(1.45)  Time cost: 1:17:39/15:54 [19:55:11/11:10:42]  Acc_iter 49550       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.38(1.45)
2025-09-04 05:12:10,691   INFO  Train:   13/20 ( 65%) [3255/3862 ( 84%)]  Loss: 1.116 (1.28)  LR: 6.492e-04  Grad: 28.3194  max=1.0925(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0938(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4245, loss_cls=0.0729, loss_bbox=0.4674, matched_ious=0.5839, loss_iou=0.0868, loss_iou_reg=0.1995, d_time=0.00(0.01), f_time=1.39(1.44), b_time=1.40(1.45)  Time cost: 1:18:49/14:41 [19:56:21/11:09:10]  Acc_iter 49600       Data time: 0.00(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.45)
2025-09-04 05:13:21,331   INFO  Train:   13/20 ( 65%) [3305/3862 ( 86%)]  Loss: 1.100 (1.28)  LR: 6.476e-04  Grad: 28.3680  max=1.0915(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0985(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4279, loss_cls=0.0735, loss_bbox=0.4920, matched_ious=0.5793, loss_iou=0.0857, loss_iou_reg=0.2013, d_time=0.01(0.01), f_time=1.51(1.44), b_time=1.51(1.45)  Time cost: 1:20:00/13:28 [19:57:32/11:07:41]  Acc_iter 49650       Data time: 0.01(0.01)  Forward time: 1.51(1.44)  Batch time: 1.51(1.45)
2025-09-04 05:14:38,907   INFO  Train:   13/20 ( 65%) [3355/3862 ( 87%)]  Loss: 1.234 (1.28)  LR: 6.459e-04  Grad: 28.4820  max=1.5295(module.vfe.pfn_layers.0.linear.weight)  min: -1.0973(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4181, loss_cls=0.0699, loss_bbox=0.5087, matched_ious=0.5759, loss_iou=0.0872, loss_iou_reg=0.2017, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 1:21:17/12:16 [19:58:50/11:07:09]  Acc_iter 49700       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-04 05:15:50,089   INFO  Train:   13/20 ( 65%) [3405/3862 ( 88%)]  Loss: 1.138 (1.28)  LR: 6.443e-04  Grad: 28.4313  max=1.0985(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0993(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4156, loss_cls=0.0730, loss_bbox=0.4636, matched_ious=0.5823, loss_iou=0.0854, loss_iou_reg=0.1992, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.35(1.45)  Time cost: 1:22:29/11:04 [20:00:01/11:05:45]  Acc_iter 49750       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.35(1.45)
2025-09-04 05:17:01,278   INFO  Train:   13/20 ( 65%) [3455/3862 ( 89%)]  Loss: 1.232 (1.28)  LR: 6.427e-04  Grad: 28.4469  max=1.1011(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1004(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4147, loss_cls=0.0704, loss_bbox=0.4770, matched_ious=0.5780, loss_iou=0.0867, loss_iou_reg=0.2037, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 1:23:40/09:51 [20:01:12/11:04:20]  Acc_iter 49800       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-04 05:18:12,278   INFO  Train:   13/20 ( 65%) [3505/3862 ( 91%)]  Loss: 1.131 (1.28)  LR: 6.411e-04  Grad: 28.4820  max=1.0998(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1031(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4349, loss_cls=0.0749, loss_bbox=0.4974, matched_ious=0.5816, loss_iou=0.0856, loss_iou_reg=0.1985, d_time=0.00(0.01), f_time=1.44(1.44), b_time=1.44(1.45)  Time cost: 1:24:51/08:38 [20:02:23/11:02:55]  Acc_iter 49850       Data time: 0.00(0.01)  Forward time: 1.44(1.44)  Batch time: 1.44(1.45)
2025-09-04 05:19:23,539   INFO  Train:   13/20 ( 65%) [3555/3862 ( 92%)]  Loss: 1.368 (1.28)  LR: 6.394e-04  Grad: 28.5173  max=1.1057(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1032(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4017, loss_cls=0.0703, loss_bbox=0.4727, matched_ious=0.5811, loss_iou=0.0861, loss_iou_reg=0.2006, d_time=0.00(0.01), f_time=1.46(1.44), b_time=1.47(1.45)  Time cost: 1:26:02/07:25 [20:03:34/11:01:32]  Acc_iter 49900       Data time: 0.00(0.01)  Forward time: 1.46(1.44)  Batch time: 1.47(1.45)
2025-09-04 05:20:40,713   INFO  Train:   13/20 ( 65%) [3605/3862 ( 93%)]  Loss: 1.499 (1.28)  LR: 6.378e-04  Grad: 28.5577  max=1.1067(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1053(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4195, loss_cls=0.0709, loss_bbox=0.4822, matched_ious=0.5792, loss_iou=0.0865, loss_iou_reg=0.2028, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.42(1.45)  Time cost: 1:27:19/06:13 [20:04:51/11:00:54]  Acc_iter 49950       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.45)
2025-09-04 05:21:51,520   INFO  Train:   13/20 ( 65%) [3655/3862 ( 95%)]  Loss: 1.405 (1.28)  LR: 6.362e-04  Grad: 28.5744  max=1.1185(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1081(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4266, loss_cls=0.0741, loss_bbox=0.4866, matched_ious=0.5792, loss_iou=0.0869, loss_iou_reg=0.2007, d_time=0.00(0.01), f_time=1.34(1.44), b_time=1.34(1.45)  Time cost: 1:28:30/05:00 [20:06:02/10:59:28]  Acc_iter 50000       Data time: 0.00(0.01)  Forward time: 1.34(1.44)  Batch time: 1.34(1.45)
2025-09-04 05:23:02,790   INFO  Train:   13/20 ( 65%) [3705/3862 ( 96%)]  Loss: 1.404 (1.27)  LR: 6.345e-04  Grad: 28.6094  max=1.1125(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1073(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4134, loss_cls=0.0730, loss_bbox=0.4595, matched_ious=0.5836, loss_iou=0.0854, loss_iou_reg=0.2012, d_time=0.01(0.01), f_time=1.34(1.44), b_time=1.34(1.45)  Time cost: 1:29:41/03:47 [20:07:13/10:58:05]  Acc_iter 50050       Data time: 0.01(0.01)  Forward time: 1.34(1.44)  Batch time: 1.34(1.45)
2025-09-04 05:24:14,084   INFO  Train:   13/20 ( 65%) [3755/3862 ( 97%)]  Loss: 1.532 (1.27)  LR: 6.329e-04  Grad: 28.6459  max=1.1167(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1102(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4189, loss_cls=0.0729, loss_bbox=0.4873, matched_ious=0.5789, loss_iou=0.0852, loss_iou_reg=0.2002, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 1:30:53/02:35 [20:08:25/10:56:43]  Acc_iter 50100       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-04 05:25:24,614   INFO  Train:   13/20 ( 65%) [3805/3862 ( 99%)]  Loss: 1.041 (1.27)  LR: 6.313e-04  Grad: 28.6844  max=1.1139(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1122(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4107, loss_cls=0.0702, loss_bbox=0.4642, matched_ious=0.5843, loss_iou=0.0840, loss_iou_reg=0.1985, d_time=0.00(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 1:32:03/01:22 [20:09:35/10:55:16]  Acc_iter 50150       Data time: 0.00(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-04 05:26:40,491   INFO  Train:   13/20 ( 65%) [3855/3862 (100%)]  Loss: 1.416 (1.27)  LR: 6.296e-04  Grad: 28.7156  max=1.1163(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1176(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4168, loss_cls=0.0711, loss_bbox=0.4849, matched_ious=0.5771, loss_iou=0.0874, loss_iou_reg=0.2022, d_time=0.00(0.01), f_time=1.32(1.44), b_time=1.32(1.45)  Time cost: 1:33:19/00:10 [20:10:51/10:54:27]  Acc_iter 50200       Data time: 0.00(0.01)  Forward time: 1.32(1.44)  Batch time: 1.32(1.45)
2025-09-04 05:26:48,748   INFO  Train:   13/20 ( 65%) [3861/3862 (100%)]  Loss: 1.242 (1.27)  LR: 6.294e-04  Grad: 28.7193  max=1.1194(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1154(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3975, loss_cls=0.0717, loss_bbox=0.4659, matched_ious=0.5879, loss_iou=0.0823, loss_iou_reg=0.1972, d_time=0.01(0.01), f_time=1.39(1.44), b_time=1.39(1.45)  Time cost: 1:33:27/00:01 [20:10:59/10:54:15]  Acc_iter 50206       Data time: 0.01(0.01)  Forward time: 1.39(1.44)  Batch time: 1.39(1.45)

                                               [Aepochs:  65%|██████▌   | 13/20 [20:11:00<10:53:51, 5604.54s/it]epochs:  65%|██████▌   | 13/20 [20:11:00<10:53:51, 5604.56s/it]epochs:  65%|██████▌   | 13/20 [20:11:00<10:53:51, 5604.56s/it]epochs:  65%|██████▌   | 13/20 [20:11:00<10:53:51, 5604.57s/it]epochs:  65%|██████▌   | 13/20 [20:11:00<10:53:51, 5604.56s/it]epochs:  65%|██████▌   | 13/20 [20:11:00<10:53:51, 5604.56s/it]epochs:  65%|██████▌   | 13/20 [20:11:00<10:53:52, 5604.57s/it]epochs:  65%|██████▌   | 13/20 [20:11:00<10:53:51, 5604.57s/it]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-04 05:26:54,949   INFO  Train:   14/20 ( 70%) [   0/3862 (  0%)]  Loss: 1.329 (1.33)  LR: 6.294e-04  Grad: 28.7087  max=1.1199(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1144(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4480, loss_cls=0.0684, loss_bbox=0.4996, matched_ious=0.5595, loss_iou=0.0960, loss_iou_reg=0.2167, d_time=2.11(2.11), f_time=2.85(2.85), b_time=4.96(4.96)  Time cost: 00:04/4:56:22 [20:11:06/34:34:40]  Acc_iter 50207       Data time: 2.11(2.11)  Forward time: 2.85(2.85)  Batch time: 4.96(4.96)
2025-09-04 05:27:57,026   INFO  Train:   14/20 ( 70%) [  43/3862 (  1%)]  Loss: 1.219 (1.24)  LR: 6.280e-04  Grad: 28.7629  max=1.1188(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1156(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4111, loss_cls=0.0704, loss_bbox=0.4682, matched_ious=0.5759, loss_iou=0.0870, loss_iou_reg=0.2043, d_time=0.01(0.05), f_time=1.41(1.47), b_time=1.42(1.52)  Time cost: 01:06/1:36:29 [20:12:08/11:21:57]  Acc_iter 50250       Data time: 0.01(0.05)  Forward time: 1.41(1.47)  Batch time: 1.42(1.52)
2025-09-04 05:29:08,576   INFO  Train:   14/20 ( 70%) [  93/3862 (  2%)]  Loss: 1.679 (1.25)  LR: 6.264e-04  Grad: 28.7557  max=1.1206(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1172(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4185, loss_cls=0.0711, loss_bbox=0.4832, matched_ious=0.5839, loss_iou=0.0847, loss_iou_reg=0.1978, d_time=0.01(0.03), f_time=1.40(1.45), b_time=1.41(1.47)  Time cost: 02:18/1:32:22 [20:13:19/11:00:20]  Acc_iter 50300       Data time: 0.01(0.03)  Forward time: 1.40(1.45)  Batch time: 1.41(1.47)
2025-09-04 05:30:20,306   INFO  Train:   14/20 ( 70%) [ 143/3862 (  4%)]  Loss: 1.116 (1.24)  LR: 6.247e-04  Grad: 28.8103  max=1.1220(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1211(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4074, loss_cls=0.0693, loss_bbox=0.4550, matched_ious=0.5823, loss_iou=0.0861, loss_iou_reg=0.2022, d_time=0.00(0.02), f_time=1.41(1.44), b_time=1.41(1.46)  Time cost: 03:29/1:30:22 [20:14:31/10:53:32]  Acc_iter 50350       Data time: 0.00(0.02)  Forward time: 1.41(1.44)  Batch time: 1.41(1.46)
2025-09-04 05:31:31,404   INFO  Train:   14/20 ( 70%) [ 193/3862 (  5%)]  Loss: 1.117 (1.23)  LR: 6.231e-04  Grad: 28.8399  max=1.1245(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1214(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4002, loss_cls=0.0692, loss_bbox=0.4588, matched_ious=0.5789, loss_iou=0.0863, loss_iou_reg=0.2025, d_time=0.00(0.02), f_time=1.41(1.43), b_time=1.42(1.45)  Time cost: 04:41/1:28:35 [20:15:42/10:48:07]  Acc_iter 50400       Data time: 0.00(0.02)  Forward time: 1.41(1.43)  Batch time: 1.42(1.45)
2025-09-04 05:32:50,029   INFO  Train:   14/20 ( 70%) [ 243/3862 (  6%)]  Loss: 1.259 (1.24)  LR: 6.214e-04  Grad: 29.8880  max=6.6758(module.vfe.pfn_layers.0.linear.weight)  min: -3.0333(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4159, loss_cls=0.0709, loss_bbox=0.4725, matched_ious=0.5799, loss_iou=0.0865, loss_iou_reg=0.2029, d_time=0.01(0.02), f_time=1.44(1.46), b_time=1.44(1.48)  Time cost: 05:59/1:28:55 [20:17:01/10:58:14]  Acc_iter 50450       Data time: 0.01(0.02)  Forward time: 1.44(1.46)  Batch time: 1.44(1.48)
2025-09-04 05:34:01,232   INFO  Train:   14/20 ( 70%) [ 293/3862 (  8%)]  Loss: 1.395 (1.24)  LR: 6.198e-04  Grad: 28.9030  max=1.1265(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1223(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4181, loss_cls=0.0719, loss_bbox=0.4859, matched_ious=0.5774, loss_iou=0.0864, loss_iou_reg=0.2019, d_time=0.00(0.02), f_time=1.43(1.45), b_time=1.43(1.47)  Time cost: 07:10/1:27:10 [20:18:12/10:53:13]  Acc_iter 50500       Data time: 0.00(0.02)  Forward time: 1.43(1.45)  Batch time: 1.43(1.47)
2025-09-04 05:35:12,284   INFO  Train:   14/20 ( 70%) [ 343/3862 (  9%)]  Loss: 1.007 (1.24)  LR: 6.181e-04  Grad: 28.9270  max=1.1288(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1214(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4082, loss_cls=0.0704, loss_bbox=0.4703, matched_ious=0.5791, loss_iou=0.0862, loss_iou_reg=0.2020, d_time=0.01(0.02), f_time=1.38(1.44), b_time=1.39(1.46)  Time cost: 08:21/1:25:34 [20:19:23/10:49:07]  Acc_iter 50550       Data time: 0.01(0.02)  Forward time: 1.38(1.44)  Batch time: 1.39(1.46)
2025-09-04 05:36:24,488   INFO  Train:   14/20 ( 70%) [ 393/3862 ( 10%)]  Loss: 1.183 (1.24)  LR: 6.165e-04  Grad: 28.9771  max=1.1302(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1247(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4244, loss_cls=0.0729, loss_bbox=0.4802, matched_ious=0.5795, loss_iou=0.0855, loss_iou_reg=0.2014, d_time=0.01(0.01), f_time=1.45(1.44), b_time=1.45(1.46)  Time cost: 09:34/1:24:15 [20:20:35/10:47:02]  Acc_iter 50600       Data time: 0.01(0.01)  Forward time: 1.45(1.44)  Batch time: 1.45(1.46)
2025-09-04 05:37:38,136   INFO  Train:   14/20 ( 70%) [ 443/3862 ( 11%)]  Loss: 1.049 (1.24)  LR: 6.149e-04  Grad: 29.0108  max=1.1329(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1259(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3984, loss_cls=0.0705, loss_bbox=0.4662, matched_ious=0.5806, loss_iou=0.0853, loss_iou_reg=0.2015, d_time=0.00(0.01), f_time=1.33(1.45), b_time=1.34(1.46)  Time cost: 10:47/1:23:08 [20:21:49/10:46:36]  Acc_iter 50650       Data time: 0.00(0.01)  Forward time: 1.33(1.45)  Batch time: 1.34(1.46)
2025-09-04 05:38:53,592   INFO  Train:   14/20 ( 70%) [ 493/3862 ( 13%)]  Loss: 1.538 (1.24)  LR: 6.132e-04  Grad: 29.0240  max=1.1367(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1271(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4094, loss_cls=0.0690, loss_bbox=0.4738, matched_ious=0.5816, loss_iou=0.0873, loss_iou_reg=0.2004, d_time=0.00(0.01), f_time=1.36(1.45), b_time=1.36(1.46)  Time cost: 12:03/1:22:12 [20:23:04/10:47:38]  Acc_iter 50700       Data time: 0.00(0.01)  Forward time: 1.36(1.45)  Batch time: 1.36(1.46)
2025-09-04 05:40:05,340   INFO  Train:   14/20 ( 70%) [ 543/3862 ( 14%)]  Loss: 1.528 (1.24)  LR: 6.116e-04  Grad: 29.0545  max=1.1423(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1259(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4021, loss_cls=0.0674, loss_bbox=0.4597, matched_ious=0.5839, loss_iou=0.0862, loss_iou_reg=0.2006, d_time=0.01(0.01), f_time=1.37(1.45), b_time=1.38(1.46)  Time cost: 13:15/1:20:50 [20:24:16/10:45:14]  Acc_iter 50750       Data time: 0.01(0.01)  Forward time: 1.37(1.45)  Batch time: 1.38(1.46)
2025-09-04 05:41:16,704   INFO  Train:   14/20 ( 70%) [ 593/3862 ( 15%)]  Loss: 1.305 (1.24)  LR: 6.099e-04  Grad: 29.1034  max=1.1399(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1295(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4063, loss_cls=0.0684, loss_bbox=0.4731, matched_ious=0.5806, loss_iou=0.0838, loss_iou_reg=0.1997, d_time=0.01(0.01), f_time=1.37(1.45), b_time=1.38(1.46)  Time cost: 14:26/1:19:28 [20:25:27/10:42:45]  Acc_iter 50800       Data time: 0.01(0.01)  Forward time: 1.37(1.45)  Batch time: 1.38(1.46)
2025-09-04 05:42:27,968   INFO  Train:   14/20 ( 70%) [ 643/3862 ( 17%)]  Loss: 1.030 (1.24)  LR: 6.082e-04  Grad: 29.1472  max=1.1444(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1353(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4180, loss_cls=0.0713, loss_bbox=0.4896, matched_ious=0.5813, loss_iou=0.0856, loss_iou_reg=0.2003, d_time=0.01(0.01), f_time=1.32(1.45), b_time=1.33(1.46)  Time cost: 15:37/1:18:06 [20:26:39/10:40:24]  Acc_iter 50850       Data time: 0.01(0.01)  Forward time: 1.32(1.45)  Batch time: 1.33(1.46)
2025-09-04 05:43:43,114   INFO  Train:   14/20 ( 70%) [ 693/3862 ( 18%)]  Loss: 1.335 (1.24)  LR: 6.066e-04  Grad: 29.1785  max=1.1430(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1350(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4142, loss_cls=0.0701, loss_bbox=0.4975, matched_ious=0.5770, loss_iou=0.0853, loss_iou_reg=0.2023, d_time=0.01(0.01), f_time=3.08(1.45), b_time=3.09(1.46)  Time cost: 16:52/1:17:04 [20:27:54/10:40:40]  Acc_iter 50900       Data time: 0.01(0.01)  Forward time: 3.08(1.45)  Batch time: 3.09(1.46)
2025-09-04 05:44:57,729   INFO  Train:   14/20 ( 70%) [ 743/3862 ( 19%)]  Loss: 1.034 (1.24)  LR: 6.049e-04  Grad: 29.2222  max=1.1419(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1359(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4093, loss_cls=0.0714, loss_bbox=0.4552, matched_ious=0.5824, loss_iou=0.0861, loss_iou_reg=0.2003, d_time=0.00(0.01), f_time=1.36(1.45), b_time=1.36(1.46)  Time cost: 18:07/1:15:58 [20:29:08/10:40:26]  Acc_iter 50950       Data time: 0.00(0.01)  Forward time: 1.36(1.45)  Batch time: 1.36(1.46)
2025-09-04 05:46:09,724   INFO  Train:   14/20 ( 70%) [ 793/3862 ( 21%)]  Loss: 1.378 (1.24)  LR: 6.033e-04  Grad: 29.2369  max=1.1488(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1357(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3912, loss_cls=0.0680, loss_bbox=0.4537, matched_ious=0.5824, loss_iou=0.0879, loss_iou_reg=0.2019, d_time=0.00(0.01), f_time=1.39(1.45), b_time=1.39(1.46)  Time cost: 19:19/1:14:41 [20:30:20/10:38:36]  Acc_iter 51000       Data time: 0.00(0.01)  Forward time: 1.39(1.45)  Batch time: 1.39(1.46)
2025-09-04 05:47:21,928   INFO  Train:   14/20 ( 70%) [ 843/3862 ( 22%)]  Loss: 0.9886 (1.24)  LR: 6.016e-04  Grad: 29.2660  max=1.1496(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1383(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4050, loss_cls=0.0687, loss_bbox=0.4772, matched_ious=0.5816, loss_iou=0.0867, loss_iou_reg=0.2012, d_time=0.00(0.01), f_time=1.38(1.45), b_time=1.38(1.46)  Time cost: 20:31/1:13:25 [20:31:33/10:36:58]  Acc_iter 51050       Data time: 0.00(0.01)  Forward time: 1.38(1.45)  Batch time: 1.38(1.46)
2025-09-04 05:48:33,306   INFO  Train:   14/20 ( 70%) [ 893/3862 ( 23%)]  Loss: 1.547 (1.24)  LR: 6.000e-04  Grad: 29.3189  max=1.1531(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1440(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4155, loss_cls=0.0710, loss_bbox=0.4867, matched_ious=0.5800, loss_iou=0.0862, loss_iou_reg=0.2014, d_time=0.01(0.01), f_time=1.44(1.45), b_time=1.45(1.46)  Time cost: 21:42/1:12:07 [20:32:44/10:34:59]  Acc_iter 51100       Data time: 0.01(0.01)  Forward time: 1.44(1.45)  Batch time: 1.45(1.46)
2025-09-04 05:49:48,019   INFO  Train:   14/20 ( 70%) [ 943/3862 ( 24%)]  Loss: 1.294 (1.24)  LR: 5.983e-04  Grad: 29.3465  max=1.1524(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1457(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4141, loss_cls=0.0706, loss_bbox=0.4829, matched_ious=0.5788, loss_iou=0.0857, loss_iou_reg=0.2019, d_time=0.01(0.01), f_time=1.34(1.45), b_time=1.34(1.46)  Time cost: 22:57/1:11:00 [20:33:59/10:34:37]  Acc_iter 51150       Data time: 0.01(0.01)  Forward time: 1.34(1.45)  Batch time: 1.34(1.46)
2025-09-04 05:51:03,473   INFO  Train:   14/20 ( 70%) [ 993/3862 ( 26%)]  Loss: 1.171 (1.24)  LR: 5.966e-04  Grad: 29.3904  max=1.1509(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1492(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4153, loss_cls=0.0695, loss_bbox=0.4851, matched_ious=0.5805, loss_iou=0.0857, loss_iou_reg=0.2001, d_time=0.00(0.01), f_time=1.52(1.45), b_time=1.52(1.46)  Time cost: 24:13/1:09:54 [20:35:14/10:34:29]  Acc_iter 51200       Data time: 0.00(0.01)  Forward time: 1.52(1.45)  Batch time: 1.52(1.46)
2025-09-04 05:52:14,549   INFO  Train:   14/20 ( 70%) [1043/3862 ( 27%)]  Loss: 1.402 (1.24)  LR: 5.950e-04  Grad: 28.0060  max=1.0929(module.dense_head.decoder.self_attn.in_proj_weight)  min: -2.0209(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.3940, loss_cls=0.0673, loss_bbox=0.4753, matched_ious=0.5848, loss_iou=0.0850, loss_iou_reg=0.1997, d_time=0.00(0.01), f_time=1.29(1.45), b_time=1.30(1.46)  Time cost: 25:24/1:08:35 [20:36:25/10:32:26]  Acc_iter 51250       Data time: 0.00(0.01)  Forward time: 1.29(1.45)  Batch time: 1.30(1.46)
2025-09-04 05:53:24,672   INFO  Train:   14/20 ( 70%) [1093/3862 ( 28%)]  Loss: 1.077 (1.24)  LR: 5.933e-04  Grad: 27.9791  max=1.0983(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0924(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4086, loss_cls=0.0728, loss_bbox=0.4659, matched_ious=0.5836, loss_iou=0.0852, loss_iou_reg=0.1984, d_time=0.00(0.01), f_time=1.34(1.45), b_time=1.35(1.46)  Time cost: 26:34/1:07:15 [20:37:35/10:30:05]  Acc_iter 51300       Data time: 0.00(0.01)  Forward time: 1.34(1.45)  Batch time: 1.35(1.46)
2025-09-04 05:54:35,245   INFO  Train:   14/20 ( 70%) [1143/3862 ( 30%)]  Loss: 1.463 (1.24)  LR: 5.916e-04  Grad: 27.9850  max=1.1037(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0928(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4210, loss_cls=0.0722, loss_bbox=0.4679, matched_ious=0.5815, loss_iou=0.0863, loss_iou_reg=0.1998, d_time=0.01(0.01), f_time=1.40(1.45), b_time=1.40(1.46)  Time cost: 27:44/1:05:57 [20:38:46/10:28:00]  Acc_iter 51350       Data time: 0.01(0.01)  Forward time: 1.40(1.45)  Batch time: 1.40(1.46)
2025-09-04 05:55:50,203   INFO  Train:   14/20 ( 70%) [1193/3862 ( 31%)]  Loss: 1.316 (1.24)  LR: 5.900e-04  Grad: 28.0031  max=1.1015(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0935(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4136, loss_cls=0.0701, loss_bbox=0.4751, matched_ious=0.5848, loss_iou=0.0860, loss_iou_reg=0.1996, d_time=0.01(0.01), f_time=1.45(1.45), b_time=1.45(1.46)  Time cost: 28:59/1:04:49 [20:40:01/10:27:34]  Acc_iter 51400       Data time: 0.01(0.01)  Forward time: 1.45(1.45)  Batch time: 1.45(1.46)
2025-09-04 05:57:03,759   INFO  Train:   14/20 ( 70%) [1243/3862 ( 32%)]  Loss: 1.161 (1.24)  LR: 5.883e-04  Grad: 28.0461  max=1.1063(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0936(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4068, loss_cls=0.0702, loss_bbox=0.4414, matched_ious=0.5908, loss_iou=0.0836, loss_iou_reg=0.1948, d_time=0.01(0.01), f_time=1.40(1.45), b_time=1.41(1.46)  Time cost: 30:13/1:03:37 [20:41:14/10:26:36]  Acc_iter 51450       Data time: 0.01(0.01)  Forward time: 1.40(1.45)  Batch time: 1.41(1.46)
2025-09-04 05:58:15,004   INFO  Train:   14/20 ( 70%) [1293/3862 ( 33%)]  Loss: 1.585 (1.24)  LR: 5.866e-04  Grad: 28.0686  max=1.1035(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0946(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3997, loss_cls=0.0684, loss_bbox=0.4754, matched_ious=0.5875, loss_iou=0.0868, loss_iou_reg=0.1972, d_time=0.00(0.01), f_time=1.45(1.45), b_time=1.45(1.46)  Time cost: 31:24/1:02:21 [20:42:26/10:24:51]  Acc_iter 51500       Data time: 0.00(0.01)  Forward time: 1.45(1.45)  Batch time: 1.45(1.46)
2025-09-04 05:59:25,566   INFO  Train:   14/20 ( 70%) [1343/3862 ( 35%)]  Loss: 1.265 (1.24)  LR: 5.850e-04  Grad: 28.1175  max=1.1091(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0984(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4077, loss_cls=0.0687, loss_bbox=0.4816, matched_ious=0.5830, loss_iou=0.0860, loss_iou_reg=0.2010, d_time=0.01(0.01), f_time=1.30(1.45), b_time=1.31(1.46)  Time cost: 32:35/1:01:04 [20:43:36/10:22:54]  Acc_iter 51550       Data time: 0.01(0.01)  Forward time: 1.30(1.45)  Batch time: 1.31(1.46)
2025-09-04 06:00:37,317   INFO  Train:   14/20 ( 70%) [1393/3862 ( 36%)]  Loss: 1.329 (1.24)  LR: 5.833e-04  Grad: 28.1516  max=1.1117(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1023(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4190, loss_cls=0.0723, loss_bbox=0.4833, matched_ious=0.5847, loss_iou=0.0845, loss_iou_reg=0.1989, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.42(1.45)  Time cost: 33:46/59:50 [20:44:48/10:21:24]  Acc_iter 51600       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.45)
2025-09-04 06:01:51,928   INFO  Train:   14/20 ( 70%) [1443/3862 ( 37%)]  Loss: 0.9806 (1.24)  LR: 5.816e-04  Grad: 28.1889  max=1.1131(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1014(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4137, loss_cls=0.0711, loss_bbox=0.4502, matched_ious=0.5851, loss_iou=0.0860, loss_iou_reg=0.1988, d_time=0.01(0.01), f_time=2.48(1.45), b_time=2.48(1.46)  Time cost: 35:01/58:40 [20:46:03/10:20:45]  Acc_iter 51650       Data time: 0.01(0.01)  Forward time: 2.48(1.45)  Batch time: 2.48(1.46)
2025-09-04 06:03:04,891   INFO  Train:   14/20 ( 70%) [1493/3862 ( 39%)]  Loss: 1.041 (1.24)  LR: 5.800e-04  Grad: 28.2374  max=1.1117(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1041(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4157, loss_cls=0.0732, loss_bbox=0.4767, matched_ious=0.5851, loss_iou=0.0862, loss_iou_reg=0.1979, d_time=0.00(0.01), f_time=1.36(1.45), b_time=1.37(1.46)  Time cost: 36:14/57:28 [20:47:16/10:19:35]  Acc_iter 51700       Data time: 0.00(0.01)  Forward time: 1.36(1.45)  Batch time: 1.37(1.46)
2025-09-04 06:04:15,484   INFO  Train:   14/20 ( 70%) [1543/3862 ( 40%)]  Loss: 1.052 (1.24)  LR: 5.783e-04  Grad: 28.2379  max=1.1151(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1066(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4146, loss_cls=0.0709, loss_bbox=0.4823, matched_ious=0.5819, loss_iou=0.0854, loss_iou_reg=0.1981, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.38(1.45)  Time cost: 37:25/56:12 [20:48:26/10:17:46]  Acc_iter 51750       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.38(1.45)
2025-09-04 06:05:27,379   INFO  Train:   14/20 ( 70%) [1593/3862 ( 41%)]  Loss: 1.201 (1.24)  LR: 5.766e-04  Grad: 28.3141  max=1.1130(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1086(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4076, loss_cls=0.0694, loss_bbox=0.4471, matched_ious=0.5874, loss_iou=0.0849, loss_iou_reg=0.1990, d_time=0.01(0.01), f_time=1.37(1.44), b_time=1.37(1.45)  Time cost: 38:37/54:58 [20:49:38/10:16:21]  Acc_iter 51800       Data time: 0.01(0.01)  Forward time: 1.37(1.44)  Batch time: 1.37(1.45)
2025-09-04 06:06:39,996   INFO  Train:   14/20 ( 70%) [1643/3862 ( 43%)]  Loss: 1.059 (1.24)  LR: 5.749e-04  Grad: 28.3364  max=1.1168(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1101(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4119, loss_cls=0.0707, loss_bbox=0.4615, matched_ious=0.5801, loss_iou=0.0868, loss_iou_reg=0.2024, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 39:49/53:45 [20:50:51/10:15:07]  Acc_iter 51850       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-04 06:07:54,480   INFO  Train:   14/20 ( 70%) [1693/3862 ( 44%)]  Loss: 1.374 (1.24)  LR: 5.733e-04  Grad: 28.3507  max=1.1234(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1103(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4006, loss_cls=0.0684, loss_bbox=0.4659, matched_ious=0.5832, loss_iou=0.0866, loss_iou_reg=0.2005, d_time=0.00(0.01), f_time=1.48(1.45), b_time=1.48(1.45)  Time cost: 41:04/52:35 [20:52:05/10:14:21]  Acc_iter 51900       Data time: 0.00(0.01)  Forward time: 1.48(1.45)  Batch time: 1.48(1.45)
2025-09-04 06:09:08,092   INFO  Train:   14/20 ( 70%) [1743/3862 ( 45%)]  Loss: 1.087 (1.24)  LR: 5.716e-04  Grad: 28.4131  max=1.1239(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1131(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4012, loss_cls=0.0686, loss_bbox=0.4593, matched_ious=0.5840, loss_iou=0.0867, loss_iou_reg=0.1981, d_time=0.00(0.01), f_time=1.47(1.45), b_time=1.48(1.46)  Time cost: 42:17/51:23 [20:53:19/10:13:21]  Acc_iter 51950       Data time: 0.00(0.01)  Forward time: 1.47(1.45)  Batch time: 1.48(1.46)
2025-09-04 06:10:20,055   INFO  Train:   14/20 ( 70%) [1793/3862 ( 46%)]  Loss: 1.155 (1.24)  LR: 5.699e-04  Grad: 28.5968  max=1.7436(module.vfe.pfn_layers.0.linear.weight)  min: -2.7267(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.4026, loss_cls=0.0693, loss_bbox=0.4619, matched_ious=0.5856, loss_iou=0.0853, loss_iou_reg=0.1991, d_time=0.00(0.01), f_time=1.44(1.45), b_time=1.44(1.45)  Time cost: 43:29/50:09 [20:54:31/10:11:57]  Acc_iter 52000       Data time: 0.00(0.01)  Forward time: 1.44(1.45)  Batch time: 1.44(1.45)
2025-09-04 06:11:31,136   INFO  Train:   14/20 ( 70%) [1843/3862 ( 48%)]  Loss: 1.160 (1.24)  LR: 5.682e-04  Grad: 28.4624  max=1.1187(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1139(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4068, loss_cls=0.0715, loss_bbox=0.4682, matched_ious=0.5864, loss_iou=0.0844, loss_iou_reg=0.1985, d_time=0.00(0.01), f_time=1.36(1.44), b_time=1.37(1.45)  Time cost: 44:40/48:55 [20:55:42/10:10:22]  Acc_iter 52050       Data time: 0.00(0.01)  Forward time: 1.36(1.44)  Batch time: 1.37(1.45)
2025-09-04 06:12:43,772   INFO  Train:   14/20 ( 70%) [1893/3862 ( 49%)]  Loss: 1.547 (1.24)  LR: 5.665e-04  Grad: 28.5094  max=1.1191(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1176(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4051, loss_cls=0.0687, loss_bbox=0.4671, matched_ious=0.5873, loss_iou=0.0836, loss_iou_reg=0.1970, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 45:53/47:42 [20:56:54/10:09:09]  Acc_iter 52100       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-04 06:13:57,903   INFO  Train:   14/20 ( 70%) [1943/3862 ( 50%)]  Loss: 1.207 (1.24)  LR: 5.649e-04  Grad: 28.5203  max=1.1240(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1173(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3979, loss_cls=0.0694, loss_bbox=0.4578, matched_ious=0.5895, loss_iou=0.0839, loss_iou_reg=0.1966, d_time=0.02(0.01), f_time=1.42(1.45), b_time=1.44(1.45)  Time cost: 47:07/46:31 [20:58:09/10:08:15]  Acc_iter 52150       Data time: 0.02(0.01)  Forward time: 1.42(1.45)  Batch time: 1.44(1.45)
2025-09-04 06:15:11,944   INFO  Train:   14/20 ( 70%) [1993/3862 ( 52%)]  Loss: 0.9936 (1.23)  LR: 5.632e-04  Grad: 28.5462  max=1.1291(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1188(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3981, loss_cls=0.0694, loss_bbox=0.4471, matched_ious=0.5914, loss_iou=0.0843, loss_iou_reg=0.1952, d_time=0.00(0.01), f_time=1.46(1.45), b_time=1.47(1.46)  Time cost: 48:21/45:19 [20:59:23/10:07:19]  Acc_iter 52200       Data time: 0.00(0.01)  Forward time: 1.46(1.45)  Batch time: 1.47(1.46)
2025-09-04 06:16:22,828   INFO  Train:   14/20 ( 70%) [2043/3862 ( 53%)]  Loss: 1.155 (1.23)  LR: 5.615e-04  Grad: 28.5774  max=1.1257(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1179(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4017, loss_cls=0.0688, loss_bbox=0.4682, matched_ious=0.5892, loss_iou=0.0846, loss_iou_reg=0.1967, d_time=0.01(0.01), f_time=1.45(1.45), b_time=1.45(1.45)  Time cost: 49:32/44:05 [21:00:33/10:05:43]  Acc_iter 52250       Data time: 0.01(0.01)  Forward time: 1.45(1.45)  Batch time: 1.45(1.45)
2025-09-04 06:17:34,027   INFO  Train:   14/20 ( 70%) [2093/3862 ( 54%)]  Loss: 1.229 (1.23)  LR: 5.598e-04  Grad: 28.6154  max=1.1321(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1177(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3885, loss_cls=0.0675, loss_bbox=0.4464, matched_ious=0.5859, loss_iou=0.0859, loss_iou_reg=0.1981, d_time=0.01(0.01), f_time=1.39(1.44), b_time=1.40(1.45)  Time cost: 50:43/42:51 [21:01:45/10:04:12]  Acc_iter 52300       Data time: 0.01(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.45)
2025-09-04 06:18:46,275   INFO  Train:   14/20 ( 70%) [2143/3862 ( 55%)]  Loss: 1.214 (1.23)  LR: 5.581e-04  Grad: 28.6342  max=1.1310(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1197(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4024, loss_cls=0.0654, loss_bbox=0.4568, matched_ious=0.5844, loss_iou=0.0850, loss_iou_reg=0.1999, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.43(1.45)  Time cost: 51:55/41:38 [21:02:57/10:02:54]  Acc_iter 52350       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.43(1.45)
2025-09-04 06:20:02,201   INFO  Train:   14/20 ( 70%) [2193/3862 ( 57%)]  Loss: 1.161 (1.23)  LR: 5.565e-04  Grad: 28.6860  max=1.1288(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1272(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4068, loss_cls=0.0692, loss_bbox=0.4638, matched_ious=0.5825, loss_iou=0.0853, loss_iou_reg=0.1999, d_time=0.01(0.01), f_time=1.39(1.45), b_time=1.39(1.45)  Time cost: 53:11/40:28 [21:04:13/10:02:19]  Acc_iter 52400       Data time: 0.01(0.01)  Forward time: 1.39(1.45)  Batch time: 1.39(1.45)
2025-09-04 06:21:14,067   INFO  Train:   14/20 ( 70%) [2243/3862 ( 58%)]  Loss: 1.053 (1.23)  LR: 5.548e-04  Grad: 28.6940  max=1.1352(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1269(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4064, loss_cls=0.0691, loss_bbox=0.4558, matched_ious=0.5896, loss_iou=0.0850, loss_iou_reg=0.1971, d_time=0.01(0.01), f_time=1.50(1.45), b_time=1.50(1.45)  Time cost: 54:23/39:14 [21:05:25/10:00:56]  Acc_iter 52450       Data time: 0.01(0.01)  Forward time: 1.50(1.45)  Batch time: 1.50(1.45)
2025-09-04 06:22:25,812   INFO  Train:   14/20 ( 70%) [2293/3862 ( 59%)]  Loss: 1.435 (1.23)  LR: 5.531e-04  Grad: 28.7182  max=1.1382(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1288(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4015, loss_cls=0.0695, loss_bbox=0.4552, matched_ious=0.5797, loss_iou=0.0872, loss_iou_reg=0.2000, d_time=0.01(0.01), f_time=1.48(1.45), b_time=1.48(1.45)  Time cost: 55:35/38:01 [21:06:36/9:59:33]  Acc_iter 52500       Data time: 0.01(0.01)  Forward time: 1.48(1.45)  Batch time: 1.48(1.45)
2025-09-04 06:23:38,935   INFO  Train:   14/20 ( 70%) [2343/3862 ( 61%)]  Loss: 1.289 (1.23)  LR: 5.514e-04  Grad: 28.7321  max=1.1382(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1317(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3885, loss_cls=0.0642, loss_bbox=0.4715, matched_ious=0.5823, loss_iou=0.0867, loss_iou_reg=0.2012, d_time=0.01(0.01), f_time=1.54(1.45), b_time=1.55(1.45)  Time cost: 56:48/36:48 [21:07:50/9:58:25]  Acc_iter 52550       Data time: 0.01(0.01)  Forward time: 1.54(1.45)  Batch time: 1.55(1.45)
2025-09-04 06:24:50,433   INFO  Train:   14/20 ( 70%) [2393/3862 ( 62%)]  Loss: 1.076 (1.23)  LR: 5.497e-04  Grad: 28.7610  max=1.1421(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1294(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3889, loss_cls=0.0669, loss_bbox=0.4456, matched_ious=0.5851, loss_iou=0.0858, loss_iou_reg=0.1991, d_time=0.01(0.01), f_time=1.36(1.44), b_time=1.37(1.45)  Time cost: 58:00/35:35 [21:09:01/9:57:00]  Acc_iter 52600       Data time: 0.01(0.01)  Forward time: 1.36(1.44)  Batch time: 1.37(1.45)
2025-09-04 06:26:06,588   INFO  Train:   14/20 ( 70%) [2443/3862 ( 63%)]  Loss: 1.093 (1.23)  LR: 5.480e-04  Grad: 28.7996  max=1.1445(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1311(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4135, loss_cls=0.0700, loss_bbox=0.4767, matched_ious=0.5868, loss_iou=0.0847, loss_iou_reg=0.1985, d_time=0.01(0.01), f_time=1.37(1.45), b_time=1.38(1.46)  Time cost: 59:16/34:24 [21:10:17/9:56:22]  Acc_iter 52650       Data time: 0.01(0.01)  Forward time: 1.37(1.45)  Batch time: 1.38(1.46)
2025-09-04 06:27:19,485   INFO  Train:   14/20 ( 70%) [2493/3862 ( 65%)]  Loss: 1.027 (1.23)  LR: 5.463e-04  Grad: 28.8129  max=1.1449(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1334(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3924, loss_cls=0.0665, loss_bbox=0.4430, matched_ious=0.5906, loss_iou=0.0832, loss_iou_reg=0.1977, d_time=0.00(0.01), f_time=1.36(1.45), b_time=1.37(1.46)  Time cost: 1:00:29/33:12 [21:11:30/9:55:10]  Acc_iter 52700       Data time: 0.00(0.01)  Forward time: 1.36(1.45)  Batch time: 1.37(1.46)
2025-09-04 06:28:31,003   INFO  Train:   14/20 ( 70%) [2543/3862 ( 66%)]  Loss: 0.9792 (1.23)  LR: 5.447e-04  Grad: 28.8588  max=1.1447(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1374(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3950, loss_cls=0.0668, loss_bbox=0.4653, matched_ious=0.5880, loss_iou=0.0844, loss_iou_reg=0.1975, d_time=0.00(0.01), f_time=1.40(1.45), b_time=1.41(1.45)  Time cost: 1:01:40/31:58 [21:12:42/9:53:46]  Acc_iter 52750       Data time: 0.00(0.01)  Forward time: 1.40(1.45)  Batch time: 1.41(1.45)
2025-09-04 06:29:43,482   INFO  Train:   14/20 ( 70%) [2593/3862 ( 67%)]  Loss: 1.024 (1.23)  LR: 5.430e-04  Grad: 28.9187  max=1.1460(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1365(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3831, loss_cls=0.0661, loss_bbox=0.4528, matched_ious=0.5879, loss_iou=0.0855, loss_iou_reg=0.1984, d_time=0.00(0.01), f_time=1.36(1.45), b_time=1.36(1.45)  Time cost: 1:02:53/30:45 [21:13:54/9:52:31]  Acc_iter 52800       Data time: 0.00(0.01)  Forward time: 1.36(1.45)  Batch time: 1.36(1.45)
2025-09-04 06:30:55,032   INFO  Train:   14/20 ( 70%) [2643/3862 ( 68%)]  Loss: 1.238 (1.23)  LR: 5.413e-04  Grad: 28.9206  max=1.1450(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1383(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3958, loss_cls=0.0661, loss_bbox=0.4449, matched_ious=0.5858, loss_iou=0.0855, loss_iou_reg=0.1983, d_time=0.00(0.01), f_time=1.40(1.45), b_time=1.41(1.45)  Time cost: 1:04:04/29:32 [21:15:06/9:51:07]  Acc_iter 52850       Data time: 0.00(0.01)  Forward time: 1.40(1.45)  Batch time: 1.41(1.45)
2025-09-04 06:32:10,402   INFO  Train:   14/20 ( 70%) [2693/3862 ( 70%)]  Loss: 1.169 (1.23)  LR: 5.396e-04  Grad: 28.9662  max=1.1451(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1388(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4016, loss_cls=0.0696, loss_bbox=0.4579, matched_ious=0.5841, loss_iou=0.0853, loss_iou_reg=0.1999, d_time=0.00(0.01), f_time=1.45(1.45), b_time=1.45(1.46)  Time cost: 1:05:20/28:21 [21:16:21/9:50:18]  Acc_iter 52900       Data time: 0.00(0.01)  Forward time: 1.45(1.45)  Batch time: 1.45(1.46)
2025-09-04 06:33:22,285   INFO  Train:   14/20 ( 70%) [2743/3862 ( 71%)]  Loss: 1.220 (1.23)  LR: 5.379e-04  Grad: 29.0049  max=1.1454(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1417(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3990, loss_cls=0.0686, loss_bbox=0.4677, matched_ious=0.5900, loss_iou=0.0841, loss_iou_reg=0.1965, d_time=0.00(0.01), f_time=1.51(1.45), b_time=1.51(1.45)  Time cost: 1:06:31/27:07 [21:17:33/9:48:58]  Acc_iter 52950       Data time: 0.00(0.01)  Forward time: 1.51(1.45)  Batch time: 1.51(1.45)
2025-09-04 06:34:33,804   INFO  Train:   14/20 ( 70%) [2793/3862 ( 72%)]  Loss: 1.150 (1.23)  LR: 5.362e-04  Grad: 29.0372  max=1.1494(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1437(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4031, loss_cls=0.0705, loss_bbox=0.4648, matched_ious=0.5864, loss_iou=0.0842, loss_iou_reg=0.1977, d_time=0.01(0.01), f_time=1.61(1.45), b_time=1.62(1.45)  Time cost: 1:07:43/25:54 [21:18:44/9:47:35]  Acc_iter 53000       Data time: 0.01(0.01)  Forward time: 1.61(1.45)  Batch time: 1.62(1.45)
2025-09-04 06:35:47,152   INFO  Train:   14/20 ( 70%) [2843/3862 ( 74%)]  Loss: 1.257 (1.23)  LR: 5.345e-04  Grad: 29.0810  max=1.1524(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1476(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3936, loss_cls=0.0665, loss_bbox=0.4447, matched_ious=0.5865, loss_iou=0.0858, loss_iou_reg=0.1991, d_time=0.00(0.01), f_time=1.33(1.45), b_time=1.33(1.45)  Time cost: 1:08:56/24:42 [21:19:58/9:46:27]  Acc_iter 53050       Data time: 0.00(0.01)  Forward time: 1.33(1.45)  Batch time: 1.33(1.45)
2025-09-04 06:36:58,842   INFO  Train:   14/20 ( 70%) [2893/3862 ( 75%)]  Loss: 1.014 (1.23)  LR: 5.328e-04  Grad: 29.1065  max=1.1561(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1476(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4022, loss_cls=0.0689, loss_bbox=0.4656, matched_ious=0.5865, loss_iou=0.0863, loss_iou_reg=0.1987, d_time=0.00(0.01), f_time=1.38(1.45), b_time=1.38(1.45)  Time cost: 1:10:08/23:29 [21:21:09/9:45:06]  Acc_iter 53100       Data time: 0.00(0.01)  Forward time: 1.38(1.45)  Batch time: 1.38(1.45)
2025-09-04 06:38:15,179   INFO  Train:   14/20 ( 70%) [2943/3862 ( 76%)]  Loss: 1.232 (1.23)  LR: 5.311e-04  Grad: 29.1510  max=1.1528(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1493(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3997, loss_cls=0.0675, loss_bbox=0.4653, matched_ious=0.5789, loss_iou=0.0856, loss_iou_reg=0.2031, d_time=0.01(0.01), f_time=1.53(1.45), b_time=1.53(1.46)  Time cost: 1:11:24/22:17 [21:22:26/9:44:23]  Acc_iter 53150       Data time: 0.01(0.01)  Forward time: 1.53(1.45)  Batch time: 1.53(1.46)
2025-09-04 06:39:26,478   INFO  Train:   14/20 ( 70%) [2993/3862 ( 77%)]  Loss: 1.183 (1.23)  LR: 5.294e-04  Grad: 29.1522  max=1.1540(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1497(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4155, loss_cls=0.0703, loss_bbox=0.4580, matched_ious=0.5850, loss_iou=0.0851, loss_iou_reg=0.1986, d_time=0.01(0.01), f_time=1.30(1.45), b_time=1.31(1.46)  Time cost: 1:12:36/21:04 [21:23:37/9:42:58]  Acc_iter 53200       Data time: 0.01(0.01)  Forward time: 1.30(1.45)  Batch time: 1.31(1.46)
2025-09-04 06:40:37,583   INFO  Train:   14/20 ( 70%) [3043/3862 ( 79%)]  Loss: 1.267 (1.23)  LR: 5.277e-04  Grad: 29.1781  max=1.1567(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1509(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4188, loss_cls=0.0695, loss_bbox=0.4696, matched_ious=0.5868, loss_iou=0.0851, loss_iou_reg=0.1978, d_time=0.01(0.01), f_time=1.33(1.45), b_time=1.34(1.45)  Time cost: 1:13:47/19:51 [21:24:48/9:41:32]  Acc_iter 53250       Data time: 0.01(0.01)  Forward time: 1.33(1.45)  Batch time: 1.34(1.45)
2025-09-04 06:41:51,046   INFO  Train:   14/20 ( 70%) [3093/3862 ( 80%)]  Loss: 1.276 (1.23)  LR: 5.261e-04  Grad: 29.2073  max=1.1567(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1507(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3944, loss_cls=0.0674, loss_bbox=0.4692, matched_ious=0.5896, loss_iou=0.0857, loss_iou_reg=0.1966, d_time=0.00(0.01), f_time=1.38(1.45), b_time=1.39(1.45)  Time cost: 1:15:00/18:38 [21:26:02/9:40:26]  Acc_iter 53300       Data time: 0.00(0.01)  Forward time: 1.38(1.45)  Batch time: 1.39(1.45)
2025-09-04 06:43:02,147   INFO  Train:   14/20 ( 70%) [3143/3862 ( 81%)]  Loss: 1.693 (1.23)  LR: 5.244e-04  Grad: 29.1949  max=1.1607(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1509(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4118, loss_cls=0.0702, loss_bbox=0.4735, matched_ious=0.5909, loss_iou=0.0856, loss_iou_reg=0.1954, d_time=0.00(0.01), f_time=1.50(1.45), b_time=1.50(1.45)  Time cost: 1:16:11/17:25 [21:27:13/9:39:00]  Acc_iter 53350       Data time: 0.00(0.01)  Forward time: 1.50(1.45)  Batch time: 1.50(1.45)
2025-09-04 06:44:17,762   INFO  Train:   14/20 ( 70%) [3193/3862 ( 83%)]  Loss: 1.223 (1.23)  LR: 5.227e-04  Grad: 29.2578  max=1.1594(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1556(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3837, loss_cls=0.0674, loss_bbox=0.4597, matched_ious=0.5888, loss_iou=0.0849, loss_iou_reg=0.1967, d_time=0.00(0.01), f_time=1.43(1.45), b_time=1.43(1.46)  Time cost: 1:17:27/16:13 [21:28:28/9:38:09]  Acc_iter 53400       Data time: 0.00(0.01)  Forward time: 1.43(1.45)  Batch time: 1.43(1.46)
2025-09-04 06:45:28,787   INFO  Train:   14/20 ( 70%) [3243/3862 ( 84%)]  Loss: 0.9101 (1.23)  LR: 5.210e-04  Grad: 29.2880  max=1.1582(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1571(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3895, loss_cls=0.0656, loss_bbox=0.4585, matched_ious=0.5899, loss_iou=0.0857, loss_iou_reg=0.1974, d_time=0.01(0.01), f_time=1.36(1.45), b_time=1.36(1.45)  Time cost: 1:18:38/15:00 [21:29:39/9:36:44]  Acc_iter 53450       Data time: 0.01(0.01)  Forward time: 1.36(1.45)  Batch time: 1.36(1.45)
2025-09-04 06:46:41,373   INFO  Train:   14/20 ( 70%) [3293/3862 ( 85%)]  Loss: 1.419 (1.22)  LR: 5.193e-04  Grad: 29.3065  max=1.1605(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1571(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3942, loss_cls=0.0661, loss_bbox=0.4488, matched_ious=0.5849, loss_iou=0.0859, loss_iou_reg=0.1990, d_time=0.01(0.01), f_time=1.36(1.45), b_time=1.36(1.45)  Time cost: 1:19:51/13:47 [21:30:52/9:35:30]  Acc_iter 53500       Data time: 0.01(0.01)  Forward time: 1.36(1.45)  Batch time: 1.36(1.45)
2025-09-04 06:47:52,684   INFO  Train:   14/20 ( 70%) [3343/3862 ( 87%)]  Loss: 1.112 (1.22)  LR: 5.176e-04  Grad: 29.3377  max=1.1629(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1571(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3864, loss_cls=0.0661, loss_bbox=0.4350, matched_ious=0.5888, loss_iou=0.0850, loss_iou_reg=0.1986, d_time=0.01(0.01), f_time=1.42(1.45), b_time=1.42(1.45)  Time cost: 1:21:02/12:34 [21:32:03/9:34:08]  Acc_iter 53550       Data time: 0.01(0.01)  Forward time: 1.42(1.45)  Batch time: 1.42(1.45)
2025-09-04 06:49:03,858   INFO  Train:   14/20 ( 70%) [3393/3862 ( 88%)]  Loss: 1.276 (1.22)  LR: 5.159e-04  Grad: 29.3559  max=1.1650(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1591(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3990, loss_cls=0.0689, loss_bbox=0.4399, matched_ious=0.5847, loss_iou=0.0863, loss_iou_reg=0.1985, d_time=0.00(0.01), f_time=1.35(1.44), b_time=1.35(1.45)  Time cost: 1:22:13/11:21 [21:33:14/9:32:44]  Acc_iter 53600       Data time: 0.00(0.01)  Forward time: 1.35(1.44)  Batch time: 1.35(1.45)
2025-09-04 06:50:20,858   INFO  Train:   14/20 ( 70%) [3443/3862 ( 89%)]  Loss: 1.185 (1.22)  LR: 5.142e-04  Grad: 29.3873  max=1.1673(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1594(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4237, loss_cls=0.0699, loss_bbox=0.4834, matched_ious=0.5850, loss_iou=0.0846, loss_iou_reg=0.1976, d_time=0.01(0.01), f_time=1.46(1.45), b_time=1.47(1.45)  Time cost: 1:23:30/10:09 [21:34:31/9:32:01]  Acc_iter 53650       Data time: 0.01(0.01)  Forward time: 1.46(1.45)  Batch time: 1.47(1.45)
2025-09-04 06:51:32,664   INFO  Train:   14/20 ( 70%) [3493/3862 ( 90%)]  Loss: 1.259 (1.22)  LR: 5.125e-04  Grad: 29.3953  max=1.1705(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1613(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4106, loss_cls=0.0696, loss_bbox=0.4630, matched_ious=0.5847, loss_iou=0.0889, loss_iou_reg=0.1980, d_time=0.00(0.01), f_time=1.38(1.45), b_time=1.38(1.45)  Time cost: 1:24:42/08:56 [21:35:43/9:30:42]  Acc_iter 53700       Data time: 0.00(0.01)  Forward time: 1.38(1.45)  Batch time: 1.38(1.45)
2025-09-04 06:52:45,494   INFO  Train:   14/20 ( 70%) [3543/3862 ( 92%)]  Loss: 1.129 (1.22)  LR: 5.108e-04  Grad: 29.4715  max=1.1708(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1628(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3861, loss_cls=0.0671, loss_bbox=0.4443, matched_ious=0.5871, loss_iou=0.0844, loss_iou_reg=0.1987, d_time=0.01(0.01), f_time=1.43(1.45), b_time=1.44(1.45)  Time cost: 1:25:55/07:44 [21:36:56/9:29:30]  Acc_iter 53750       Data time: 0.01(0.01)  Forward time: 1.43(1.45)  Batch time: 1.44(1.45)
2025-09-04 06:53:56,273   INFO  Train:   14/20 ( 70%) [3593/3862 ( 93%)]  Loss: 1.052 (1.22)  LR: 5.091e-04  Grad: 29.4907  max=1.1750(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1645(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3824, loss_cls=0.0660, loss_bbox=0.4417, matched_ious=0.5885, loss_iou=0.0859, loss_iou_reg=0.1976, d_time=0.00(0.01), f_time=1.42(1.45), b_time=1.43(1.45)  Time cost: 1:27:05/06:31 [21:38:07/9:28:04]  Acc_iter 53800       Data time: 0.00(0.01)  Forward time: 1.42(1.45)  Batch time: 1.43(1.45)
2025-09-04 06:55:07,556   INFO  Train:   14/20 ( 70%) [3643/3862 ( 94%)]  Loss: 1.032 (1.22)  LR: 5.074e-04  Grad: 29.4966  max=1.1730(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1645(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3935, loss_cls=0.0668, loss_bbox=0.4564, matched_ious=0.5899, loss_iou=0.0852, loss_iou_reg=0.1964, d_time=0.01(0.01), f_time=1.28(1.45), b_time=1.28(1.45)  Time cost: 1:28:17/05:18 [21:39:18/9:26:43]  Acc_iter 53850       Data time: 0.01(0.01)  Forward time: 1.28(1.45)  Batch time: 1.28(1.45)
2025-09-04 06:56:23,847   INFO  Train:   14/20 ( 70%) [3693/3862 ( 96%)]  Loss: 1.181 (1.22)  LR: 5.057e-04  Grad: 29.5823  max=1.1752(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1658(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3965, loss_cls=0.0669, loss_bbox=0.4470, matched_ious=0.5831, loss_iou=0.0850, loss_iou_reg=0.1999, d_time=0.00(0.01), f_time=1.32(1.45), b_time=1.32(1.45)  Time cost: 1:29:33/04:05 [21:40:34/9:25:53]  Acc_iter 53900       Data time: 0.00(0.01)  Forward time: 1.32(1.45)  Batch time: 1.32(1.45)
2025-09-04 06:57:35,897   INFO  Train:   14/20 ( 70%) [3743/3862 ( 97%)]  Loss: 1.346 (1.22)  LR: 5.040e-04  Grad: 29.5987  max=1.1786(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1678(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3993, loss_cls=0.0689, loss_bbox=0.4618, matched_ious=0.5874, loss_iou=0.0845, loss_iou_reg=0.1972, d_time=0.01(0.01), f_time=1.44(1.45), b_time=1.45(1.45)  Time cost: 1:30:45/02:53 [21:41:47/9:24:36]  Acc_iter 53950       Data time: 0.01(0.01)  Forward time: 1.44(1.45)  Batch time: 1.45(1.45)
2025-09-04 06:58:48,405   INFO  Train:   14/20 ( 70%) [3793/3862 ( 98%)]  Loss: 1.248 (1.22)  LR: 5.023e-04  Grad: 29.6635  max=1.4529(module.vfe.pfn_layers.0.linear.weight)  min: -1.1717(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3982, loss_cls=0.0670, loss_bbox=0.4479, matched_ious=0.5906, loss_iou=0.0834, loss_iou_reg=0.1955, d_time=0.00(0.01), f_time=1.48(1.45), b_time=1.49(1.45)  Time cost: 1:31:58/01:40 [21:42:59/9:23:22]  Acc_iter 54000       Data time: 0.00(0.01)  Forward time: 1.48(1.45)  Batch time: 1.49(1.45)
2025-09-04 06:59:58,956   INFO  Train:   14/20 ( 70%) [3843/3862 (100%)]  Loss: 1.415 (1.22)  LR: 5.006e-04  Grad: 29.6460  max=1.1844(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1725(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4048, loss_cls=0.0684, loss_bbox=0.4655, matched_ious=0.5855, loss_iou=0.0850, loss_iou_reg=0.1992, d_time=0.00(0.01), f_time=1.34(1.45), b_time=1.35(1.45)  Time cost: 1:33:08/00:27 [21:44:10/9:21:56]  Acc_iter 54050       Data time: 0.00(0.01)  Forward time: 1.34(1.45)  Batch time: 1.35(1.45)
2025-09-04 07:00:23,382   INFO  Train:   14/20 ( 70%) [3861/3862 (100%)]  Loss: 1.247 (1.22)  LR: 5.000e-04  Grad: 29.6651  max=1.1807(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1734(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3998, loss_cls=0.0669, loss_bbox=0.4417, matched_ious=0.5924, loss_iou=0.0853, loss_iou_reg=0.1968, d_time=0.00(0.01), f_time=1.30(1.44), b_time=1.31(1.45)  Time cost: 1:33:33/00:01 [21:44:34/9:21:19]  Acc_iter 54068       Data time: 0.00(0.01)  Forward time: 1.30(1.44)  Batch time: 1.31(1.45)

                                               [Aepochs:  70%|███████   | 14/20 [21:44:34<9:20:45, 5607.58s/it] epochs:  70%|███████   | 14/20 [21:44:34<9:20:45, 5607.60s/it] epochs:  70%|███████   | 14/20 [21:44:34<9:20:45, 5607.59s/it] epochs:  70%|███████   | 14/20 [21:44:34<9:20:45, 5607.59s/it] epochs:  70%|███████   | 14/20 [21:44:34<9:20:45, 5607.61s/it] epochs:  70%|███████   | 14/20 [21:44:34<9:20:45, 5607.60s/it] epochs:  70%|███████   | 14/20 [21:44:34<9:20:45, 5607.60s/it] epochs:  70%|███████   | 14/20 [21:44:35<9:20:45, 5607.59s/it] 
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-04 07:00:28,883   INFO  Train:   15/20 ( 75%) [   0/3862 (  0%)]  Loss: 1.371 (1.37)  LR: 5.000e-04  Grad: 29.6745  max=1.1806(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1734(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4436, loss_cls=0.0835, loss_bbox=0.5531, matched_ious=0.5797, loss_iou=0.0946, loss_iou_reg=0.1960, d_time=1.77(1.77), f_time=2.55(2.55), b_time=4.31(4.31)  Time cost: 00:04/4:21:00 [21:44:39/26:06:04]  Acc_iter 54069       Data time: 1.77(1.77)  Forward time: 2.55(2.55)  Batch time: 4.31(4.31)
2025-09-04 07:01:12,925   INFO  Train:   15/20 ( 75%) [  31/3862 (  1%)]  Loss: 1.072 (1.23)  LR: 4.990e-04  Grad: 29.6650  max=1.1820(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1742(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4043, loss_cls=0.0705, loss_bbox=0.4675, matched_ious=0.5838, loss_iou=0.0866, loss_iou_reg=0.1989, d_time=0.00(0.06), f_time=1.44(1.45), b_time=1.44(1.51)  Time cost: 00:48/1:35:57 [21:45:24/9:39:38]  Acc_iter 54100       Data time: 0.00(0.06)  Forward time: 1.44(1.45)  Batch time: 1.44(1.51)
2025-09-04 07:02:30,280   INFO  Train:   15/20 ( 75%) [  81/3862 (  2%)]  Loss: 1.270 (1.22)  LR: 4.973e-04  Grad: 29.6992  max=1.1871(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1736(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3958, loss_cls=0.0684, loss_bbox=0.4621, matched_ious=0.5889, loss_iou=0.0847, loss_iou_reg=0.1966, d_time=0.01(0.03), f_time=1.37(1.50), b_time=1.38(1.53)  Time cost: 02:05/1:36:24 [21:46:41/9:48:46]  Acc_iter 54150       Data time: 0.01(0.03)  Forward time: 1.37(1.50)  Batch time: 1.38(1.53)
2025-09-04 07:03:41,490   INFO  Train:   15/20 ( 75%) [ 131/3862 (  3%)]  Loss: 1.183 (1.22)  LR: 4.956e-04  Grad: 29.7233  max=1.1835(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1779(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4048, loss_cls=0.0693, loss_bbox=0.4596, matched_ious=0.5884, loss_iou=0.0856, loss_iou_reg=0.1975, d_time=0.00(0.02), f_time=1.45(1.47), b_time=1.45(1.49)  Time cost: 03:16/1:32:38 [21:47:52/9:32:07]  Acc_iter 54200       Data time: 0.00(0.02)  Forward time: 1.45(1.47)  Batch time: 1.45(1.49)
2025-09-04 07:04:53,521   INFO  Train:   15/20 ( 75%) [ 181/3862 (  5%)]  Loss: 1.425 (1.21)  LR: 4.939e-04  Grad: 29.7575  max=1.1880(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1799(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3865, loss_cls=0.0687, loss_bbox=0.4397, matched_ious=0.5958, loss_iou=0.0851, loss_iou_reg=0.1938, d_time=0.00(0.02), f_time=1.39(1.46), b_time=1.39(1.48)  Time cost: 04:28/1:30:34 [21:49:04/9:25:42]  Acc_iter 54250       Data time: 0.00(0.02)  Forward time: 1.39(1.46)  Batch time: 1.39(1.48)
2025-09-04 07:06:05,907   INFO  Train:   15/20 ( 75%) [ 231/3862 (  6%)]  Loss: 1.002 (1.21)  LR: 4.922e-04  Grad: 29.7872  max=1.1905(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1830(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4118, loss_cls=0.0675, loss_bbox=0.4828, matched_ious=0.5840, loss_iou=0.0861, loss_iou_reg=0.2001, d_time=0.01(0.02), f_time=1.52(1.46), b_time=1.52(1.47)  Time cost: 05:41/1:28:58 [21:50:17/9:22:07]  Acc_iter 54300       Data time: 0.01(0.02)  Forward time: 1.52(1.46)  Batch time: 1.52(1.47)
2025-09-04 07:07:17,429   INFO  Train:   15/20 ( 75%) [ 281/3862 (  7%)]  Loss: 1.062 (1.21)  LR: 4.905e-04  Grad: 29.8072  max=1.1911(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1855(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3909, loss_cls=0.0679, loss_bbox=0.4470, matched_ious=0.5879, loss_iou=0.0847, loss_iou_reg=0.1966, d_time=0.00(0.01), f_time=1.37(1.45), b_time=1.37(1.46)  Time cost: 06:52/1:27:19 [21:51:28/9:18:12]  Acc_iter 54350       Data time: 0.00(0.01)  Forward time: 1.37(1.45)  Batch time: 1.37(1.46)
2025-09-04 07:08:34,994   INFO  Train:   15/20 ( 75%) [ 331/3862 (  9%)]  Loss: 1.185 (1.21)  LR: 4.888e-04  Grad: 29.8164  max=1.1912(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1824(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3920, loss_cls=0.0659, loss_bbox=0.4660, matched_ious=0.5856, loss_iou=0.0855, loss_iou_reg=0.1985, d_time=0.01(0.01), f_time=1.50(1.46), b_time=1.51(1.48)  Time cost: 08:10/1:26:53 [21:52:46/9:22:02]  Acc_iter 54400       Data time: 0.01(0.01)  Forward time: 1.50(1.46)  Batch time: 1.51(1.48)
2025-09-04 07:09:47,241   INFO  Train:   15/20 ( 75%) [ 381/3862 ( 10%)]  Loss: 1.175 (1.21)  LR: 4.871e-04  Grad: 29.8470  max=1.1942(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1881(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3905, loss_cls=0.0663, loss_bbox=0.4515, matched_ious=0.5888, loss_iou=0.0858, loss_iou_reg=0.1962, d_time=0.01(0.01), f_time=1.34(1.46), b_time=1.35(1.47)  Time cost: 09:22/1:25:25 [21:53:58/9:19:14]  Acc_iter 54450       Data time: 0.01(0.01)  Forward time: 1.34(1.46)  Batch time: 1.35(1.47)
2025-09-04 07:10:58,348   INFO  Train:   15/20 ( 75%) [ 431/3862 ( 11%)]  Loss: 1.140 (1.21)  LR: 4.854e-04  Grad: 29.9031  max=1.1939(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1876(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3900, loss_cls=0.0658, loss_bbox=0.4718, matched_ious=0.5844, loss_iou=0.0856, loss_iou_reg=0.1997, d_time=0.01(0.01), f_time=1.37(1.46), b_time=1.37(1.47)  Time cost: 10:33/1:23:51 [21:55:09/9:15:49]  Acc_iter 54500       Data time: 0.01(0.01)  Forward time: 1.37(1.46)  Batch time: 1.37(1.47)
2025-09-04 07:12:10,145   INFO  Train:   15/20 ( 75%) [ 481/3862 ( 12%)]  Loss: 1.022 (1.20)  LR: 4.837e-04  Grad: 29.9240  max=1.1926(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1892(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3848, loss_cls=0.0656, loss_bbox=0.4331, matched_ious=0.5917, loss_iou=0.0863, loss_iou_reg=0.1961, d_time=0.01(0.01), f_time=1.45(1.45), b_time=1.45(1.46)  Time cost: 11:45/1:22:27 [21:56:21/9:13:23]  Acc_iter 54550       Data time: 0.01(0.01)  Forward time: 1.45(1.45)  Batch time: 1.45(1.46)
2025-09-04 07:13:21,348   INFO  Train:   15/20 ( 75%) [ 531/3862 ( 14%)]  Loss: 1.176 (1.20)  LR: 4.820e-04  Grad: 29.9406  max=1.1968(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1890(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3885, loss_cls=0.0657, loss_bbox=0.4622, matched_ious=0.5914, loss_iou=0.0837, loss_iou_reg=0.1960, d_time=0.01(0.01), f_time=1.44(1.45), b_time=1.45(1.46)  Time cost: 12:56/1:21:02 [21:57:32/9:10:47]  Acc_iter 54600       Data time: 0.01(0.01)  Forward time: 1.44(1.45)  Batch time: 1.45(1.46)
2025-09-04 07:14:37,629   INFO  Train:   15/20 ( 75%) [ 581/3862 ( 15%)]  Loss: 1.164 (1.20)  LR: 4.803e-04  Grad: 30.0032  max=1.1959(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.4464(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.3983, loss_cls=0.0676, loss_bbox=0.4609, matched_ious=0.5887, loss_iou=0.0847, loss_iou_reg=0.1970, d_time=0.01(0.01), f_time=1.48(1.46), b_time=1.48(1.47)  Time cost: 14:12/1:20:07 [21:58:48/9:11:42]  Acc_iter 54650       Data time: 0.01(0.01)  Forward time: 1.48(1.46)  Batch time: 1.48(1.47)
2025-09-04 07:15:49,956   INFO  Train:   15/20 ( 75%) [ 631/3862 ( 16%)]  Loss: 1.318 (1.20)  LR: 4.786e-04  Grad: 30.0096  max=1.1951(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1913(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3908, loss_cls=0.0679, loss_bbox=0.4511, matched_ious=0.5884, loss_iou=0.0851, loss_iou_reg=0.1986, d_time=0.01(0.01), f_time=1.41(1.45), b_time=1.42(1.46)  Time cost: 15:25/1:18:49 [22:00:01/9:09:55]  Acc_iter 54700       Data time: 0.01(0.01)  Forward time: 1.41(1.45)  Batch time: 1.42(1.46)
2025-09-04 07:17:00,953   INFO  Train:   15/20 ( 75%) [ 681/3862 ( 18%)]  Loss: 1.163 (1.20)  LR: 4.769e-04  Grad: 30.0305  max=1.2010(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1925(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4012, loss_cls=0.0671, loss_bbox=0.4749, matched_ious=0.5931, loss_iou=0.0828, loss_iou_reg=0.1951, d_time=0.00(0.01), f_time=1.38(1.45), b_time=1.39(1.46)  Time cost: 16:36/1:17:26 [22:01:12/9:07:30]  Acc_iter 54750       Data time: 0.00(0.01)  Forward time: 1.38(1.45)  Batch time: 1.39(1.46)
2025-09-04 07:18:12,255   INFO  Train:   15/20 ( 75%) [ 731/3862 ( 19%)]  Loss: 1.404 (1.21)  LR: 4.752e-04  Grad: 30.0529  max=1.2013(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1933(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4092, loss_cls=0.0716, loss_bbox=0.4600, matched_ious=0.5869, loss_iou=0.0851, loss_iou_reg=0.1981, d_time=0.00(0.01), f_time=1.51(1.45), b_time=1.51(1.46)  Time cost: 17:47/1:16:05 [22:02:23/9:05:24]  Acc_iter 54800       Data time: 0.00(0.01)  Forward time: 1.51(1.45)  Batch time: 1.51(1.46)
2025-09-04 07:19:22,822   INFO  Train:   15/20 ( 75%) [ 781/3862 ( 20%)]  Loss: 1.229 (1.20)  LR: 4.735e-04  Grad: 30.0879  max=1.2006(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1939(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3834, loss_cls=0.0645, loss_bbox=0.4493, matched_ious=0.5899, loss_iou=0.0845, loss_iou_reg=0.1970, d_time=0.00(0.01), f_time=1.43(1.45), b_time=1.44(1.46)  Time cost: 18:57/1:14:43 [22:03:33/9:03:04]  Acc_iter 54850       Data time: 0.00(0.01)  Forward time: 1.43(1.45)  Batch time: 1.44(1.46)
2025-09-04 07:20:39,654   INFO  Train:   15/20 ( 75%) [ 831/3862 ( 22%)]  Loss: 1.073 (1.20)  LR: 4.719e-04  Grad: 30.1064  max=1.2064(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1928(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3938, loss_cls=0.0667, loss_bbox=0.4628, matched_ious=0.5881, loss_iou=0.0844, loss_iou_reg=0.1970, d_time=0.00(0.01), f_time=1.59(1.45), b_time=1.60(1.46)  Time cost: 20:14/1:13:45 [22:04:50/9:03:40]  Acc_iter 54900       Data time: 0.00(0.01)  Forward time: 1.59(1.45)  Batch time: 1.60(1.46)
2025-09-04 07:21:52,119   INFO  Train:   15/20 ( 75%) [ 881/3862 ( 23%)]  Loss: 1.180 (1.20)  LR: 4.702e-04  Grad: 30.1418  max=1.2069(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1975(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3906, loss_cls=0.0672, loss_bbox=0.4587, matched_ious=0.5878, loss_iou=0.0850, loss_iou_reg=0.1980, d_time=0.01(0.01), f_time=1.45(1.45), b_time=1.46(1.46)  Time cost: 21:27/1:12:30 [22:06:03/9:02:13]  Acc_iter 54950       Data time: 0.01(0.01)  Forward time: 1.45(1.45)  Batch time: 1.46(1.46)
2025-09-04 07:23:04,443   INFO  Train:   15/20 ( 75%) [ 931/3862 ( 24%)]  Loss: 1.142 (1.20)  LR: 4.685e-04  Grad: 30.1526  max=1.2059(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1995(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3916, loss_cls=0.0668, loss_bbox=0.4765, matched_ious=0.5863, loss_iou=0.0843, loss_iou_reg=0.1984, d_time=0.00(0.01), f_time=1.33(1.45), b_time=1.33(1.46)  Time cost: 22:39/1:11:15 [22:07:15/9:00:45]  Acc_iter 55000       Data time: 0.00(0.01)  Forward time: 1.33(1.45)  Batch time: 1.33(1.46)
2025-09-04 07:24:15,941   INFO  Train:   15/20 ( 75%) [ 981/3862 ( 25%)]  Loss: 1.170 (1.21)  LR: 4.668e-04  Grad: 30.1794  max=1.2094(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1994(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4049, loss_cls=0.0687, loss_bbox=0.4716, matched_ious=0.5869, loss_iou=0.0853, loss_iou_reg=0.1968, d_time=0.00(0.01), f_time=1.46(1.45), b_time=1.47(1.46)  Time cost: 23:51/1:09:58 [22:08:27/8:59:00]  Acc_iter 55050       Data time: 0.00(0.01)  Forward time: 1.46(1.45)  Batch time: 1.47(1.46)
2025-09-04 07:25:28,344   INFO  Train:   15/20 ( 75%) [1031/3862 ( 27%)]  Loss: 0.9934 (1.21)  LR: 4.651e-04  Grad: 30.2138  max=1.2049(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2007(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4090, loss_cls=0.0725, loss_bbox=0.4529, matched_ious=0.5914, loss_iou=0.0849, loss_iou_reg=0.1960, d_time=0.03(0.01), f_time=2.40(1.45), b_time=2.43(1.46)  Time cost: 25:03/1:08:44 [22:09:39/8:57:37]  Acc_iter 55100       Data time: 0.03(0.01)  Forward time: 2.40(1.45)  Batch time: 2.43(1.46)
2025-09-04 07:26:44,124   INFO  Train:   15/20 ( 75%) [1081/3862 ( 28%)]  Loss: 1.309 (1.21)  LR: 4.634e-04  Grad: 30.2432  max=1.2127(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2003(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4093, loss_cls=0.0703, loss_bbox=0.4681, matched_ious=0.5905, loss_iou=0.0846, loss_iou_reg=0.1948, d_time=0.01(0.01), f_time=1.34(1.45), b_time=1.34(1.46)  Time cost: 26:19/1:07:39 [22:10:55/8:57:24]  Acc_iter 55150       Data time: 0.01(0.01)  Forward time: 1.34(1.45)  Batch time: 1.34(1.46)
2025-09-04 07:27:56,847   INFO  Train:   15/20 ( 75%) [1131/3862 ( 29%)]  Loss: 0.9186 (1.21)  LR: 4.617e-04  Grad: 30.2724  max=1.2094(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2016(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3848, loss_cls=0.0668, loss_bbox=0.4367, matched_ious=0.5862, loss_iou=0.0860, loss_iou_reg=0.1998, d_time=0.01(0.01), f_time=1.38(1.45), b_time=1.39(1.46)  Time cost: 27:32/1:06:25 [22:12:07/8:56:06]  Acc_iter 55200       Data time: 0.01(0.01)  Forward time: 1.38(1.45)  Batch time: 1.39(1.46)
2025-09-04 07:29:07,687   INFO  Train:   15/20 ( 75%) [1181/3862 ( 31%)]  Loss: 1.234 (1.20)  LR: 4.600e-04  Grad: 30.3067  max=1.2131(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2034(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3919, loss_cls=0.0667, loss_bbox=0.4402, matched_ious=0.5905, loss_iou=0.0848, loss_iou_reg=0.1961, d_time=0.00(0.01), f_time=1.40(1.45), b_time=1.41(1.46)  Time cost: 28:42/1:05:07 [22:13:18/8:54:13]  Acc_iter 55250       Data time: 0.00(0.01)  Forward time: 1.40(1.45)  Batch time: 1.41(1.46)
2025-09-04 07:30:18,439   INFO  Train:   15/20 ( 75%) [1231/3862 ( 32%)]  Loss: 1.167 (1.20)  LR: 4.583e-04  Grad: 30.3270  max=1.2130(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2049(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3830, loss_cls=0.0644, loss_bbox=0.4680, matched_ious=0.5868, loss_iou=0.0857, loss_iou_reg=0.1974, d_time=0.00(0.01), f_time=1.46(1.45), b_time=1.47(1.46)  Time cost: 29:53/1:03:50 [22:14:29/8:52:22]  Acc_iter 55300       Data time: 0.00(0.01)  Forward time: 1.46(1.45)  Batch time: 1.47(1.46)
2025-09-04 07:31:31,836   INFO  Train:   15/20 ( 75%) [1281/3862 ( 33%)]  Loss: 1.289 (1.21)  LR: 4.566e-04  Grad: 30.3458  max=1.2121(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2082(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4014, loss_cls=0.0679, loss_bbox=0.4866, matched_ious=0.5869, loss_iou=0.0860, loss_iou_reg=0.1984, d_time=0.01(0.01), f_time=2.19(1.45), b_time=2.20(1.46)  Time cost: 31:07/1:02:38 [22:15:42/8:51:20]  Acc_iter 55350       Data time: 0.01(0.01)  Forward time: 2.19(1.45)  Batch time: 2.20(1.46)
2025-09-04 07:32:47,946   INFO  Train:   15/20 ( 75%) [1331/3862 ( 34%)]  Loss: 1.382 (1.20)  LR: 4.550e-04  Grad: 30.3887  max=1.2141(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2073(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3919, loss_cls=0.0659, loss_bbox=0.4296, matched_ious=0.5932, loss_iou=0.0836, loss_iou_reg=0.1954, d_time=0.01(0.01), f_time=1.34(1.45), b_time=1.34(1.46)  Time cost: 32:23/1:01:32 [22:16:59/8:51:01]  Acc_iter 55400       Data time: 0.01(0.01)  Forward time: 1.34(1.45)  Batch time: 1.34(1.46)
2025-09-04 07:34:00,075   INFO  Train:   15/20 ( 75%) [1381/3862 ( 36%)]  Loss: 1.066 (1.20)  LR: 4.533e-04  Grad: 30.4096  max=1.2162(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2059(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3971, loss_cls=0.0673, loss_bbox=0.4488, matched_ious=0.5907, loss_iou=0.0838, loss_iou_reg=0.1961, d_time=0.02(0.01), f_time=1.48(1.45), b_time=1.50(1.46)  Time cost: 33:35/1:00:17 [22:18:11/8:49:35]  Acc_iter 55450       Data time: 0.02(0.01)  Forward time: 1.48(1.45)  Batch time: 1.50(1.46)
2025-09-04 07:35:11,780   INFO  Train:   15/20 ( 75%) [1431/3862 ( 37%)]  Loss: 1.295 (1.20)  LR: 4.516e-04  Grad: 30.4033  max=1.2196(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2031(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4011, loss_cls=0.0691, loss_bbox=0.4653, matched_ious=0.5872, loss_iou=0.0857, loss_iou_reg=0.1965, d_time=0.00(0.01), f_time=1.37(1.45), b_time=1.38(1.46)  Time cost: 34:46/59:02 [22:19:22/8:48:04]  Acc_iter 55500       Data time: 0.00(0.01)  Forward time: 1.37(1.45)  Batch time: 1.38(1.46)
2025-09-04 07:36:23,730   INFO  Train:   15/20 ( 75%) [1481/3862 ( 38%)]  Loss: 0.9695 (1.20)  LR: 4.499e-04  Grad: 30.4625  max=1.2186(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2041(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3950, loss_cls=0.0654, loss_bbox=0.4506, matched_ious=0.5853, loss_iou=0.0865, loss_iou_reg=0.1987, d_time=0.01(0.01), f_time=1.34(1.45), b_time=1.35(1.46)  Time cost: 35:58/57:48 [22:20:34/8:46:38]  Acc_iter 55550       Data time: 0.01(0.01)  Forward time: 1.34(1.45)  Batch time: 1.35(1.46)
2025-09-04 07:37:37,671   INFO  Train:   15/20 ( 75%) [1531/3862 ( 40%)]  Loss: 1.008 (1.20)  LR: 4.482e-04  Grad: 30.4824  max=1.2208(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2070(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3979, loss_cls=0.0672, loss_bbox=0.4589, matched_ious=0.5871, loss_iou=0.0843, loss_iou_reg=0.1970, d_time=0.00(0.01), f_time=2.24(1.45), b_time=2.24(1.46)  Time cost: 37:12/56:37 [22:21:48/8:45:41]  Acc_iter 55600       Data time: 0.00(0.01)  Forward time: 2.24(1.45)  Batch time: 2.24(1.46)
2025-09-04 07:38:53,804   INFO  Train:   15/20 ( 75%) [1581/3862 ( 41%)]  Loss: 1.057 (1.20)  LR: 4.465e-04  Grad: 30.5196  max=1.2266(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2098(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3896, loss_cls=0.0652, loss_bbox=0.4510, matched_ious=0.5890, loss_iou=0.0846, loss_iou_reg=0.1956, d_time=0.01(0.01), f_time=1.37(1.45), b_time=1.37(1.46)  Time cost: 38:28/55:29 [22:23:04/8:45:12]  Acc_iter 55650       Data time: 0.01(0.01)  Forward time: 1.37(1.45)  Batch time: 1.37(1.46)
2025-09-04 07:40:05,114   INFO  Train:   15/20 ( 75%) [1631/3862 ( 42%)]  Loss: 1.581 (1.20)  LR: 4.448e-04  Grad: 30.5365  max=1.2278(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2116(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3844, loss_cls=0.0647, loss_bbox=0.4806, matched_ious=0.5878, loss_iou=0.0860, loss_iou_reg=0.1983, d_time=0.00(0.01), f_time=1.41(1.45), b_time=1.41(1.46)  Time cost: 39:40/54:13 [22:24:16/8:43:37]  Acc_iter 55700       Data time: 0.00(0.01)  Forward time: 1.41(1.45)  Batch time: 1.41(1.46)
2025-09-04 07:41:15,456   INFO  Train:   15/20 ( 75%) [1681/3862 ( 44%)]  Loss: 1.149 (1.20)  LR: 4.432e-04  Grad: 30.5689  max=1.2307(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2091(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3952, loss_cls=0.0669, loss_bbox=0.4504, matched_ious=0.5929, loss_iou=0.0846, loss_iou_reg=0.1942, d_time=0.00(0.01), f_time=1.45(1.45), b_time=1.46(1.46)  Time cost: 40:50/52:57 [22:25:26/8:41:51]  Acc_iter 55750       Data time: 0.00(0.01)  Forward time: 1.45(1.45)  Batch time: 1.46(1.46)
2025-09-04 07:42:26,493   INFO  Train:   15/20 ( 75%) [1731/3862 ( 45%)]  Loss: 1.099 (1.20)  LR: 4.415e-04  Grad: 30.5842  max=1.2289(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2115(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4031, loss_cls=0.0680, loss_bbox=0.4641, matched_ious=0.5863, loss_iou=0.0839, loss_iou_reg=0.1981, d_time=0.02(0.01), f_time=1.38(1.45), b_time=1.40(1.46)  Time cost: 42:01/51:42 [22:26:37/8:40:16]  Acc_iter 55800       Data time: 0.02(0.01)  Forward time: 1.38(1.45)  Batch time: 1.40(1.46)
2025-09-04 07:43:40,808   INFO  Train:   15/20 ( 75%) [1781/3862 ( 46%)]  Loss: 1.077 (1.20)  LR: 4.398e-04  Grad: 30.5958  max=1.2294(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2144(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3756, loss_cls=0.0656, loss_bbox=0.4254, matched_ious=0.5966, loss_iou=0.0824, loss_iou_reg=0.1928, d_time=0.01(0.01), f_time=1.32(1.45), b_time=1.32(1.46)  Time cost: 43:15/50:31 [22:27:51/8:39:21]  Acc_iter 55850       Data time: 0.01(0.01)  Forward time: 1.32(1.45)  Batch time: 1.32(1.46)
2025-09-04 07:44:55,973   INFO  Train:   15/20 ( 75%) [1831/3862 ( 47%)]  Loss: 1.261 (1.20)  LR: 4.381e-04  Grad: 30.6318  max=1.2295(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2164(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3973, loss_cls=0.0685, loss_bbox=0.4556, matched_ious=0.5880, loss_iou=0.0836, loss_iou_reg=0.1968, d_time=0.01(0.01), f_time=1.47(1.45), b_time=1.47(1.46)  Time cost: 44:31/49:21 [22:29:07/8:38:36]  Acc_iter 55900       Data time: 0.01(0.01)  Forward time: 1.47(1.45)  Batch time: 1.47(1.46)
2025-09-04 07:46:07,965   INFO  Train:   15/20 ( 75%) [1881/3862 ( 49%)]  Loss: 1.482 (1.20)  LR: 4.364e-04  Grad: 30.6672  max=1.2293(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2195(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3971, loss_cls=0.0676, loss_bbox=0.4865, matched_ious=0.5877, loss_iou=0.0861, loss_iou_reg=0.1985, d_time=0.01(0.01), f_time=1.40(1.45), b_time=1.41(1.46)  Time cost: 45:43/48:07 [22:30:19/8:37:13]  Acc_iter 55950       Data time: 0.01(0.01)  Forward time: 1.40(1.45)  Batch time: 1.41(1.46)
2025-09-04 07:47:19,289   INFO  Train:   15/20 ( 75%) [1931/3862 ( 50%)]  Loss: 1.304 (1.20)  LR: 4.347e-04  Grad: 30.6864  max=1.2307(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2207(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3941, loss_cls=0.0679, loss_bbox=0.4589, matched_ious=0.5937, loss_iou=0.0831, loss_iou_reg=0.1945, d_time=0.00(0.01), f_time=1.47(1.45), b_time=1.47(1.46)  Time cost: 46:54/46:53 [22:31:30/8:35:43]  Acc_iter 56000       Data time: 0.00(0.01)  Forward time: 1.47(1.45)  Batch time: 1.47(1.46)
2025-09-04 07:48:30,802   INFO  Train:   15/20 ( 75%) [1981/3862 ( 51%)]  Loss: 1.320 (1.20)  LR: 4.331e-04  Grad: 30.7066  max=1.2328(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2171(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3928, loss_cls=0.0699, loss_bbox=0.4599, matched_ious=0.5867, loss_iou=0.0840, loss_iou_reg=0.1961, d_time=0.01(0.01), f_time=1.44(1.45), b_time=1.45(1.46)  Time cost: 48:05/45:38 [22:32:41/8:34:16]  Acc_iter 56050       Data time: 0.01(0.01)  Forward time: 1.44(1.45)  Batch time: 1.45(1.46)
2025-09-04 07:49:44,774   INFO  Train:   15/20 ( 75%) [2031/3862 ( 53%)]  Loss: 1.269 (1.20)  LR: 4.314e-04  Grad: 30.7450  max=1.2360(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2209(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3861, loss_cls=0.0655, loss_bbox=0.4727, matched_ious=0.5907, loss_iou=0.0835, loss_iou_reg=0.1956, d_time=0.01(0.01), f_time=1.41(1.45), b_time=1.42(1.46)  Time cost: 49:19/44:27 [22:33:55/8:33:15]  Acc_iter 56100       Data time: 0.01(0.01)  Forward time: 1.41(1.45)  Batch time: 1.42(1.46)
2025-09-04 07:50:59,945   INFO  Train:   15/20 ( 75%) [2081/3862 ( 54%)]  Loss: 1.021 (1.20)  LR: 4.297e-04  Grad: 30.7963  max=1.2384(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2234(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3785, loss_cls=0.0637, loss_bbox=0.4300, matched_ious=0.5945, loss_iou=0.0846, loss_iou_reg=0.1938, d_time=0.01(0.01), f_time=1.41(1.45), b_time=1.42(1.46)  Time cost: 50:35/43:16 [22:35:11/8:32:26]  Acc_iter 56150       Data time: 0.01(0.01)  Forward time: 1.41(1.45)  Batch time: 1.42(1.46)
2025-09-04 07:52:11,354   INFO  Train:   15/20 ( 75%) [2131/3862 ( 55%)]  Loss: 1.067 (1.20)  LR: 4.280e-04  Grad: 30.7957  max=1.2429(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2226(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3845, loss_cls=0.0659, loss_bbox=0.4496, matched_ious=0.5915, loss_iou=0.0845, loss_iou_reg=0.1967, d_time=0.00(0.01), f_time=1.40(1.45), b_time=1.41(1.46)  Time cost: 51:46/42:02 [22:36:22/8:30:58]  Acc_iter 56200       Data time: 0.00(0.01)  Forward time: 1.40(1.45)  Batch time: 1.41(1.46)
2025-09-04 07:53:22,599   INFO  Train:   15/20 ( 75%) [2181/3862 ( 56%)]  Loss: 1.014 (1.20)  LR: 4.264e-04  Grad: 30.8145  max=1.2436(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2217(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3873, loss_cls=0.0657, loss_bbox=0.4499, matched_ious=0.5909, loss_iou=0.0844, loss_iou_reg=0.1952, d_time=0.01(0.01), f_time=1.46(1.45), b_time=1.47(1.46)  Time cost: 52:57/40:48 [22:37:33/8:29:30]  Acc_iter 56250       Data time: 0.01(0.01)  Forward time: 1.46(1.45)  Batch time: 1.47(1.46)
2025-09-04 07:54:33,874   INFO  Train:   15/20 ( 75%) [2231/3862 ( 58%)]  Loss: 1.043 (1.20)  LR: 4.247e-04  Grad: 30.8453  max=1.2469(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2259(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3780, loss_cls=0.0644, loss_bbox=0.4397, matched_ious=0.5948, loss_iou=0.0828, loss_iou_reg=0.1952, d_time=0.01(0.01), f_time=1.37(1.45), b_time=1.38(1.46)  Time cost: 54:09/39:34 [22:38:44/8:28:03]  Acc_iter 56300       Data time: 0.01(0.01)  Forward time: 1.37(1.45)  Batch time: 1.38(1.46)
2025-09-04 07:55:47,578   INFO  Train:   15/20 ( 75%) [2281/3862 ( 59%)]  Loss: 1.168 (1.20)  LR: 4.230e-04  Grad: 30.8345  max=1.2452(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2259(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3737, loss_cls=0.0641, loss_bbox=0.4488, matched_ious=0.5897, loss_iou=0.0837, loss_iou_reg=0.1980, d_time=0.01(0.01), f_time=1.51(1.45), b_time=1.51(1.46)  Time cost: 55:22/38:22 [22:39:58/8:26:58]  Acc_iter 56350       Data time: 0.01(0.01)  Forward time: 1.51(1.45)  Batch time: 1.51(1.46)
2025-09-04 07:57:02,268   INFO  Train:   15/20 ( 75%) [2331/3862 ( 60%)]  Loss: 0.9015 (1.20)  LR: 4.213e-04  Grad: 30.8876  max=1.2484(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2272(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3788, loss_cls=0.0646, loss_bbox=0.4656, matched_ious=0.5935, loss_iou=0.0857, loss_iou_reg=0.1952, d_time=0.01(0.01), f_time=1.44(1.45), b_time=1.45(1.46)  Time cost: 56:37/37:10 [22:41:13/8:26:02]  Acc_iter 56400       Data time: 0.01(0.01)  Forward time: 1.44(1.45)  Batch time: 1.45(1.46)
2025-09-04 07:58:13,768   INFO  Train:   15/20 ( 75%) [2381/3862 ( 62%)]  Loss: 1.441 (1.20)  LR: 4.197e-04  Grad: 30.9125  max=1.2503(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2291(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3918, loss_cls=0.0670, loss_bbox=0.4678, matched_ious=0.5954, loss_iou=0.0830, loss_iou_reg=0.1934, d_time=0.00(0.01), f_time=1.44(1.45), b_time=1.45(1.46)  Time cost: 57:48/35:56 [22:42:24/8:24:38]  Acc_iter 56450       Data time: 0.00(0.01)  Forward time: 1.44(1.45)  Batch time: 1.45(1.46)
2025-09-04 07:59:25,612   INFO  Train:   15/20 ( 75%) [2431/3862 ( 63%)]  Loss: 1.225 (1.20)  LR: 4.180e-04  Grad: 30.9203  max=1.2522(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2285(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3827, loss_cls=0.0643, loss_bbox=0.4423, matched_ious=0.5891, loss_iou=0.0860, loss_iou_reg=0.1978, d_time=0.01(0.01), f_time=1.48(1.45), b_time=1.49(1.46)  Time cost: 59:00/34:43 [22:43:36/8:23:17]  Acc_iter 56500       Data time: 0.01(0.01)  Forward time: 1.48(1.45)  Batch time: 1.49(1.46)
2025-09-04 08:00:36,846   INFO  Train:   15/20 ( 75%) [2481/3862 ( 64%)]  Loss: 1.123 (1.20)  LR: 4.163e-04  Grad: 30.9309  max=1.2482(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2285(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3710, loss_cls=0.0637, loss_bbox=0.4551, matched_ious=0.5864, loss_iou=0.0853, loss_iou_reg=0.1979, d_time=0.00(0.01), f_time=1.32(1.45), b_time=1.33(1.46)  Time cost: 1:00:12/33:29 [22:44:47/8:21:51]  Acc_iter 56550       Data time: 0.00(0.01)  Forward time: 1.32(1.45)  Batch time: 1.33(1.46)
2025-09-04 08:01:52,914   INFO  Train:   15/20 ( 75%) [2531/3862 ( 66%)]  Loss: 1.475 (1.20)  LR: 4.146e-04  Grad: 30.9440  max=1.2527(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2301(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3950, loss_cls=0.0668, loss_bbox=0.4650, matched_ious=0.5891, loss_iou=0.0858, loss_iou_reg=0.1985, d_time=0.01(0.01), f_time=1.42(1.45), b_time=1.43(1.46)  Time cost: 1:01:28/32:18 [22:46:04/8:21:05]  Acc_iter 56600       Data time: 0.01(0.01)  Forward time: 1.42(1.45)  Batch time: 1.43(1.46)
2025-09-04 08:03:06,539   INFO  Train:   15/20 ( 75%) [2581/3862 ( 67%)]  Loss: 1.183 (1.20)  LR: 4.130e-04  Grad: 30.9878  max=1.2544(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2338(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3974, loss_cls=0.0678, loss_bbox=0.4784, matched_ious=0.5889, loss_iou=0.0858, loss_iou_reg=0.1965, d_time=0.01(0.01), f_time=1.50(1.45), b_time=1.51(1.46)  Time cost: 1:02:41/31:06 [22:47:17/8:19:59]  Acc_iter 56650       Data time: 0.01(0.01)  Forward time: 1.50(1.45)  Batch time: 1.51(1.46)
2025-09-04 08:04:17,493   INFO  Train:   15/20 ( 75%) [2631/3862 ( 68%)]  Loss: 1.197 (1.20)  LR: 4.113e-04  Grad: 31.0244  max=1.2496(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2361(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3864, loss_cls=0.0656, loss_bbox=0.4304, matched_ious=0.5902, loss_iou=0.0830, loss_iou_reg=0.1959, d_time=0.01(0.01), f_time=1.43(1.45), b_time=1.44(1.46)  Time cost: 1:03:52/29:52 [22:48:28/8:18:31]  Acc_iter 56700       Data time: 0.01(0.01)  Forward time: 1.43(1.45)  Batch time: 1.44(1.46)
2025-09-04 08:05:29,240   INFO  Train:   15/20 ( 75%) [2681/3862 ( 69%)]  Loss: 1.600 (1.20)  LR: 4.096e-04  Grad: 31.0548  max=1.2535(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2382(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3729, loss_cls=0.0637, loss_bbox=0.4337, matched_ious=0.5957, loss_iou=0.0833, loss_iou_reg=0.1937, d_time=0.00(0.01), f_time=1.50(1.45), b_time=1.50(1.46)  Time cost: 1:05:04/28:39 [22:49:40/8:17:10]  Acc_iter 56750       Data time: 0.00(0.01)  Forward time: 1.50(1.45)  Batch time: 1.50(1.46)
2025-09-04 08:06:40,130   INFO  Train:   15/20 ( 75%) [2731/3862 ( 71%)]  Loss: 1.254 (1.20)  LR: 4.080e-04  Grad: 31.3464  max=3.7260(module.vfe.pfn_layers.0.linear.weight)  min: -1.2426(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3926, loss_cls=0.0657, loss_bbox=0.4484, matched_ious=0.5962, loss_iou=0.0831, loss_iou_reg=0.1936, d_time=0.00(0.01), f_time=1.43(1.45), b_time=1.44(1.46)  Time cost: 1:06:15/27:25 [22:50:51/8:15:43]  Acc_iter 56800       Data time: 0.00(0.01)  Forward time: 1.43(1.45)  Batch time: 1.44(1.46)
2025-09-04 08:07:55,050   INFO  Train:   15/20 ( 75%) [2781/3862 ( 72%)]  Loss: 0.9839 (1.20)  LR: 4.063e-04  Grad: 31.1241  max=1.2580(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2414(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3769, loss_cls=0.0651, loss_bbox=0.4479, matched_ious=0.5891, loss_iou=0.0853, loss_iou_reg=0.1970, d_time=0.01(0.01), f_time=1.43(1.45), b_time=1.43(1.46)  Time cost: 1:07:30/26:13 [22:52:06/8:14:46]  Acc_iter 56850       Data time: 0.01(0.01)  Forward time: 1.43(1.45)  Batch time: 1.43(1.46)
2025-09-04 08:09:09,098   INFO  Train:   15/20 ( 75%) [2831/3862 ( 73%)]  Loss: 0.9919 (1.20)  LR: 4.046e-04  Grad: 31.1398  max=1.2555(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2402(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3925, loss_cls=0.0661, loss_bbox=0.4509, matched_ious=0.5919, loss_iou=0.0846, loss_iou_reg=0.1959, d_time=0.02(0.01), f_time=1.52(1.45), b_time=1.54(1.46)  Time cost: 1:08:44/25:01 [22:53:20/8:13:42]  Acc_iter 56900       Data time: 0.02(0.01)  Forward time: 1.52(1.45)  Batch time: 1.54(1.46)
2025-09-04 08:10:20,667   INFO  Train:   15/20 ( 75%) [2881/3862 ( 75%)]  Loss: 1.280 (1.20)  LR: 4.030e-04  Grad: 31.1426  max=1.2571(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2395(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3759, loss_cls=0.0633, loss_bbox=0.4325, matched_ious=0.5946, loss_iou=0.0841, loss_iou_reg=0.1941, d_time=0.01(0.01), f_time=1.42(1.45), b_time=1.42(1.46)  Time cost: 1:09:55/23:48 [22:54:31/8:12:21]  Acc_iter 56950       Data time: 0.01(0.01)  Forward time: 1.42(1.45)  Batch time: 1.42(1.46)
2025-09-04 08:11:32,186   INFO  Train:   15/20 ( 75%) [2931/3862 ( 76%)]  Loss: 1.619 (1.20)  LR: 4.013e-04  Grad: 31.1744  max=1.2576(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2371(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3944, loss_cls=0.0664, loss_bbox=0.4444, matched_ious=0.5972, loss_iou=0.0851, loss_iou_reg=0.1941, d_time=0.01(0.01), f_time=1.45(1.45), b_time=1.45(1.46)  Time cost: 1:11:07/22:35 [22:55:43/8:10:59]  Acc_iter 57000       Data time: 0.01(0.01)  Forward time: 1.45(1.45)  Batch time: 1.45(1.46)
2025-09-04 08:12:44,368   INFO  Train:   15/20 ( 75%) [2981/3862 ( 77%)]  Loss: 1.334 (1.19)  LR: 3.997e-04  Grad: 31.1959  max=1.2602(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2421(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3766, loss_cls=0.0659, loss_bbox=0.4500, matched_ious=0.5899, loss_iou=0.0846, loss_iou_reg=0.1967, d_time=0.01(0.01), f_time=1.49(1.45), b_time=1.49(1.46)  Time cost: 1:12:19/21:22 [22:56:55/8:09:42]  Acc_iter 57050       Data time: 0.01(0.01)  Forward time: 1.49(1.45)  Batch time: 1.49(1.46)
2025-09-04 08:14:00,409   INFO  Train:   15/20 ( 75%) [3031/3862 ( 78%)]  Loss: 1.242 (1.19)  LR: 3.980e-04  Grad: 31.2181  max=1.2637(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2452(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3803, loss_cls=0.0668, loss_bbox=0.4486, matched_ious=0.5921, loss_iou=0.0844, loss_iou_reg=0.1964, d_time=0.01(0.01), f_time=1.50(1.45), b_time=1.51(1.46)  Time cost: 1:13:35/20:10 [22:58:11/8:08:51]  Acc_iter 57100       Data time: 0.01(0.01)  Forward time: 1.50(1.45)  Batch time: 1.51(1.46)
2025-09-04 08:15:13,244   INFO  Train:   15/20 ( 75%) [3081/3862 ( 80%)]  Loss: 1.289 (1.19)  LR: 3.963e-04  Grad: 31.2479  max=1.2608(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2471(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3815, loss_cls=0.0626, loss_bbox=0.4458, matched_ious=0.5904, loss_iou=0.0843, loss_iou_reg=0.1953, d_time=0.00(0.01), f_time=1.48(1.45), b_time=1.48(1.46)  Time cost: 1:14:48/18:57 [22:59:24/8:07:39]  Acc_iter 57150       Data time: 0.00(0.01)  Forward time: 1.48(1.45)  Batch time: 1.48(1.46)
2025-09-04 08:16:24,661   INFO  Train:   15/20 ( 75%) [3131/3862 ( 81%)]  Loss: 1.219 (1.19)  LR: 3.947e-04  Grad: 31.2750  max=1.2639(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2497(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3825, loss_cls=0.0638, loss_bbox=0.4435, matched_ious=0.5961, loss_iou=0.0844, loss_iou_reg=0.1945, d_time=0.01(0.01), f_time=1.37(1.45), b_time=1.38(1.46)  Time cost: 1:15:59/17:44 [23:00:35/8:06:17]  Acc_iter 57200       Data time: 0.01(0.01)  Forward time: 1.37(1.45)  Batch time: 1.38(1.46)
2025-09-04 08:17:35,949   INFO  Train:   15/20 ( 75%) [3181/3862 ( 82%)]  Loss: 1.097 (1.19)  LR: 3.930e-04  Grad: 31.3030  max=1.2588(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2510(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3718, loss_cls=0.0638, loss_bbox=0.4419, matched_ious=0.5872, loss_iou=0.0845, loss_iou_reg=0.1980, d_time=0.01(0.01), f_time=1.43(1.45), b_time=1.43(1.46)  Time cost: 1:17:11/16:31 [23:01:47/8:04:55]  Acc_iter 57250       Data time: 0.01(0.01)  Forward time: 1.43(1.45)  Batch time: 1.43(1.46)
2025-09-04 08:18:48,039   INFO  Train:   15/20 ( 75%) [3231/3862 ( 84%)]  Loss: 1.177 (1.19)  LR: 3.914e-04  Grad: 31.3103  max=1.2638(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2528(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3878, loss_cls=0.0645, loss_bbox=0.4440, matched_ious=0.5947, loss_iou=0.0849, loss_iou_reg=0.1945, d_time=0.00(0.01), f_time=1.34(1.45), b_time=1.35(1.46)  Time cost: 1:18:23/15:18 [23:02:59/8:03:38]  Acc_iter 57300       Data time: 0.00(0.01)  Forward time: 1.34(1.45)  Batch time: 1.35(1.46)
2025-09-04 08:20:03,732   INFO  Train:   15/20 ( 75%) [3281/3862 ( 85%)]  Loss: 1.228 (1.19)  LR: 3.897e-04  Grad: 31.3669  max=1.2609(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2532(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3945, loss_cls=0.0671, loss_bbox=0.4667, matched_ious=0.5873, loss_iou=0.0836, loss_iou_reg=0.1962, d_time=0.00(0.01), f_time=1.47(1.45), b_time=1.47(1.46)  Time cost: 1:19:38/14:05 [23:04:14/8:02:43]  Acc_iter 57350       Data time: 0.00(0.01)  Forward time: 1.47(1.45)  Batch time: 1.47(1.46)
2025-09-04 08:21:15,401   INFO  Train:   15/20 ( 75%) [3331/3862 ( 86%)]  Loss: 1.049 (1.19)  LR: 3.881e-04  Grad: 31.4032  max=1.2662(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2592(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3837, loss_cls=0.0663, loss_bbox=0.4621, matched_ious=0.5885, loss_iou=0.0852, loss_iou_reg=0.1958, d_time=0.00(0.01), f_time=1.44(1.45), b_time=1.45(1.46)  Time cost: 1:20:50/12:53 [23:05:26/8:01:23]  Acc_iter 57400       Data time: 0.00(0.01)  Forward time: 1.44(1.45)  Batch time: 1.45(1.46)
2025-09-04 08:22:27,209   INFO  Train:   15/20 ( 75%) [3381/3862 ( 88%)]  Loss: 1.256 (1.19)  LR: 3.864e-04  Grad: 31.4242  max=1.2678(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2564(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3857, loss_cls=0.0662, loss_bbox=0.4611, matched_ious=0.5891, loss_iou=0.0851, loss_iou_reg=0.1965, d_time=0.01(0.01), f_time=1.58(1.45), b_time=1.60(1.46)  Time cost: 1:22:02/11:40 [23:06:38/8:00:05]  Acc_iter 57450       Data time: 0.01(0.01)  Forward time: 1.58(1.45)  Batch time: 1.60(1.46)
2025-09-04 08:23:38,106   INFO  Train:   15/20 ( 75%) [3431/3862 ( 89%)]  Loss: 1.140 (1.19)  LR: 3.848e-04  Grad: 31.4137  max=1.2685(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2550(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3878, loss_cls=0.0665, loss_bbox=0.4501, matched_ious=0.5939, loss_iou=0.0850, loss_iou_reg=0.1961, d_time=0.01(0.01), f_time=1.41(1.45), b_time=1.42(1.45)  Time cost: 1:23:13/10:27 [23:07:49/7:58:41]  Acc_iter 57500       Data time: 0.01(0.01)  Forward time: 1.41(1.45)  Batch time: 1.42(1.45)
2025-09-04 08:24:50,651   INFO  Train:   15/20 ( 75%) [3481/3862 ( 90%)]  Loss: 1.063 (1.19)  LR: 3.831e-04  Grad: 31.4483  max=1.2682(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2586(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3924, loss_cls=0.0676, loss_bbox=0.4371, matched_ious=0.5976, loss_iou=0.0841, loss_iou_reg=0.1935, d_time=0.01(0.01), f_time=1.39(1.45), b_time=1.40(1.45)  Time cost: 1:24:25/09:14 [23:09:01/7:57:27]  Acc_iter 57550       Data time: 0.01(0.01)  Forward time: 1.39(1.45)  Batch time: 1.40(1.45)
2025-09-04 08:26:06,884   INFO  Train:   15/20 ( 75%) [3531/3862 ( 91%)]  Loss: 1.040 (1.19)  LR: 3.815e-04  Grad: 31.4823  max=1.2724(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2570(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3723, loss_cls=0.0624, loss_bbox=0.4481, matched_ious=0.5931, loss_iou=0.0815, loss_iou_reg=0.1954, d_time=0.01(0.01), f_time=1.38(1.45), b_time=1.39(1.46)  Time cost: 1:25:42/08:01 [23:10:17/7:56:34]  Acc_iter 57600       Data time: 0.01(0.01)  Forward time: 1.38(1.45)  Batch time: 1.39(1.46)
2025-09-04 08:27:18,926   INFO  Train:   15/20 ( 75%) [3581/3862 ( 93%)]  Loss: 1.108 (1.19)  LR: 3.798e-04  Grad: 31.5017  max=1.2699(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2541(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3615, loss_cls=0.0618, loss_bbox=0.4235, matched_ious=0.5984, loss_iou=0.0837, loss_iou_reg=0.1925, d_time=0.00(0.01), f_time=1.47(1.45), b_time=1.48(1.46)  Time cost: 1:26:54/06:49 [23:11:30/7:55:17]  Acc_iter 57650       Data time: 0.00(0.01)  Forward time: 1.47(1.45)  Batch time: 1.48(1.46)
2025-09-04 08:28:30,529   INFO  Train:   15/20 ( 75%) [3631/3862 ( 94%)]  Loss: 1.059 (1.19)  LR: 3.782e-04  Grad: 31.5151  max=1.2698(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2560(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3875, loss_cls=0.0659, loss_bbox=0.4359, matched_ious=0.5951, loss_iou=0.0844, loss_iou_reg=0.1944, d_time=0.01(0.01), f_time=1.40(1.45), b_time=1.41(1.46)  Time cost: 1:28:05/05:36 [23:12:41/7:53:58]  Acc_iter 57700       Data time: 0.01(0.01)  Forward time: 1.40(1.45)  Batch time: 1.41(1.46)
2025-09-04 08:29:41,823   INFO  Train:   15/20 ( 75%) [3681/3862 ( 95%)]  Loss: 1.274 (1.19)  LR: 3.765e-04  Grad: 31.5286  max=1.2722(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2549(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3903, loss_cls=0.0686, loss_bbox=0.4349, matched_ious=0.5918, loss_iou=0.0844, loss_iou_reg=0.1952, d_time=0.01(0.01), f_time=1.50(1.45), b_time=1.50(1.45)  Time cost: 1:29:16/04:23 [23:13:52/7:52:37]  Acc_iter 57750       Data time: 0.01(0.01)  Forward time: 1.50(1.45)  Batch time: 1.50(1.45)
2025-09-04 08:30:54,185   INFO  Train:   15/20 ( 75%) [3731/3862 ( 97%)]  Loss: 0.9400 (1.19)  LR: 3.749e-04  Grad: 31.5620  max=1.2759(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2573(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3683, loss_cls=0.0642, loss_bbox=0.4404, matched_ious=0.5896, loss_iou=0.0841, loss_iou_reg=0.1975, d_time=0.01(0.01), f_time=1.51(1.45), b_time=1.51(1.45)  Time cost: 1:30:29/03:10 [23:15:05/7:51:22]  Acc_iter 57800       Data time: 0.01(0.01)  Forward time: 1.51(1.45)  Batch time: 1.51(1.45)
2025-09-04 08:32:09,302   INFO  Train:   15/20 ( 75%) [3781/3862 ( 98%)]  Loss: 1.151 (1.19)  LR: 3.733e-04  Grad: 31.6219  max=1.2779(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2607(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3714, loss_cls=0.0627, loss_bbox=0.4329, matched_ious=0.5975, loss_iou=0.0830, loss_iou_reg=0.1923, d_time=0.01(0.01), f_time=1.40(1.45), b_time=1.41(1.46)  Time cost: 1:31:44/01:57 [23:16:20/7:50:22]  Acc_iter 57850       Data time: 0.01(0.01)  Forward time: 1.40(1.45)  Batch time: 1.41(1.46)
2025-09-04 08:33:21,481   INFO  Train:   15/20 ( 75%) [3831/3862 ( 99%)]  Loss: 1.226 (1.19)  LR: 3.716e-04  Grad: 31.6420  max=1.2796(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2585(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3813, loss_cls=0.0664, loss_bbox=0.4486, matched_ious=0.5911, loss_iou=0.0846, loss_iou_reg=0.1959, d_time=0.01(0.01), f_time=1.45(1.45), b_time=1.46(1.46)  Time cost: 1:32:56/00:45 [23:17:32/7:49:06]  Acc_iter 57900       Data time: 0.01(0.01)  Forward time: 1.45(1.45)  Batch time: 1.46(1.46)
2025-09-04 08:34:02,359   INFO  Train:   15/20 ( 75%) [3861/3862 (100%)]  Loss: 1.199 (1.19)  LR: 3.706e-04  Grad: 31.6355  max=1.2758(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2619(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3958, loss_cls=0.0684, loss_bbox=0.4565, matched_ious=0.5860, loss_iou=0.0854, loss_iou_reg=0.1995, d_time=0.00(0.01), f_time=1.29(1.45), b_time=1.30(1.45)  Time cost: 1:33:37/00:01 [23:18:13/7:48:09]  Acc_iter 57930       Data time: 0.00(0.01)  Forward time: 1.29(1.45)  Batch time: 1.30(1.45)

                                               [Aepochs:  75%|███████▌  | 15/20 [23:18:13<7:47:35, 5611.00s/it]epochs:  75%|███████▌  | 15/20 [23:18:13<7:47:35, 5611.02s/it]epochs:  75%|███████▌  | 15/20 [23:18:13<7:47:35, 5611.01s/it]epochs:  75%|███████▌  | 15/20 [23:18:13<7:47:35, 5611.01s/it]epochs:  75%|███████▌  | 15/20 [23:18:13<7:47:35, 5611.03s/it]epochs:  75%|███████▌  | 15/20 [23:18:13<7:47:35, 5611.04s/it]epochs:  75%|███████▌  | 15/20 [23:18:13<7:47:35, 5611.03s/it]epochs:  75%|███████▌  | 15/20 [23:18:14<7:47:35, 5611.03s/it]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-04 08:34:07,877   INFO  Train:   16/20 ( 80%) [   0/3862 (  0%)]  Loss: 1.284 (1.28)  LR: 3.706e-04  Grad: 31.6274  max=1.2765(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2624(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3630, loss_cls=0.0773, loss_bbox=0.5429, matched_ious=0.5671, loss_iou=0.0885, loss_iou_reg=0.2121, d_time=2.04(2.04), f_time=2.32(2.32), b_time=4.35(4.35)  Time cost: 00:04/4:19:17 [23:18:18/21:36:28]  Acc_iter 57931       Data time: 2.04(2.04)  Forward time: 2.32(2.32)  Batch time: 4.35(4.35)
2025-09-04 08:34:35,217   INFO  Train:   16/20 ( 80%) [  19/3862 (  0%)]  Loss: 1.060 (1.24)  LR: 3.700e-04  Grad: 31.6827  max=1.2748(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2633(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4086, loss_cls=0.0678, loss_bbox=0.4768, matched_ious=0.5857, loss_iou=0.0866, loss_iou_reg=0.1982, d_time=0.01(0.11), f_time=1.42(1.48), b_time=1.42(1.58)  Time cost: 00:31/1:40:26 [23:18:46/8:24:13]  Acc_iter 57950       Data time: 0.01(0.11)  Forward time: 1.42(1.48)  Batch time: 1.42(1.58)
2025-09-04 08:35:47,241   INFO  Train:   16/20 ( 80%) [  69/3862 (  2%)]  Loss: 0.8535 (1.20)  LR: 3.683e-04  Grad: 31.6675  max=1.2767(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2597(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3853, loss_cls=0.0659, loss_bbox=0.4567, matched_ious=0.5956, loss_iou=0.0848, loss_iou_reg=0.1948, d_time=0.01(0.04), f_time=1.42(1.45), b_time=1.42(1.48)  Time cost: 01:43/1:33:22 [23:19:58/7:53:40]  Acc_iter 58000       Data time: 0.01(0.04)  Forward time: 1.42(1.45)  Batch time: 1.42(1.48)
2025-09-04 08:36:59,934   INFO  Train:   16/20 ( 80%) [ 119/3862 (  3%)]  Loss: 1.193 (1.20)  LR: 3.667e-04  Grad: 31.6579  max=1.2796(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2595(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3853, loss_cls=0.0649, loss_bbox=0.4629, matched_ious=0.5903, loss_iou=0.0837, loss_iou_reg=0.1953, d_time=0.02(0.02), f_time=1.35(1.45), b_time=1.37(1.47)  Time cost: 02:56/1:31:32 [23:21:11/7:49:18]  Acc_iter 58050       Data time: 0.02(0.02)  Forward time: 1.35(1.45)  Batch time: 1.37(1.47)
2025-09-04 08:38:16,422   INFO  Train:   16/20 ( 80%) [ 169/3862 (  4%)]  Loss: 1.099 (1.19)  LR: 3.651e-04  Grad: 31.7121  max=1.2797(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2638(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3787, loss_cls=0.0639, loss_bbox=0.4424, matched_ious=0.5973, loss_iou=0.0828, loss_iou_reg=0.1927, d_time=0.00(0.02), f_time=1.50(1.47), b_time=1.50(1.49)  Time cost: 04:12/1:31:26 [23:22:27/7:53:58]  Acc_iter 58100       Data time: 0.00(0.02)  Forward time: 1.50(1.47)  Batch time: 1.50(1.49)
2025-09-04 08:39:29,271   INFO  Train:   16/20 ( 80%) [ 219/3862 (  6%)]  Loss: 1.157 (1.18)  LR: 3.634e-04  Grad: 31.7025  max=1.2817(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2664(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3673, loss_cls=0.0619, loss_bbox=0.4337, matched_ious=0.5954, loss_iou=0.0855, loss_iou_reg=0.1941, d_time=0.01(0.02), f_time=1.49(1.46), b_time=1.49(1.48)  Time cost: 05:25/1:29:48 [23:23:40/7:50:39]  Acc_iter 58150       Data time: 0.01(0.02)  Forward time: 1.49(1.46)  Batch time: 1.49(1.48)
2025-09-04 08:40:40,644   INFO  Train:   16/20 ( 80%) [ 269/3862 (  7%)]  Loss: 1.227 (1.18)  LR: 3.618e-04  Grad: 31.7745  max=1.2771(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2683(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3744, loss_cls=0.0652, loss_bbox=0.4487, matched_ious=0.5917, loss_iou=0.0843, loss_iou_reg=0.1951, d_time=0.00(0.02), f_time=1.37(1.45), b_time=1.37(1.47)  Time cost: 06:36/1:28:00 [23:24:51/7:46:23]  Acc_iter 58200       Data time: 0.00(0.02)  Forward time: 1.37(1.45)  Batch time: 1.37(1.47)
2025-09-04 08:41:52,650   INFO  Train:   16/20 ( 80%) [ 319/3862 (  8%)]  Loss: 1.454 (1.18)  LR: 3.602e-04  Grad: 31.7884  max=1.2758(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2674(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3928, loss_cls=0.0661, loss_bbox=0.4573, matched_ious=0.5887, loss_iou=0.0852, loss_iou_reg=0.1970, d_time=0.01(0.01), f_time=1.42(1.45), b_time=1.43(1.47)  Time cost: 07:48/1:26:30 [23:26:03/7:43:41]  Acc_iter 58250       Data time: 0.01(0.01)  Forward time: 1.42(1.45)  Batch time: 1.43(1.47)
2025-09-04 08:43:04,430   INFO  Train:   16/20 ( 80%) [ 369/3862 ( 10%)]  Loss: 1.186 (1.18)  LR: 3.586e-04  Grad: 31.8279  max=1.2825(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2685(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3790, loss_cls=0.0643, loss_bbox=0.4371, matched_ious=0.5949, loss_iou=0.0838, loss_iou_reg=0.1945, d_time=0.00(0.01), f_time=1.43(1.45), b_time=1.44(1.46)  Time cost: 09:00/1:25:03 [23:27:15/7:41:13]  Acc_iter 58300       Data time: 0.00(0.01)  Forward time: 1.43(1.45)  Batch time: 1.44(1.46)
2025-09-04 08:44:20,184   INFO  Train:   16/20 ( 80%) [ 419/3862 ( 11%)]  Loss: 1.270 (1.17)  LR: 3.569e-04  Grad: 31.8313  max=1.2802(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2689(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3855, loss_cls=0.0653, loss_bbox=0.4279, matched_ious=0.5918, loss_iou=0.0858, loss_iou_reg=0.1962, d_time=0.01(0.02), f_time=1.55(1.45), b_time=1.55(1.47)  Time cost: 10:16/1:24:12 [23:28:31/7:42:01]  Acc_iter 58350       Data time: 0.01(0.02)  Forward time: 1.55(1.45)  Batch time: 1.55(1.47)
2025-09-04 08:45:32,248   INFO  Train:   16/20 ( 80%) [ 469/3862 ( 12%)]  Loss: 1.170 (1.17)  LR: 3.553e-04  Grad: 31.8442  max=1.2830(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2716(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3918, loss_cls=0.0651, loss_bbox=0.4399, matched_ious=0.5955, loss_iou=0.0843, loss_iou_reg=0.1941, d_time=0.00(0.01), f_time=1.38(1.45), b_time=1.39(1.47)  Time cost: 11:28/1:22:49 [23:29:43/7:39:56]  Acc_iter 58400       Data time: 0.00(0.01)  Forward time: 1.38(1.45)  Batch time: 1.39(1.47)
2025-09-04 08:46:42,954   INFO  Train:   16/20 ( 80%) [ 519/3862 ( 13%)]  Loss: 1.144 (1.17)  LR: 3.537e-04  Grad: 31.8699  max=1.2835(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2706(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3701, loss_cls=0.0622, loss_bbox=0.4534, matched_ious=0.5912, loss_iou=0.0848, loss_iou_reg=0.1963, d_time=0.00(0.01), f_time=1.46(1.45), b_time=1.47(1.46)  Time cost: 12:39/1:21:20 [23:30:54/7:37:11]  Acc_iter 58450       Data time: 0.00(0.01)  Forward time: 1.46(1.45)  Batch time: 1.47(1.46)
2025-09-04 08:47:54,767   INFO  Train:   16/20 ( 80%) [ 569/3862 ( 15%)]  Loss: 1.114 (1.17)  LR: 3.521e-04  Grad: 31.9064  max=1.2843(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2711(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3734, loss_cls=0.0651, loss_bbox=0.4316, matched_ious=0.5919, loss_iou=0.0843, loss_iou_reg=0.1958, d_time=0.01(0.01), f_time=1.40(1.45), b_time=1.40(1.46)  Time cost: 13:50/1:20:00 [23:32:05/7:35:19]  Acc_iter 58500       Data time: 0.01(0.01)  Forward time: 1.40(1.45)  Batch time: 1.40(1.46)
2025-09-04 08:49:06,923   INFO  Train:   16/20 ( 80%) [ 619/3862 ( 16%)]  Loss: 1.040 (1.17)  LR: 3.505e-04  Grad: 31.9147  max=1.2851(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2735(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3678, loss_cls=0.0623, loss_bbox=0.4292, matched_ious=0.5916, loss_iou=0.0866, loss_iou_reg=0.1959, d_time=0.03(0.01), f_time=1.70(1.44), b_time=1.73(1.46)  Time cost: 15:03/1:18:43 [23:33:18/7:33:44]  Acc_iter 58550       Data time: 0.03(0.01)  Forward time: 1.70(1.44)  Batch time: 1.73(1.46)
2025-09-04 08:50:22,620   INFO  Train:   16/20 ( 80%) [ 669/3862 ( 17%)]  Loss: 1.045 (1.17)  LR: 3.488e-04  Grad: 31.9235  max=1.2885(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2732(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3759, loss_cls=0.0629, loss_bbox=0.4302, matched_ious=0.5930, loss_iou=0.0841, loss_iou_reg=0.1945, d_time=0.01(0.01), f_time=1.33(1.45), b_time=1.34(1.46)  Time cost: 16:18/1:17:44 [23:34:33/7:33:51]  Acc_iter 58600       Data time: 0.01(0.01)  Forward time: 1.33(1.45)  Batch time: 1.34(1.46)
2025-09-04 08:51:34,098   INFO  Train:   16/20 ( 80%) [ 719/3862 ( 19%)]  Loss: 1.096 (1.17)  LR: 3.472e-04  Grad: 31.9372  max=1.2876(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2773(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3662, loss_cls=0.0632, loss_bbox=0.4281, matched_ious=0.5948, loss_iou=0.0846, loss_iou_reg=0.1946, d_time=0.01(0.01), f_time=1.38(1.45), b_time=1.39(1.46)  Time cost: 17:30/1:16:24 [23:35:45/7:31:58]  Acc_iter 58650       Data time: 0.01(0.01)  Forward time: 1.38(1.45)  Batch time: 1.39(1.46)
2025-09-04 08:52:45,281   INFO  Train:   16/20 ( 80%) [ 769/3862 ( 20%)]  Loss: 1.454 (1.16)  LR: 3.456e-04  Grad: 31.9891  max=1.2928(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2841(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3699, loss_cls=0.0614, loss_bbox=0.4443, matched_ious=0.5974, loss_iou=0.0832, loss_iou_reg=0.1930, d_time=0.01(0.01), f_time=1.34(1.44), b_time=1.35(1.46)  Time cost: 18:41/1:15:04 [23:36:56/7:30:03]  Acc_iter 58700       Data time: 0.01(0.01)  Forward time: 1.34(1.44)  Batch time: 1.35(1.46)
2025-09-04 08:53:58,060   INFO  Train:   16/20 ( 80%) [ 819/3862 ( 21%)]  Loss: 1.089 (1.16)  LR: 3.440e-04  Grad: 31.9596  max=1.2932(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2768(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3742, loss_cls=0.0640, loss_bbox=0.4372, matched_ious=0.5962, loss_iou=0.0823, loss_iou_reg=0.1924, d_time=0.01(0.01), f_time=1.23(1.44), b_time=1.23(1.46)  Time cost: 19:54/1:13:51 [23:38:09/7:28:48]  Acc_iter 58750       Data time: 0.01(0.01)  Forward time: 1.23(1.44)  Batch time: 1.23(1.46)
2025-09-04 08:55:09,606   INFO  Train:   16/20 ( 80%) [ 869/3862 ( 23%)]  Loss: 1.316 (1.16)  LR: 3.424e-04  Grad: 32.0098  max=1.2946(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2777(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3680, loss_cls=0.0622, loss_bbox=0.4428, matched_ious=0.5977, loss_iou=0.0836, loss_iou_reg=0.1929, d_time=0.00(0.01), f_time=1.44(1.44), b_time=1.45(1.46)  Time cost: 21:05/1:12:34 [23:39:20/7:27:09]  Acc_iter 58800       Data time: 0.00(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.46)
2025-09-04 08:56:26,062   INFO  Train:   16/20 ( 80%) [ 919/3862 ( 24%)]  Loss: 1.278 (1.16)  LR: 3.408e-04  Grad: 32.0266  max=1.2999(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2801(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3855, loss_cls=0.0666, loss_bbox=0.4459, matched_ious=0.5927, loss_iou=0.0849, loss_iou_reg=0.1948, d_time=0.01(0.01), f_time=1.45(1.45), b_time=1.46(1.46)  Time cost: 22:22/1:11:33 [23:40:37/7:27:11]  Acc_iter 58850       Data time: 0.01(0.01)  Forward time: 1.45(1.45)  Batch time: 1.46(1.46)
2025-09-04 08:57:36,835   INFO  Train:   16/20 ( 80%) [ 969/3862 ( 25%)]  Loss: 1.032 (1.16)  LR: 3.392e-04  Grad: 32.0702  max=1.2956(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2843(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3753, loss_cls=0.0655, loss_bbox=0.4285, matched_ious=0.5952, loss_iou=0.0839, loss_iou_reg=0.1935, d_time=0.01(0.01), f_time=1.46(1.45), b_time=1.47(1.46)  Time cost: 23:32/1:10:14 [23:41:47/7:25:17]  Acc_iter 58900       Data time: 0.01(0.01)  Forward time: 1.46(1.45)  Batch time: 1.47(1.46)
2025-09-04 08:58:47,696   INFO  Train:   16/20 ( 80%) [1019/3862 ( 26%)]  Loss: 1.242 (1.16)  LR: 3.376e-04  Grad: 32.0734  max=1.3026(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2833(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3769, loss_cls=0.0656, loss_bbox=0.4430, matched_ious=0.5921, loss_iou=0.0846, loss_iou_reg=0.1958, d_time=0.00(0.01), f_time=1.41(1.44), b_time=1.42(1.46)  Time cost: 24:43/1:08:55 [23:42:58/7:23:28]  Acc_iter 58950       Data time: 0.00(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.46)
2025-09-04 09:00:00,127   INFO  Train:   16/20 ( 80%) [1069/3862 ( 28%)]  Loss: 1.122 (1.16)  LR: 3.360e-04  Grad: 32.0797  max=1.2994(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2820(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3733, loss_cls=0.0639, loss_bbox=0.4262, matched_ious=0.5936, loss_iou=0.0840, loss_iou_reg=0.1959, d_time=0.00(0.01), f_time=1.46(1.44), b_time=1.47(1.45)  Time cost: 25:56/1:07:42 [23:44:11/7:22:10]  Acc_iter 59000       Data time: 0.00(0.01)  Forward time: 1.46(1.44)  Batch time: 1.47(1.45)
2025-09-04 09:01:11,399   INFO  Train:   16/20 ( 80%) [1119/3862 ( 29%)]  Loss: 1.099 (1.16)  LR: 3.344e-04  Grad: 32.0878  max=1.3020(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2820(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3858, loss_cls=0.0640, loss_bbox=0.4427, matched_ious=0.5974, loss_iou=0.0834, loss_iou_reg=0.1933, d_time=0.00(0.01), f_time=1.52(1.44), b_time=1.52(1.45)  Time cost: 27:07/1:06:26 [23:45:22/7:20:34]  Acc_iter 59050       Data time: 0.00(0.01)  Forward time: 1.52(1.44)  Batch time: 1.52(1.45)
2025-09-04 09:02:28,580   INFO  Train:   16/20 ( 80%) [1169/3862 ( 30%)]  Loss: 1.234 (1.16)  LR: 3.328e-04  Grad: 32.1842  max=1.3051(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.6623(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.3702, loss_cls=0.0634, loss_bbox=0.4304, matched_ious=0.5916, loss_iou=0.0842, loss_iou_reg=0.1960, d_time=0.00(0.01), f_time=1.42(1.45), b_time=1.43(1.46)  Time cost: 28:24/1:05:23 [23:46:39/7:20:32]  Acc_iter 59100       Data time: 0.00(0.01)  Forward time: 1.42(1.45)  Batch time: 1.43(1.46)
2025-09-04 09:03:40,038   INFO  Train:   16/20 ( 80%) [1219/3862 ( 32%)]  Loss: 0.9796 (1.16)  LR: 3.312e-04  Grad: 32.1635  max=1.3061(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2829(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3755, loss_cls=0.0627, loss_bbox=0.4408, matched_ious=0.5963, loss_iou=0.0830, loss_iou_reg=0.1934, d_time=0.01(0.01), f_time=1.40(1.45), b_time=1.41(1.46)  Time cost: 29:36/1:04:07 [23:47:51/7:18:58]  Acc_iter 59150       Data time: 0.01(0.01)  Forward time: 1.40(1.45)  Batch time: 1.41(1.46)
2025-09-04 09:04:52,821   INFO  Train:   16/20 ( 80%) [1269/3862 ( 33%)]  Loss: 1.223 (1.16)  LR: 3.296e-04  Grad: 32.1711  max=1.3044(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2853(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3782, loss_cls=0.0646, loss_bbox=0.4337, matched_ious=0.5970, loss_iou=0.0849, loss_iou_reg=0.1940, d_time=0.01(0.01), f_time=1.50(1.45), b_time=1.51(1.46)  Time cost: 30:48/1:02:55 [23:49:03/7:17:45]  Acc_iter 59200       Data time: 0.01(0.01)  Forward time: 1.50(1.45)  Batch time: 1.51(1.46)
2025-09-04 09:06:03,797   INFO  Train:   16/20 ( 80%) [1319/3862 ( 34%)]  Loss: 1.266 (1.16)  LR: 3.280e-04  Grad: 32.2236  max=1.3059(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2876(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3828, loss_cls=0.0670, loss_bbox=0.4606, matched_ious=0.5930, loss_iou=0.0832, loss_iou_reg=0.1952, d_time=0.01(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 31:59/1:01:38 [23:50:14/7:16:08]  Acc_iter 59250       Data time: 0.01(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-04 09:07:14,826   INFO  Train:   16/20 ( 80%) [1369/3862 ( 35%)]  Loss: 1.200 (1.16)  LR: 3.264e-04  Grad: 32.2289  max=1.3045(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2873(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3532, loss_cls=0.0610, loss_bbox=0.3990, matched_ious=0.6037, loss_iou=0.0836, loss_iou_reg=0.1909, d_time=0.01(0.01), f_time=1.35(1.44), b_time=1.36(1.45)  Time cost: 33:10/1:00:23 [23:51:25/7:14:33]  Acc_iter 59300       Data time: 0.01(0.01)  Forward time: 1.35(1.44)  Batch time: 1.36(1.45)
2025-09-04 09:08:31,394   INFO  Train:   16/20 ( 80%) [1419/3862 ( 37%)]  Loss: 1.129 (1.16)  LR: 3.248e-04  Grad: 32.2244  max=1.3081(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2826(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3613, loss_cls=0.0619, loss_bbox=0.4360, matched_ious=0.5968, loss_iou=0.0844, loss_iou_reg=0.1940, d_time=0.01(0.01), f_time=1.35(1.45), b_time=1.35(1.46)  Time cost: 34:27/59:17 [23:52:42/7:14:09]  Acc_iter 59350       Data time: 0.01(0.01)  Forward time: 1.35(1.45)  Batch time: 1.35(1.46)
2025-09-04 09:09:42,393   INFO  Train:   16/20 ( 80%) [1469/3862 ( 38%)]  Loss: 1.018 (1.16)  LR: 3.232e-04  Grad: 32.2389  max=1.3105(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2874(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3726, loss_cls=0.0641, loss_bbox=0.4377, matched_ious=0.5971, loss_iou=0.0837, loss_iou_reg=0.1923, d_time=0.00(0.01), f_time=1.37(1.44), b_time=1.37(1.46)  Time cost: 35:38/58:01 [23:53:53/7:12:34]  Acc_iter 59400       Data time: 0.00(0.01)  Forward time: 1.37(1.44)  Batch time: 1.37(1.46)
2025-09-04 09:10:54,687   INFO  Train:   16/20 ( 80%) [1519/3862 ( 39%)]  Loss: 1.278 (1.16)  LR: 3.216e-04  Grad: 32.2434  max=1.3111(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2915(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3727, loss_cls=0.0633, loss_bbox=0.4384, matched_ious=0.5974, loss_iou=0.0848, loss_iou_reg=0.1924, d_time=0.00(0.01), f_time=1.41(1.44), b_time=1.42(1.45)  Time cost: 36:50/56:47 [23:55:05/7:11:17]  Acc_iter 59450       Data time: 0.00(0.01)  Forward time: 1.41(1.44)  Batch time: 1.42(1.45)
2025-09-04 09:12:05,409   INFO  Train:   16/20 ( 80%) [1569/3862 ( 41%)]  Loss: 1.106 (1.16)  LR: 3.201e-04  Grad: 32.2866  max=1.3111(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2954(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3773, loss_cls=0.0636, loss_bbox=0.4306, matched_ious=0.5943, loss_iou=0.0857, loss_iou_reg=0.1947, d_time=0.02(0.01), f_time=1.40(1.44), b_time=1.41(1.45)  Time cost: 38:01/55:32 [23:56:16/7:09:41]  Acc_iter 59500       Data time: 0.02(0.01)  Forward time: 1.40(1.44)  Batch time: 1.41(1.45)
2025-09-04 09:13:16,764   INFO  Train:   16/20 ( 80%) [1619/3862 ( 42%)]  Loss: 1.148 (1.16)  LR: 3.185e-04  Grad: 32.3269  max=1.3129(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3004(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3801, loss_cls=0.0649, loss_bbox=0.4512, matched_ious=0.5939, loss_iou=0.0846, loss_iou_reg=0.1959, d_time=0.00(0.01), f_time=1.36(1.44), b_time=1.37(1.45)  Time cost: 39:12/54:17 [23:57:27/7:08:14]  Acc_iter 59550       Data time: 0.00(0.01)  Forward time: 1.36(1.44)  Batch time: 1.37(1.45)
2025-09-04 09:14:32,398   INFO  Train:   16/20 ( 80%) [1669/3862 ( 43%)]  Loss: 1.404 (1.16)  LR: 3.169e-04  Grad: 32.3694  max=1.3114(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2970(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3679, loss_cls=0.0639, loss_bbox=0.4273, matched_ious=0.5953, loss_iou=0.0845, loss_iou_reg=0.1942, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.43(1.45)  Time cost: 40:28/53:09 [23:58:43/7:07:33]  Acc_iter 59600       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.43(1.45)
2025-09-04 09:15:43,535   INFO  Train:   16/20 ( 80%) [1719/3862 ( 45%)]  Loss: 1.089 (1.16)  LR: 3.153e-04  Grad: 32.3740  max=1.3095(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2985(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3761, loss_cls=0.0646, loss_bbox=0.4235, matched_ious=0.5960, loss_iou=0.0855, loss_iou_reg=0.1942, d_time=0.01(0.01), f_time=1.37(1.44), b_time=1.38(1.45)  Time cost: 41:39/51:54 [23:59:54/7:06:05]  Acc_iter 59650       Data time: 0.01(0.01)  Forward time: 1.37(1.44)  Batch time: 1.38(1.45)
2025-09-04 09:16:55,583   INFO  Train:   16/20 ( 80%) [1769/3862 ( 46%)]  Loss: 0.9955 (1.16)  LR: 3.137e-04  Grad: 32.3863  max=1.3092(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2986(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3722, loss_cls=0.0657, loss_bbox=0.4142, matched_ious=0.5985, loss_iou=0.0827, loss_iou_reg=0.1945, d_time=0.01(0.01), f_time=1.45(1.44), b_time=1.46(1.45)  Time cost: 42:51/50:41 [24:01:06/7:04:46]  Acc_iter 59700       Data time: 0.01(0.01)  Forward time: 1.45(1.44)  Batch time: 1.46(1.45)
2025-09-04 09:18:06,718   INFO  Train:   16/20 ( 80%) [1819/3862 ( 47%)]  Loss: 0.9874 (1.16)  LR: 3.122e-04  Grad: 32.3922  max=1.3195(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2975(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3586, loss_cls=0.0613, loss_bbox=0.4226, matched_ious=0.5990, loss_iou=0.0835, loss_iou_reg=0.1926, d_time=0.00(0.01), f_time=1.32(1.44), b_time=1.33(1.45)  Time cost: 44:02/49:26 [24:02:17/7:03:19]  Acc_iter 59750       Data time: 0.00(0.01)  Forward time: 1.32(1.44)  Batch time: 1.33(1.45)
2025-09-04 09:19:18,864   INFO  Train:   16/20 ( 80%) [1869/3862 ( 48%)]  Loss: 1.147 (1.15)  LR: 3.106e-04  Grad: 32.4178  max=1.3203(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3045(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3659, loss_cls=0.0619, loss_bbox=0.4135, matched_ious=0.5970, loss_iou=0.0839, loss_iou_reg=0.1927, d_time=0.01(0.01), f_time=2.14(1.44), b_time=2.15(1.45)  Time cost: 45:15/48:13 [24:03:29/7:02:02]  Acc_iter 59800       Data time: 0.01(0.01)  Forward time: 2.14(1.44)  Batch time: 2.15(1.45)
2025-09-04 09:20:33,836   INFO  Train:   16/20 ( 80%) [1919/3862 ( 50%)]  Loss: 0.9504 (1.15)  LR: 3.090e-04  Grad: 32.4443  max=1.3150(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3023(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3797, loss_cls=0.0644, loss_bbox=0.4426, matched_ious=0.5962, loss_iou=0.0845, loss_iou_reg=0.1940, d_time=0.00(0.01), f_time=1.33(1.44), b_time=1.34(1.45)  Time cost: 46:29/47:03 [24:04:44/7:01:11]  Acc_iter 59850       Data time: 0.00(0.01)  Forward time: 1.33(1.44)  Batch time: 1.34(1.45)
2025-09-04 09:21:45,016   INFO  Train:   16/20 ( 80%) [1969/3862 ( 51%)]  Loss: 1.054 (1.16)  LR: 3.075e-04  Grad: 32.4538  max=1.3137(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3009(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3854, loss_cls=0.0653, loss_bbox=0.4300, matched_ious=0.5961, loss_iou=0.0849, loss_iou_reg=0.1940, d_time=0.01(0.01), f_time=1.47(1.44), b_time=1.47(1.45)  Time cost: 47:41/45:49 [24:05:56/6:59:45]  Acc_iter 59900       Data time: 0.01(0.01)  Forward time: 1.47(1.44)  Batch time: 1.47(1.45)
2025-09-04 09:22:57,242   INFO  Train:   16/20 ( 80%) [2019/3862 ( 52%)]  Loss: 1.427 (1.15)  LR: 3.059e-04  Grad: 32.4719  max=1.3178(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3002(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3792, loss_cls=0.0647, loss_bbox=0.4267, matched_ious=0.5978, loss_iou=0.0829, loss_iou_reg=0.1930, d_time=0.00(0.01), f_time=1.39(1.44), b_time=1.40(1.45)  Time cost: 48:53/44:36 [24:07:08/6:58:29]  Acc_iter 59950       Data time: 0.00(0.01)  Forward time: 1.39(1.44)  Batch time: 1.40(1.45)
2025-09-04 09:24:08,822   INFO  Train:   16/20 ( 80%) [2069/3862 ( 54%)]  Loss: 1.011 (1.15)  LR: 3.044e-04  Grad: 32.4912  max=1.3207(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3023(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3678, loss_cls=0.0612, loss_bbox=0.4236, matched_ious=0.5965, loss_iou=0.0838, loss_iou_reg=0.1952, d_time=0.00(0.01), f_time=1.46(1.44), b_time=1.46(1.45)  Time cost: 50:04/43:22 [24:08:19/6:57:08]  Acc_iter 60000       Data time: 0.00(0.01)  Forward time: 1.46(1.44)  Batch time: 1.46(1.45)
2025-09-04 09:25:21,726   INFO  Train:   16/20 ( 80%) [2119/3862 ( 55%)]  Loss: 1.192 (1.15)  LR: 3.028e-04  Grad: 32.4916  max=1.3209(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3034(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3854, loss_cls=0.0660, loss_bbox=0.4445, matched_ious=0.5930, loss_iou=0.0844, loss_iou_reg=0.1946, d_time=0.00(0.01), f_time=1.42(1.44), b_time=1.42(1.45)  Time cost: 51:17/42:10 [24:09:32/6:55:58]  Acc_iter 60050       Data time: 0.00(0.01)  Forward time: 1.42(1.44)  Batch time: 1.42(1.45)
2025-09-04 09:26:35,509   INFO  Train:   16/20 ( 80%) [2169/3862 ( 56%)]  Loss: 1.039 (1.15)  LR: 3.012e-04  Grad: 32.5109  max=1.3235(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3029(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3666, loss_cls=0.0622, loss_bbox=0.4389, matched_ious=0.5949, loss_iou=0.0830, loss_iou_reg=0.1947, d_time=0.01(0.01), f_time=1.36(1.44), b_time=1.36(1.45)  Time cost: 52:31/40:58 [24:10:46/6:54:55]  Acc_iter 60100       Data time: 0.01(0.01)  Forward time: 1.36(1.44)  Batch time: 1.36(1.45)
2025-09-04 09:27:46,855   INFO  Train:   16/20 ( 80%) [2219/3862 ( 57%)]  Loss: 1.394 (1.15)  LR: 2.997e-04  Grad: 32.5783  max=1.3238(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3072(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3707, loss_cls=0.0642, loss_bbox=0.4268, matched_ious=0.5947, loss_iou=0.0842, loss_iou_reg=0.1942, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 53:43/39:45 [24:11:57/6:53:32]  Acc_iter 60150       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-04 09:28:58,845   INFO  Train:   16/20 ( 80%) [2269/3862 ( 59%)]  Loss: 1.031 (1.15)  LR: 2.981e-04  Grad: 32.5936  max=1.3235(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3067(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3620, loss_cls=0.0605, loss_bbox=0.4369, matched_ious=0.5951, loss_iou=0.0853, loss_iou_reg=0.1952, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.43(1.45)  Time cost: 54:54/38:32 [24:13:09/6:52:15]  Acc_iter 60200       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.43(1.45)
2025-09-04 09:30:09,948   INFO  Train:   16/20 ( 80%) [2319/3862 ( 60%)]  Loss: 0.9585 (1.15)  LR: 2.966e-04  Grad: 32.6117  max=1.3220(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3082(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3640, loss_cls=0.0636, loss_bbox=0.4215, matched_ious=0.5977, loss_iou=0.0840, loss_iou_reg=0.1928, d_time=0.01(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 56:06/37:18 [24:14:21/6:50:52]  Acc_iter 60250       Data time: 0.01(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-04 09:31:23,185   INFO  Train:   16/20 ( 80%) [2369/3862 ( 61%)]  Loss: 1.128 (1.15)  LR: 2.950e-04  Grad: 32.6300  max=1.3233(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3106(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3688, loss_cls=0.0611, loss_bbox=0.4531, matched_ious=0.5950, loss_iou=0.0850, loss_iou_reg=0.1937, d_time=0.01(0.01), f_time=1.49(1.44), b_time=1.50(1.45)  Time cost: 57:19/36:06 [24:15:34/6:49:44]  Acc_iter 60300       Data time: 0.01(0.01)  Forward time: 1.49(1.44)  Batch time: 1.50(1.45)
2025-09-04 09:32:38,840   INFO  Train:   16/20 ( 80%) [2419/3862 ( 63%)]  Loss: 1.231 (1.15)  LR: 2.935e-04  Grad: 32.6454  max=1.3221(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3121(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3713, loss_cls=0.0630, loss_bbox=0.4358, matched_ious=0.5980, loss_iou=0.0828, loss_iou_reg=0.1932, d_time=0.00(0.01), f_time=1.45(1.44), b_time=1.45(1.45)  Time cost: 58:34/34:55 [24:16:49/6:48:53]  Acc_iter 60350       Data time: 0.00(0.01)  Forward time: 1.45(1.44)  Batch time: 1.45(1.45)
2025-09-04 09:33:51,157   INFO  Train:   16/20 ( 80%) [2469/3862 ( 64%)]  Loss: 1.145 (1.15)  LR: 2.919e-04  Grad: 32.6488  max=1.3252(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3090(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3692, loss_cls=0.0618, loss_bbox=0.4260, matched_ious=0.5991, loss_iou=0.0833, loss_iou_reg=0.1927, d_time=0.00(0.01), f_time=1.45(1.44), b_time=1.45(1.45)  Time cost: 59:47/33:43 [24:18:02/6:47:39]  Acc_iter 60400       Data time: 0.00(0.01)  Forward time: 1.45(1.44)  Batch time: 1.45(1.45)
2025-09-04 09:35:02,963   INFO  Train:   16/20 ( 80%) [2519/3862 ( 65%)]  Loss: 1.279 (1.15)  LR: 2.904e-04  Grad: 32.6758  max=1.3238(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3110(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3682, loss_cls=0.0631, loss_bbox=0.4351, matched_ious=0.5954, loss_iou=0.0845, loss_iou_reg=0.1942, d_time=0.01(0.01), f_time=1.49(1.44), b_time=1.50(1.45)  Time cost: 1:00:59/32:30 [24:19:14/6:46:21]  Acc_iter 60450       Data time: 0.01(0.01)  Forward time: 1.49(1.44)  Batch time: 1.50(1.45)
2025-09-04 09:36:13,833   INFO  Train:   16/20 ( 80%) [2569/3862 ( 67%)]  Loss: 1.400 (1.15)  LR: 2.889e-04  Grad: 32.7116  max=1.3279(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3131(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3749, loss_cls=0.0626, loss_bbox=0.4508, matched_ious=0.5966, loss_iou=0.0824, loss_iou_reg=0.1931, d_time=0.00(0.01), f_time=1.48(1.44), b_time=1.49(1.45)  Time cost: 1:02:09/31:16 [24:20:24/6:44:57]  Acc_iter 60500       Data time: 0.00(0.01)  Forward time: 1.48(1.44)  Batch time: 1.49(1.45)
2025-09-04 09:37:26,691   INFO  Train:   16/20 ( 80%) [2619/3862 ( 68%)]  Loss: 1.017 (1.15)  LR: 2.873e-04  Grad: 32.7186  max=1.3278(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3177(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3735, loss_cls=0.0623, loss_bbox=0.4198, matched_ious=0.5967, loss_iou=0.0837, loss_iou_reg=0.1942, d_time=0.01(0.01), f_time=1.50(1.44), b_time=1.50(1.45)  Time cost: 1:03:22/30:04 [24:21:37/6:43:46]  Acc_iter 60550       Data time: 0.01(0.01)  Forward time: 1.50(1.44)  Batch time: 1.50(1.45)
2025-09-04 09:38:42,143   INFO  Train:   16/20 ( 80%) [2669/3862 ( 69%)]  Loss: 1.067 (1.15)  LR: 2.858e-04  Grad: 32.7398  max=1.3308(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3159(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3769, loss_cls=0.0652, loss_bbox=0.4431, matched_ious=0.5934, loss_iou=0.0840, loss_iou_reg=0.1951, d_time=0.00(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 1:04:38/28:52 [24:22:53/6:42:51]  Acc_iter 60600       Data time: 0.00(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-04 09:39:54,700   INFO  Train:   16/20 ( 80%) [2719/3862 ( 70%)]  Loss: 1.033 (1.15)  LR: 2.843e-04  Grad: 32.7589  max=1.3329(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3143(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3943, loss_cls=0.0671, loss_bbox=0.4445, matched_ious=0.5934, loss_iou=0.0839, loss_iou_reg=0.1943, d_time=0.00(0.01), f_time=1.36(1.44), b_time=1.37(1.45)  Time cost: 1:05:50/27:40 [24:24:05/6:41:38]  Acc_iter 60650       Data time: 0.00(0.01)  Forward time: 1.36(1.44)  Batch time: 1.37(1.45)
2025-09-04 09:41:06,059   INFO  Train:   16/20 ( 80%) [2769/3862 ( 72%)]  Loss: 1.128 (1.15)  LR: 2.827e-04  Grad: 32.7757  max=1.3319(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3107(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3796, loss_cls=0.0638, loss_bbox=0.4462, matched_ious=0.5988, loss_iou=0.0841, loss_iou_reg=0.1907, d_time=0.00(0.01), f_time=1.49(1.44), b_time=1.50(1.45)  Time cost: 1:07:02/26:27 [24:25:17/6:40:18]  Acc_iter 60700       Data time: 0.00(0.01)  Forward time: 1.49(1.44)  Batch time: 1.50(1.45)
2025-09-04 09:42:16,800   INFO  Train:   16/20 ( 80%) [2819/3862 ( 73%)]  Loss: 0.9184 (1.15)  LR: 2.812e-04  Grad: 32.8010  max=1.3336(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3171(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3793, loss_cls=0.0632, loss_bbox=0.4433, matched_ious=0.5954, loss_iou=0.0833, loss_iou_reg=0.1934, d_time=0.00(0.01), f_time=1.48(1.44), b_time=1.49(1.45)  Time cost: 1:08:12/25:13 [24:26:27/6:38:55]  Acc_iter 60750       Data time: 0.00(0.01)  Forward time: 1.48(1.44)  Batch time: 1.49(1.45)
2025-09-04 09:43:30,810   INFO  Train:   16/20 ( 80%) [2869/3862 ( 74%)]  Loss: 1.035 (1.15)  LR: 2.797e-04  Grad: 32.8199  max=1.3385(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3163(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3664, loss_cls=0.0629, loss_bbox=0.4275, matched_ious=0.6017, loss_iou=0.0828, loss_iou_reg=0.1923, d_time=0.00(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 1:09:26/24:01 [24:27:41/6:37:50]  Acc_iter 60800       Data time: 0.00(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-04 09:44:45,621   INFO  Train:   16/20 ( 80%) [2919/3862 ( 76%)]  Loss: 1.213 (1.15)  LR: 2.782e-04  Grad: 32.8233  max=1.3371(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3181(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3636, loss_cls=0.0611, loss_bbox=0.4137, matched_ious=0.5948, loss_iou=0.0834, loss_iou_reg=0.1950, d_time=0.00(0.01), f_time=1.47(1.44), b_time=1.48(1.45)  Time cost: 1:10:41/22:49 [24:28:56/6:36:50]  Acc_iter 60850       Data time: 0.00(0.01)  Forward time: 1.47(1.44)  Batch time: 1.48(1.45)
2025-09-04 09:45:57,575   INFO  Train:   16/20 ( 80%) [2969/3862 ( 77%)]  Loss: 1.058 (1.15)  LR: 2.767e-04  Grad: 32.8523  max=1.3388(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3209(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3661, loss_cls=0.0620, loss_bbox=0.4249, matched_ious=0.5973, loss_iou=0.0847, loss_iou_reg=0.1939, d_time=0.02(0.01), f_time=1.43(1.44), b_time=1.45(1.45)  Time cost: 1:11:53/21:37 [24:30:08/6:35:34]  Acc_iter 60900       Data time: 0.02(0.01)  Forward time: 1.43(1.44)  Batch time: 1.45(1.45)
2025-09-04 09:47:09,205   INFO  Train:   16/20 ( 80%) [3019/3862 ( 78%)]  Loss: 0.8780 (1.15)  LR: 2.751e-04  Grad: 32.8516  max=1.3374(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3229(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3723, loss_cls=0.0609, loss_bbox=0.4223, matched_ious=0.5973, loss_iou=0.0845, loss_iou_reg=0.1946, d_time=0.01(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 1:13:05/20:24 [24:31:20/6:34:16]  Acc_iter 60950       Data time: 0.01(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-04 09:48:20,221   INFO  Train:   16/20 ( 80%) [3069/3862 ( 79%)]  Loss: 1.022 (1.15)  LR: 2.736e-04  Grad: 32.8821  max=1.3422(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3230(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3692, loss_cls=0.0629, loss_bbox=0.4258, matched_ious=0.5973, loss_iou=0.0836, loss_iou_reg=0.1931, d_time=0.00(0.01), f_time=1.38(1.44), b_time=1.39(1.45)  Time cost: 1:14:16/19:11 [24:32:31/6:32:55]  Acc_iter 61000       Data time: 0.00(0.01)  Forward time: 1.38(1.44)  Batch time: 1.39(1.45)
2025-09-04 09:49:35,472   INFO  Train:   16/20 ( 80%) [3119/3862 ( 81%)]  Loss: 0.9545 (1.15)  LR: 2.721e-04  Grad: 32.8934  max=1.3392(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3191(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3720, loss_cls=0.0623, loss_bbox=0.4351, matched_ious=0.5931, loss_iou=0.0853, loss_iou_reg=0.1941, d_time=0.00(0.01), f_time=1.53(1.44), b_time=1.54(1.45)  Time cost: 1:15:31/17:59 [24:33:46/6:31:56]  Acc_iter 61050       Data time: 0.00(0.01)  Forward time: 1.53(1.44)  Batch time: 1.54(1.45)
2025-09-04 09:50:49,592   INFO  Train:   16/20 ( 80%) [3169/3862 ( 82%)]  Loss: 0.9379 (1.15)  LR: 2.706e-04  Grad: 32.9217  max=1.3419(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3259(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3642, loss_cls=0.0628, loss_bbox=0.4196, matched_ious=0.5986, loss_iou=0.0829, loss_iou_reg=0.1928, d_time=0.00(0.01), f_time=1.44(1.44), b_time=1.45(1.45)  Time cost: 1:16:45/16:46 [24:35:00/6:30:51]  Acc_iter 61100       Data time: 0.00(0.01)  Forward time: 1.44(1.44)  Batch time: 1.45(1.45)
2025-09-04 09:52:02,122   INFO  Train:   16/20 ( 80%) [3219/3862 ( 83%)]  Loss: 1.232 (1.15)  LR: 2.691e-04  Grad: 32.9510  max=1.3418(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3229(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3549, loss_cls=0.0601, loss_bbox=0.4271, matched_ious=0.5960, loss_iou=0.0839, loss_iou_reg=0.1946, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.44(1.45)  Time cost: 1:17:58/15:34 [24:36:13/6:29:38]  Acc_iter 61150       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.44(1.45)
2025-09-04 09:53:14,242   INFO  Train:   16/20 ( 80%) [3269/3862 ( 85%)]  Loss: 1.264 (1.15)  LR: 2.676e-04  Grad: 32.9544  max=1.3360(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3246(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3751, loss_cls=0.0633, loss_bbox=0.4437, matched_ious=0.6017, loss_iou=0.0831, loss_iou_reg=0.1902, d_time=0.00(0.01), f_time=1.43(1.44), b_time=1.43(1.45)  Time cost: 1:19:10/14:21 [24:37:25/6:28:23]  Acc_iter 61200       Data time: 0.00(0.01)  Forward time: 1.43(1.44)  Batch time: 1.43(1.45)
2025-09-04 09:54:25,144   INFO  Train:   16/20 ( 80%) [3319/3862 ( 86%)]  Loss: 1.280 (1.15)  LR: 2.661e-04  Grad: 32.9853  max=1.3419(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3267(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3612, loss_cls=0.0606, loss_bbox=0.4128, matched_ious=0.6029, loss_iou=0.0825, loss_iou_reg=0.1915, d_time=0.01(0.01), f_time=1.47(1.44), b_time=1.47(1.45)  Time cost: 1:20:21/13:08 [24:38:36/6:27:02]  Acc_iter 61250       Data time: 0.01(0.01)  Forward time: 1.47(1.44)  Batch time: 1.47(1.45)
2025-09-04 09:55:40,107   INFO  Train:   16/20 ( 80%) [3369/3862 ( 87%)]  Loss: 0.9397 (1.15)  LR: 2.646e-04  Grad: 33.0055  max=1.3407(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3261(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3665, loss_cls=0.0629, loss_bbox=0.4178, matched_ious=0.6011, loss_iou=0.0817, loss_iou_reg=0.1910, d_time=0.01(0.01), f_time=1.41(1.44), b_time=1.41(1.45)  Time cost: 1:21:36/11:56 [24:39:51/6:26:00]  Acc_iter 61300       Data time: 0.01(0.01)  Forward time: 1.41(1.44)  Batch time: 1.41(1.45)
2025-09-04 09:56:53,843   INFO  Train:   16/20 ( 80%) [3419/3862 ( 89%)]  Loss: 1.238 (1.15)  LR: 2.631e-04  Grad: 33.0235  max=1.3387(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3262(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3675, loss_cls=0.0626, loss_bbox=0.4222, matched_ious=0.5981, loss_iou=0.0830, loss_iou_reg=0.1924, d_time=0.00(0.01), f_time=1.41(1.44), b_time=1.41(1.45)  Time cost: 1:22:49/10:43 [24:41:04/6:24:53]  Acc_iter 61350       Data time: 0.00(0.01)  Forward time: 1.41(1.44)  Batch time: 1.41(1.45)
2025-09-04 09:58:05,247   INFO  Train:   16/20 ( 80%) [3469/3862 ( 90%)]  Loss: 1.246 (1.15)  LR: 2.616e-04  Grad: 33.0340  max=1.3381(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3298(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3606, loss_cls=0.0613, loss_bbox=0.4314, matched_ious=0.5984, loss_iou=0.0832, loss_iou_reg=0.1937, d_time=0.01(0.01), f_time=1.53(1.44), b_time=1.53(1.45)  Time cost: 1:24:01/09:30 [24:42:16/6:23:34]  Acc_iter 61400       Data time: 0.01(0.01)  Forward time: 1.53(1.44)  Batch time: 1.53(1.45)
2025-09-04 09:59:16,719   INFO  Train:   16/20 ( 80%) [3519/3862 ( 91%)]  Loss: 1.122 (1.15)  LR: 2.601e-04  Grad: 33.0351  max=1.3385(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3280(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3752, loss_cls=0.0641, loss_bbox=0.4562, matched_ious=0.5983, loss_iou=0.0825, loss_iou_reg=0.1919, d_time=0.01(0.01), f_time=1.51(1.44), b_time=1.51(1.45)  Time cost: 1:25:12/08:18 [24:43:27/6:22:16]  Acc_iter 61450       Data time: 0.01(0.01)  Forward time: 1.51(1.44)  Batch time: 1.51(1.45)
2025-09-04 10:00:27,894   INFO  Train:   16/20 ( 80%) [3569/3862 ( 92%)]  Loss: 1.017 (1.15)  LR: 2.587e-04  Grad: 33.0524  max=1.3439(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3270(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3686, loss_cls=0.0631, loss_bbox=0.4456, matched_ious=0.5959, loss_iou=0.0846, loss_iou_reg=0.1950, d_time=0.01(0.01), f_time=1.42(1.44), b_time=1.43(1.45)  Time cost: 1:26:24/07:05 [24:44:39/6:20:57]  Acc_iter 61500       Data time: 0.01(0.01)  Forward time: 1.42(1.44)  Batch time: 1.43(1.45)
2025-09-04 10:01:42,485   INFO  Train:   16/20 ( 80%) [3619/3862 ( 94%)]  Loss: 0.9924 (1.15)  LR: 2.572e-04  Grad: 33.0748  max=1.3454(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3299(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3726, loss_cls=0.0629, loss_bbox=0.4174, matched_ious=0.6003, loss_iou=0.0825, loss_iou_reg=0.1917, d_time=0.36(0.01), f_time=1.39(1.44), b_time=1.75(1.45)  Time cost: 1:27:38/05:52 [24:45:53/6:19:53]  Acc_iter 61550       Data time: 0.36(0.01)  Forward time: 1.39(1.44)  Batch time: 1.75(1.45)
2025-09-04 10:02:55,439   INFO  Train:   16/20 ( 80%) [3669/3862 ( 95%)]  Loss: 0.9210 (1.15)  LR: 2.557e-04  Grad: 33.1108  max=1.3475(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3307(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3678, loss_cls=0.0639, loss_bbox=0.4065, matched_ious=0.5974, loss_iou=0.0839, loss_iou_reg=0.1938, d_time=0.00(0.01), f_time=1.45(1.44), b_time=1.46(1.45)  Time cost: 1:28:51/04:40 [24:47:06/6:18:42]  Acc_iter 61600       Data time: 0.00(0.01)  Forward time: 1.45(1.44)  Batch time: 1.46(1.45)
2025-09-04 10:04:06,998   INFO  Train:   16/20 ( 80%) [3719/3862 ( 96%)]  Loss: 1.142 (1.15)  LR: 2.542e-04  Grad: 33.1357  max=1.3456(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3323(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3685, loss_cls=0.0622, loss_bbox=0.4438, matched_ious=0.5999, loss_iou=0.0839, loss_iou_reg=0.1925, d_time=0.03(0.01), f_time=1.59(1.44), b_time=1.63(1.45)  Time cost: 1:30:03/03:27 [24:48:18/6:17:25]  Acc_iter 61650       Data time: 0.03(0.01)  Forward time: 1.59(1.44)  Batch time: 1.63(1.45)
2025-09-04 10:05:17,794   INFO  Train:   16/20 ( 80%) [3769/3862 ( 98%)]  Loss: 0.9339 (1.15)  LR: 2.527e-04  Grad: 33.1616  max=1.3492(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3328(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3760, loss_cls=0.0626, loss_bbox=0.4535, matched_ious=0.5992, loss_iou=0.0834, loss_iou_reg=0.1896, d_time=0.01(0.01), f_time=1.49(1.44), b_time=1.50(1.45)  Time cost: 1:31:13/02:15 [24:49:28/6:16:05]  Acc_iter 61700       Data time: 0.01(0.01)  Forward time: 1.49(1.44)  Batch time: 1.50(1.45)
2025-09-04 10:06:29,143   INFO  Train:   16/20 ( 80%) [3819/3862 ( 99%)]  Loss: 1.288 (1.15)  LR: 2.513e-04  Grad: 33.1700  max=1.3526(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3338(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3726, loss_cls=0.0620, loss_bbox=0.4427, matched_ious=0.5991, loss_iou=0.0831, loss_iou_reg=0.1917, d_time=0.00(0.01), f_time=1.40(1.44), b_time=1.40(1.45)  Time cost: 1:32:25/01:02 [24:50:40/6:14:47]  Acc_iter 61750       Data time: 0.00(0.01)  Forward time: 1.40(1.44)  Batch time: 1.40(1.45)
2025-09-04 10:07:30,593   INFO  Train:   16/20 ( 80%) [3861/3862 (100%)]  Loss: 1.319 (1.15)  LR: 2.500e-04  Grad: 33.1602  max=1.3519(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3324(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3675, loss_cls=0.0624, loss_bbox=0.4442, matched_ious=0.5961, loss_iou=0.0839, loss_iou_reg=0.1940, d_time=0.00(0.01), f_time=1.50(1.44), b_time=1.50(1.45)  Time cost: 1:33:26/00:01 [24:51:41/6:13:48]  Acc_iter 61792       Data time: 0.00(0.01)  Forward time: 1.50(1.44)  Batch time: 1.50(1.45)

                                               [Aepochs:  80%|████████  | 16/20 [24:51:42<6:14:00, 5610.18s/it]epochs:  80%|████████  | 16/20 [24:51:42<6:14:00, 5610.19s/it]epochs:  80%|████████  | 16/20 [24:51:42<6:14:00, 5610.21s/it]epochs:  80%|████████  | 16/20 [24:51:42<6:14:00, 5610.21s/it]epochs:  80%|████████  | 16/20 [24:51:42<6:14:00, 5610.19s/it]epochs:  80%|████████  | 16/20 [24:51:42<6:14:00, 5610.19s/it]epochs:  80%|████████  | 16/20 [24:51:42<6:14:00, 5610.20s/it]epochs:  80%|████████  | 16/20 [24:51:42<6:14:00, 5610.20s/it]2025-09-04 10:07:31,085   INFO  Disable augmentations: ['gt_sampling']

train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-04 10:07:35,935   INFO  Train:   17/20 ( 85%) [   0/3862 (  0%)]  Loss: 1.221 (1.22)  LR: 2.500e-04  Grad: 33.1773  max=1.3542(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3310(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4805, loss_cls=0.1363, loss_bbox=0.3264, matched_ious=0.6008, loss_iou=0.0858, loss_iou_reg=0.1924, d_time=1.47(1.47), f_time=2.06(2.06), b_time=3.52(3.52)  Time cost: 00:03/3:22:28 [24:51:47/13:29:55]  Acc_iter 61793       Data time: 1.47(1.47)  Forward time: 2.06(2.06)  Batch time: 3.52(3.52)
2025-09-04 10:07:45,684   INFO  Train:   17/20 ( 85%) [   7/3862 (  0%)]  Loss: 1.206 (1.15)  LR: 2.498e-04  Grad: 33.1183  max=1.3590(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3274(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.4096, loss_cls=0.0876, loss_bbox=0.3500, matched_ious=0.5791, loss_iou=0.0920, loss_iou_reg=0.1983, d_time=0.01(0.19), f_time=1.31(1.47), b_time=1.32(1.66)  Time cost: 00:12/1:43:44 [24:51:56/6:55:30]  Acc_iter 61800       Data time: 0.01(0.19)  Forward time: 1.31(1.47)  Batch time: 1.32(1.66)
2025-09-04 10:08:53,936   INFO  Train:   17/20 ( 85%) [  57/3862 (  1%)]  Loss: 0.9640 (1.12)  LR: 2.483e-04  Grad: 32.6594  max=1.3347(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3086(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3733, loss_cls=0.0711, loss_bbox=0.3834, matched_ious=0.5943, loss_iou=0.0877, loss_iou_reg=0.1999, d_time=0.00(0.03), f_time=1.33(1.37), b_time=1.34(1.41)  Time cost: 01:21/1:28:44 [24:53:05/5:58:58]  Acc_iter 61850       Data time: 0.00(0.03)  Forward time: 1.33(1.37)  Batch time: 1.34(1.41)
2025-09-04 10:10:00,672   INFO  Train:   17/20 ( 85%) [ 107/3862 (  3%)]  Loss: 0.9592 (1.10)  LR: 2.469e-04  Grad: 32.7029  max=1.3350(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3105(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3626, loss_cls=0.0674, loss_bbox=0.3577, matched_ious=0.6075, loss_iou=0.0864, loss_iou_reg=0.1961, d_time=0.00(0.02), f_time=1.37(1.35), b_time=1.38(1.37)  Time cost: 02:27/1:25:42 [24:54:11/5:50:09]  Acc_iter 61900       Data time: 0.00(0.02)  Forward time: 1.37(1.35)  Batch time: 1.38(1.37)
2025-09-04 10:11:07,975   INFO  Train:   17/20 ( 85%) [ 157/3862 (  4%)]  Loss: 1.221 (1.10)  LR: 2.454e-04  Grad: 32.7191  max=1.3351(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3121(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3658, loss_cls=0.0689, loss_bbox=0.3803, matched_ious=0.6006, loss_iou=0.0851, loss_iou_reg=0.1957, d_time=0.01(0.02), f_time=1.35(1.35), b_time=1.36(1.36)  Time cost: 03:35/1:24:06 [24:55:19/5:47:07]  Acc_iter 61950       Data time: 0.01(0.02)  Forward time: 1.35(1.35)  Batch time: 1.36(1.36)
2025-09-04 10:12:14,734   INFO  Train:   17/20 ( 85%) [ 207/3862 (  5%)]  Loss: 1.040 (1.10)  LR: 2.440e-04  Grad: 32.7110  max=1.3347(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3153(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3915, loss_cls=0.0719, loss_bbox=0.3745, matched_ious=0.5988, loss_iou=0.0859, loss_iou_reg=0.1984, d_time=0.00(0.01), f_time=1.32(1.34), b_time=1.33(1.36)  Time cost: 04:41/1:22:34 [24:56:25/5:44:20]  Acc_iter 62000       Data time: 0.00(0.01)  Forward time: 1.32(1.34)  Batch time: 1.33(1.36)
2025-09-04 10:13:22,769   INFO  Train:   17/20 ( 85%) [ 257/3862 (  7%)]  Loss: 1.202 (1.10)  LR: 2.425e-04  Grad: 32.7195  max=1.3407(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3192(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3705, loss_cls=0.0698, loss_bbox=0.3579, matched_ious=0.6014, loss_iou=0.0850, loss_iou_reg=0.1959, d_time=0.00(0.01), f_time=1.30(1.35), b_time=1.31(1.36)  Time cost: 05:50/1:21:30 [24:57:33/5:43:28]  Acc_iter 62050       Data time: 0.00(0.01)  Forward time: 1.30(1.35)  Batch time: 1.31(1.36)
2025-09-04 10:14:29,295   INFO  Train:   17/20 ( 85%) [ 307/3862 (  8%)]  Loss: 1.379 (1.10)  LR: 2.411e-04  Grad: 32.7665  max=1.3390(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3178(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3676, loss_cls=0.0696, loss_bbox=0.3751, matched_ious=0.6010, loss_iou=0.0845, loss_iou_reg=0.1952, d_time=0.00(0.01), f_time=1.58(1.34), b_time=1.59(1.35)  Time cost: 06:56/1:20:07 [24:58:40/5:41:15]  Acc_iter 62100       Data time: 0.00(0.01)  Forward time: 1.58(1.34)  Batch time: 1.59(1.35)
2025-09-04 10:15:36,614   INFO  Train:   17/20 ( 85%) [ 357/3862 (  9%)]  Loss: 0.9165 (1.10)  LR: 2.396e-04  Grad: 32.7118  max=1.3337(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3112(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3802, loss_cls=0.0705, loss_bbox=0.3704, matched_ious=0.6011, loss_iou=0.0852, loss_iou_reg=0.1956, d_time=0.00(0.01), f_time=1.35(1.34), b_time=1.36(1.35)  Time cost: 08:03/1:18:57 [24:59:47/5:39:55]  Acc_iter 62150       Data time: 0.00(0.01)  Forward time: 1.35(1.34)  Batch time: 1.36(1.35)
2025-09-04 10:16:44,228   INFO  Train:   17/20 ( 85%) [ 407/3862 ( 11%)]  Loss: 1.178 (1.10)  LR: 2.382e-04  Grad: 32.7517  max=1.3425(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3137(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3746, loss_cls=0.0691, loss_bbox=0.3838, matched_ious=0.6076, loss_iou=0.0867, loss_iou_reg=0.1940, d_time=0.01(0.01), f_time=1.27(1.34), b_time=1.28(1.35)  Time cost: 09:11/1:17:49 [25:00:55/5:38:49]  Acc_iter 62200       Data time: 0.01(0.01)  Forward time: 1.27(1.34)  Batch time: 1.28(1.35)
2025-09-04 10:17:52,338   INFO  Train:   17/20 ( 85%) [ 457/3862 ( 12%)]  Loss: 1.280 (1.10)  LR: 2.367e-04  Grad: 32.7732  max=1.3379(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3156(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3532, loss_cls=0.0678, loss_bbox=0.3738, matched_ious=0.6020, loss_iou=0.0867, loss_iou_reg=0.1932, d_time=0.00(0.01), f_time=1.30(1.34), b_time=1.30(1.35)  Time cost: 10:19/1:16:46 [25:02:03/5:37:59]  Acc_iter 62250       Data time: 0.00(0.01)  Forward time: 1.30(1.34)  Batch time: 1.30(1.35)
2025-09-04 10:18:59,539   INFO  Train:   17/20 ( 85%) [ 507/3862 ( 13%)]  Loss: 1.185 (1.10)  LR: 2.353e-04  Grad: 32.7903  max=1.3392(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3210(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3689, loss_cls=0.0680, loss_bbox=0.3808, matched_ious=0.5987, loss_iou=0.0852, loss_iou_reg=0.1955, d_time=0.00(0.01), f_time=1.36(1.34), b_time=1.36(1.35)  Time cost: 11:26/1:15:35 [25:03:10/5:36:38]  Acc_iter 62300       Data time: 0.00(0.01)  Forward time: 1.36(1.34)  Batch time: 1.36(1.35)
2025-09-04 10:20:07,369   INFO  Train:   17/20 ( 85%) [ 557/3862 ( 14%)]  Loss: 1.056 (1.10)  LR: 2.338e-04  Grad: 32.8290  max=1.3343(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3259(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3728, loss_cls=0.0670, loss_bbox=0.3786, matched_ious=0.5951, loss_iou=0.0858, loss_iou_reg=0.1958, d_time=0.00(0.01), f_time=1.56(1.34), b_time=1.56(1.35)  Time cost: 12:34/1:14:29 [25:04:18/5:35:37]  Acc_iter 62350       Data time: 0.00(0.01)  Forward time: 1.56(1.34)  Batch time: 1.56(1.35)
2025-09-04 10:21:15,417   INFO  Train:   17/20 ( 85%) [ 607/3862 ( 16%)]  Loss: 1.444 (1.10)  LR: 2.324e-04  Grad: 32.7723  max=1.3322(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3245(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3951, loss_cls=0.0703, loss_bbox=0.3878, matched_ious=0.5967, loss_iou=0.0880, loss_iou_reg=0.1999, d_time=0.01(0.01), f_time=1.31(1.35), b_time=1.32(1.35)  Time cost: 13:42/1:13:24 [25:05:26/5:34:40]  Acc_iter 62400       Data time: 0.01(0.01)  Forward time: 1.31(1.35)  Batch time: 1.32(1.35)
2025-09-04 10:22:23,341   INFO  Train:   17/20 ( 85%) [ 657/3862 ( 17%)]  Loss: 0.9405 (1.10)  LR: 2.310e-04  Grad: 32.8653  max=1.3399(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3317(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3693, loss_cls=0.0684, loss_bbox=0.3550, matched_ious=0.6096, loss_iou=0.0855, loss_iou_reg=0.1934, d_time=0.00(0.01), f_time=1.22(1.35), b_time=1.22(1.35)  Time cost: 14:50/1:12:17 [25:06:34/5:33:38]  Acc_iter 62450       Data time: 0.00(0.01)  Forward time: 1.22(1.35)  Batch time: 1.22(1.35)
2025-09-04 10:23:32,344   INFO  Train:   17/20 ( 85%) [ 707/3862 ( 18%)]  Loss: 1.150 (1.10)  LR: 2.295e-04  Grad: 32.9056  max=1.3327(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3330(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3693, loss_cls=0.0633, loss_bbox=0.3678, matched_ious=0.6089, loss_iou=0.0857, loss_iou_reg=0.1941, d_time=0.00(0.01), f_time=1.17(1.35), b_time=1.18(1.36)  Time cost: 15:59/1:11:16 [25:07:43/5:32:58]  Acc_iter 62500       Data time: 0.00(0.01)  Forward time: 1.17(1.35)  Batch time: 1.18(1.36)
2025-09-04 10:24:40,157   INFO  Train:   17/20 ( 85%) [ 757/3862 ( 20%)]  Loss: 1.283 (1.10)  LR: 2.281e-04  Grad: 32.8809  max=1.3350(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3344(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3841, loss_cls=0.0672, loss_bbox=0.3761, matched_ious=0.5966, loss_iou=0.0872, loss_iou_reg=0.1979, d_time=0.00(0.01), f_time=1.21(1.35), b_time=1.22(1.36)  Time cost: 17:07/1:10:08 [25:08:51/5:31:52]  Acc_iter 62550       Data time: 0.00(0.01)  Forward time: 1.21(1.35)  Batch time: 1.22(1.36)
2025-09-04 10:25:48,182   INFO  Train:   17/20 ( 85%) [ 807/3862 ( 21%)]  Loss: 1.395 (1.10)  LR: 2.267e-04  Grad: 32.8561  max=1.3418(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3381(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3537, loss_cls=0.0660, loss_bbox=0.3792, matched_ious=0.5964, loss_iou=0.0875, loss_iou_reg=0.2006, d_time=0.00(0.01), f_time=1.29(1.35), b_time=1.29(1.36)  Time cost: 18:15/1:09:01 [25:09:59/5:30:48]  Acc_iter 62600       Data time: 0.00(0.01)  Forward time: 1.29(1.35)  Batch time: 1.29(1.36)
2025-09-04 10:26:55,828   INFO  Train:   17/20 ( 85%) [ 857/3862 ( 22%)]  Loss: 0.7546 (1.10)  LR: 2.253e-04  Grad: 32.8951  max=1.3395(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3373(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3684, loss_cls=0.0652, loss_bbox=0.3772, matched_ious=0.6009, loss_iou=0.0867, loss_iou_reg=0.1950, d_time=0.02(0.01), f_time=1.27(1.35), b_time=1.29(1.36)  Time cost: 19:23/1:07:53 [25:11:06/5:29:38]  Acc_iter 62650       Data time: 0.02(0.01)  Forward time: 1.27(1.35)  Batch time: 1.29(1.36)
2025-09-04 10:28:03,837   INFO  Train:   17/20 ( 85%) [ 907/3862 ( 23%)]  Loss: 1.026 (1.09)  LR: 2.239e-04  Grad: 32.9194  max=1.3407(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3422(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3482, loss_cls=0.0650, loss_bbox=0.3496, matched_ious=0.6042, loss_iou=0.0873, loss_iou_reg=0.1973, d_time=0.00(0.01), f_time=1.31(1.35), b_time=1.31(1.36)  Time cost: 20:31/1:06:46 [25:12:14/5:28:34]  Acc_iter 62700       Data time: 0.00(0.01)  Forward time: 1.31(1.35)  Batch time: 1.31(1.36)
2025-09-04 10:29:12,549   INFO  Train:   17/20 ( 85%) [ 957/3862 ( 25%)]  Loss: 1.217 (1.09)  LR: 2.225e-04  Grad: 32.8998  max=1.3468(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3416(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3665, loss_cls=0.0663, loss_bbox=0.3896, matched_ious=0.6059, loss_iou=0.0869, loss_iou_reg=0.1965, d_time=0.01(0.01), f_time=1.31(1.35), b_time=1.32(1.36)  Time cost: 21:39/1:05:41 [25:13:23/5:27:40]  Acc_iter 62750       Data time: 0.01(0.01)  Forward time: 1.31(1.35)  Batch time: 1.32(1.36)
2025-09-04 10:30:20,577   INFO  Train:   17/20 ( 85%) [1007/3862 ( 26%)]  Loss: 1.225 (1.10)  LR: 2.211e-04  Grad: 32.9669  max=1.3479(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3423(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3660, loss_cls=0.0679, loss_bbox=0.3848, matched_ious=0.6017, loss_iou=0.0857, loss_iou_reg=0.1977, d_time=0.00(0.01), f_time=1.35(1.35), b_time=1.36(1.36)  Time cost: 22:47/1:04:34 [25:14:31/5:26:35]  Acc_iter 62800       Data time: 0.00(0.01)  Forward time: 1.35(1.35)  Batch time: 1.36(1.36)
2025-09-04 10:31:27,973   INFO  Train:   17/20 ( 85%) [1057/3862 ( 27%)]  Loss: 1.011 (1.09)  LR: 2.196e-04  Grad: 32.9420  max=1.3467(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3397(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3470, loss_cls=0.0648, loss_bbox=0.3677, matched_ious=0.6017, loss_iou=0.0844, loss_iou_reg=0.1959, d_time=0.00(0.01), f_time=1.33(1.35), b_time=1.33(1.36)  Time cost: 23:55/1:03:25 [25:15:39/5:25:21]  Acc_iter 62850       Data time: 0.00(0.01)  Forward time: 1.33(1.35)  Batch time: 1.33(1.36)
2025-09-04 10:32:36,802   INFO  Train:   17/20 ( 85%) [1107/3862 ( 29%)]  Loss: 0.8655 (1.09)  LR: 2.182e-04  Grad: 32.9521  max=1.3498(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3421(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3547, loss_cls=0.0657, loss_bbox=0.3711, matched_ious=0.6032, loss_iou=0.0838, loss_iou_reg=0.1940, d_time=0.00(0.01), f_time=1.47(1.35), b_time=1.47(1.36)  Time cost: 25:04/1:02:19 [25:16:47/5:24:26]  Acc_iter 62900       Data time: 0.00(0.01)  Forward time: 1.47(1.35)  Batch time: 1.47(1.36)
2025-09-04 10:33:44,654   INFO  Train:   17/20 ( 85%) [1157/3862 ( 30%)]  Loss: 1.574 (1.09)  LR: 2.168e-04  Grad: 33.0064  max=1.3491(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3435(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3633, loss_cls=0.0649, loss_bbox=0.3489, matched_ious=0.6134, loss_iou=0.0837, loss_iou_reg=0.1895, d_time=0.00(0.01), f_time=1.39(1.35), b_time=1.39(1.36)  Time cost: 26:11/1:01:11 [25:17:55/5:23:18]  Acc_iter 62950       Data time: 0.00(0.01)  Forward time: 1.39(1.35)  Batch time: 1.39(1.36)
2025-09-04 10:34:52,505   INFO  Train:   17/20 ( 85%) [1207/3862 ( 31%)]  Loss: 0.9202 (1.09)  LR: 2.155e-04  Grad: 33.0115  max=1.3434(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3415(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3387, loss_cls=0.0642, loss_bbox=0.3823, matched_ious=0.6026, loss_iou=0.0885, loss_iou_reg=0.1985, d_time=0.00(0.01), f_time=1.36(1.35), b_time=1.36(1.36)  Time cost: 27:19/1:00:03 [25:19:03/5:22:10]  Acc_iter 63000       Data time: 0.00(0.01)  Forward time: 1.36(1.35)  Batch time: 1.36(1.36)
2025-09-04 10:35:59,757   INFO  Train:   17/20 ( 85%) [1257/3862 ( 33%)]  Loss: 1.029 (1.09)  LR: 2.141e-04  Grad: 33.0516  max=1.3416(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3433(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3484, loss_cls=0.0624, loss_bbox=0.3528, matched_ious=0.6042, loss_iou=0.0854, loss_iou_reg=0.1960, d_time=0.01(0.01), f_time=1.34(1.35), b_time=1.35(1.36)  Time cost: 28:26/58:54 [25:20:10/5:20:55]  Acc_iter 63050       Data time: 0.01(0.01)  Forward time: 1.34(1.35)  Batch time: 1.35(1.36)
2025-09-04 10:37:08,460   INFO  Train:   17/20 ( 85%) [1307/3862 ( 34%)]  Loss: 1.457 (1.09)  LR: 2.127e-04  Grad: 33.0178  max=1.3413(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3468(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3745, loss_cls=0.0682, loss_bbox=0.3541, matched_ious=0.6090, loss_iou=0.0854, loss_iou_reg=0.1940, d_time=0.00(0.01), f_time=1.38(1.35), b_time=1.38(1.36)  Time cost: 29:35/57:48 [25:21:19/5:19:57]  Acc_iter 63100       Data time: 0.00(0.01)  Forward time: 1.38(1.35)  Batch time: 1.38(1.36)
2025-09-04 10:38:15,674   INFO  Train:   17/20 ( 85%) [1357/3862 ( 35%)]  Loss: 0.8275 (1.09)  LR: 2.113e-04  Grad: 33.0149  max=1.3470(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.3539(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3424, loss_cls=0.0631, loss_bbox=0.3549, matched_ious=0.6066, loss_iou=0.0839, loss_iou_reg=0.1955, d_time=0.00(0.01), f_time=1.27(1.35), b_time=1.28(1.36)  Time cost: 30:42/56:39 [25:22:26/5:18:42]  Acc_iter 63150       Data time: 0.00(0.01)  Forward time: 1.27(1.35)  Batch time: 1.28(1.36)
2025-09-04 10:39:22,913   INFO  Train:   17/20 ( 85%) [1407/3862 ( 36%)]  Loss: 1.253 (1.09)  LR: 2.099e-04  Grad: 25.2872  max=1.0337(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0302(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3662, loss_cls=0.0685, loss_bbox=0.3631, matched_ious=0.6082, loss_iou=0.0874, loss_iou_reg=0.1952, d_time=0.01(0.01), f_time=1.65(1.35), b_time=1.66(1.36)  Time cost: 31:50/55:30 [25:23:34/5:17:28]  Acc_iter 63200       Data time: 0.01(0.01)  Forward time: 1.65(1.35)  Batch time: 1.66(1.36)
2025-09-04 10:40:29,832   INFO  Train:   17/20 ( 85%) [1457/3862 ( 38%)]  Loss: 1.121 (1.09)  LR: 2.085e-04  Grad: 25.3503  max=1.0377(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0362(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3785, loss_cls=0.0683, loss_bbox=0.3870, matched_ious=0.6025, loss_iou=0.0863, loss_iou_reg=0.1952, d_time=0.00(0.01), f_time=1.32(1.35), b_time=1.32(1.36)  Time cost: 32:57/54:21 [25:24:40/5:16:11]  Acc_iter 63250       Data time: 0.00(0.01)  Forward time: 1.32(1.35)  Batch time: 1.32(1.36)
2025-09-04 10:41:37,050   INFO  Train:   17/20 ( 85%) [1507/3862 ( 39%)]  Loss: 2.033 (1.09)  LR: 2.072e-04  Grad: 25.3784  max=1.0381(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0351(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3678, loss_cls=0.0665, loss_bbox=0.3852, matched_ious=0.6073, loss_iou=0.0860, loss_iou_reg=0.1944, d_time=0.00(0.01), f_time=1.36(1.35), b_time=1.36(1.36)  Time cost: 34:04/53:12 [25:25:48/5:14:58]  Acc_iter 63300       Data time: 0.00(0.01)  Forward time: 1.36(1.35)  Batch time: 1.36(1.36)
2025-09-04 10:42:45,539   INFO  Train:   17/20 ( 85%) [1557/3862 ( 40%)]  Loss: 1.031 (1.09)  LR: 2.058e-04  Grad: 25.4062  max=1.0407(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0335(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3642, loss_cls=0.0659, loss_bbox=0.3602, matched_ious=0.6066, loss_iou=0.0838, loss_iou_reg=0.1934, d_time=0.00(0.01), f_time=1.35(1.35), b_time=1.35(1.36)  Time cost: 35:12/52:05 [25:26:56/5:13:57]  Acc_iter 63350       Data time: 0.00(0.01)  Forward time: 1.35(1.35)  Batch time: 1.35(1.36)
2025-09-04 10:43:52,763   INFO  Train:   17/20 ( 85%) [1607/3862 ( 42%)]  Loss: 1.231 (1.09)  LR: 2.044e-04  Grad: 25.4116  max=1.0490(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0366(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3642, loss_cls=0.0662, loss_bbox=0.4056, matched_ious=0.6060, loss_iou=0.0846, loss_iou_reg=0.1965, d_time=0.01(0.01), f_time=1.31(1.35), b_time=1.32(1.36)  Time cost: 36:19/50:57 [25:28:03/5:12:44]  Acc_iter 63400       Data time: 0.01(0.01)  Forward time: 1.31(1.35)  Batch time: 1.32(1.36)
2025-09-04 10:45:00,571   INFO  Train:   17/20 ( 85%) [1657/3862 ( 43%)]  Loss: 1.008 (1.09)  LR: 2.030e-04  Grad: 25.4931  max=1.0452(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0408(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3492, loss_cls=0.0652, loss_bbox=0.3483, matched_ious=0.6078, loss_iou=0.0852, loss_iou_reg=0.1937, d_time=0.00(0.01), f_time=1.52(1.35), b_time=1.52(1.36)  Time cost: 37:27/49:49 [25:29:11/5:11:36]  Acc_iter 63450       Data time: 0.00(0.01)  Forward time: 1.52(1.35)  Batch time: 1.52(1.36)
2025-09-04 10:46:08,522   INFO  Train:   17/20 ( 85%) [1707/3862 ( 44%)]  Loss: 1.224 (1.09)  LR: 2.017e-04  Grad: 25.4812  max=1.0448(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0383(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3723, loss_cls=0.0682, loss_bbox=0.3690, matched_ious=0.6049, loss_iou=0.0864, loss_iou_reg=0.1951, d_time=0.01(0.01), f_time=1.29(1.35), b_time=1.29(1.36)  Time cost: 38:35/48:41 [25:30:19/5:10:30]  Acc_iter 63500       Data time: 0.01(0.01)  Forward time: 1.29(1.35)  Batch time: 1.29(1.36)
2025-09-04 10:47:15,957   INFO  Train:   17/20 ( 85%) [1757/3862 ( 45%)]  Loss: 1.026 (1.09)  LR: 2.003e-04  Grad: 25.4604  max=1.0447(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0380(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3804, loss_cls=0.0691, loss_bbox=0.3614, matched_ious=0.6004, loss_iou=0.0850, loss_iou_reg=0.1953, d_time=0.00(0.01), f_time=1.20(1.35), b_time=1.20(1.36)  Time cost: 39:43/47:33 [25:31:27/5:09:19]  Acc_iter 63550       Data time: 0.00(0.01)  Forward time: 1.20(1.35)  Batch time: 1.20(1.36)
2025-09-04 10:48:23,690   INFO  Train:   17/20 ( 85%) [1807/3862 ( 47%)]  Loss: 1.033 (1.08)  LR: 1.990e-04  Grad: 25.5596  max=1.0428(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0424(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3365, loss_cls=0.0623, loss_bbox=0.3582, matched_ious=0.6060, loss_iou=0.0827, loss_iou_reg=0.1942, d_time=0.00(0.01), f_time=1.37(1.35), b_time=1.38(1.36)  Time cost: 40:50/46:25 [25:32:34/5:08:11]  Acc_iter 63600       Data time: 0.00(0.01)  Forward time: 1.37(1.35)  Batch time: 1.38(1.36)
2025-09-04 10:49:31,645   INFO  Train:   17/20 ( 85%) [1857/3862 ( 48%)]  Loss: 0.9106 (1.08)  LR: 1.976e-04  Grad: 25.5797  max=1.0468(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0475(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3380, loss_cls=0.0632, loss_bbox=0.3885, matched_ious=0.6129, loss_iou=0.0847, loss_iou_reg=0.1931, d_time=0.01(0.01), f_time=1.32(1.35), b_time=1.33(1.36)  Time cost: 41:58/45:18 [25:33:42/5:07:05]  Acc_iter 63650       Data time: 0.01(0.01)  Forward time: 1.32(1.35)  Batch time: 1.33(1.36)
2025-09-04 10:50:38,736   INFO  Train:   17/20 ( 85%) [1907/3862 ( 49%)]  Loss: 1.064 (1.08)  LR: 1.963e-04  Grad: 25.5526  max=1.0416(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0468(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3505, loss_cls=0.0656, loss_bbox=0.3736, matched_ious=0.6038, loss_iou=0.0845, loss_iou_reg=0.1931, d_time=0.00(0.01), f_time=1.35(1.35), b_time=1.35(1.36)  Time cost: 43:05/44:09 [25:34:49/5:05:52]  Acc_iter 63700       Data time: 0.00(0.01)  Forward time: 1.35(1.35)  Batch time: 1.35(1.36)
2025-09-04 10:51:46,037   INFO  Train:   17/20 ( 85%) [1957/3862 ( 51%)]  Loss: 1.053 (1.08)  LR: 1.949e-04  Grad: 25.5439  max=1.0465(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0468(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3483, loss_cls=0.0628, loss_bbox=0.3782, matched_ious=0.6060, loss_iou=0.0842, loss_iou_reg=0.1924, d_time=0.01(0.01), f_time=1.26(1.35), b_time=1.26(1.36)  Time cost: 44:13/43:01 [25:35:57/5:04:41]  Acc_iter 63750       Data time: 0.01(0.01)  Forward time: 1.26(1.35)  Batch time: 1.26(1.36)
2025-09-04 10:52:53,548   INFO  Train:   17/20 ( 85%) [2007/3862 ( 52%)]  Loss: 0.8257 (1.08)  LR: 1.936e-04  Grad: 25.5745  max=1.0485(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0466(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3681, loss_cls=0.0675, loss_bbox=0.3648, matched_ious=0.6115, loss_iou=0.0846, loss_iou_reg=0.1926, d_time=0.00(0.01), f_time=1.37(1.35), b_time=1.37(1.36)  Time cost: 45:20/41:53 [25:37:04/5:03:32]  Acc_iter 63800       Data time: 0.00(0.01)  Forward time: 1.37(1.35)  Batch time: 1.37(1.36)
2025-09-04 10:54:01,172   INFO  Train:   17/20 ( 85%) [2057/3862 ( 53%)]  Loss: 0.8357 (1.08)  LR: 1.923e-04  Grad: 25.5703  max=1.0457(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0443(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3540, loss_cls=0.0641, loss_bbox=0.3542, matched_ious=0.6043, loss_iou=0.0865, loss_iou_reg=0.1935, d_time=0.00(0.01), f_time=1.43(1.35), b_time=1.43(1.36)  Time cost: 46:28/40:45 [25:38:12/5:02:23]  Acc_iter 63850       Data time: 0.00(0.01)  Forward time: 1.43(1.35)  Batch time: 1.43(1.36)
2025-09-04 10:55:09,020   INFO  Train:   17/20 ( 85%) [2107/3862 ( 55%)]  Loss: 0.9170 (1.08)  LR: 1.909e-04  Grad: 25.5821  max=1.0410(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0499(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3364, loss_cls=0.0638, loss_bbox=0.3362, matched_ious=0.6058, loss_iou=0.0853, loss_iou_reg=0.1934, d_time=0.01(0.01), f_time=1.34(1.35), b_time=1.34(1.36)  Time cost: 47:36/39:37 [25:39:20/5:01:16]  Acc_iter 63900       Data time: 0.01(0.01)  Forward time: 1.34(1.35)  Batch time: 1.34(1.36)
2025-09-04 10:56:16,742   INFO  Train:   17/20 ( 85%) [2157/3862 ( 56%)]  Loss: 0.9547 (1.08)  LR: 1.896e-04  Grad: 25.5947  max=1.0437(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0474(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3497, loss_cls=0.0629, loss_bbox=0.3583, matched_ious=0.6023, loss_iou=0.0850, loss_iou_reg=0.1955, d_time=0.01(0.01), f_time=1.34(1.35), b_time=1.35(1.36)  Time cost: 48:43/38:30 [25:40:27/5:00:08]  Acc_iter 63950       Data time: 0.01(0.01)  Forward time: 1.34(1.35)  Batch time: 1.35(1.36)
2025-09-04 10:57:23,436   INFO  Train:   17/20 ( 85%) [2207/3862 ( 57%)]  Loss: 1.239 (1.08)  LR: 1.883e-04  Grad: 25.6241  max=1.0450(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0485(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3761, loss_cls=0.0711, loss_bbox=0.4113, matched_ious=0.6031, loss_iou=0.0849, loss_iou_reg=0.1940, d_time=0.00(0.01), f_time=1.40(1.35), b_time=1.40(1.35)  Time cost: 49:50/37:21 [25:41:34/4:58:54]  Acc_iter 64000       Data time: 0.00(0.01)  Forward time: 1.40(1.35)  Batch time: 1.40(1.35)
2025-09-04 10:58:31,369   INFO  Train:   17/20 ( 85%) [2257/3862 ( 58%)]  Loss: 0.9784 (1.08)  LR: 1.869e-04  Grad: 25.5785  max=1.0461(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0610(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3814, loss_cls=0.0700, loss_bbox=0.3683, matched_ious=0.6051, loss_iou=0.0852, loss_iou_reg=0.1940, d_time=0.02(0.01), f_time=1.41(1.35), b_time=1.43(1.35)  Time cost: 50:58/36:14 [25:42:42/4:57:48]  Acc_iter 64050       Data time: 0.02(0.01)  Forward time: 1.41(1.35)  Batch time: 1.43(1.35)
2025-09-04 10:59:38,947   INFO  Train:   17/20 ( 85%) [2307/3862 ( 60%)]  Loss: 1.050 (1.08)  LR: 1.856e-04  Grad: 25.6080  max=1.0398(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0530(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3620, loss_cls=0.0654, loss_bbox=0.3620, matched_ious=0.5953, loss_iou=0.0876, loss_iou_reg=0.1976, d_time=0.01(0.01), f_time=1.34(1.35), b_time=1.35(1.35)  Time cost: 52:06/35:06 [25:43:50/4:56:39]  Acc_iter 64100       Data time: 0.01(0.01)  Forward time: 1.34(1.35)  Batch time: 1.35(1.35)
2025-09-04 11:00:47,179   INFO  Train:   17/20 ( 85%) [2357/3862 ( 61%)]  Loss: 1.102 (1.08)  LR: 1.843e-04  Grad: 25.7342  max=1.0535(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0562(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3422, loss_cls=0.0612, loss_bbox=0.3458, matched_ious=0.6084, loss_iou=0.0848, loss_iou_reg=0.1905, d_time=0.01(0.01), f_time=1.32(1.35), b_time=1.32(1.35)  Time cost: 53:14/33:58 [25:44:58/4:55:34]  Acc_iter 64150       Data time: 0.01(0.01)  Forward time: 1.32(1.35)  Batch time: 1.32(1.35)
2025-09-04 11:01:54,439   INFO  Train:   17/20 ( 85%) [2407/3862 ( 62%)]  Loss: 1.013 (1.08)  LR: 1.830e-04  Grad: 25.6790  max=1.0455(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0508(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3695, loss_cls=0.0683, loss_bbox=0.3688, matched_ious=0.6052, loss_iou=0.0863, loss_iou_reg=0.1950, d_time=0.00(0.01), f_time=1.23(1.35), b_time=1.23(1.35)  Time cost: 54:21/32:50 [25:46:05/4:54:24]  Acc_iter 64200       Data time: 0.00(0.01)  Forward time: 1.23(1.35)  Batch time: 1.23(1.35)
2025-09-04 11:03:02,104   INFO  Train:   17/20 ( 85%) [2457/3862 ( 64%)]  Loss: 1.203 (1.08)  LR: 1.817e-04  Grad: 25.7095  max=1.0505(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0544(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3590, loss_cls=0.0641, loss_bbox=0.3615, matched_ious=0.6081, loss_iou=0.0868, loss_iou_reg=0.1943, d_time=0.00(0.01), f_time=1.49(1.35), b_time=1.50(1.35)  Time cost: 55:29/31:43 [25:47:13/4:53:16]  Acc_iter 64250       Data time: 0.00(0.01)  Forward time: 1.49(1.35)  Batch time: 1.50(1.35)
2025-09-04 11:04:09,467   INFO  Train:   17/20 ( 85%) [2507/3862 ( 65%)]  Loss: 0.8451 (1.08)  LR: 1.804e-04  Grad: 25.7480  max=1.0569(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0542(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3555, loss_cls=0.0676, loss_bbox=0.3506, matched_ious=0.6081, loss_iou=0.0854, loss_iou_reg=0.1938, d_time=0.01(0.01), f_time=1.31(1.35), b_time=1.32(1.35)  Time cost: 56:36/30:35 [25:48:20/4:52:06]  Acc_iter 64300       Data time: 0.01(0.01)  Forward time: 1.31(1.35)  Batch time: 1.32(1.35)
2025-09-04 11:05:17,700   INFO  Train:   17/20 ( 85%) [2557/3862 ( 66%)]  Loss: 1.087 (1.08)  LR: 1.791e-04  Grad: 25.7555  max=1.0587(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0540(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3456, loss_cls=0.0630, loss_bbox=0.3494, matched_ious=0.6070, loss_iou=0.0858, loss_iou_reg=0.1946, d_time=0.01(0.01), f_time=1.24(1.35), b_time=1.25(1.35)  Time cost: 57:44/29:27 [25:49:28/4:51:01]  Acc_iter 64350       Data time: 0.01(0.01)  Forward time: 1.24(1.35)  Batch time: 1.25(1.35)
2025-09-04 11:06:25,973   INFO  Train:   17/20 ( 85%) [2607/3862 ( 68%)]  Loss: 0.8728 (1.08)  LR: 1.778e-04  Grad: 25.7742  max=1.0639(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0509(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3609, loss_cls=0.0655, loss_bbox=0.3483, matched_ious=0.6050, loss_iou=0.0864, loss_iou_reg=0.1968, d_time=0.01(0.01), f_time=1.32(1.35), b_time=1.32(1.35)  Time cost: 58:53/28:20 [25:50:37/4:49:56]  Acc_iter 64400       Data time: 0.01(0.01)  Forward time: 1.32(1.35)  Batch time: 1.32(1.35)
2025-09-04 11:07:34,404   INFO  Train:   17/20 ( 85%) [2657/3862 ( 69%)]  Loss: 1.052 (1.08)  LR: 1.765e-04  Grad: 25.7710  max=1.0625(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0499(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3398, loss_cls=0.0622, loss_bbox=0.3323, matched_ious=0.6047, loss_iou=0.0858, loss_iou_reg=0.1958, d_time=0.03(0.01), f_time=1.49(1.35), b_time=1.52(1.36)  Time cost: 1:00:01/27:12 [25:51:45/4:48:52]  Acc_iter 64450       Data time: 0.03(0.01)  Forward time: 1.49(1.35)  Batch time: 1.52(1.36)
2025-09-04 11:08:42,129   INFO  Train:   17/20 ( 85%) [2707/3862 ( 70%)]  Loss: 0.8591 (1.08)  LR: 1.752e-04  Grad: 26.0083  max=1.0596(module.dense_head.decoder.self_attn.in_proj_weight)  min: -3.2438(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.3578, loss_cls=0.0636, loss_bbox=0.3632, matched_ious=0.6132, loss_iou=0.0849, loss_iou_reg=0.1902, d_time=0.01(0.01), f_time=1.25(1.35), b_time=1.26(1.36)  Time cost: 1:01:09/26:05 [25:52:53/4:47:44]  Acc_iter 64500       Data time: 0.01(0.01)  Forward time: 1.25(1.35)  Batch time: 1.26(1.36)
2025-09-04 11:09:49,753   INFO  Train:   17/20 ( 85%) [2757/3862 ( 71%)]  Loss: 1.108 (1.08)  LR: 1.739e-04  Grad: 25.8482  max=1.0616(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0573(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3453, loss_cls=0.0622, loss_bbox=0.3661, matched_ious=0.6101, loss_iou=0.0838, loss_iou_reg=0.1905, d_time=0.01(0.01), f_time=1.27(1.35), b_time=1.28(1.36)  Time cost: 1:02:16/24:57 [25:54:00/4:46:35]  Acc_iter 64550       Data time: 0.01(0.01)  Forward time: 1.27(1.35)  Batch time: 1.28(1.36)
2025-09-04 11:10:57,481   INFO  Train:   17/20 ( 85%) [2807/3862 ( 73%)]  Loss: 1.081 (1.08)  LR: 1.726e-04  Grad: 25.7972  max=1.0578(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0595(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3718, loss_cls=0.0678, loss_bbox=0.3605, matched_ious=0.6039, loss_iou=0.0855, loss_iou_reg=0.1928, d_time=0.00(0.01), f_time=1.39(1.35), b_time=1.40(1.36)  Time cost: 1:03:24/23:49 [25:55:08/4:45:27]  Acc_iter 64600       Data time: 0.00(0.01)  Forward time: 1.39(1.35)  Batch time: 1.40(1.36)
2025-09-04 11:12:06,392   INFO  Train:   17/20 ( 85%) [2857/3862 ( 74%)]  Loss: 1.339 (1.08)  LR: 1.713e-04  Grad: 25.8365  max=1.0656(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0631(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3819, loss_cls=0.0713, loss_bbox=0.3793, matched_ious=0.5999, loss_iou=0.0873, loss_iou_reg=0.1980, d_time=0.00(0.01), f_time=1.31(1.35), b_time=1.32(1.36)  Time cost: 1:04:33/22:42 [25:56:17/4:44:25]  Acc_iter 64650       Data time: 0.00(0.01)  Forward time: 1.31(1.35)  Batch time: 1.32(1.36)
2025-09-04 11:13:14,664   INFO  Train:   17/20 ( 85%) [2907/3862 ( 75%)]  Loss: 1.163 (1.08)  LR: 1.701e-04  Grad: 25.8345  max=1.0698(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0634(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3335, loss_cls=0.0619, loss_bbox=0.3693, matched_ious=0.6026, loss_iou=0.0848, loss_iou_reg=0.1974, d_time=0.00(0.01), f_time=1.35(1.35), b_time=1.36(1.36)  Time cost: 1:05:41/21:34 [25:57:25/4:43:19]  Acc_iter 64700       Data time: 0.00(0.01)  Forward time: 1.35(1.35)  Batch time: 1.36(1.36)
2025-09-04 11:14:23,412   INFO  Train:   17/20 ( 85%) [2957/3862 ( 77%)]  Loss: 1.310 (1.08)  LR: 1.688e-04  Grad: 25.8479  max=1.0635(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0669(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3622, loss_cls=0.0666, loss_bbox=0.3761, matched_ious=0.5991, loss_iou=0.0866, loss_iou_reg=0.1992, d_time=0.00(0.01), f_time=1.36(1.35), b_time=1.36(1.36)  Time cost: 1:06:50/20:27 [25:58:34/4:42:16]  Acc_iter 64750       Data time: 0.00(0.01)  Forward time: 1.36(1.35)  Batch time: 1.36(1.36)
2025-09-04 11:15:31,121   INFO  Train:   17/20 ( 85%) [3007/3862 ( 78%)]  Loss: 0.8487 (1.08)  LR: 1.675e-04  Grad: 25.9245  max=1.0585(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0619(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3354, loss_cls=0.0631, loss_bbox=0.3643, matched_ious=0.6153, loss_iou=0.0848, loss_iou_reg=0.1900, d_time=0.00(0.01), f_time=1.35(1.35), b_time=1.36(1.36)  Time cost: 1:07:58/19:19 [25:59:42/4:41:07]  Acc_iter 64800       Data time: 0.00(0.01)  Forward time: 1.35(1.35)  Batch time: 1.36(1.36)
2025-09-04 11:16:37,923   INFO  Train:   17/20 ( 85%) [3057/3862 ( 79%)]  Loss: 1.244 (1.08)  LR: 1.663e-04  Grad: 25.8840  max=1.0608(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0631(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3463, loss_cls=0.0637, loss_bbox=0.3638, matched_ious=0.6033, loss_iou=0.0859, loss_iou_reg=0.1963, d_time=0.01(0.01), f_time=1.27(1.35), b_time=1.28(1.36)  Time cost: 1:09:05/18:11 [26:00:49/4:39:56]  Acc_iter 64850       Data time: 0.01(0.01)  Forward time: 1.27(1.35)  Batch time: 1.28(1.36)
2025-09-04 11:17:45,670   INFO  Train:   17/20 ( 85%) [3107/3862 ( 80%)]  Loss: 0.9654 (1.08)  LR: 1.650e-04  Grad: 25.9018  max=1.0616(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0686(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3511, loss_cls=0.0639, loss_bbox=0.3441, matched_ious=0.6118, loss_iou=0.0849, loss_iou_reg=0.1910, d_time=0.00(0.01), f_time=1.35(1.35), b_time=1.35(1.36)  Time cost: 1:10:12/17:03 [26:01:56/4:38:48]  Acc_iter 64900       Data time: 0.00(0.01)  Forward time: 1.35(1.35)  Batch time: 1.35(1.36)
2025-09-04 11:18:54,143   INFO  Train:   17/20 ( 85%) [3157/3862 ( 82%)]  Loss: 0.9923 (1.07)  LR: 1.637e-04  Grad: 25.9028  max=1.0666(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0737(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3426, loss_cls=0.0615, loss_bbox=0.3438, matched_ious=0.6036, loss_iou=0.0865, loss_iou_reg=0.1962, d_time=0.00(0.01), f_time=1.35(1.35), b_time=1.36(1.36)  Time cost: 1:11:21/15:55 [26:03:05/4:37:43]  Acc_iter 64950       Data time: 0.00(0.01)  Forward time: 1.35(1.35)  Batch time: 1.36(1.36)
2025-09-04 11:20:02,229   INFO  Train:   17/20 ( 85%) [3207/3862 ( 83%)]  Loss: 1.177 (1.07)  LR: 1.625e-04  Grad: 25.9144  max=1.0687(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0792(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3651, loss_cls=0.0663, loss_bbox=0.3628, matched_ious=0.6135, loss_iou=0.0862, loss_iou_reg=0.1906, d_time=0.01(0.01), f_time=1.41(1.35), b_time=1.42(1.36)  Time cost: 1:12:29/14:48 [26:04:13/4:36:36]  Acc_iter 65000       Data time: 0.01(0.01)  Forward time: 1.41(1.35)  Batch time: 1.42(1.36)
2025-09-04 11:21:10,720   INFO  Train:   17/20 ( 85%) [3257/3862 ( 84%)]  Loss: 1.193 (1.07)  LR: 1.612e-04  Grad: 25.9097  max=1.0721(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0800(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3369, loss_cls=0.0611, loss_bbox=0.3458, matched_ious=0.6128, loss_iou=0.0859, loss_iou_reg=0.1940, d_time=0.01(0.01), f_time=1.24(1.35), b_time=1.24(1.36)  Time cost: 1:13:37/13:40 [26:05:21/4:35:31]  Acc_iter 65050       Data time: 0.01(0.01)  Forward time: 1.24(1.35)  Batch time: 1.24(1.36)
2025-09-04 11:22:18,347   INFO  Train:   17/20 ( 85%) [3307/3862 ( 86%)]  Loss: 0.9774 (1.07)  LR: 1.600e-04  Grad: 25.9468  max=1.0678(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0738(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3443, loss_cls=0.0637, loss_bbox=0.3329, matched_ious=0.6182, loss_iou=0.0847, loss_iou_reg=0.1905, d_time=0.00(0.01), f_time=1.25(1.35), b_time=1.25(1.36)  Time cost: 1:14:45/12:32 [26:06:29/4:34:22]  Acc_iter 65100       Data time: 0.00(0.01)  Forward time: 1.25(1.35)  Batch time: 1.25(1.36)
2025-09-04 11:23:27,015   INFO  Train:   17/20 ( 85%) [3357/3862 ( 87%)]  Loss: 0.9754 (1.07)  LR: 1.588e-04  Grad: 25.9456  max=1.0743(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0757(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3439, loss_cls=0.0625, loss_bbox=0.3478, matched_ious=0.6050, loss_iou=0.0857, loss_iou_reg=0.1953, d_time=0.00(0.01), f_time=1.33(1.35), b_time=1.33(1.36)  Time cost: 1:15:54/11:24 [26:07:38/4:33:18]  Acc_iter 65150       Data time: 0.00(0.01)  Forward time: 1.33(1.35)  Batch time: 1.33(1.36)
2025-09-04 11:24:35,435   INFO  Train:   17/20 ( 85%) [3407/3862 ( 88%)]  Loss: 0.8252 (1.07)  LR: 1.575e-04  Grad: 25.9558  max=1.0707(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0781(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3255, loss_cls=0.0602, loss_bbox=0.3485, matched_ious=0.6108, loss_iou=0.0880, loss_iou_reg=0.1924, d_time=0.01(0.01), f_time=1.38(1.35), b_time=1.39(1.36)  Time cost: 1:17:02/10:17 [26:08:46/4:32:12]  Acc_iter 65200       Data time: 0.01(0.01)  Forward time: 1.38(1.35)  Batch time: 1.39(1.36)
2025-09-04 11:25:43,672   INFO  Train:   17/20 ( 85%) [3457/3862 ( 90%)]  Loss: 0.8183 (1.07)  LR: 1.563e-04  Grad: 25.9889  max=1.0723(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0750(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3461, loss_cls=0.0633, loss_bbox=0.3685, matched_ious=0.6072, loss_iou=0.0848, loss_iou_reg=0.1958, d_time=0.01(0.01), f_time=1.28(1.35), b_time=1.30(1.36)  Time cost: 1:18:10/09:09 [26:09:54/4:31:06]  Acc_iter 65250       Data time: 0.01(0.01)  Forward time: 1.28(1.35)  Batch time: 1.30(1.36)
2025-09-04 11:26:51,642   INFO  Train:   17/20 ( 85%) [3507/3862 ( 91%)]  Loss: 1.018 (1.07)  LR: 1.551e-04  Grad: 26.0298  max=1.0751(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0648(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3468, loss_cls=0.0660, loss_bbox=0.3762, matched_ious=0.5900, loss_iou=0.0894, loss_iou_reg=0.2052, d_time=0.01(0.01), f_time=1.32(1.35), b_time=1.32(1.36)  Time cost: 1:19:18/08:01 [26:11:02/4:29:58]  Acc_iter 65300       Data time: 0.01(0.01)  Forward time: 1.32(1.35)  Batch time: 1.32(1.36)
2025-09-04 11:28:00,166   INFO  Train:   17/20 ( 85%) [3557/3862 ( 92%)]  Loss: 0.9659 (1.07)  LR: 1.538e-04  Grad: 26.0112  max=1.0749(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2092(module.vfe.pfn_layers.0.linear.weight)  NaN: False  loss_hm=0.3339, loss_cls=0.0615, loss_bbox=0.3759, matched_ious=0.6002, loss_iou=0.0869, loss_iou_reg=0.1981, d_time=0.00(0.01), f_time=1.54(1.35), b_time=1.55(1.36)  Time cost: 1:20:27/06:53 [26:12:11/4:28:53]  Acc_iter 65350       Data time: 0.00(0.01)  Forward time: 1.54(1.35)  Batch time: 1.55(1.36)
2025-09-04 11:29:07,234   INFO  Train:   17/20 ( 85%) [3607/3862 ( 93%)]  Loss: 1.394 (1.07)  LR: 1.526e-04  Grad: 26.0194  max=1.0742(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0783(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3667, loss_cls=0.0665, loss_bbox=0.3607, matched_ious=0.6122, loss_iou=0.0857, loss_iou_reg=0.1930, d_time=0.01(0.01), f_time=1.33(1.35), b_time=1.33(1.36)  Time cost: 1:21:34/05:45 [26:13:18/4:27:43]  Acc_iter 65400       Data time: 0.01(0.01)  Forward time: 1.33(1.35)  Batch time: 1.33(1.36)
2025-09-04 11:30:15,017   INFO  Train:   17/20 ( 85%) [3657/3862 ( 95%)]  Loss: 1.135 (1.07)  LR: 1.514e-04  Grad: 26.0545  max=1.0753(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0756(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3430, loss_cls=0.0625, loss_bbox=0.3563, matched_ious=0.6057, loss_iou=0.0864, loss_iou_reg=0.1932, d_time=0.00(0.01), f_time=1.28(1.35), b_time=1.28(1.36)  Time cost: 1:22:42/04:38 [26:14:26/4:26:35]  Acc_iter 65450       Data time: 0.00(0.01)  Forward time: 1.28(1.35)  Batch time: 1.28(1.36)
2025-09-04 11:31:23,179   INFO  Train:   17/20 ( 85%) [3707/3862 ( 96%)]  Loss: 1.239 (1.07)  LR: 1.502e-04  Grad: 26.0502  max=1.0793(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0870(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3516, loss_cls=0.0656, loss_bbox=0.3591, matched_ious=0.6058, loss_iou=0.0851, loss_iou_reg=0.1950, d_time=0.00(0.01), f_time=1.38(1.35), b_time=1.39(1.36)  Time cost: 1:23:50/03:30 [26:15:34/4:25:28]  Acc_iter 65500       Data time: 0.00(0.01)  Forward time: 1.38(1.35)  Batch time: 1.39(1.36)
2025-09-04 11:32:31,711   INFO  Train:   17/20 ( 85%) [3757/3862 ( 97%)]  Loss: 1.119 (1.07)  LR: 1.490e-04  Grad: 26.1032  max=1.0668(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0798(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3292, loss_cls=0.0608, loss_bbox=0.3520, matched_ious=0.6050, loss_iou=0.0850, loss_iou_reg=0.1947, d_time=0.01(0.01), f_time=1.57(1.35), b_time=1.58(1.36)  Time cost: 1:24:58/02:22 [26:16:42/4:24:22]  Acc_iter 65550       Data time: 0.01(0.01)  Forward time: 1.57(1.35)  Batch time: 1.58(1.36)
2025-09-04 11:33:39,717   INFO  Train:   17/20 ( 85%) [3807/3862 ( 99%)]  Loss: 1.013 (1.07)  LR: 1.478e-04  Grad: 26.0801  max=1.0743(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0769(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3695, loss_cls=0.0697, loss_bbox=0.4046, matched_ious=0.6038, loss_iou=0.0844, loss_iou_reg=0.1941, d_time=0.01(0.01), f_time=1.38(1.35), b_time=1.39(1.36)  Time cost: 1:26:06/01:14 [26:17:50/4:23:15]  Acc_iter 65600       Data time: 0.01(0.01)  Forward time: 1.38(1.35)  Batch time: 1.39(1.36)
2025-09-04 11:34:46,290   INFO  Train:   17/20 ( 85%) [3857/3862 (100%)]  Loss: 0.8848 (1.07)  LR: 1.466e-04  Grad: 26.1101  max=1.0715(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0772(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3293, loss_cls=0.0621, loss_bbox=0.3551, matched_ious=0.6089, loss_iou=0.0856, loss_iou_reg=0.1936, d_time=0.00(0.01), f_time=1.22(1.35), b_time=1.23(1.36)  Time cost: 1:27:13/00:06 [26:18:57/4:22:03]  Acc_iter 65650       Data time: 0.00(0.01)  Forward time: 1.22(1.35)  Batch time: 1.23(1.36)
2025-09-04 11:34:51,384   INFO  Train:   17/20 ( 85%) [3861/3862 (100%)]  Loss: 1.089 (1.07)  LR: 1.465e-04  Grad: 26.1132  max=1.0711(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0754(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3046, loss_cls=0.0538, loss_bbox=0.3378, matched_ious=0.6305, loss_iou=0.0862, loss_iou_reg=0.1972, d_time=0.00(0.01), f_time=1.26(1.35), b_time=1.27(1.36)  Time cost: 1:27:18/00:01 [26:19:02/4:21:57]  Acc_iter 65654       Data time: 0.00(0.01)  Forward time: 1.26(1.35)  Batch time: 1.27(1.36)

                                               [Aepochs:  85%|████████▌ | 17/20 [26:19:02<4:34:57, 5499.09s/it]epochs:  85%|████████▌ | 17/20 [26:19:02<4:34:57, 5499.10s/it]epochs:  85%|████████▌ | 17/20 [26:19:02<4:34:57, 5499.11s/it]epochs:  85%|████████▌ | 17/20 [26:19:02<4:34:57, 5499.09s/it]epochs:  85%|████████▌ | 17/20 [26:19:02<4:34:57, 5499.10s/it]epochs:  85%|████████▌ | 17/20 [26:19:02<4:34:57, 5499.10s/it]epochs:  85%|████████▌ | 17/20 [26:19:02<4:34:57, 5499.10s/it]epochs:  85%|████████▌ | 17/20 [26:19:03<4:34:57, 5499.10s/it]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-04 11:34:56,456   INFO  Train:   18/20 ( 90%) [   0/3862 (  0%)]  Loss: 1.094 (1.09)  LR: 1.465e-04  Grad: 26.1079  max=1.0732(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0743(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3892, loss_cls=0.0656, loss_bbox=0.3563, matched_ious=0.6089, loss_iou=0.0879, loss_iou_reg=0.1947, d_time=1.53(1.53), f_time=2.37(2.37), b_time=3.90(3.90)  Time cost: 00:03/3:57:05 [26:19:07/11:51:16]  Acc_iter 65655       Data time: 1.53(1.53)  Forward time: 2.37(2.37)  Batch time: 3.90(3.90)
2025-09-04 11:35:58,610   INFO  Train:   18/20 ( 90%) [  45/3862 (  1%)]  Loss: 0.8295 (1.09)  LR: 1.454e-04  Grad: 26.1150  max=1.0826(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0741(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3761, loss_cls=0.0640, loss_bbox=0.3676, matched_ious=0.6147, loss_iou=0.0860, loss_iou_reg=0.1933, d_time=0.00(0.04), f_time=1.33(1.40), b_time=1.34(1.44)  Time cost: 01:05/1:31:04 [26:20:09/4:35:21]  Acc_iter 65700       Data time: 0.00(0.04)  Forward time: 1.33(1.40)  Batch time: 1.34(1.44)
2025-09-04 11:37:06,327   INFO  Train:   18/20 ( 90%) [  95/3862 (  2%)]  Loss: 1.057 (1.07)  LR: 1.442e-04  Grad: 26.2127  max=1.0725(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0749(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3563, loss_cls=0.0645, loss_bbox=0.3565, matched_ious=0.6068, loss_iou=0.0861, loss_iou_reg=0.1907, d_time=0.00(0.02), f_time=1.29(1.37), b_time=1.29(1.39)  Time cost: 02:13/1:27:21 [26:21:17/4:26:27]  Acc_iter 65750       Data time: 0.00(0.02)  Forward time: 1.29(1.37)  Batch time: 1.29(1.39)
2025-09-04 11:38:14,460   INFO  Train:   18/20 ( 90%) [ 145/3862 (  4%)]  Loss: 1.199 (1.07)  LR: 1.430e-04  Grad: 26.1643  max=1.0723(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0726(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3585, loss_cls=0.0661, loss_bbox=0.3597, matched_ious=0.6075, loss_iou=0.0855, loss_iou_reg=0.1942, d_time=0.00(0.02), f_time=1.34(1.37), b_time=1.35(1.38)  Time cost: 03:21/1:25:35 [26:22:25/4:23:25]  Acc_iter 65800       Data time: 0.00(0.02)  Forward time: 1.34(1.37)  Batch time: 1.35(1.38)
2025-09-04 11:39:22,005   INFO  Train:   18/20 ( 90%) [ 195/3862 (  5%)]  Loss: 1.128 (1.07)  LR: 1.418e-04  Grad: 26.1684  max=1.0714(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0738(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3548, loss_cls=0.0641, loss_bbox=0.3652, matched_ious=0.6109, loss_iou=0.0842, loss_iou_reg=0.1910, d_time=0.00(0.01), f_time=1.28(1.36), b_time=1.29(1.37)  Time cost: 04:29/1:23:57 [26:23:33/4:20:47]  Acc_iter 65850       Data time: 0.00(0.01)  Forward time: 1.28(1.36)  Batch time: 1.29(1.37)
2025-09-04 11:40:30,488   INFO  Train:   18/20 ( 90%) [ 245/3862 (  6%)]  Loss: 0.9684 (1.06)  LR: 1.406e-04  Grad: 26.1196  max=1.0774(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0901(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3415, loss_cls=0.0609, loss_bbox=0.3599, matched_ious=0.6103, loss_iou=0.0858, loss_iou_reg=0.1911, d_time=0.01(0.01), f_time=1.64(1.36), b_time=1.65(1.37)  Time cost: 05:37/1:22:45 [26:24:41/4:19:29]  Acc_iter 65900       Data time: 0.01(0.01)  Forward time: 1.64(1.36)  Batch time: 1.65(1.37)
2025-09-04 11:41:38,590   INFO  Train:   18/20 ( 90%) [ 295/3862 (  8%)]  Loss: 1.164 (1.05)  LR: 1.395e-04  Grad: 26.1794  max=1.0747(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0806(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3342, loss_cls=0.0613, loss_bbox=0.3497, matched_ious=0.6072, loss_iou=0.0860, loss_iou_reg=0.1949, d_time=0.00(0.01), f_time=1.37(1.36), b_time=1.38(1.37)  Time cost: 06:45/1:21:30 [26:25:49/4:18:00]  Acc_iter 65950       Data time: 0.00(0.01)  Forward time: 1.37(1.36)  Batch time: 1.38(1.37)
2025-09-04 11:42:46,835   INFO  Train:   18/20 ( 90%) [ 345/3862 (  9%)]  Loss: 0.9144 (1.05)  LR: 1.383e-04  Grad: 26.1866  max=1.0734(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0796(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3380, loss_cls=0.0621, loss_bbox=0.3494, matched_ious=0.6070, loss_iou=0.0862, loss_iou_reg=0.1952, d_time=0.01(0.01), f_time=1.43(1.36), b_time=1.44(1.37)  Time cost: 07:54/1:20:18 [26:26:57/4:16:41]  Acc_iter 66000       Data time: 0.01(0.01)  Forward time: 1.43(1.36)  Batch time: 1.44(1.37)
2025-09-04 11:43:55,210   INFO  Train:   18/20 ( 90%) [ 395/3862 ( 10%)]  Loss: 1.182 (1.05)  LR: 1.371e-04  Grad: 26.2187  max=1.0772(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0741(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3569, loss_cls=0.0633, loss_bbox=0.3676, matched_ious=0.6130, loss_iou=0.0843, loss_iou_reg=0.1927, d_time=0.01(0.01), f_time=1.27(1.36), b_time=1.27(1.37)  Time cost: 09:02/1:19:09 [26:28:06/4:15:29]  Acc_iter 66050       Data time: 0.01(0.01)  Forward time: 1.27(1.36)  Batch time: 1.27(1.37)
2025-09-04 11:45:03,395   INFO  Train:   18/20 ( 90%) [ 445/3862 ( 12%)]  Loss: 1.020 (1.05)  LR: 1.360e-04  Grad: 26.2170  max=1.0763(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0789(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3491, loss_cls=0.0615, loss_bbox=0.3335, matched_ious=0.6132, loss_iou=0.0862, loss_iou_reg=0.1930, d_time=0.00(0.01), f_time=1.34(1.36), b_time=1.34(1.37)  Time cost: 10:10/1:17:58 [26:29:14/4:14:13]  Acc_iter 66100       Data time: 0.00(0.01)  Forward time: 1.34(1.36)  Batch time: 1.34(1.37)
2025-09-04 11:46:11,504   INFO  Train:   18/20 ( 90%) [ 495/3862 ( 13%)]  Loss: 0.9845 (1.05)  LR: 1.348e-04  Grad: 26.2495  max=1.0754(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0780(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3507, loss_cls=0.0608, loss_bbox=0.3609, matched_ious=0.6161, loss_iou=0.0860, loss_iou_reg=0.1931, d_time=0.00(0.01), f_time=1.39(1.36), b_time=1.40(1.37)  Time cost: 11:18/1:16:47 [26:30:22/4:12:57]  Acc_iter 66150       Data time: 0.00(0.01)  Forward time: 1.39(1.36)  Batch time: 1.40(1.37)
2025-09-04 11:47:18,807   INFO  Train:   18/20 ( 90%) [ 545/3862 ( 14%)]  Loss: 0.9650 (1.05)  LR: 1.336e-04  Grad: 26.2267  max=1.0741(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0927(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3224, loss_cls=0.0613, loss_bbox=0.3444, matched_ious=0.6144, loss_iou=0.0839, loss_iou_reg=0.1901, d_time=0.01(0.01), f_time=1.34(1.36), b_time=1.34(1.37)  Time cost: 12:26/1:15:32 [26:31:29/4:11:26]  Acc_iter 66200       Data time: 0.01(0.01)  Forward time: 1.34(1.36)  Batch time: 1.34(1.37)
2025-09-04 11:48:26,569   INFO  Train:   18/20 ( 90%) [ 595/3862 ( 15%)]  Loss: 0.9515 (1.05)  LR: 1.325e-04  Grad: 26.2617  max=1.0699(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0861(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3589, loss_cls=0.0639, loss_bbox=0.3589, matched_ious=0.6039, loss_iou=0.0870, loss_iou_reg=0.1963, d_time=0.00(0.01), f_time=1.32(1.36), b_time=1.32(1.37)  Time cost: 13:33/1:14:20 [26:32:37/4:10:07]  Acc_iter 66250       Data time: 0.00(0.01)  Forward time: 1.32(1.36)  Batch time: 1.32(1.37)
2025-09-04 11:49:34,707   INFO  Train:   18/20 ( 90%) [ 645/3862 ( 17%)]  Loss: 1.030 (1.05)  LR: 1.313e-04  Grad: 26.2557  max=1.0793(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0860(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3452, loss_cls=0.0635, loss_bbox=0.3493, matched_ious=0.6035, loss_iou=0.0871, loss_iou_reg=0.1957, d_time=0.00(0.01), f_time=1.34(1.36), b_time=1.35(1.37)  Time cost: 14:41/1:13:12 [26:33:45/4:08:57]  Acc_iter 66300       Data time: 0.00(0.01)  Forward time: 1.34(1.36)  Batch time: 1.35(1.37)
2025-09-04 11:50:43,471   INFO  Train:   18/20 ( 90%) [ 695/3862 ( 18%)]  Loss: 1.191 (1.05)  LR: 1.302e-04  Grad: 26.3506  max=1.0725(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0753(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3373, loss_cls=0.0620, loss_bbox=0.3653, matched_ious=0.6127, loss_iou=0.0854, loss_iou_reg=0.1902, d_time=0.00(0.01), f_time=1.25(1.36), b_time=1.25(1.37)  Time cost: 15:50/1:12:06 [26:34:54/4:07:56]  Acc_iter 66350       Data time: 0.00(0.01)  Forward time: 1.25(1.36)  Batch time: 1.25(1.37)
2025-09-04 11:51:53,082   INFO  Train:   18/20 ( 90%) [ 745/3862 ( 19%)]  Loss: 0.9195 (1.04)  LR: 1.291e-04  Grad: 26.3169  max=1.0788(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0785(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3343, loss_cls=0.0624, loss_bbox=0.3484, matched_ious=0.6020, loss_iou=0.0839, loss_iou_reg=0.1943, d_time=0.01(0.01), f_time=1.41(1.36), b_time=1.42(1.37)  Time cost: 17:00/1:11:03 [26:36:04/4:07:07]  Acc_iter 66400       Data time: 0.01(0.01)  Forward time: 1.41(1.36)  Batch time: 1.42(1.37)
2025-09-04 11:53:00,934   INFO  Train:   18/20 ( 90%) [ 795/3862 ( 21%)]  Loss: 1.058 (1.04)  LR: 1.279e-04  Grad: 26.3204  max=1.0812(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0810(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3264, loss_cls=0.0601, loss_bbox=0.3359, matched_ious=0.6157, loss_iou=0.0836, loss_iou_reg=0.1891, d_time=0.00(0.01), f_time=1.30(1.36), b_time=1.30(1.37)  Time cost: 18:08/1:09:52 [26:37:12/4:05:51]  Acc_iter 66450       Data time: 0.00(0.01)  Forward time: 1.30(1.36)  Batch time: 1.30(1.37)
2025-09-04 11:54:08,645   INFO  Train:   18/20 ( 90%) [ 845/3862 ( 22%)]  Loss: 1.212 (1.04)  LR: 1.268e-04  Grad: 26.3671  max=1.0845(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0811(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3460, loss_cls=0.0642, loss_bbox=0.3567, matched_ious=0.6098, loss_iou=0.0827, loss_iou_reg=0.1894, d_time=0.00(0.01), f_time=1.38(1.36), b_time=1.39(1.37)  Time cost: 19:15/1:08:42 [26:38:19/4:04:35]  Acc_iter 66500       Data time: 0.00(0.01)  Forward time: 1.38(1.36)  Batch time: 1.39(1.37)
2025-09-04 11:55:16,225   INFO  Train:   18/20 ( 90%) [ 895/3862 ( 23%)]  Loss: 1.052 (1.04)  LR: 1.257e-04  Grad: 26.3418  max=1.0841(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0914(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3283, loss_cls=0.0622, loss_bbox=0.3419, matched_ious=0.6162, loss_iou=0.0839, loss_iou_reg=0.1890, d_time=0.00(0.01), f_time=1.37(1.36), b_time=1.37(1.37)  Time cost: 20:23/1:07:31 [26:39:27/4:03:18]  Acc_iter 66550       Data time: 0.00(0.01)  Forward time: 1.37(1.36)  Batch time: 1.37(1.37)
2025-09-04 11:56:23,636   INFO  Train:   18/20 ( 90%) [ 945/3862 ( 24%)]  Loss: 1.191 (1.04)  LR: 1.245e-04  Grad: 26.3389  max=1.0802(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0992(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3647, loss_cls=0.0634, loss_bbox=0.3474, matched_ious=0.6044, loss_iou=0.0840, loss_iou_reg=0.1935, d_time=0.00(0.01), f_time=1.32(1.36), b_time=1.32(1.36)  Time cost: 21:30/1:06:20 [26:40:34/4:02:00]  Acc_iter 66600       Data time: 0.00(0.01)  Forward time: 1.32(1.36)  Batch time: 1.32(1.36)
2025-09-04 11:57:31,102   INFO  Train:   18/20 ( 90%) [ 995/3862 ( 26%)]  Loss: 1.227 (1.04)  LR: 1.234e-04  Grad: 26.3970  max=1.0886(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0833(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3376, loss_cls=0.0622, loss_bbox=0.3557, matched_ious=0.6133, loss_iou=0.0855, loss_iou_reg=0.1917, d_time=0.01(0.01), f_time=1.31(1.36), b_time=1.31(1.36)  Time cost: 22:38/1:05:10 [26:41:42/4:00:44]  Acc_iter 66650       Data time: 0.01(0.01)  Forward time: 1.31(1.36)  Batch time: 1.31(1.36)
2025-09-04 11:58:38,703   INFO  Train:   18/20 ( 90%) [1045/3862 ( 27%)]  Loss: 1.301 (1.04)  LR: 1.223e-04  Grad: 26.3923  max=1.0826(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0923(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3531, loss_cls=0.0617, loss_bbox=0.3710, matched_ious=0.6028, loss_iou=0.0856, loss_iou_reg=0.1959, d_time=0.00(0.01), f_time=1.63(1.36), b_time=1.64(1.36)  Time cost: 23:45/1:04:00 [26:42:49/3:59:29]  Acc_iter 66700       Data time: 0.00(0.01)  Forward time: 1.63(1.36)  Batch time: 1.64(1.36)
2025-09-04 11:59:46,368   INFO  Train:   18/20 ( 90%) [1095/3862 ( 28%)]  Loss: 1.362 (1.04)  LR: 1.212e-04  Grad: 26.3855  max=1.0808(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0988(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3452, loss_cls=0.0635, loss_bbox=0.3530, matched_ious=0.6129, loss_iou=0.0850, loss_iou_reg=0.1908, d_time=0.01(0.01), f_time=1.34(1.36), b_time=1.35(1.36)  Time cost: 24:53/1:02:50 [26:43:57/3:58:16]  Acc_iter 66750       Data time: 0.01(0.01)  Forward time: 1.34(1.36)  Batch time: 1.35(1.36)
2025-09-04 12:00:54,169   INFO  Train:   18/20 ( 90%) [1145/3862 ( 30%)]  Loss: 1.053 (1.04)  LR: 1.201e-04  Grad: 26.4209  max=1.0744(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0960(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3513, loss_cls=0.0653, loss_bbox=0.3600, matched_ious=0.6156, loss_iou=0.0846, loss_iou_reg=0.1905, d_time=0.01(0.01), f_time=1.23(1.36), b_time=1.23(1.36)  Time cost: 26:01/1:01:41 [26:45:05/3:57:05]  Acc_iter 66800       Data time: 0.01(0.01)  Forward time: 1.23(1.36)  Batch time: 1.23(1.36)
2025-09-04 12:02:02,254   INFO  Train:   18/20 ( 90%) [1195/3862 ( 31%)]  Loss: 1.205 (1.04)  LR: 1.190e-04  Grad: 26.4267  max=1.0761(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1054(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3641, loss_cls=0.0650, loss_bbox=0.3530, matched_ious=0.6150, loss_iou=0.0844, loss_iou_reg=0.1914, d_time=0.00(0.01), f_time=1.40(1.36), b_time=1.41(1.36)  Time cost: 27:09/1:00:33 [26:46:13/3:55:57]  Acc_iter 66850       Data time: 0.00(0.01)  Forward time: 1.40(1.36)  Batch time: 1.41(1.36)
2025-09-04 12:03:10,247   INFO  Train:   18/20 ( 90%) [1245/3862 ( 32%)]  Loss: 1.196 (1.04)  LR: 1.179e-04  Grad: 26.4383  max=1.0756(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1086(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3393, loss_cls=0.0614, loss_bbox=0.3581, matched_ious=0.6032, loss_iou=0.0864, loss_iou_reg=0.1935, d_time=0.00(0.01), f_time=1.52(1.36), b_time=1.52(1.36)  Time cost: 28:17/59:25 [26:47:21/3:54:48]  Acc_iter 66900       Data time: 0.00(0.01)  Forward time: 1.52(1.36)  Batch time: 1.52(1.36)
2025-09-04 12:04:17,389   INFO  Train:   18/20 ( 90%) [1295/3862 ( 34%)]  Loss: 1.010 (1.04)  LR: 1.168e-04  Grad: 26.4992  max=1.0741(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.0874(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3517, loss_cls=0.0657, loss_bbox=0.3798, matched_ious=0.6021, loss_iou=0.0861, loss_iou_reg=0.1974, d_time=0.00(0.01), f_time=1.25(1.35), b_time=1.26(1.36)  Time cost: 29:24/58:15 [26:48:28/3:53:32]  Acc_iter 66950       Data time: 0.00(0.01)  Forward time: 1.25(1.35)  Batch time: 1.26(1.36)
2025-09-04 12:05:25,078   INFO  Train:   18/20 ( 90%) [1345/3862 ( 35%)]  Loss: 0.8787 (1.04)  LR: 1.157e-04  Grad: 26.4402  max=1.0828(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1017(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3513, loss_cls=0.0615, loss_bbox=0.3541, matched_ious=0.6224, loss_iou=0.0819, loss_iou_reg=0.1862, d_time=0.00(0.01), f_time=1.24(1.35), b_time=1.25(1.36)  Time cost: 30:32/57:06 [26:49:36/3:52:21]  Acc_iter 67000       Data time: 0.00(0.01)  Forward time: 1.24(1.35)  Batch time: 1.25(1.36)
2025-09-04 12:06:32,615   INFO  Train:   18/20 ( 90%) [1395/3862 ( 36%)]  Loss: 1.075 (1.04)  LR: 1.147e-04  Grad: 26.4537  max=1.0789(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1057(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3577, loss_cls=0.0637, loss_bbox=0.3664, matched_ious=0.6052, loss_iou=0.0853, loss_iou_reg=0.1961, d_time=0.00(0.01), f_time=1.20(1.35), b_time=1.21(1.36)  Time cost: 31:39/55:57 [26:50:43/3:51:09]  Acc_iter 67050       Data time: 0.00(0.01)  Forward time: 1.20(1.35)  Batch time: 1.21(1.36)
2025-09-04 12:07:40,364   INFO  Train:   18/20 ( 90%) [1445/3862 ( 37%)]  Loss: 1.060 (1.04)  LR: 1.136e-04  Grad: 26.5224  max=1.0776(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1026(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3399, loss_cls=0.0647, loss_bbox=0.3413, matched_ious=0.6169, loss_iou=0.0834, loss_iou_reg=0.1877, d_time=0.00(0.01), f_time=1.41(1.35), b_time=1.42(1.36)  Time cost: 32:47/54:48 [26:51:51/3:49:59]  Acc_iter 67100       Data time: 0.00(0.01)  Forward time: 1.41(1.35)  Batch time: 1.42(1.36)
2025-09-04 12:08:49,235   INFO  Train:   18/20 ( 90%) [1495/3862 ( 39%)]  Loss: 0.8758 (1.04)  LR: 1.125e-04  Grad: 26.5468  max=1.0755(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1012(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3268, loss_cls=0.0583, loss_bbox=0.3452, matched_ious=0.6187, loss_iou=0.0851, loss_iou_reg=0.1892, d_time=0.01(0.01), f_time=1.33(1.35), b_time=1.34(1.36)  Time cost: 33:56/53:42 [26:53:00/3:48:56]  Acc_iter 67150       Data time: 0.01(0.01)  Forward time: 1.33(1.35)  Batch time: 1.34(1.36)
2025-09-04 12:09:57,470   INFO  Train:   18/20 ( 90%) [1545/3862 ( 40%)]  Loss: 1.443 (1.04)  LR: 1.114e-04  Grad: 26.5013  max=1.0819(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1176(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3601, loss_cls=0.0655, loss_bbox=0.3660, matched_ious=0.6061, loss_iou=0.0855, loss_iou_reg=0.1936, d_time=0.00(0.01), f_time=1.30(1.35), b_time=1.30(1.36)  Time cost: 35:04/52:34 [26:54:08/3:47:49]  Acc_iter 67200       Data time: 0.00(0.01)  Forward time: 1.30(1.35)  Batch time: 1.30(1.36)
2025-09-04 12:11:05,498   INFO  Train:   18/20 ( 90%) [1595/3862 ( 41%)]  Loss: 0.9779 (1.04)  LR: 1.104e-04  Grad: 26.5412  max=1.0806(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1100(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3302, loss_cls=0.0616, loss_bbox=0.3407, matched_ious=0.6063, loss_iou=0.0861, loss_iou_reg=0.1965, d_time=0.00(0.01), f_time=1.32(1.35), b_time=1.32(1.36)  Time cost: 36:12/51:26 [26:55:16/3:46:41]  Acc_iter 67250       Data time: 0.00(0.01)  Forward time: 1.32(1.35)  Batch time: 1.32(1.36)
2025-09-04 12:12:12,861   INFO  Train:   18/20 ( 90%) [1645/3862 ( 43%)]  Loss: 1.463 (1.04)  LR: 1.093e-04  Grad: 26.5702  max=1.0762(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1178(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3230, loss_cls=0.0591, loss_bbox=0.3568, matched_ious=0.6132, loss_iou=0.0824, loss_iou_reg=0.1922, d_time=0.01(0.01), f_time=1.34(1.35), b_time=1.34(1.36)  Time cost: 37:20/50:17 [26:56:23/3:45:29]  Acc_iter 67300       Data time: 0.01(0.01)  Forward time: 1.34(1.35)  Batch time: 1.34(1.36)
2025-09-04 12:13:20,433   INFO  Train:   18/20 ( 90%) [1695/3862 ( 44%)]  Loss: 0.8052 (1.04)  LR: 1.083e-04  Grad: 26.6027  max=1.0739(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1150(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3432, loss_cls=0.0611, loss_bbox=0.3404, matched_ious=0.6083, loss_iou=0.0859, loss_iou_reg=0.1924, d_time=0.00(0.01), f_time=1.46(1.35), b_time=1.47(1.36)  Time cost: 38:27/49:08 [26:57:31/3:44:18]  Acc_iter 67350       Data time: 0.00(0.01)  Forward time: 1.46(1.35)  Batch time: 1.47(1.36)
2025-09-04 12:14:28,723   INFO  Train:   18/20 ( 90%) [1745/3862 ( 45%)]  Loss: 1.346 (1.04)  LR: 1.072e-04  Grad: 26.6178  max=1.0797(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1083(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3603, loss_cls=0.0652, loss_bbox=0.3709, matched_ious=0.6097, loss_iou=0.0855, loss_iou_reg=0.1956, d_time=0.00(0.01), f_time=1.35(1.35), b_time=1.36(1.36)  Time cost: 39:35/48:00 [26:58:39/3:43:11]  Acc_iter 67400       Data time: 0.00(0.01)  Forward time: 1.35(1.35)  Batch time: 1.36(1.36)
2025-09-04 12:15:36,225   INFO  Train:   18/20 ( 90%) [1795/3862 ( 46%)]  Loss: 0.7840 (1.04)  LR: 1.062e-04  Grad: 26.5860  max=1.0870(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1175(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3449, loss_cls=0.0626, loss_bbox=0.3604, matched_ious=0.6087, loss_iou=0.0849, loss_iou_reg=0.1901, d_time=0.01(0.01), f_time=1.28(1.35), b_time=1.29(1.36)  Time cost: 40:43/46:52 [26:59:47/3:42:00]  Acc_iter 67450       Data time: 0.01(0.01)  Forward time: 1.28(1.35)  Batch time: 1.29(1.36)
2025-09-04 12:16:44,354   INFO  Train:   18/20 ( 90%) [1845/3862 ( 48%)]  Loss: 0.7911 (1.04)  LR: 1.051e-04  Grad: 26.5590  max=1.0901(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1316(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3377, loss_cls=0.0633, loss_bbox=0.3643, matched_ious=0.6108, loss_iou=0.0858, loss_iou_reg=0.1910, d_time=0.00(0.01), f_time=1.23(1.35), b_time=1.23(1.36)  Time cost: 41:51/45:44 [27:00:55/3:40:53]  Acc_iter 67500       Data time: 0.00(0.01)  Forward time: 1.23(1.35)  Batch time: 1.23(1.36)
2025-09-04 12:17:52,045   INFO  Train:   18/20 ( 90%) [1895/3862 ( 49%)]  Loss: 1.104 (1.04)  LR: 1.041e-04  Grad: 26.5773  max=1.0878(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1285(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3567, loss_cls=0.0638, loss_bbox=0.3541, matched_ious=0.6183, loss_iou=0.0858, loss_iou_reg=0.1888, d_time=0.00(0.01), f_time=1.35(1.35), b_time=1.35(1.36)  Time cost: 42:59/44:35 [27:02:03/3:39:43]  Acc_iter 67550       Data time: 0.00(0.01)  Forward time: 1.35(1.35)  Batch time: 1.35(1.36)
2025-09-04 12:19:00,037   INFO  Train:   18/20 ( 90%) [1945/3862 ( 50%)]  Loss: 0.8956 (1.04)  LR: 1.030e-04  Grad: 26.6113  max=1.0877(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1231(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3569, loss_cls=0.0647, loss_bbox=0.3731, matched_ious=0.6083, loss_iou=0.0863, loss_iou_reg=0.1909, d_time=0.00(0.01), f_time=1.50(1.35), b_time=1.51(1.36)  Time cost: 44:07/43:27 [27:03:11/3:38:35]  Acc_iter 67600       Data time: 0.00(0.01)  Forward time: 1.50(1.35)  Batch time: 1.51(1.36)
2025-09-04 12:20:07,934   INFO  Train:   18/20 ( 90%) [1995/3862 ( 52%)]  Loss: 0.9335 (1.04)  LR: 1.020e-04  Grad: 26.6093  max=1.0803(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1310(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3304, loss_cls=0.0613, loss_bbox=0.3426, matched_ious=0.6133, loss_iou=0.0860, loss_iou_reg=0.1942, d_time=0.00(0.01), f_time=1.26(1.35), b_time=1.26(1.36)  Time cost: 45:15/42:19 [27:04:19/3:37:26]  Acc_iter 67650       Data time: 0.00(0.01)  Forward time: 1.26(1.35)  Batch time: 1.26(1.36)
2025-09-04 12:21:14,453   INFO  Train:   18/20 ( 90%) [2045/3862 ( 53%)]  Loss: 1.275 (1.04)  LR: 1.010e-04  Grad: 26.6458  max=1.0888(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1251(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3441, loss_cls=0.0628, loss_bbox=0.3516, matched_ious=0.6131, loss_iou=0.0843, loss_iou_reg=0.1907, d_time=0.01(0.01), f_time=1.37(1.35), b_time=1.38(1.36)  Time cost: 46:21/41:10 [27:05:25/3:36:11]  Acc_iter 67700       Data time: 0.01(0.01)  Forward time: 1.37(1.35)  Batch time: 1.38(1.36)
2025-09-04 12:22:21,453   INFO  Train:   18/20 ( 90%) [2095/3862 ( 54%)]  Loss: 0.9936 (1.04)  LR: 9.997e-05  Grad: 26.6625  max=1.0792(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1238(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3286, loss_cls=0.0593, loss_bbox=0.3388, matched_ious=0.6132, loss_iou=0.0836, loss_iou_reg=0.1904, d_time=0.01(0.01), f_time=1.35(1.35), b_time=1.35(1.36)  Time cost: 47:28/40:01 [27:06:32/3:34:59]  Acc_iter 67750       Data time: 0.01(0.01)  Forward time: 1.35(1.35)  Batch time: 1.35(1.36)
2025-09-04 12:23:29,924   INFO  Train:   18/20 ( 90%) [2145/3862 ( 56%)]  Loss: 0.9681 (1.04)  LR: 9.896e-05  Grad: 26.6423  max=1.0801(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1285(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3350, loss_cls=0.0601, loss_bbox=0.3479, matched_ious=0.6208, loss_iou=0.0838, loss_iou_reg=0.1871, d_time=0.00(0.01), f_time=1.42(1.35), b_time=1.42(1.36)  Time cost: 48:37/38:54 [27:07:41/3:33:53]  Acc_iter 67800       Data time: 0.00(0.01)  Forward time: 1.42(1.35)  Batch time: 1.42(1.36)
2025-09-04 12:24:37,322   INFO  Train:   18/20 ( 90%) [2195/3862 ( 57%)]  Loss: 1.430 (1.04)  LR: 9.795e-05  Grad: 26.6663  max=1.0833(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1277(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3594, loss_cls=0.0612, loss_bbox=0.3688, matched_ious=0.6152, loss_iou=0.0853, loss_iou_reg=0.1923, d_time=0.00(0.01), f_time=1.45(1.35), b_time=1.45(1.36)  Time cost: 49:44/37:45 [27:08:48/3:32:43]  Acc_iter 67850       Data time: 0.00(0.01)  Forward time: 1.45(1.35)  Batch time: 1.45(1.36)
2025-09-04 12:25:45,942   INFO  Train:   18/20 ( 90%) [2245/3862 ( 58%)]  Loss: 0.9430 (1.04)  LR: 9.694e-05  Grad: 26.6552  max=1.0831(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1292(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3413, loss_cls=0.0636, loss_bbox=0.3628, matched_ious=0.6108, loss_iou=0.0844, loss_iou_reg=0.1929, d_time=0.00(0.01), f_time=1.40(1.35), b_time=1.41(1.36)  Time cost: 50:53/36:38 [27:09:57/3:31:38]  Acc_iter 67900       Data time: 0.00(0.01)  Forward time: 1.40(1.35)  Batch time: 1.41(1.36)
2025-09-04 12:26:54,466   INFO  Train:   18/20 ( 90%) [2295/3862 ( 59%)]  Loss: 0.9201 (1.04)  LR: 9.594e-05  Grad: 26.7368  max=1.0819(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1153(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3720, loss_cls=0.0653, loss_bbox=0.3638, matched_ious=0.6111, loss_iou=0.0859, loss_iou_reg=0.1892, d_time=0.01(0.01), f_time=1.36(1.35), b_time=1.37(1.36)  Time cost: 52:01/35:30 [27:11:05/3:30:32]  Acc_iter 67950       Data time: 0.01(0.01)  Forward time: 1.36(1.35)  Batch time: 1.37(1.36)
2025-09-04 12:28:03,154   INFO  Train:   18/20 ( 90%) [2345/3862 ( 61%)]  Loss: 0.9694 (1.04)  LR: 9.495e-05  Grad: 26.7182  max=1.0831(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1239(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3487, loss_cls=0.0681, loss_bbox=0.3563, matched_ious=0.6003, loss_iou=0.0853, loss_iou_reg=0.1950, d_time=0.00(0.01), f_time=1.54(1.35), b_time=1.55(1.36)  Time cost: 53:10/34:23 [27:12:14/3:29:27]  Acc_iter 68000       Data time: 0.00(0.01)  Forward time: 1.54(1.35)  Batch time: 1.55(1.36)
2025-09-04 12:29:10,901   INFO  Train:   18/20 ( 90%) [2395/3862 ( 62%)]  Loss: 1.433 (1.04)  LR: 9.396e-05  Grad: 26.7577  max=1.0850(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1232(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3651, loss_cls=0.0677, loss_bbox=0.3870, matched_ious=0.6078, loss_iou=0.0867, loss_iou_reg=0.1948, d_time=0.00(0.01), f_time=1.37(1.35), b_time=1.38(1.36)  Time cost: 54:18/33:14 [27:13:22/3:28:18]  Acc_iter 68050       Data time: 0.00(0.01)  Forward time: 1.37(1.35)  Batch time: 1.38(1.36)
2025-09-04 12:30:18,351   INFO  Train:   18/20 ( 90%) [2445/3862 ( 63%)]  Loss: 0.8858 (1.04)  LR: 9.297e-05  Grad: 26.7266  max=1.0911(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1241(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3348, loss_cls=0.0611, loss_bbox=0.3659, matched_ious=0.6123, loss_iou=0.0843, loss_iou_reg=0.1886, d_time=0.00(0.01), f_time=1.24(1.35), b_time=1.24(1.36)  Time cost: 55:25/32:06 [27:14:29/3:27:08]  Acc_iter 68100       Data time: 0.00(0.01)  Forward time: 1.24(1.35)  Batch time: 1.24(1.36)
2025-09-04 12:31:26,371   INFO  Train:   18/20 ( 90%) [2495/3862 ( 65%)]  Loss: 0.8960 (1.04)  LR: 9.199e-05  Grad: 26.7148  max=1.0805(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1468(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3337, loss_cls=0.0639, loss_bbox=0.3409, matched_ious=0.6060, loss_iou=0.0853, loss_iou_reg=0.1951, d_time=0.00(0.01), f_time=1.50(1.35), b_time=1.51(1.36)  Time cost: 56:33/30:58 [27:15:37/3:26:00]  Acc_iter 68150       Data time: 0.00(0.01)  Forward time: 1.50(1.35)  Batch time: 1.51(1.36)
2025-09-04 12:32:34,024   INFO  Train:   18/20 ( 90%) [2545/3862 ( 66%)]  Loss: 1.091 (1.04)  LR: 9.101e-05  Grad: 26.7268  max=1.0944(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1433(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3383, loss_cls=0.0635, loss_bbox=0.3472, matched_ious=0.6092, loss_iou=0.0849, loss_iou_reg=0.1923, d_time=0.01(0.01), f_time=1.33(1.35), b_time=1.33(1.36)  Time cost: 57:41/29:50 [27:16:45/3:24:51]  Acc_iter 68200       Data time: 0.01(0.01)  Forward time: 1.33(1.35)  Batch time: 1.33(1.36)
2025-09-04 12:33:42,016   INFO  Train:   18/20 ( 90%) [2595/3862 ( 67%)]  Loss: 0.8864 (1.04)  LR: 9.004e-05  Grad: 26.7852  max=1.0957(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1299(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3237, loss_cls=0.0560, loss_bbox=0.3338, matched_ious=0.6161, loss_iou=0.0828, loss_iou_reg=0.1892, d_time=0.01(0.01), f_time=1.40(1.35), b_time=1.41(1.36)  Time cost: 58:49/28:42 [27:17:53/3:23:43]  Acc_iter 68250       Data time: 0.01(0.01)  Forward time: 1.40(1.35)  Batch time: 1.41(1.36)
2025-09-04 12:34:49,297   INFO  Train:   18/20 ( 90%) [2645/3862 ( 68%)]  Loss: 1.138 (1.04)  LR: 8.907e-05  Grad: 26.7993  max=1.0945(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1322(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3520, loss_cls=0.0635, loss_bbox=0.3557, matched_ious=0.6075, loss_iou=0.0845, loss_iou_reg=0.1938, d_time=0.00(0.01), f_time=1.26(1.35), b_time=1.27(1.36)  Time cost: 59:56/27:34 [27:19:00/3:22:32]  Acc_iter 68300       Data time: 0.00(0.01)  Forward time: 1.26(1.35)  Batch time: 1.27(1.36)
2025-09-04 12:35:56,956   INFO  Train:   18/20 ( 90%) [2695/3862 ( 70%)]  Loss: 1.063 (1.04)  LR: 8.811e-05  Grad: 26.7664  max=1.1000(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1401(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3464, loss_cls=0.0637, loss_bbox=0.3687, matched_ious=0.6077, loss_iou=0.0861, loss_iou_reg=0.1924, d_time=0.00(0.01), f_time=1.31(1.35), b_time=1.32(1.36)  Time cost: 1:01:04/26:26 [27:20:08/3:21:23]  Acc_iter 68350       Data time: 0.00(0.01)  Forward time: 1.31(1.35)  Batch time: 1.32(1.36)
2025-09-04 12:37:05,460   INFO  Train:   18/20 ( 90%) [2745/3862 ( 71%)]  Loss: 1.472 (1.04)  LR: 8.715e-05  Grad: 26.7973  max=1.0996(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1472(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3352, loss_cls=0.0595, loss_bbox=0.3595, matched_ious=0.6205, loss_iou=0.0837, loss_iou_reg=0.1891, d_time=0.00(0.01), f_time=1.30(1.35), b_time=1.30(1.36)  Time cost: 1:02:12/25:18 [27:21:16/3:20:17]  Acc_iter 68400       Data time: 0.00(0.01)  Forward time: 1.30(1.35)  Batch time: 1.30(1.36)
2025-09-04 12:38:13,517   INFO  Train:   18/20 ( 90%) [2795/3862 ( 72%)]  Loss: 0.9297 (1.04)  LR: 8.620e-05  Grad: 26.7821  max=1.0962(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1531(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3439, loss_cls=0.0615, loss_bbox=0.3767, matched_ious=0.6105, loss_iou=0.0845, loss_iou_reg=0.1911, d_time=0.00(0.01), f_time=1.45(1.35), b_time=1.45(1.36)  Time cost: 1:03:20/24:10 [27:22:24/3:19:10]  Acc_iter 68450       Data time: 0.00(0.01)  Forward time: 1.45(1.35)  Batch time: 1.45(1.36)
2025-09-04 12:39:21,990   INFO  Train:   18/20 ( 90%) [2845/3862 ( 74%)]  Loss: 0.9247 (1.04)  LR: 8.525e-05  Grad: 26.8502  max=1.0992(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1362(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3331, loss_cls=0.0604, loss_bbox=0.3435, matched_ious=0.6122, loss_iou=0.0854, loss_iou_reg=0.1950, d_time=0.00(0.01), f_time=1.33(1.35), b_time=1.34(1.36)  Time cost: 1:04:29/23:02 [27:23:33/3:18:03]  Acc_iter 68500       Data time: 0.00(0.01)  Forward time: 1.33(1.35)  Batch time: 1.34(1.36)
2025-09-04 12:40:31,083   INFO  Train:   18/20 ( 90%) [2895/3862 ( 75%)]  Loss: 1.054 (1.04)  LR: 8.430e-05  Grad: 26.8376  max=1.0900(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1447(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3489, loss_cls=0.0617, loss_bbox=0.3642, matched_ious=0.6068, loss_iou=0.0840, loss_iou_reg=0.1936, d_time=0.00(0.01), f_time=1.27(1.35), b_time=1.28(1.36)  Time cost: 1:05:38/21:55 [27:24:42/3:16:59]  Acc_iter 68550       Data time: 0.00(0.01)  Forward time: 1.27(1.35)  Batch time: 1.28(1.36)
2025-09-04 12:41:38,509   INFO  Train:   18/20 ( 90%) [2945/3862 ( 76%)]  Loss: 1.153 (1.04)  LR: 8.336e-05  Grad: 26.8594  max=1.0962(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1408(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3393, loss_cls=0.0642, loss_bbox=0.3518, matched_ious=0.6177, loss_iou=0.0852, loss_iou_reg=0.1893, d_time=0.01(0.01), f_time=1.42(1.35), b_time=1.42(1.36)  Time cost: 1:06:45/20:46 [27:25:49/3:15:49]  Acc_iter 68600       Data time: 0.01(0.01)  Forward time: 1.42(1.35)  Batch time: 1.42(1.36)
2025-09-04 12:42:46,362   INFO  Train:   18/20 ( 90%) [2995/3862 ( 78%)]  Loss: 0.8542 (1.04)  LR: 8.243e-05  Grad: 26.8313  max=1.0917(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1539(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3367, loss_cls=0.0627, loss_bbox=0.3326, matched_ious=0.6083, loss_iou=0.0845, loss_iou_reg=0.1918, d_time=0.01(0.01), f_time=1.39(1.35), b_time=1.39(1.36)  Time cost: 1:07:53/19:38 [27:26:57/3:14:40]  Acc_iter 68650       Data time: 0.01(0.01)  Forward time: 1.39(1.35)  Batch time: 1.39(1.36)
2025-09-04 12:43:53,702   INFO  Train:   18/20 ( 90%) [3045/3862 ( 79%)]  Loss: 0.8041 (1.04)  LR: 8.150e-05  Grad: 26.8435  max=1.0988(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1527(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3224, loss_cls=0.0589, loss_bbox=0.3404, matched_ious=0.6111, loss_iou=0.0817, loss_iou_reg=0.1927, d_time=0.00(0.01), f_time=1.31(1.35), b_time=1.31(1.36)  Time cost: 1:09:00/18:30 [27:28:04/3:13:31]  Acc_iter 68700       Data time: 0.00(0.01)  Forward time: 1.31(1.35)  Batch time: 1.31(1.36)
2025-09-04 12:45:02,402   INFO  Train:   18/20 ( 90%) [3095/3862 ( 80%)]  Loss: 0.8175 (1.04)  LR: 8.057e-05  Grad: 26.8700  max=1.0968(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1443(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3311, loss_cls=0.0603, loss_bbox=0.3553, matched_ious=0.6100, loss_iou=0.0842, loss_iou_reg=0.1918, d_time=0.01(0.01), f_time=1.33(1.35), b_time=1.34(1.36)  Time cost: 1:10:09/17:22 [27:29:13/3:12:25]  Acc_iter 68750       Data time: 0.01(0.01)  Forward time: 1.33(1.35)  Batch time: 1.34(1.36)
2025-09-04 12:46:11,172   INFO  Train:   18/20 ( 90%) [3145/3862 ( 81%)]  Loss: 0.9466 (1.04)  LR: 7.965e-05  Grad: 26.8458  max=1.0988(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1568(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3376, loss_cls=0.0617, loss_bbox=0.3282, matched_ious=0.6208, loss_iou=0.0826, loss_iou_reg=0.1883, d_time=0.01(0.01), f_time=1.22(1.35), b_time=1.22(1.36)  Time cost: 1:11:18/16:15 [27:30:22/3:11:19]  Acc_iter 68800       Data time: 0.01(0.01)  Forward time: 1.22(1.35)  Batch time: 1.22(1.36)
2025-09-04 12:47:18,799   INFO  Train:   18/20 ( 90%) [3195/3862 ( 83%)]  Loss: 0.8275 (1.04)  LR: 7.874e-05  Grad: 26.9087  max=1.1024(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1426(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3265, loss_cls=0.0587, loss_bbox=0.3386, matched_ious=0.6192, loss_iou=0.0849, loss_iou_reg=0.1892, d_time=0.00(0.01), f_time=1.46(1.35), b_time=1.47(1.36)  Time cost: 1:12:26/15:07 [27:31:29/3:10:10]  Acc_iter 68850       Data time: 0.00(0.01)  Forward time: 1.46(1.35)  Batch time: 1.47(1.36)
2025-09-04 12:48:26,276   INFO  Train:   18/20 ( 90%) [3245/3862 ( 84%)]  Loss: 0.8045 (1.04)  LR: 7.783e-05  Grad: 26.9856  max=1.1052(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1272(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3131, loss_cls=0.0592, loss_bbox=0.3328, matched_ious=0.6093, loss_iou=0.0842, loss_iou_reg=0.1921, d_time=0.00(0.01), f_time=1.36(1.35), b_time=1.36(1.36)  Time cost: 1:13:33/13:58 [27:32:37/3:09:01]  Acc_iter 68900       Data time: 0.00(0.01)  Forward time: 1.36(1.35)  Batch time: 1.36(1.36)
2025-09-04 12:49:33,249   INFO  Train:   18/20 ( 90%) [3295/3862 ( 85%)]  Loss: 0.8614 (1.04)  LR: 7.692e-05  Grad: 26.8951  max=1.1118(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1480(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3408, loss_cls=0.0611, loss_bbox=0.3415, matched_ious=0.6158, loss_iou=0.0830, loss_iou_reg=0.1904, d_time=0.00(0.01), f_time=1.28(1.35), b_time=1.29(1.36)  Time cost: 1:14:40/12:50 [27:33:44/3:07:50]  Acc_iter 68950       Data time: 0.00(0.01)  Forward time: 1.28(1.35)  Batch time: 1.29(1.36)
2025-09-04 12:50:41,044   INFO  Train:   18/20 ( 90%) [3345/3862 ( 87%)]  Loss: 0.9432 (1.04)  LR: 7.602e-05  Grad: 26.9245  max=1.1135(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1421(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3461, loss_cls=0.0645, loss_bbox=0.3415, matched_ious=0.6185, loss_iou=0.0825, loss_iou_reg=0.1885, d_time=0.00(0.01), f_time=1.37(1.35), b_time=1.37(1.36)  Time cost: 1:15:48/11:42 [27:34:52/3:06:42]  Acc_iter 69000       Data time: 0.00(0.01)  Forward time: 1.37(1.35)  Batch time: 1.37(1.36)
2025-09-04 12:51:50,035   INFO  Train:   18/20 ( 90%) [3395/3862 ( 88%)]  Loss: 1.002 (1.04)  LR: 7.513e-05  Grad: 26.9280  max=1.1130(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1438(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3430, loss_cls=0.0623, loss_bbox=0.3419, matched_ious=0.6151, loss_iou=0.0865, loss_iou_reg=0.1912, d_time=0.01(0.01), f_time=1.44(1.35), b_time=1.44(1.36)  Time cost: 1:16:57/10:34 [27:36:01/3:05:36]  Acc_iter 69050       Data time: 0.01(0.01)  Forward time: 1.44(1.35)  Batch time: 1.44(1.36)
2025-09-04 12:52:56,910   INFO  Train:   18/20 ( 90%) [3445/3862 ( 89%)]  Loss: 0.9489 (1.04)  LR: 7.424e-05  Grad: 26.8986  max=1.1068(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1667(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3520, loss_cls=0.0626, loss_bbox=0.3581, matched_ious=0.6066, loss_iou=0.0863, loss_iou_reg=0.1948, d_time=0.01(0.01), f_time=1.32(1.35), b_time=1.32(1.36)  Time cost: 1:18:04/09:26 [27:37:08/3:04:26]  Acc_iter 69100       Data time: 0.01(0.01)  Forward time: 1.32(1.35)  Batch time: 1.32(1.36)
2025-09-04 12:54:04,665   INFO  Train:   18/20 ( 90%) [3495/3862 ( 90%)]  Loss: 0.8295 (1.04)  LR: 7.335e-05  Grad: 26.9161  max=1.1116(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1581(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3242, loss_cls=0.0572, loss_bbox=0.3534, matched_ious=0.6161, loss_iou=0.0850, loss_iou_reg=0.1900, d_time=0.01(0.01), f_time=1.73(1.35), b_time=1.74(1.36)  Time cost: 1:19:11/08:18 [27:38:15/3:03:17]  Acc_iter 69150       Data time: 0.01(0.01)  Forward time: 1.73(1.35)  Batch time: 1.74(1.36)
2025-09-04 12:55:13,125   INFO  Train:   18/20 ( 90%) [3545/3862 ( 92%)]  Loss: 0.9014 (1.04)  LR: 7.247e-05  Grad: 26.9830  max=1.0929(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1531(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3257, loss_cls=0.0566, loss_bbox=0.3523, matched_ious=0.6080, loss_iou=0.0855, loss_iou_reg=0.1945, d_time=0.01(0.01), f_time=1.35(1.35), b_time=1.36(1.36)  Time cost: 1:20:20/07:10 [27:39:24/3:02:10]  Acc_iter 69200       Data time: 0.01(0.01)  Forward time: 1.35(1.35)  Batch time: 1.36(1.36)
2025-09-04 12:56:21,020   INFO  Train:   18/20 ( 90%) [3595/3862 ( 93%)]  Loss: 1.029 (1.04)  LR: 7.159e-05  Grad: 27.0287  max=1.1029(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1483(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3530, loss_cls=0.0622, loss_bbox=0.3530, matched_ious=0.6097, loss_iou=0.0850, loss_iou_reg=0.1919, d_time=0.00(0.01), f_time=1.34(1.35), b_time=1.34(1.36)  Time cost: 1:21:28/06:02 [27:40:32/3:01:02]  Acc_iter 69250       Data time: 0.00(0.01)  Forward time: 1.34(1.35)  Batch time: 1.34(1.36)
2025-09-04 12:57:28,761   INFO  Train:   18/20 ( 90%) [3645/3862 ( 94%)]  Loss: 0.9242 (1.04)  LR: 7.072e-05  Grad: 26.9730  max=1.0998(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1678(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3482, loss_cls=0.0604, loss_bbox=0.3499, matched_ious=0.6101, loss_iou=0.0857, loss_iou_reg=0.1920, d_time=0.01(0.01), f_time=1.33(1.35), b_time=1.34(1.36)  Time cost: 1:22:36/04:54 [27:41:39/2:59:54]  Acc_iter 69300       Data time: 0.01(0.01)  Forward time: 1.33(1.35)  Batch time: 1.34(1.36)
2025-09-04 12:58:36,621   INFO  Train:   18/20 ( 90%) [3695/3862 ( 96%)]  Loss: 0.9930 (1.04)  LR: 6.985e-05  Grad: 26.9495  max=1.1053(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1751(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3479, loss_cls=0.0639, loss_bbox=0.3375, matched_ious=0.6096, loss_iou=0.0847, loss_iou_reg=0.1898, d_time=0.00(0.01), f_time=1.28(1.35), b_time=1.28(1.36)  Time cost: 1:23:43/03:46 [27:42:47/2:58:45]  Acc_iter 69350       Data time: 0.00(0.01)  Forward time: 1.28(1.35)  Batch time: 1.28(1.36)
2025-09-04 12:59:44,848   INFO  Train:   18/20 ( 90%) [3745/3862 ( 97%)]  Loss: 0.9207 (1.04)  LR: 6.899e-05  Grad: 27.0022  max=1.1053(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1601(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3502, loss_cls=0.0641, loss_bbox=0.3684, matched_ious=0.6137, loss_iou=0.0854, loss_iou_reg=0.1928, d_time=0.00(0.01), f_time=1.53(1.35), b_time=1.54(1.36)  Time cost: 1:24:52/02:39 [27:43:55/2:57:38]  Acc_iter 69400       Data time: 0.00(0.01)  Forward time: 1.53(1.35)  Batch time: 1.54(1.36)
2025-09-04 13:00:52,693   INFO  Train:   18/20 ( 90%) [3795/3862 ( 98%)]  Loss: 1.303 (1.04)  LR: 6.814e-05  Grad: 27.0096  max=1.1073(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1675(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3567, loss_cls=0.0605, loss_bbox=0.3562, matched_ious=0.6151, loss_iou=0.0835, loss_iou_reg=0.1870, d_time=0.01(0.01), f_time=1.37(1.35), b_time=1.37(1.36)  Time cost: 1:25:59/01:31 [27:45:03/2:56:30]  Acc_iter 69450       Data time: 0.01(0.01)  Forward time: 1.37(1.35)  Batch time: 1.37(1.36)
2025-09-04 13:01:59,688   INFO  Train:   18/20 ( 90%) [3845/3862 (100%)]  Loss: 1.188 (1.04)  LR: 6.729e-05  Grad: 27.0424  max=1.1040(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1596(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3355, loss_cls=0.0615, loss_bbox=0.3374, matched_ious=0.6121, loss_iou=0.0858, loss_iou_reg=0.1908, d_time=0.01(0.01), f_time=1.43(1.35), b_time=1.44(1.36)  Time cost: 1:27:06/00:23 [27:46:10/2:55:20]  Acc_iter 69500       Data time: 0.01(0.01)  Forward time: 1.43(1.35)  Batch time: 1.44(1.36)
2025-09-04 13:02:20,779   INFO  Train:   18/20 ( 90%) [3861/3862 (100%)]  Loss: 0.9368 (1.04)  LR: 6.701e-05  Grad: 26.9856  max=1.1048(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1703(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3325, loss_cls=0.0633, loss_bbox=0.3596, matched_ious=0.6028, loss_iou=0.0882, loss_iou_reg=0.1961, d_time=0.00(0.01), f_time=1.38(1.35), b_time=1.38(1.36)  Time cost: 1:27:28/00:01 [27:46:31/2:54:57]  Acc_iter 69516       Data time: 0.00(0.01)  Forward time: 1.38(1.35)  Batch time: 1.38(1.36)

                                               [Aepochs:  90%|█████████ | 18/20 [27:46:32<3:00:48, 5424.05s/it]epochs:  90%|█████████ | 18/20 [27:46:32<3:00:48, 5424.05s/it]epochs:  90%|█████████ | 18/20 [27:46:32<3:00:48, 5424.06s/it]epochs:  90%|█████████ | 18/20 [27:46:32<3:00:48, 5424.06s/it]epochs:  90%|█████████ | 18/20 [27:46:32<3:00:48, 5424.07s/it]epochs:  90%|█████████ | 18/20 [27:46:32<3:00:48, 5424.06s/it]epochs:  90%|█████████ | 18/20 [27:46:32<3:00:48, 5424.07s/it]epochs:  90%|█████████ | 18/20 [27:46:32<3:00:48, 5424.06s/it]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-04 13:02:25,486   INFO  Train:   19/20 ( 95%) [   0/3862 (  0%)]  Loss: 1.253 (1.25)  LR: 6.700e-05  Grad: 26.9818  max=1.1061(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1705(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3466, loss_cls=0.0602, loss_bbox=0.5188, matched_ious=0.5674, loss_iou=0.1018, loss_iou_reg=0.2253, d_time=1.41(1.41), f_time=2.15(2.15), b_time=3.56(3.56)  Time cost: 00:03/3:35:42 [27:46:36/7:11:24]  Acc_iter 69517       Data time: 1.41(1.41)  Forward time: 2.15(2.15)  Batch time: 3.56(3.56)
2025-09-04 13:03:10,827   INFO  Train:   19/20 ( 95%) [  33/3862 (  1%)]  Loss: 0.9959 (1.06)  LR: 6.644e-05  Grad: 27.0558  max=1.0988(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1591(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3494, loss_cls=0.0643, loss_bbox=0.3624, matched_ious=0.6111, loss_iou=0.0856, loss_iou_reg=0.1893, d_time=0.01(0.05), f_time=1.29(1.39), b_time=1.29(1.44)  Time cost: 00:48/1:31:23 [27:47:21/3:03:34]  Acc_iter 69550       Data time: 0.01(0.05)  Forward time: 1.29(1.39)  Batch time: 1.29(1.44)
2025-09-04 13:04:19,124   INFO  Train:   19/20 ( 95%) [  83/3862 (  2%)]  Loss: 0.8789 (1.05)  LR: 6.560e-05  Grad: 27.0056  max=1.1042(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1710(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3461, loss_cls=0.0631, loss_bbox=0.3586, matched_ious=0.6165, loss_iou=0.0838, loss_iou_reg=0.1920, d_time=0.01(0.02), f_time=1.43(1.37), b_time=1.44(1.40)  Time cost: 01:56/1:27:43 [27:48:30/2:57:22]  Acc_iter 69600       Data time: 0.01(0.02)  Forward time: 1.43(1.37)  Batch time: 1.44(1.40)
2025-09-04 13:05:27,490   INFO  Train:   19/20 ( 95%) [ 133/3862 (  3%)]  Loss: 1.065 (1.03)  LR: 6.476e-05  Grad: 27.0553  max=1.1111(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1596(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3324, loss_cls=0.0587, loss_bbox=0.3429, matched_ious=0.6179, loss_iou=0.0850, loss_iou_reg=0.1878, d_time=0.01(0.02), f_time=1.26(1.37), b_time=1.26(1.38)  Time cost: 03:05/1:25:58 [27:49:38/2:55:00]  Acc_iter 69650       Data time: 0.01(0.02)  Forward time: 1.26(1.37)  Batch time: 1.26(1.38)
2025-09-04 13:06:35,030   INFO  Train:   19/20 ( 95%) [ 183/3862 (  5%)]  Loss: 0.9422 (1.02)  LR: 6.393e-05  Grad: 27.0384  max=1.1080(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1729(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3153, loss_cls=0.0580, loss_bbox=0.3412, matched_ious=0.6114, loss_iou=0.0853, loss_iou_reg=0.1939, d_time=0.01(0.01), f_time=1.24(1.36), b_time=1.25(1.38)  Time cost: 04:12/1:24:16 [27:50:46/2:52:44]  Acc_iter 69700       Data time: 0.01(0.01)  Forward time: 1.24(1.36)  Batch time: 1.25(1.38)
2025-09-04 13:07:43,837   INFO  Train:   19/20 ( 95%) [ 233/3862 (  6%)]  Loss: 1.188 (1.01)  LR: 6.310e-05  Grad: 27.1021  max=1.1073(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1565(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3122, loss_cls=0.0573, loss_bbox=0.3295, matched_ious=0.6198, loss_iou=0.0846, loss_iou_reg=0.1909, d_time=0.00(0.01), f_time=1.48(1.36), b_time=1.48(1.38)  Time cost: 05:21/1:23:09 [27:51:54/2:51:38]  Acc_iter 69750       Data time: 0.00(0.01)  Forward time: 1.48(1.36)  Batch time: 1.48(1.38)
2025-09-04 13:08:52,120   INFO  Train:   19/20 ( 95%) [ 283/3862 (  7%)]  Loss: 0.9651 (1.01)  LR: 6.228e-05  Grad: 27.0979  max=1.1032(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1637(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3362, loss_cls=0.0599, loss_bbox=0.3344, matched_ious=0.6128, loss_iou=0.0841, loss_iou_reg=0.1871, d_time=0.00(0.01), f_time=1.33(1.36), b_time=1.34(1.37)  Time cost: 06:29/1:21:54 [27:53:03/2:50:17]  Acc_iter 69800       Data time: 0.00(0.01)  Forward time: 1.33(1.36)  Batch time: 1.34(1.37)
2025-09-04 13:09:59,911   INFO  Train:   19/20 ( 95%) [ 333/3862 (  9%)]  Loss: 0.8304 (1.01)  LR: 6.146e-05  Grad: 27.0531  max=1.1074(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1720(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3129, loss_cls=0.0572, loss_bbox=0.3593, matched_ious=0.6077, loss_iou=0.0855, loss_iou_reg=0.1940, d_time=0.01(0.01), f_time=1.30(1.36), b_time=1.31(1.37)  Time cost: 07:37/1:20:36 [27:54:11/2:48:49]  Acc_iter 69850       Data time: 0.01(0.01)  Forward time: 1.30(1.36)  Batch time: 1.31(1.37)
2025-09-04 13:11:08,154   INFO  Train:   19/20 ( 95%) [ 383/3862 ( 10%)]  Loss: 0.8158 (1.01)  LR: 6.065e-05  Grad: 27.1068  max=1.1041(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1597(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3519, loss_cls=0.0628, loss_bbox=0.3592, matched_ious=0.6214, loss_iou=0.0837, loss_iou_reg=0.1865, d_time=0.00(0.01), f_time=1.35(1.36), b_time=1.36(1.37)  Time cost: 08:46/1:19:25 [27:55:19/2:47:36]  Acc_iter 69900       Data time: 0.00(0.01)  Forward time: 1.35(1.36)  Batch time: 1.36(1.37)
2025-09-04 13:12:16,142   INFO  Train:   19/20 ( 95%) [ 433/3862 ( 11%)]  Loss: 1.079 (1.01)  LR: 5.985e-05  Grad: 27.1187  max=1.1078(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1600(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3329, loss_cls=0.0577, loss_bbox=0.3539, matched_ious=0.6219, loss_iou=0.0831, loss_iou_reg=0.1878, d_time=0.00(0.01), f_time=1.40(1.36), b_time=1.40(1.37)  Time cost: 09:54/1:18:13 [27:56:27/2:46:19]  Acc_iter 69950       Data time: 0.00(0.01)  Forward time: 1.40(1.36)  Batch time: 1.40(1.37)
2025-09-04 13:13:23,523   INFO  Train:   19/20 ( 95%) [ 483/3862 ( 13%)]  Loss: 1.065 (1.02)  LR: 5.904e-05  Grad: 27.0902  max=1.1009(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1684(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3321, loss_cls=0.0601, loss_bbox=0.3528, matched_ious=0.6158, loss_iou=0.0839, loss_iou_reg=0.1891, d_time=0.01(0.01), f_time=1.39(1.36), b_time=1.39(1.37)  Time cost: 11:01/1:16:57 [27:57:34/2:44:54]  Acc_iter 70000       Data time: 0.01(0.01)  Forward time: 1.39(1.36)  Batch time: 1.39(1.37)
2025-09-04 13:14:30,276   INFO  Train:   19/20 ( 95%) [ 533/3862 ( 14%)]  Loss: 1.138 (1.01)  LR: 5.825e-05  Grad: 27.1229  max=1.0973(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1641(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3360, loss_cls=0.0617, loss_bbox=0.3401, matched_ious=0.6171, loss_iou=0.0856, loss_iou_reg=0.1885, d_time=0.01(0.01), f_time=1.29(1.36), b_time=1.29(1.36)  Time cost: 12:08/1:15:39 [27:58:41/2:43:25]  Acc_iter 70050       Data time: 0.01(0.01)  Forward time: 1.29(1.36)  Batch time: 1.29(1.36)
2025-09-04 13:15:38,099   INFO  Train:   19/20 ( 95%) [ 583/3862 ( 15%)]  Loss: 0.8936 (1.02)  LR: 5.746e-05  Grad: 27.1287  max=1.1056(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1687(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3278, loss_cls=0.0576, loss_bbox=0.3687, matched_ious=0.6105, loss_iou=0.0840, loss_iou_reg=0.1892, d_time=0.00(0.01), f_time=1.26(1.36), b_time=1.27(1.36)  Time cost: 13:15/1:14:29 [27:59:49/2:42:12]  Acc_iter 70100       Data time: 0.00(0.01)  Forward time: 1.26(1.36)  Batch time: 1.27(1.36)
2025-09-04 13:16:46,185   INFO  Train:   19/20 ( 95%) [ 633/3862 ( 16%)]  Loss: 1.008 (1.02)  LR: 5.667e-05  Grad: 27.1510  max=1.1085(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1642(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3484, loss_cls=0.0647, loss_bbox=0.3483, matched_ious=0.6166, loss_iou=0.0843, loss_iou_reg=0.1913, d_time=0.00(0.01), f_time=1.33(1.36), b_time=1.33(1.36)  Time cost: 14:24/1:13:20 [28:00:57/2:41:04]  Acc_iter 70150       Data time: 0.00(0.01)  Forward time: 1.33(1.36)  Batch time: 1.33(1.36)
2025-09-04 13:17:54,599   INFO  Train:   19/20 ( 95%) [ 683/3862 ( 18%)]  Loss: 1.220 (1.02)  LR: 5.589e-05  Grad: 27.1395  max=1.1007(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1765(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3322, loss_cls=0.0577, loss_bbox=0.3657, matched_ious=0.6085, loss_iou=0.0856, loss_iou_reg=0.1949, d_time=0.01(0.01), f_time=1.25(1.36), b_time=1.26(1.36)  Time cost: 15:32/1:12:13 [28:02:05/2:39:58]  Acc_iter 70200       Data time: 0.01(0.01)  Forward time: 1.25(1.36)  Batch time: 1.26(1.36)
2025-09-04 13:19:01,947   INFO  Train:   19/20 ( 95%) [ 733/3862 ( 19%)]  Loss: 0.9869 (1.02)  LR: 5.511e-05  Grad: 27.1466  max=1.1037(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1673(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3419, loss_cls=0.0628, loss_bbox=0.3546, matched_ious=0.6091, loss_iou=0.0844, loss_iou_reg=0.1925, d_time=0.01(0.01), f_time=1.29(1.35), b_time=1.30(1.36)  Time cost: 16:39/1:11:02 [28:03:13/2:38:42]  Acc_iter 70250       Data time: 0.01(0.01)  Forward time: 1.29(1.35)  Batch time: 1.30(1.36)
2025-09-04 13:20:10,418   INFO  Train:   19/20 ( 95%) [ 783/3862 ( 20%)]  Loss: 0.9766 (1.02)  LR: 5.434e-05  Grad: 27.2025  max=1.1060(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1619(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3401, loss_cls=0.0594, loss_bbox=0.3438, matched_ious=0.6142, loss_iou=0.0850, loss_iou_reg=0.1912, d_time=0.01(0.01), f_time=1.21(1.36), b_time=1.22(1.36)  Time cost: 17:48/1:09:55 [28:04:21/2:37:37]  Acc_iter 70300       Data time: 0.01(0.01)  Forward time: 1.21(1.36)  Batch time: 1.22(1.36)
2025-09-04 13:21:18,315   INFO  Train:   19/20 ( 95%) [ 833/3862 ( 22%)]  Loss: 0.9319 (1.02)  LR: 5.358e-05  Grad: 27.1764  max=1.1061(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1846(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3302, loss_cls=0.0630, loss_bbox=0.3537, matched_ious=0.6175, loss_iou=0.0825, loss_iou_reg=0.1887, d_time=0.00(0.01), f_time=1.30(1.36), b_time=1.31(1.36)  Time cost: 18:56/1:08:46 [28:05:29/2:36:27]  Acc_iter 70350       Data time: 0.00(0.01)  Forward time: 1.30(1.36)  Batch time: 1.31(1.36)
2025-09-04 13:22:27,091   INFO  Train:   19/20 ( 95%) [ 883/3862 ( 23%)]  Loss: 1.085 (1.02)  LR: 5.282e-05  Grad: 27.1687  max=1.1047(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1810(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3299, loss_cls=0.0582, loss_bbox=0.3438, matched_ious=0.6100, loss_iou=0.0876, loss_iou_reg=0.1925, d_time=0.00(0.01), f_time=1.25(1.36), b_time=1.25(1.36)  Time cost: 20:04/1:07:40 [28:06:38/2:35:24]  Acc_iter 70400       Data time: 0.00(0.01)  Forward time: 1.25(1.36)  Batch time: 1.25(1.36)
2025-09-04 13:23:35,666   INFO  Train:   19/20 ( 95%) [ 933/3862 ( 24%)]  Loss: 0.9064 (1.02)  LR: 5.206e-05  Grad: 27.1963  max=1.1066(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1828(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3267, loss_cls=0.0610, loss_bbox=0.3318, matched_ious=0.6129, loss_iou=0.0848, loss_iou_reg=0.1912, d_time=0.00(0.01), f_time=1.29(1.36), b_time=1.29(1.36)  Time cost: 21:13/1:06:33 [28:07:46/2:34:19]  Acc_iter 70450       Data time: 0.00(0.01)  Forward time: 1.29(1.36)  Batch time: 1.29(1.36)
2025-09-04 13:24:43,316   INFO  Train:   19/20 ( 95%) [ 983/3862 ( 25%)]  Loss: 0.9267 (1.02)  LR: 5.131e-05  Grad: 27.1902  max=1.1141(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1812(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3277, loss_cls=0.0591, loss_bbox=0.3558, matched_ious=0.6191, loss_iou=0.0846, loss_iou_reg=0.1890, d_time=0.00(0.01), f_time=1.33(1.36), b_time=1.33(1.36)  Time cost: 22:21/1:05:24 [28:08:54/2:33:07]  Acc_iter 70500       Data time: 0.00(0.01)  Forward time: 1.33(1.36)  Batch time: 1.33(1.36)
2025-09-04 13:25:51,210   INFO  Train:   19/20 ( 95%) [1033/3862 ( 27%)]  Loss: 1.070 (1.02)  LR: 5.057e-05  Grad: 27.2423  max=1.1086(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1780(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3380, loss_cls=0.0619, loss_bbox=0.3690, matched_ious=0.6115, loss_iou=0.0845, loss_iou_reg=0.1939, d_time=0.00(0.01), f_time=1.28(1.36), b_time=1.28(1.36)  Time cost: 23:29/1:04:15 [28:10:02/2:31:58]  Acc_iter 70550       Data time: 0.00(0.01)  Forward time: 1.28(1.36)  Batch time: 1.28(1.36)
2025-09-04 13:26:59,505   INFO  Train:   19/20 ( 95%) [1083/3862 ( 28%)]  Loss: 0.9042 (1.02)  LR: 4.983e-05  Grad: 27.2065  max=1.1133(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1989(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3437, loss_cls=0.0629, loss_bbox=0.3612, matched_ious=0.6107, loss_iou=0.0865, loss_iou_reg=0.1939, d_time=0.00(0.01), f_time=1.29(1.36), b_time=1.29(1.36)  Time cost: 24:37/1:03:07 [28:11:10/2:30:50]  Acc_iter 70600       Data time: 0.00(0.01)  Forward time: 1.29(1.36)  Batch time: 1.29(1.36)
2025-09-04 13:28:08,009   INFO  Train:   19/20 ( 95%) [1133/3862 ( 29%)]  Loss: 0.9579 (1.02)  LR: 4.909e-05  Grad: 27.2043  max=1.1142(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2003(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3461, loss_cls=0.0620, loss_bbox=0.3698, matched_ious=0.6082, loss_iou=0.0847, loss_iou_reg=0.1910, d_time=0.01(0.01), f_time=1.22(1.36), b_time=1.23(1.36)  Time cost: 25:45/1:02:00 [28:12:19/2:29:44]  Acc_iter 70650       Data time: 0.01(0.01)  Forward time: 1.22(1.36)  Batch time: 1.23(1.36)
2025-09-04 13:29:16,278   INFO  Train:   19/20 ( 95%) [1183/3862 ( 31%)]  Loss: 0.8551 (1.02)  LR: 4.836e-05  Grad: 27.2366  max=1.1175(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1886(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3209, loss_cls=0.0594, loss_bbox=0.3576, matched_ious=0.6066, loss_iou=0.0864, loss_iou_reg=0.1927, d_time=0.01(0.01), f_time=1.23(1.36), b_time=1.24(1.36)  Time cost: 26:54/1:00:52 [28:13:27/2:28:37]  Acc_iter 70700       Data time: 0.01(0.01)  Forward time: 1.23(1.36)  Batch time: 1.24(1.36)
2025-09-04 13:30:24,472   INFO  Train:   19/20 ( 95%) [1233/3862 ( 32%)]  Loss: 1.123 (1.02)  LR: 4.764e-05  Grad: 27.2137  max=1.1192(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2008(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3684, loss_cls=0.0651, loss_bbox=0.3767, matched_ious=0.6066, loss_iou=0.0857, loss_iou_reg=0.1896, d_time=0.01(0.01), f_time=1.26(1.36), b_time=1.27(1.36)  Time cost: 28:02/59:44 [28:14:35/2:27:29]  Acc_iter 70750       Data time: 0.01(0.01)  Forward time: 1.26(1.36)  Batch time: 1.27(1.36)
2025-09-04 13:31:32,087   INFO  Train:   19/20 ( 95%) [1283/3862 ( 33%)]  Loss: 0.8450 (1.02)  LR: 4.692e-05  Grad: 27.2246  max=1.1245(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1817(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3268, loss_cls=0.0585, loss_bbox=0.3225, matched_ious=0.6199, loss_iou=0.0838, loss_iou_reg=0.1904, d_time=0.01(0.01), f_time=1.33(1.36), b_time=1.33(1.36)  Time cost: 29:09/58:34 [28:15:43/2:26:18]  Acc_iter 70800       Data time: 0.01(0.01)  Forward time: 1.33(1.36)  Batch time: 1.33(1.36)
2025-09-04 13:32:40,569   INFO  Train:   19/20 ( 95%) [1333/3862 ( 35%)]  Loss: 1.349 (1.02)  LR: 4.620e-05  Grad: 27.1972  max=1.1192(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2060(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3489, loss_cls=0.0628, loss_bbox=0.3462, matched_ious=0.6125, loss_iou=0.0826, loss_iou_reg=0.1866, d_time=0.00(0.01), f_time=1.45(1.36), b_time=1.46(1.36)  Time cost: 30:18/57:27 [28:16:51/2:25:11]  Acc_iter 70850       Data time: 0.00(0.01)  Forward time: 1.45(1.36)  Batch time: 1.46(1.36)
2025-09-04 13:33:49,295   INFO  Train:   19/20 ( 95%) [1383/3862 ( 36%)]  Loss: 1.161 (1.02)  LR: 4.549e-05  Grad: 27.2469  max=1.1211(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2037(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3485, loss_cls=0.0610, loss_bbox=0.3520, matched_ious=0.6170, loss_iou=0.0836, loss_iou_reg=0.1908, d_time=0.00(0.01), f_time=1.32(1.36), b_time=1.33(1.36)  Time cost: 31:27/56:20 [28:18:00/2:24:06]  Acc_iter 70900       Data time: 0.00(0.01)  Forward time: 1.32(1.36)  Batch time: 1.33(1.36)
2025-09-04 13:34:57,454   INFO  Train:   19/20 ( 95%) [1433/3862 ( 37%)]  Loss: 1.034 (1.02)  LR: 4.479e-05  Grad: 27.2366  max=1.1210(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2019(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3333, loss_cls=0.0617, loss_bbox=0.3771, matched_ious=0.6097, loss_iou=0.0851, loss_iou_reg=0.1921, d_time=0.00(0.01), f_time=1.43(1.36), b_time=1.43(1.36)  Time cost: 32:35/55:12 [28:19:08/2:22:58]  Acc_iter 70950       Data time: 0.00(0.01)  Forward time: 1.43(1.36)  Batch time: 1.43(1.36)
2025-09-04 13:36:04,725   INFO  Train:   19/20 ( 95%) [1483/3862 ( 38%)]  Loss: 1.224 (1.03)  LR: 4.409e-05  Grad: 27.2259  max=1.1239(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2009(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3452, loss_cls=0.0625, loss_bbox=0.3630, matched_ious=0.6053, loss_iou=0.0861, loss_iou_reg=0.1939, d_time=0.00(0.01), f_time=1.27(1.36), b_time=1.28(1.36)  Time cost: 33:42/54:02 [28:20:15/2:21:46]  Acc_iter 71000       Data time: 0.00(0.01)  Forward time: 1.27(1.36)  Batch time: 1.28(1.36)
2025-09-04 13:37:12,648   INFO  Train:   19/20 ( 95%) [1533/3862 ( 40%)]  Loss: 0.9020 (1.03)  LR: 4.340e-05  Grad: 27.2518  max=1.1217(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1936(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3277, loss_cls=0.0609, loss_bbox=0.3569, matched_ious=0.6126, loss_iou=0.0841, loss_iou_reg=0.1886, d_time=0.00(0.01), f_time=1.50(1.36), b_time=1.51(1.36)  Time cost: 34:50/52:53 [28:21:23/2:20:37]  Acc_iter 71050       Data time: 0.00(0.01)  Forward time: 1.50(1.36)  Batch time: 1.51(1.36)
2025-09-04 13:38:20,171   INFO  Train:   19/20 ( 95%) [1583/3862 ( 41%)]  Loss: 0.8983 (1.02)  LR: 4.271e-05  Grad: 27.2652  max=1.1233(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1973(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3211, loss_cls=0.0593, loss_bbox=0.3241, matched_ious=0.6212, loss_iou=0.0830, loss_iou_reg=0.1872, d_time=0.00(0.01), f_time=1.29(1.36), b_time=1.30(1.36)  Time cost: 35:58/51:44 [28:22:31/2:19:26]  Acc_iter 71100       Data time: 0.00(0.01)  Forward time: 1.29(1.36)  Batch time: 1.30(1.36)
2025-09-04 13:39:28,304   INFO  Train:   19/20 ( 95%) [1633/3862 ( 42%)]  Loss: 0.9477 (1.03)  LR: 4.203e-05  Grad: 27.2848  max=1.1216(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1898(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3486, loss_cls=0.0645, loss_bbox=0.3799, matched_ious=0.6007, loss_iou=0.0846, loss_iou_reg=0.1970, d_time=0.01(0.01), f_time=1.28(1.36), b_time=1.29(1.36)  Time cost: 37:06/50:36 [28:23:39/2:18:18]  Acc_iter 71150       Data time: 0.01(0.01)  Forward time: 1.28(1.36)  Batch time: 1.29(1.36)
2025-09-04 13:40:36,468   INFO  Train:   19/20 ( 95%) [1683/3862 ( 44%)]  Loss: 1.249 (1.02)  LR: 4.135e-05  Grad: 27.2829  max=1.1236(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1889(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3343, loss_cls=0.0586, loss_bbox=0.3506, matched_ious=0.6137, loss_iou=0.0833, loss_iou_reg=0.1912, d_time=0.00(0.01), f_time=1.50(1.36), b_time=1.51(1.36)  Time cost: 38:14/49:28 [28:24:47/2:17:10]  Acc_iter 71200       Data time: 0.00(0.01)  Forward time: 1.50(1.36)  Batch time: 1.51(1.36)
2025-09-04 13:41:44,852   INFO  Train:   19/20 ( 95%) [1733/3862 ( 45%)]  Loss: 0.9634 (1.03)  LR: 4.068e-05  Grad: 27.2785  max=1.1242(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1800(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3353, loss_cls=0.0594, loss_bbox=0.3664, matched_ious=0.6128, loss_iou=0.0849, loss_iou_reg=0.1948, d_time=0.00(0.01), f_time=1.41(1.36), b_time=1.42(1.36)  Time cost: 39:22/48:20 [28:25:55/2:16:03]  Acc_iter 71250       Data time: 0.00(0.01)  Forward time: 1.41(1.36)  Batch time: 1.42(1.36)
2025-09-04 13:42:53,812   INFO  Train:   19/20 ( 95%) [1783/3862 ( 46%)]  Loss: 0.9241 (1.03)  LR: 4.001e-05  Grad: 27.2996  max=1.1151(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1907(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3375, loss_cls=0.0610, loss_bbox=0.3581, matched_ious=0.6115, loss_iou=0.0866, loss_iou_reg=0.1951, d_time=0.01(0.01), f_time=1.20(1.36), b_time=1.21(1.36)  Time cost: 40:31/47:13 [28:27:04/2:14:57]  Acc_iter 71300       Data time: 0.01(0.01)  Forward time: 1.20(1.36)  Batch time: 1.21(1.36)
2025-09-04 13:44:02,227   INFO  Train:   19/20 ( 95%) [1833/3862 ( 47%)]  Loss: 0.9639 (1.02)  LR: 3.935e-05  Grad: 27.2789  max=1.1146(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1920(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3126, loss_cls=0.0544, loss_bbox=0.3470, matched_ious=0.6149, loss_iou=0.0831, loss_iou_reg=0.1900, d_time=0.00(0.01), f_time=1.32(1.36), b_time=1.32(1.36)  Time cost: 41:40/46:05 [28:28:13/2:13:50]  Acc_iter 71350       Data time: 0.00(0.01)  Forward time: 1.32(1.36)  Batch time: 1.32(1.36)
2025-09-04 13:45:10,814   INFO  Train:   19/20 ( 95%) [1883/3862 ( 49%)]  Loss: 0.9907 (1.02)  LR: 3.869e-05  Grad: 27.3342  max=1.1192(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1812(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3312, loss_cls=0.0592, loss_bbox=0.3555, matched_ious=0.6123, loss_iou=0.0842, loss_iou_reg=0.1928, d_time=0.00(0.01), f_time=1.31(1.36), b_time=1.31(1.36)  Time cost: 42:48/44:58 [28:29:21/2:12:43]  Acc_iter 71400       Data time: 0.00(0.01)  Forward time: 1.31(1.36)  Batch time: 1.31(1.36)
2025-09-04 13:46:19,527   INFO  Train:   19/20 ( 95%) [1933/3862 ( 50%)]  Loss: 1.021 (1.02)  LR: 3.804e-05  Grad: 27.3650  max=1.1119(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1777(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3227, loss_cls=0.0564, loss_bbox=0.3362, matched_ious=0.6200, loss_iou=0.0828, loss_iou_reg=0.1890, d_time=0.00(0.01), f_time=1.42(1.36), b_time=1.42(1.36)  Time cost: 43:57/43:50 [28:30:30/2:11:37]  Acc_iter 71450       Data time: 0.00(0.01)  Forward time: 1.42(1.36)  Batch time: 1.42(1.36)
2025-09-04 13:47:28,450   INFO  Train:   19/20 ( 95%) [1983/3862 ( 51%)]  Loss: 0.7912 (1.02)  LR: 3.740e-05  Grad: 27.3876  max=1.1145(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1747(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3190, loss_cls=0.0581, loss_bbox=0.3140, matched_ious=0.6224, loss_iou=0.0831, loss_iou_reg=0.1875, d_time=0.00(0.01), f_time=1.22(1.36), b_time=1.23(1.36)  Time cost: 45:06/42:43 [28:31:39/2:10:31]  Acc_iter 71500       Data time: 0.00(0.01)  Forward time: 1.22(1.36)  Batch time: 1.23(1.36)
2025-09-04 13:48:36,652   INFO  Train:   19/20 ( 95%) [2033/3862 ( 53%)]  Loss: 0.8359 (1.02)  LR: 3.676e-05  Grad: 27.3767  max=1.1192(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1737(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3511, loss_cls=0.0641, loss_bbox=0.3550, matched_ious=0.6105, loss_iou=0.0846, loss_iou_reg=0.1909, d_time=0.01(0.01), f_time=1.22(1.36), b_time=1.22(1.36)  Time cost: 46:14/41:34 [28:32:47/2:09:22]  Acc_iter 71550       Data time: 0.01(0.01)  Forward time: 1.22(1.36)  Batch time: 1.22(1.36)
2025-09-04 13:49:43,396   INFO  Train:   19/20 ( 95%) [2083/3862 ( 54%)]  Loss: 1.333 (1.02)  LR: 3.612e-05  Grad: 27.3642  max=1.1234(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1853(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3232, loss_cls=0.0578, loss_bbox=0.3438, matched_ious=0.6147, loss_iou=0.0856, loss_iou_reg=0.1923, d_time=0.00(0.01), f_time=1.23(1.36), b_time=1.24(1.36)  Time cost: 47:21/40:25 [28:33:54/2:08:10]  Acc_iter 71600       Data time: 0.00(0.01)  Forward time: 1.23(1.36)  Batch time: 1.24(1.36)
2025-09-04 13:50:51,323   INFO  Train:   19/20 ( 95%) [2133/3862 ( 55%)]  Loss: 1.010 (1.02)  LR: 3.549e-05  Grad: 27.3705  max=1.1333(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1848(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3204, loss_cls=0.0604, loss_bbox=0.3411, matched_ious=0.6250, loss_iou=0.0824, loss_iou_reg=0.1882, d_time=0.00(0.01), f_time=1.30(1.36), b_time=1.31(1.36)  Time cost: 48:29/39:17 [28:35:02/2:07:01]  Acc_iter 71650       Data time: 0.00(0.01)  Forward time: 1.30(1.36)  Batch time: 1.31(1.36)
2025-09-04 13:52:00,042   INFO  Train:   19/20 ( 95%) [2183/3862 ( 57%)]  Loss: 0.9336 (1.02)  LR: 3.487e-05  Grad: 27.3903  max=1.1296(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1864(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3169, loss_cls=0.0581, loss_bbox=0.3291, matched_ious=0.6132, loss_iou=0.0842, loss_iou_reg=0.1923, d_time=0.01(0.01), f_time=1.39(1.36), b_time=1.40(1.36)  Time cost: 49:37/38:09 [28:36:11/2:05:55]  Acc_iter 71700       Data time: 0.01(0.01)  Forward time: 1.39(1.36)  Batch time: 1.40(1.36)
2025-09-04 13:53:09,214   INFO  Train:   19/20 ( 95%) [2233/3862 ( 58%)]  Loss: 0.9733 (1.02)  LR: 3.425e-05  Grad: 27.4095  max=1.1248(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1869(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3513, loss_cls=0.0629, loss_bbox=0.3683, matched_ious=0.6147, loss_iou=0.0846, loss_iou_reg=0.1928, d_time=0.00(0.01), f_time=1.39(1.36), b_time=1.39(1.36)  Time cost: 50:47/37:01 [28:37:20/2:04:49]  Acc_iter 71750       Data time: 0.00(0.01)  Forward time: 1.39(1.36)  Batch time: 1.39(1.36)
2025-09-04 13:54:17,128   INFO  Train:   19/20 ( 95%) [2283/3862 ( 59%)]  Loss: 1.069 (1.02)  LR: 3.364e-05  Grad: 27.4112  max=1.1245(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2005(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3374, loss_cls=0.0613, loss_bbox=0.3426, matched_ious=0.6115, loss_iou=0.0846, loss_iou_reg=0.1908, d_time=0.00(0.01), f_time=1.35(1.36), b_time=1.35(1.36)  Time cost: 51:54/35:53 [28:38:28/2:03:40]  Acc_iter 71800       Data time: 0.00(0.01)  Forward time: 1.35(1.36)  Batch time: 1.35(1.36)
2025-09-04 13:55:25,003   INFO  Train:   19/20 ( 95%) [2333/3862 ( 60%)]  Loss: 0.8980 (1.02)  LR: 3.303e-05  Grad: 27.3782  max=1.1236(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2103(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3373, loss_cls=0.0610, loss_bbox=0.3623, matched_ious=0.6027, loss_iou=0.0863, loss_iou_reg=0.1966, d_time=0.00(0.01), f_time=1.55(1.36), b_time=1.55(1.36)  Time cost: 53:02/34:45 [28:39:36/2:02:31]  Acc_iter 71850       Data time: 0.00(0.01)  Forward time: 1.55(1.36)  Batch time: 1.55(1.36)
2025-09-04 13:56:33,238   INFO  Train:   19/20 ( 95%) [2383/3862 ( 62%)]  Loss: 0.8798 (1.02)  LR: 3.242e-05  Grad: 27.4014  max=1.1230(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2035(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3227, loss_cls=0.0586, loss_bbox=0.3597, matched_ious=0.6108, loss_iou=0.0846, loss_iou_reg=0.1935, d_time=0.00(0.01), f_time=1.40(1.36), b_time=1.40(1.36)  Time cost: 54:11/33:36 [28:40:44/2:01:23]  Acc_iter 71900       Data time: 0.00(0.01)  Forward time: 1.40(1.36)  Batch time: 1.40(1.36)
2025-09-04 13:57:41,389   INFO  Train:   19/20 ( 95%) [2433/3862 ( 63%)]  Loss: 0.9137 (1.02)  LR: 3.183e-05  Grad: 27.3671  max=1.1216(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2259(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3235, loss_cls=0.0585, loss_bbox=0.3370, matched_ious=0.6170, loss_iou=0.0841, loss_iou_reg=0.1863, d_time=0.00(0.01), f_time=1.43(1.36), b_time=1.44(1.36)  Time cost: 55:19/32:28 [28:41:52/2:00:15]  Acc_iter 71950       Data time: 0.00(0.01)  Forward time: 1.43(1.36)  Batch time: 1.44(1.36)
2025-09-04 13:58:49,641   INFO  Train:   19/20 ( 95%) [2483/3862 ( 64%)]  Loss: 1.013 (1.02)  LR: 3.124e-05  Grad: 27.3875  max=1.1268(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2115(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3381, loss_cls=0.0595, loss_bbox=0.3641, matched_ious=0.6136, loss_iou=0.0857, loss_iou_reg=0.1901, d_time=0.00(0.01), f_time=1.31(1.36), b_time=1.31(1.36)  Time cost: 56:27/31:20 [28:43:00/1:59:07]  Acc_iter 72000       Data time: 0.00(0.01)  Forward time: 1.31(1.36)  Batch time: 1.31(1.36)
2025-09-04 13:59:57,087   INFO  Train:   19/20 ( 95%) [2533/3862 ( 66%)]  Loss: 0.9270 (1.02)  LR: 3.065e-05  Grad: 27.4168  max=1.1240(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2108(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3272, loss_cls=0.0587, loss_bbox=0.3366, matched_ious=0.6168, loss_iou=0.0829, loss_iou_reg=0.1870, d_time=0.00(0.01), f_time=1.28(1.36), b_time=1.28(1.36)  Time cost: 57:34/30:12 [28:44:08/1:57:57]  Acc_iter 72050       Data time: 0.00(0.01)  Forward time: 1.28(1.36)  Batch time: 1.28(1.36)
2025-09-04 14:01:04,660   INFO  Train:   19/20 ( 95%) [2583/3862 ( 67%)]  Loss: 1.300 (1.02)  LR: 3.007e-05  Grad: 27.4254  max=1.1190(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2146(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3336, loss_cls=0.0595, loss_bbox=0.3602, matched_ious=0.6196, loss_iou=0.0836, loss_iou_reg=0.1887, d_time=0.01(0.01), f_time=1.35(1.36), b_time=1.36(1.36)  Time cost: 58:42/29:03 [28:45:15/1:56:48]  Acc_iter 72100       Data time: 0.01(0.01)  Forward time: 1.35(1.36)  Batch time: 1.36(1.36)
2025-09-04 14:02:12,947   INFO  Train:   19/20 ( 95%) [2633/3862 ( 68%)]  Loss: 0.9829 (1.02)  LR: 2.949e-05  Grad: 27.4557  max=1.1270(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2028(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3368, loss_cls=0.0619, loss_bbox=0.3423, matched_ious=0.6092, loss_iou=0.0849, loss_iou_reg=0.1913, d_time=0.00(0.01), f_time=1.28(1.36), b_time=1.29(1.36)  Time cost: 59:50/27:55 [28:46:24/1:55:40]  Acc_iter 72150       Data time: 0.00(0.01)  Forward time: 1.28(1.36)  Batch time: 1.29(1.36)
2025-09-04 14:03:20,548   INFO  Train:   19/20 ( 95%) [2683/3862 ( 69%)]  Loss: 0.9735 (1.02)  LR: 2.892e-05  Grad: 27.4777  max=1.1249(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2039(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3248, loss_cls=0.0586, loss_bbox=0.3349, matched_ious=0.6166, loss_iou=0.0849, loss_iou_reg=0.1885, d_time=0.00(0.01), f_time=1.24(1.36), b_time=1.25(1.36)  Time cost: 1:00:58/26:47 [28:47:31/1:54:31]  Acc_iter 72200       Data time: 0.00(0.01)  Forward time: 1.24(1.36)  Batch time: 1.25(1.36)
2025-09-04 14:04:28,805   INFO  Train:   19/20 ( 95%) [2733/3862 ( 71%)]  Loss: 1.145 (1.02)  LR: 2.836e-05  Grad: 27.5174  max=1.1186(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2108(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3172, loss_cls=0.0574, loss_bbox=0.3242, matched_ious=0.6208, loss_iou=0.0819, loss_iou_reg=0.1867, d_time=0.01(0.01), f_time=1.25(1.36), b_time=1.26(1.36)  Time cost: 1:02:06/25:38 [28:48:39/1:53:23]  Acc_iter 72250       Data time: 0.01(0.01)  Forward time: 1.25(1.36)  Batch time: 1.26(1.36)
2025-09-04 14:05:37,104   INFO  Train:   19/20 ( 95%) [2783/3862 ( 72%)]  Loss: 0.7837 (1.02)  LR: 2.780e-05  Grad: 27.5465  max=1.1195(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2013(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3339, loss_cls=0.0598, loss_bbox=0.3378, matched_ious=0.6209, loss_iou=0.0843, loss_iou_reg=0.1872, d_time=0.01(0.01), f_time=1.31(1.36), b_time=1.31(1.36)  Time cost: 1:03:14/24:30 [28:49:48/1:52:15]  Acc_iter 72300       Data time: 0.01(0.01)  Forward time: 1.31(1.36)  Batch time: 1.31(1.36)
2025-09-04 14:06:44,751   INFO  Train:   19/20 ( 95%) [2833/3862 ( 73%)]  Loss: 1.078 (1.02)  LR: 2.724e-05  Grad: 27.5131  max=1.1187(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2119(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3439, loss_cls=0.0602, loss_bbox=0.3817, matched_ious=0.6196, loss_iou=0.0853, loss_iou_reg=0.1885, d_time=0.01(0.01), f_time=1.28(1.36), b_time=1.28(1.36)  Time cost: 1:04:22/23:22 [28:50:55/1:51:06]  Acc_iter 72350       Data time: 0.01(0.01)  Forward time: 1.28(1.36)  Batch time: 1.28(1.36)
2025-09-04 14:07:53,306   INFO  Train:   19/20 ( 95%) [2883/3862 ( 75%)]  Loss: 0.7949 (1.02)  LR: 2.669e-05  Grad: 27.5383  max=1.1132(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2041(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3378, loss_cls=0.0602, loss_bbox=0.3367, matched_ious=0.6190, loss_iou=0.0833, loss_iou_reg=0.1871, d_time=0.00(0.01), f_time=1.34(1.36), b_time=1.35(1.36)  Time cost: 1:05:31/22:14 [28:52:04/1:49:58]  Acc_iter 72400       Data time: 0.00(0.01)  Forward time: 1.34(1.36)  Batch time: 1.35(1.36)
2025-09-04 14:09:00,354   INFO  Train:   19/20 ( 95%) [2933/3862 ( 76%)]  Loss: 0.8926 (1.02)  LR: 2.615e-05  Grad: 27.5242  max=1.1159(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2147(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3437, loss_cls=0.0620, loss_bbox=0.3412, matched_ious=0.6167, loss_iou=0.0862, loss_iou_reg=0.1905, d_time=0.01(0.01), f_time=1.38(1.36), b_time=1.38(1.36)  Time cost: 1:06:38/21:05 [28:53:11/1:48:48]  Acc_iter 72450       Data time: 0.01(0.01)  Forward time: 1.38(1.36)  Batch time: 1.38(1.36)
2025-09-04 14:10:08,282   INFO  Train:   19/20 ( 95%) [2983/3862 ( 77%)]  Loss: 1.058 (1.02)  LR: 2.561e-05  Grad: 27.5484  max=1.1308(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2081(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3157, loss_cls=0.0612, loss_bbox=0.3309, matched_ious=0.6191, loss_iou=0.0856, loss_iou_reg=0.1885, d_time=0.01(0.01), f_time=1.59(1.36), b_time=1.60(1.36)  Time cost: 1:07:46/19:57 [28:54:19/1:47:40]  Acc_iter 72500       Data time: 0.01(0.01)  Forward time: 1.59(1.36)  Batch time: 1.60(1.36)
2025-09-04 14:11:16,207   INFO  Train:   19/20 ( 95%) [3033/3862 ( 79%)]  Loss: 1.011 (1.02)  LR: 2.508e-05  Grad: 27.5727  max=1.1329(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2148(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3311, loss_cls=0.0583, loss_bbox=0.3413, matched_ious=0.6201, loss_iou=0.0830, loss_iou_reg=0.1882, d_time=0.01(0.01), f_time=1.29(1.36), b_time=1.30(1.36)  Time cost: 1:08:54/18:49 [28:55:27/1:46:31]  Acc_iter 72550       Data time: 0.01(0.01)  Forward time: 1.29(1.36)  Batch time: 1.30(1.36)
2025-09-04 14:12:24,156   INFO  Train:   19/20 ( 95%) [3083/3862 ( 80%)]  Loss: 0.7682 (1.02)  LR: 2.455e-05  Grad: 27.5376  max=1.1307(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2287(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3546, loss_cls=0.0611, loss_bbox=0.3524, matched_ious=0.6103, loss_iou=0.0833, loss_iou_reg=0.1904, d_time=0.03(0.01), f_time=1.50(1.36), b_time=1.53(1.36)  Time cost: 1:10:02/17:41 [28:56:35/1:45:23]  Acc_iter 72600       Data time: 0.03(0.01)  Forward time: 1.50(1.36)  Batch time: 1.53(1.36)
2025-09-04 14:13:31,419   INFO  Train:   19/20 ( 95%) [3133/3862 ( 81%)]  Loss: 1.011 (1.02)  LR: 2.403e-05  Grad: 27.5262  max=1.1350(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2392(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3104, loss_cls=0.0569, loss_bbox=0.3545, matched_ious=0.6179, loss_iou=0.0838, loss_iou_reg=0.1912, d_time=0.00(0.01), f_time=1.27(1.36), b_time=1.28(1.36)  Time cost: 1:11:09/16:33 [28:57:42/1:44:14]  Acc_iter 72650       Data time: 0.00(0.01)  Forward time: 1.27(1.36)  Batch time: 1.28(1.36)
2025-09-04 14:14:38,820   INFO  Train:   19/20 ( 95%) [3183/3862 ( 82%)]  Loss: 1.069 (1.02)  LR: 2.351e-05  Grad: 27.5847  max=1.1457(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2003(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3356, loss_cls=0.0629, loss_bbox=0.3452, matched_ious=0.6198, loss_iou=0.0823, loss_iou_reg=0.1873, d_time=0.01(0.01), f_time=1.35(1.36), b_time=1.36(1.36)  Time cost: 1:12:16/15:24 [28:58:49/1:43:04]  Acc_iter 72700       Data time: 0.01(0.01)  Forward time: 1.35(1.36)  Batch time: 1.36(1.36)
2025-09-04 14:15:46,331   INFO  Train:   19/20 ( 95%) [3233/3862 ( 84%)]  Loss: 0.9512 (1.02)  LR: 2.300e-05  Grad: 27.5917  max=1.1417(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1899(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3175, loss_cls=0.0599, loss_bbox=0.3500, matched_ious=0.6129, loss_iou=0.0827, loss_iou_reg=0.1913, d_time=0.00(0.01), f_time=1.37(1.36), b_time=1.38(1.36)  Time cost: 1:13:24/14:16 [28:59:57/1:41:56]  Acc_iter 72750       Data time: 0.00(0.01)  Forward time: 1.37(1.36)  Batch time: 1.38(1.36)
2025-09-04 14:16:54,326   INFO  Train:   19/20 ( 95%) [3283/3862 ( 85%)]  Loss: 0.7010 (1.02)  LR: 2.250e-05  Grad: 27.6125  max=1.1382(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1934(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3315, loss_cls=0.0589, loss_bbox=0.3306, matched_ious=0.6198, loss_iou=0.0842, loss_iou_reg=0.1882, d_time=0.00(0.01), f_time=1.41(1.36), b_time=1.42(1.36)  Time cost: 1:14:32/13:08 [29:01:05/1:40:47]  Acc_iter 72800       Data time: 0.00(0.01)  Forward time: 1.41(1.36)  Batch time: 1.42(1.36)
2025-09-04 14:18:02,583   INFO  Train:   19/20 ( 95%) [3333/3862 ( 86%)]  Loss: 0.7524 (1.02)  LR: 2.200e-05  Grad: 27.6064  max=1.1341(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1983(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3423, loss_cls=0.0608, loss_bbox=0.3338, matched_ious=0.6193, loss_iou=0.0833, loss_iou_reg=0.1867, d_time=0.00(0.01), f_time=1.34(1.36), b_time=1.34(1.36)  Time cost: 1:15:40/12:00 [29:02:13/1:39:39]  Acc_iter 72850       Data time: 0.00(0.01)  Forward time: 1.34(1.36)  Batch time: 1.34(1.36)
2025-09-04 14:19:09,419   INFO  Train:   19/20 ( 95%) [3383/3862 ( 88%)]  Loss: 0.9624 (1.02)  LR: 2.150e-05  Grad: 27.7000  max=1.1319(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1765(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3306, loss_cls=0.0583, loss_bbox=0.3283, matched_ious=0.6107, loss_iou=0.0837, loss_iou_reg=0.1911, d_time=0.00(0.01), f_time=1.35(1.36), b_time=1.35(1.36)  Time cost: 1:16:47/10:52 [29:03:20/1:38:30]  Acc_iter 72900       Data time: 0.00(0.01)  Forward time: 1.35(1.36)  Batch time: 1.35(1.36)
2025-09-04 14:20:16,167   INFO  Train:   19/20 ( 95%) [3433/3862 ( 89%)]  Loss: 0.8870 (1.02)  LR: 2.101e-05  Grad: 27.6195  max=1.1288(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2060(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3201, loss_cls=0.0565, loss_bbox=0.3233, matched_ious=0.6190, loss_iou=0.0856, loss_iou_reg=0.1895, d_time=0.00(0.01), f_time=1.62(1.35), b_time=1.62(1.36)  Time cost: 1:17:54/09:43 [29:04:27/1:37:20]  Acc_iter 72950       Data time: 0.00(0.01)  Forward time: 1.62(1.35)  Batch time: 1.62(1.36)
2025-09-04 14:21:23,692   INFO  Train:   19/20 ( 95%) [3483/3862 ( 90%)]  Loss: 1.141 (1.02)  LR: 2.053e-05  Grad: 27.5988  max=1.1286(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2170(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3388, loss_cls=0.0608, loss_bbox=0.3376, matched_ious=0.6189, loss_iou=0.0838, loss_iou_reg=0.1910, d_time=0.00(0.01), f_time=1.42(1.35), b_time=1.43(1.36)  Time cost: 1:19:01/08:35 [29:05:34/1:36:11]  Acc_iter 73000       Data time: 0.00(0.01)  Forward time: 1.42(1.35)  Batch time: 1.43(1.36)
2025-09-04 14:22:31,767   INFO  Train:   19/20 ( 95%) [3533/3862 ( 91%)]  Loss: 1.162 (1.02)  LR: 2.005e-05  Grad: 27.6145  max=1.1316(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2089(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3337, loss_cls=0.0595, loss_bbox=0.3590, matched_ious=0.6116, loss_iou=0.0841, loss_iou_reg=0.1903, d_time=0.01(0.01), f_time=1.41(1.35), b_time=1.41(1.36)  Time cost: 1:20:09/07:27 [29:06:42/1:35:03]  Acc_iter 73050       Data time: 0.01(0.01)  Forward time: 1.41(1.35)  Batch time: 1.41(1.36)
2025-09-04 14:23:39,159   INFO  Train:   19/20 ( 95%) [3583/3862 ( 93%)]  Loss: 1.092 (1.02)  LR: 1.958e-05  Grad: 27.6311  max=1.1386(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2132(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3243, loss_cls=0.0594, loss_bbox=0.3414, matched_ious=0.6117, loss_iou=0.0849, loss_iou_reg=0.1924, d_time=0.01(0.01), f_time=1.29(1.35), b_time=1.30(1.36)  Time cost: 1:21:17/06:19 [29:07:50/1:33:54]  Acc_iter 73100       Data time: 0.01(0.01)  Forward time: 1.29(1.35)  Batch time: 1.30(1.36)
2025-09-04 14:24:47,513   INFO  Train:   19/20 ( 95%) [3633/3862 ( 94%)]  Loss: 0.8859 (1.02)  LR: 1.911e-05  Grad: 27.6627  max=1.1387(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1903(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3207, loss_cls=0.0572, loss_bbox=0.3564, matched_ious=0.6237, loss_iou=0.0834, loss_iou_reg=0.1865, d_time=0.01(0.01), f_time=1.29(1.35), b_time=1.30(1.36)  Time cost: 1:22:25/05:11 [29:08:58/1:32:47]  Acc_iter 73150       Data time: 0.01(0.01)  Forward time: 1.29(1.35)  Batch time: 1.30(1.36)
2025-09-04 14:25:55,273   INFO  Train:   19/20 ( 95%) [3683/3862 ( 95%)]  Loss: 1.068 (1.02)  LR: 1.865e-05  Grad: 27.6530  max=1.1416(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2074(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3462, loss_cls=0.0614, loss_bbox=0.3575, matched_ious=0.6103, loss_iou=0.0858, loss_iou_reg=0.1911, d_time=0.00(0.01), f_time=1.26(1.35), b_time=1.27(1.36)  Time cost: 1:23:33/04:03 [29:10:06/1:31:38]  Acc_iter 73200       Data time: 0.00(0.01)  Forward time: 1.26(1.35)  Batch time: 1.27(1.36)
2025-09-04 14:27:03,573   INFO  Train:   19/20 ( 95%) [3733/3862 ( 97%)]  Loss: 0.8692 (1.02)  LR: 1.820e-05  Grad: 27.6765  max=1.1331(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2061(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3240, loss_cls=0.0577, loss_bbox=0.3477, matched_ious=0.6152, loss_iou=0.0824, loss_iou_reg=0.1905, d_time=0.01(0.01), f_time=1.38(1.35), b_time=1.38(1.36)  Time cost: 1:24:41/02:55 [29:11:14/1:30:31]  Acc_iter 73250       Data time: 0.01(0.01)  Forward time: 1.38(1.35)  Batch time: 1.38(1.36)
2025-09-04 14:28:11,084   INFO  Train:   19/20 ( 95%) [3783/3862 ( 98%)]  Loss: 1.030 (1.02)  LR: 1.775e-05  Grad: 27.6592  max=1.1398(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2066(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3271, loss_cls=0.0592, loss_bbox=0.3409, matched_ious=0.6146, loss_iou=0.0862, loss_iou_reg=0.1938, d_time=0.01(0.01), f_time=1.25(1.35), b_time=1.25(1.36)  Time cost: 1:25:48/01:47 [29:12:22/1:29:22]  Acc_iter 73300       Data time: 0.01(0.01)  Forward time: 1.25(1.35)  Batch time: 1.25(1.36)
2025-09-04 14:29:20,136   INFO  Train:   19/20 ( 95%) [3833/3862 ( 99%)]  Loss: 0.9855 (1.02)  LR: 1.730e-05  Grad: 27.7054  max=1.1382(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1885(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3154, loss_cls=0.0568, loss_bbox=0.3533, matched_ious=0.6065, loss_iou=0.0853, loss_iou_reg=0.1930, d_time=0.00(0.01), f_time=1.40(1.35), b_time=1.40(1.36)  Time cost: 1:26:58/00:39 [29:13:31/1:28:15]  Acc_iter 73350       Data time: 0.00(0.01)  Forward time: 1.40(1.35)  Batch time: 1.40(1.36)
2025-09-04 14:29:56,955   INFO  Train:   19/20 ( 95%) [3861/3862 (100%)]  Loss: 1.162 (1.02)  LR: 1.706e-05  Grad: 27.6998  max=1.1383(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1940(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3199, loss_cls=0.0575, loss_bbox=0.3628, matched_ious=0.6253, loss_iou=0.0830, loss_iou_reg=0.1837, d_time=0.00(0.01), f_time=1.55(1.35), b_time=1.55(1.36)  Time cost: 1:27:34/00:01 [29:14:08/1:27:36]  Acc_iter 73378       Data time: 0.00(0.01)  Forward time: 1.55(1.35)  Batch time: 1.55(1.36)

                                               [Aepochs:  95%|█████████▌| 19/20 [29:14:08<1:29:33, 5373.64s/it]epochs:  95%|█████████▌| 19/20 [29:14:08<1:29:33, 5373.67s/it]epochs:  95%|█████████▌| 19/20 [29:14:08<1:29:33, 5373.66s/it]epochs:  95%|█████████▌| 19/20 [29:14:08<1:29:33, 5373.66s/it]epochs:  95%|█████████▌| 19/20 [29:14:08<1:29:33, 5373.66s/it]epochs:  95%|█████████▌| 19/20 [29:14:08<1:29:33, 5373.66s/it]epochs:  95%|█████████▌| 19/20 [29:14:08<1:29:33, 5373.68s/it]epochs:  95%|█████████▌| 19/20 [29:14:08<1:29:33, 5373.67s/it]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A2025-09-04 14:30:02,465   INFO  Train:   20/20 (100%) [   0/3862 (  0%)]  Loss: 0.9945 (0.995)  LR: 1.705e-05  Grad: 27.7082  max=1.1378(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1917(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3157, loss_cls=0.0586, loss_bbox=0.3528, matched_ious=0.6037, loss_iou=0.0834, loss_iou_reg=0.1840, d_time=1.50(1.50), f_time=2.79(2.79), b_time=4.29(4.29)  Time cost: 00:04/4:20:28 [29:14:13/4:20:28]  Acc_iter 73379       Data time: 1.50(1.50)  Forward time: 2.79(2.79)  Batch time: 4.29(4.29)
2025-09-04 14:30:32,178   INFO  Train:   20/20 (100%) [  21/3862 (  1%)]  Loss: 0.9209 (0.984)  LR: 1.686e-05  Grad: 27.7168  max=1.1416(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1938(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3231, loss_cls=0.0554, loss_bbox=0.3295, matched_ious=0.6163, loss_iou=0.0868, loss_iou_reg=0.1888, d_time=0.01(0.07), f_time=1.38(1.47), b_time=1.38(1.55)  Time cost: 00:33/1:38:14 [29:14:43/1:38:14]  Acc_iter 73400       Data time: 0.01(0.07)  Forward time: 1.38(1.47)  Batch time: 1.38(1.55)
2025-09-04 14:31:40,421   INFO  Train:   20/20 (100%) [  71/3862 (  2%)]  Loss: 1.029 (0.997)  LR: 1.643e-05  Grad: 27.7356  max=1.1434(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1849(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3197, loss_cls=0.0582, loss_bbox=0.3508, matched_ious=0.6123, loss_iou=0.0844, loss_iou_reg=0.1902, d_time=0.01(0.03), f_time=1.39(1.39), b_time=1.39(1.42)  Time cost: 01:42/1:29:30 [29:15:51/1:29:30]  Acc_iter 73450       Data time: 0.01(0.03)  Forward time: 1.39(1.39)  Batch time: 1.39(1.42)
2025-09-04 14:32:48,325   INFO  Train:   20/20 (100%) [ 121/3862 (  3%)]  Loss: 0.8091 (1.01)  LR: 1.600e-05  Grad: 27.7122  max=1.1364(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2020(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3439, loss_cls=0.0618, loss_bbox=0.3410, matched_ious=0.6126, loss_iou=0.0833, loss_iou_reg=0.1893, d_time=0.00(0.02), f_time=1.62(1.38), b_time=1.62(1.39)  Time cost: 02:49/1:26:50 [29:16:59/1:26:50]  Acc_iter 73500       Data time: 0.00(0.02)  Forward time: 1.62(1.38)  Batch time: 1.62(1.39)
2025-09-04 14:33:56,525   INFO  Train:   20/20 (100%) [ 171/3862 (  4%)]  Loss: 0.8701 (1.00)  LR: 1.558e-05  Grad: 27.7303  max=1.1382(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.1998(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3265, loss_cls=0.0592, loss_bbox=0.3342, matched_ious=0.6207, loss_iou=0.0844, loss_iou_reg=0.1901, d_time=0.00(0.01), f_time=1.30(1.37), b_time=1.31(1.39)  Time cost: 03:58/1:25:09 [29:18:07/1:25:09]  Acc_iter 73550       Data time: 0.00(0.01)  Forward time: 1.30(1.37)  Batch time: 1.31(1.39)
2025-09-04 14:35:03,437   INFO  Train:   20/20 (100%) [ 221/3862 (  6%)]  Loss: 0.8934 (1.00)  LR: 1.516e-05  Grad: 27.7323  max=1.1453(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2055(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3354, loss_cls=0.0594, loss_bbox=0.3377, matched_ious=0.6226, loss_iou=0.0835, loss_iou_reg=0.1896, d_time=0.00(0.01), f_time=1.37(1.36), b_time=1.37(1.38)  Time cost: 05:05/1:23:22 [29:19:14/1:23:22]  Acc_iter 73600       Data time: 0.00(0.01)  Forward time: 1.37(1.36)  Batch time: 1.37(1.38)
2025-09-04 14:36:11,765   INFO  Train:   20/20 (100%) [ 271/3862 (  7%)]  Loss: 1.015 (1.01)  LR: 1.475e-05  Grad: 27.7135  max=1.1402(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2270(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3388, loss_cls=0.0634, loss_bbox=0.3544, matched_ious=0.6069, loss_iou=0.0864, loss_iou_reg=0.1977, d_time=0.01(0.01), f_time=1.34(1.36), b_time=1.35(1.37)  Time cost: 06:13/1:22:09 [29:20:22/1:22:09]  Acc_iter 73650       Data time: 0.01(0.01)  Forward time: 1.34(1.36)  Batch time: 1.35(1.37)
2025-09-04 14:37:19,620   INFO  Train:   20/20 (100%) [ 321/3862 (  8%)]  Loss: 1.096 (1.01)  LR: 1.435e-05  Grad: 27.7256  max=1.1379(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2189(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3410, loss_cls=0.0602, loss_bbox=0.3400, matched_ious=0.6230, loss_iou=0.0832, loss_iou_reg=0.1850, d_time=0.00(0.01), f_time=1.44(1.36), b_time=1.44(1.37)  Time cost: 07:21/1:20:51 [29:21:30/1:20:51]  Acc_iter 73700       Data time: 0.00(0.01)  Forward time: 1.44(1.36)  Batch time: 1.44(1.37)
2025-09-04 14:38:28,058   INFO  Train:   20/20 (100%) [ 371/3862 ( 10%)]  Loss: 1.002 (1.01)  LR: 1.395e-05  Grad: 27.7501  max=1.1433(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2122(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3205, loss_cls=0.0569, loss_bbox=0.3385, matched_ious=0.6162, loss_iou=0.0859, loss_iou_reg=0.1906, d_time=0.00(0.01), f_time=1.33(1.36), b_time=1.33(1.37)  Time cost: 08:29/1:19:42 [29:22:39/1:19:42]  Acc_iter 73750       Data time: 0.00(0.01)  Forward time: 1.33(1.36)  Batch time: 1.33(1.37)
2025-09-04 14:39:36,532   INFO  Train:   20/20 (100%) [ 421/3862 ( 11%)]  Loss: 1.216 (1.01)  LR: 1.355e-05  Grad: 27.7623  max=1.1398(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2122(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3378, loss_cls=0.0608, loss_bbox=0.3641, matched_ious=0.5994, loss_iou=0.0853, loss_iou_reg=0.1982, d_time=0.00(0.01), f_time=1.29(1.36), b_time=1.29(1.37)  Time cost: 09:38/1:18:33 [29:23:47/1:18:33]  Acc_iter 73800       Data time: 0.00(0.01)  Forward time: 1.29(1.36)  Batch time: 1.29(1.37)
2025-09-04 14:40:45,295   INFO  Train:   20/20 (100%) [ 471/3862 ( 12%)]  Loss: 0.6942 (1.01)  LR: 1.316e-05  Grad: 27.7422  max=1.1388(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2105(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3236, loss_cls=0.0578, loss_bbox=0.3388, matched_ious=0.6159, loss_iou=0.0853, loss_iou_reg=0.1879, d_time=0.00(0.01), f_time=1.34(1.36), b_time=1.34(1.37)  Time cost: 10:46/1:17:27 [29:24:56/1:17:27]  Acc_iter 73850       Data time: 0.00(0.01)  Forward time: 1.34(1.36)  Batch time: 1.34(1.37)
2025-09-04 14:41:53,547   INFO  Train:   20/20 (100%) [ 521/3862 ( 13%)]  Loss: 1.055 (1.01)  LR: 1.278e-05  Grad: 27.8065  max=1.1481(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2043(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3195, loss_cls=0.0595, loss_bbox=0.3336, matched_ious=0.6082, loss_iou=0.0846, loss_iou_reg=0.1918, d_time=0.00(0.01), f_time=1.32(1.36), b_time=1.33(1.37)  Time cost: 11:55/1:16:17 [29:26:04/1:16:17]  Acc_iter 73900       Data time: 0.00(0.01)  Forward time: 1.32(1.36)  Batch time: 1.33(1.37)
2025-09-04 14:43:02,140   INFO  Train:   20/20 (100%) [ 571/3862 ( 15%)]  Loss: 1.050 (1.01)  LR: 1.240e-05  Grad: 27.8047  max=1.1433(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2222(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3350, loss_cls=0.0586, loss_bbox=0.3607, matched_ious=0.6154, loss_iou=0.0853, loss_iou_reg=0.1914, d_time=0.00(0.01), f_time=1.40(1.36), b_time=1.41(1.37)  Time cost: 13:03/1:15:09 [29:27:13/1:15:09]  Acc_iter 73950       Data time: 0.00(0.01)  Forward time: 1.40(1.36)  Batch time: 1.41(1.37)
2025-09-04 14:44:09,513   INFO  Train:   20/20 (100%) [ 621/3862 ( 16%)]  Loss: 0.9088 (1.01)  LR: 1.203e-05  Grad: 27.8314  max=1.1438(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2136(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3340, loss_cls=0.0585, loss_bbox=0.3409, matched_ious=0.6132, loss_iou=0.0858, loss_iou_reg=0.1904, d_time=0.00(0.01), f_time=1.27(1.36), b_time=1.28(1.37)  Time cost: 14:11/1:13:54 [29:28:20/1:13:54]  Acc_iter 74000       Data time: 0.00(0.01)  Forward time: 1.27(1.36)  Batch time: 1.28(1.37)
2025-09-04 14:45:16,700   INFO  Train:   20/20 (100%) [ 671/3862 ( 17%)]  Loss: 0.7963 (1.01)  LR: 1.166e-05  Grad: 27.7948  max=1.1455(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2265(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3331, loss_cls=0.0597, loss_bbox=0.3335, matched_ious=0.6111, loss_iou=0.0854, loss_iou_reg=0.1897, d_time=0.00(0.01), f_time=1.35(1.36), b_time=1.36(1.37)  Time cost: 15:18/1:12:40 [29:29:27/1:12:40]  Acc_iter 74050       Data time: 0.00(0.01)  Forward time: 1.35(1.36)  Batch time: 1.36(1.37)
2025-09-04 14:46:26,215   INFO  Train:   20/20 (100%) [ 721/3862 ( 19%)]  Loss: 0.9087 (1.01)  LR: 1.130e-05  Grad: 27.7547  max=1.1412(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2593(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3202, loss_cls=0.0585, loss_bbox=0.3432, matched_ious=0.6134, loss_iou=0.0847, loss_iou_reg=0.1934, d_time=0.01(0.01), f_time=1.33(1.36), b_time=1.34(1.37)  Time cost: 16:27/1:11:37 [29:30:37/1:11:37]  Acc_iter 74100       Data time: 0.01(0.01)  Forward time: 1.33(1.36)  Batch time: 1.34(1.37)
2025-09-04 14:47:34,243   INFO  Train:   20/20 (100%) [ 771/3862 ( 20%)]  Loss: 1.183 (1.01)  LR: 1.095e-05  Grad: 27.8128  max=1.2176(module.vfe.pfn_layers.0.linear.weight)  min: -1.2543(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3563, loss_cls=0.0616, loss_bbox=0.3618, matched_ious=0.6120, loss_iou=0.0861, loss_iou_reg=0.1917, d_time=0.01(0.01), f_time=1.43(1.36), b_time=1.43(1.37)  Time cost: 17:35/1:10:27 [29:31:45/1:10:27]  Acc_iter 74150       Data time: 0.01(0.01)  Forward time: 1.43(1.36)  Batch time: 1.43(1.37)
2025-09-04 14:48:41,620   INFO  Train:   20/20 (100%) [ 821/3862 ( 21%)]  Loss: 1.119 (1.01)  LR: 1.060e-05  Grad: 27.8215  max=1.1531(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2428(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3433, loss_cls=0.0618, loss_bbox=0.3452, matched_ious=0.6082, loss_iou=0.0842, loss_iou_reg=0.1895, d_time=0.00(0.01), f_time=1.39(1.36), b_time=1.40(1.37)  Time cost: 18:43/1:09:15 [29:32:52/1:09:15]  Acc_iter 74200       Data time: 0.00(0.01)  Forward time: 1.39(1.36)  Batch time: 1.40(1.37)
2025-09-04 14:49:50,356   INFO  Train:   20/20 (100%) [ 871/3862 ( 23%)]  Loss: 0.6303 (1.01)  LR: 1.025e-05  Grad: 27.8415  max=1.1568(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2364(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3079, loss_cls=0.0574, loss_bbox=0.3496, matched_ious=0.6134, loss_iou=0.0838, loss_iou_reg=0.1885, d_time=0.00(0.01), f_time=1.46(1.36), b_time=1.47(1.37)  Time cost: 19:51/1:08:08 [29:34:01/1:08:08]  Acc_iter 74250       Data time: 0.00(0.01)  Forward time: 1.46(1.36)  Batch time: 1.47(1.37)
2025-09-04 14:50:58,598   INFO  Train:   20/20 (100%) [ 921/3862 ( 24%)]  Loss: 0.9829 (1.01)  LR: 9.914e-06  Grad: 27.7758  max=1.1514(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2660(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3288, loss_cls=0.0595, loss_bbox=0.3586, matched_ious=0.6233, loss_iou=0.0818, loss_iou_reg=0.1887, d_time=0.00(0.01), f_time=1.63(1.36), b_time=1.64(1.37)  Time cost: 21:00/1:06:59 [29:35:09/1:06:59]  Acc_iter 74300       Data time: 0.00(0.01)  Forward time: 1.63(1.36)  Batch time: 1.64(1.37)
2025-09-04 14:52:06,180   INFO  Train:   20/20 (100%) [ 971/3862 ( 25%)]  Loss: 1.109 (1.01)  LR: 9.581e-06  Grad: 27.8021  max=1.1632(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2701(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3343, loss_cls=0.0587, loss_bbox=0.3510, matched_ious=0.6174, loss_iou=0.0846, loss_iou_reg=0.1875, d_time=0.00(0.01), f_time=1.52(1.36), b_time=1.52(1.37)  Time cost: 22:07/1:05:49 [29:36:17/1:05:49]  Acc_iter 74350       Data time: 0.00(0.01)  Forward time: 1.52(1.36)  Batch time: 1.52(1.37)
2025-09-04 14:53:14,185   INFO  Train:   20/20 (100%) [1021/3862 ( 26%)]  Loss: 1.357 (1.01)  LR: 9.254e-06  Grad: 27.8257  max=1.1668(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2552(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3364, loss_cls=0.0610, loss_bbox=0.3430, matched_ious=0.6119, loss_iou=0.0855, loss_iou_reg=0.1903, d_time=0.00(0.01), f_time=1.32(1.36), b_time=1.33(1.37)  Time cost: 23:15/1:04:40 [29:37:25/1:04:40]  Acc_iter 74400       Data time: 0.00(0.01)  Forward time: 1.32(1.36)  Batch time: 1.33(1.37)
2025-09-04 14:54:23,359   INFO  Train:   20/20 (100%) [1071/3862 ( 28%)]  Loss: 1.246 (1.01)  LR: 8.932e-06  Grad: 27.8683  max=1.1572(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2451(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3296, loss_cls=0.0599, loss_bbox=0.3420, matched_ious=0.6075, loss_iou=0.0853, loss_iou_reg=0.1941, d_time=0.01(0.01), f_time=1.38(1.36), b_time=1.39(1.37)  Time cost: 24:24/1:03:34 [29:38:34/1:03:34]  Acc_iter 74450       Data time: 0.01(0.01)  Forward time: 1.38(1.36)  Batch time: 1.39(1.37)
2025-09-04 14:55:31,340   INFO  Train:   20/20 (100%) [1121/3862 ( 29%)]  Loss: 0.9722 (1.01)  LR: 8.616e-06  Grad: 27.8447  max=1.1601(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2458(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3365, loss_cls=0.0612, loss_bbox=0.3560, matched_ious=0.6093, loss_iou=0.0858, loss_iou_reg=0.1942, d_time=0.01(0.01), f_time=1.33(1.36), b_time=1.34(1.37)  Time cost: 25:32/1:02:24 [29:39:42/1:02:24]  Acc_iter 74500       Data time: 0.01(0.01)  Forward time: 1.33(1.36)  Batch time: 1.34(1.37)
2025-09-04 14:56:39,579   INFO  Train:   20/20 (100%) [1171/3862 ( 30%)]  Loss: 0.8233 (1.01)  LR: 8.306e-06  Grad: 27.8251  max=1.1563(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2624(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3373, loss_cls=0.0597, loss_bbox=0.3345, matched_ious=0.6143, loss_iou=0.0822, loss_iou_reg=0.1895, d_time=0.00(0.01), f_time=1.42(1.36), b_time=1.42(1.37)  Time cost: 26:41/1:01:16 [29:40:50/1:01:16]  Acc_iter 74550       Data time: 0.00(0.01)  Forward time: 1.42(1.36)  Batch time: 1.42(1.37)
2025-09-04 14:57:47,208   INFO  Train:   20/20 (100%) [1221/3862 ( 32%)]  Loss: 0.8897 (1.01)  LR: 8.001e-06  Grad: 27.8476  max=1.1542(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2633(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3362, loss_cls=0.0606, loss_bbox=0.3473, matched_ious=0.6097, loss_iou=0.0872, loss_iou_reg=0.1939, d_time=0.01(0.01), f_time=1.22(1.36), b_time=1.23(1.37)  Time cost: 27:48/1:00:06 [29:41:58/1:00:06]  Acc_iter 74600       Data time: 0.01(0.01)  Forward time: 1.22(1.36)  Batch time: 1.23(1.37)
2025-09-04 14:58:55,940   INFO  Train:   20/20 (100%) [1271/3862 ( 33%)]  Loss: 1.028 (1.01)  LR: 7.702e-06  Grad: 27.8541  max=1.1602(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2478(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3345, loss_cls=0.0600, loss_bbox=0.3534, matched_ious=0.6149, loss_iou=0.0829, loss_iou_reg=0.1903, d_time=0.00(0.01), f_time=1.43(1.36), b_time=1.44(1.37)  Time cost: 28:57/58:59 [29:43:07/58:59]  Acc_iter 74650       Data time: 0.00(0.01)  Forward time: 1.43(1.36)  Batch time: 1.44(1.37)
2025-09-04 15:00:03,390   INFO  Train:   20/20 (100%) [1321/3862 ( 34%)]  Loss: 1.078 (1.01)  LR: 7.409e-06  Grad: 27.8488  max=1.1608(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2389(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3376, loss_cls=0.0599, loss_bbox=0.3637, matched_ious=0.6076, loss_iou=0.0856, loss_iou_reg=0.1938, d_time=0.00(0.01), f_time=1.43(1.36), b_time=1.44(1.37)  Time cost: 30:04/57:49 [29:44:14/57:49]  Acc_iter 74700       Data time: 0.00(0.01)  Forward time: 1.43(1.36)  Batch time: 1.44(1.37)
2025-09-04 15:01:11,463   INFO  Train:   20/20 (100%) [1371/3862 ( 35%)]  Loss: 0.8682 (1.01)  LR: 7.122e-06  Grad: 27.8689  max=1.1610(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2461(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3262, loss_cls=0.0573, loss_bbox=0.3272, matched_ious=0.6226, loss_iou=0.0839, loss_iou_reg=0.1848, d_time=0.00(0.01), f_time=1.34(1.36), b_time=1.34(1.37)  Time cost: 31:13/56:40 [29:45:22/56:40]  Acc_iter 74750       Data time: 0.00(0.01)  Forward time: 1.34(1.36)  Batch time: 1.34(1.37)
2025-09-04 15:02:19,513   INFO  Train:   20/20 (100%) [1421/3862 ( 37%)]  Loss: 0.8183 (1.01)  LR: 6.840e-06  Grad: 27.8798  max=1.1627(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2367(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3184, loss_cls=0.0583, loss_bbox=0.3596, matched_ious=0.6146, loss_iou=0.0855, loss_iou_reg=0.1909, d_time=0.01(0.01), f_time=1.28(1.36), b_time=1.29(1.37)  Time cost: 32:21/55:32 [29:46:30/55:32]  Acc_iter 74800       Data time: 0.01(0.01)  Forward time: 1.28(1.36)  Batch time: 1.29(1.37)
2025-09-04 15:03:27,527   INFO  Train:   20/20 (100%) [1471/3862 ( 38%)]  Loss: 1.064 (1.01)  LR: 6.563e-06  Grad: 27.8902  max=1.1542(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2578(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3157, loss_cls=0.0589, loss_bbox=0.3400, matched_ious=0.6113, loss_iou=0.0836, loss_iou_reg=0.1914, d_time=0.00(0.01), f_time=1.44(1.36), b_time=1.44(1.37)  Time cost: 33:29/54:23 [29:47:38/54:23]  Acc_iter 74850       Data time: 0.00(0.01)  Forward time: 1.44(1.36)  Batch time: 1.44(1.37)
2025-09-04 15:04:35,314   INFO  Train:   20/20 (100%) [1521/3862 ( 39%)]  Loss: 1.377 (1.02)  LR: 6.293e-06  Grad: 27.8821  max=1.1668(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2417(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3586, loss_cls=0.0633, loss_bbox=0.4043, matched_ious=0.6081, loss_iou=0.0862, loss_iou_reg=0.1935, d_time=0.00(0.01), f_time=1.58(1.36), b_time=1.58(1.36)  Time cost: 34:36/53:14 [29:48:46/53:14]  Acc_iter 74900       Data time: 0.00(0.01)  Forward time: 1.58(1.36)  Batch time: 1.58(1.36)
2025-09-04 15:05:43,652   INFO  Train:   20/20 (100%) [1571/3862 ( 41%)]  Loss: 0.8604 (1.02)  LR: 6.028e-06  Grad: 27.8710  max=1.1687(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2441(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3388, loss_cls=0.0588, loss_bbox=0.3448, matched_ious=0.6196, loss_iou=0.0814, loss_iou_reg=0.1877, d_time=0.00(0.01), f_time=1.28(1.36), b_time=1.29(1.36)  Time cost: 35:45/52:06 [29:49:54/52:06]  Acc_iter 74950       Data time: 0.00(0.01)  Forward time: 1.28(1.36)  Batch time: 1.29(1.36)
2025-09-04 15:06:51,515   INFO  Train:   20/20 (100%) [1621/3862 ( 42%)]  Loss: 0.9715 (1.02)  LR: 5.768e-06  Grad: 27.8617  max=1.1647(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2523(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3296, loss_cls=0.0603, loss_bbox=0.3612, matched_ious=0.6065, loss_iou=0.0857, loss_iou_reg=0.1947, d_time=0.00(0.01), f_time=1.37(1.36), b_time=1.38(1.36)  Time cost: 36:53/50:57 [29:51:02/50:57]  Acc_iter 75000       Data time: 0.00(0.01)  Forward time: 1.37(1.36)  Batch time: 1.38(1.36)
2025-09-04 15:07:59,376   INFO  Train:   20/20 (100%) [1671/3862 ( 43%)]  Loss: 0.7725 (1.02)  LR: 5.515e-06  Grad: 27.8691  max=1.1673(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2617(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3324, loss_cls=0.0578, loss_bbox=0.3322, matched_ious=0.6199, loss_iou=0.0844, loss_iou_reg=0.1871, d_time=0.00(0.01), f_time=1.18(1.36), b_time=1.18(1.36)  Time cost: 38:00/49:48 [29:52:10/49:48]  Acc_iter 75050       Data time: 0.00(0.01)  Forward time: 1.18(1.36)  Batch time: 1.18(1.36)
2025-09-04 15:09:08,123   INFO  Train:   20/20 (100%) [1721/3862 ( 45%)]  Loss: 1.085 (1.02)  LR: 5.267e-06  Grad: 27.8710  max=1.1689(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2552(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3278, loss_cls=0.0599, loss_bbox=0.3469, matched_ious=0.6063, loss_iou=0.0859, loss_iou_reg=0.1929, d_time=0.00(0.01), f_time=1.31(1.36), b_time=1.32(1.36)  Time cost: 39:09/48:41 [29:53:19/48:41]  Acc_iter 75100       Data time: 0.00(0.01)  Forward time: 1.31(1.36)  Batch time: 1.32(1.36)
2025-09-04 15:10:16,286   INFO  Train:   20/20 (100%) [1771/3862 ( 46%)]  Loss: 0.8294 (1.01)  LR: 5.025e-06  Grad: 27.8660  max=1.1632(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2595(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3194, loss_cls=0.0571, loss_bbox=0.3245, matched_ious=0.6166, loss_iou=0.0842, loss_iou_reg=0.1881, d_time=0.01(0.01), f_time=1.26(1.36), b_time=1.27(1.36)  Time cost: 40:17/47:33 [29:54:27/47:33]  Acc_iter 75150       Data time: 0.01(0.01)  Forward time: 1.26(1.36)  Batch time: 1.27(1.36)
2025-09-04 15:11:23,983   INFO  Train:   20/20 (100%) [1821/3862 ( 47%)]  Loss: 0.9856 (1.01)  LR: 4.788e-06  Grad: 27.9744  max=1.1678(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2393(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3383, loss_cls=0.0623, loss_bbox=0.3443, matched_ious=0.6175, loss_iou=0.0836, loss_iou_reg=0.1897, d_time=0.00(0.01), f_time=1.47(1.36), b_time=1.48(1.36)  Time cost: 41:25/46:24 [29:55:35/46:24]  Acc_iter 75200       Data time: 0.00(0.01)  Forward time: 1.47(1.36)  Batch time: 1.48(1.36)
2025-09-04 15:12:31,962   INFO  Train:   20/20 (100%) [1871/3862 ( 48%)]  Loss: 0.6554 (1.01)  LR: 4.557e-06  Grad: 27.9563  max=1.1588(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2437(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3006, loss_cls=0.0561, loss_bbox=0.3634, matched_ious=0.6127, loss_iou=0.0852, loss_iou_reg=0.1910, d_time=0.00(0.01), f_time=1.40(1.36), b_time=1.41(1.36)  Time cost: 42:33/45:15 [29:56:43/45:15]  Acc_iter 75250       Data time: 0.00(0.01)  Forward time: 1.40(1.36)  Batch time: 1.41(1.36)
2025-09-04 15:13:40,205   INFO  Train:   20/20 (100%) [1921/3862 ( 50%)]  Loss: 0.9403 (1.01)  LR: 4.332e-06  Grad: 27.9424  max=1.1581(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2566(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3171, loss_cls=0.0563, loss_bbox=0.3476, matched_ious=0.5995, loss_iou=0.0850, loss_iou_reg=0.1964, d_time=0.00(0.01), f_time=1.32(1.36), b_time=1.33(1.36)  Time cost: 43:41/44:07 [29:57:51/44:07]  Acc_iter 75300       Data time: 0.00(0.01)  Forward time: 1.32(1.36)  Batch time: 1.33(1.36)
2025-09-04 15:14:48,170   INFO  Train:   20/20 (100%) [1971/3862 ( 51%)]  Loss: 0.8043 (1.01)  LR: 4.112e-06  Grad: 27.9621  max=1.1593(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2446(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3339, loss_cls=0.0613, loss_bbox=0.3427, matched_ious=0.6129, loss_iou=0.0851, loss_iou_reg=0.1935, d_time=0.00(0.01), f_time=1.27(1.36), b_time=1.28(1.36)  Time cost: 44:49/42:59 [29:58:59/42:59]  Acc_iter 75350       Data time: 0.00(0.01)  Forward time: 1.27(1.36)  Batch time: 1.28(1.36)
2025-09-04 15:15:56,518   INFO  Train:   20/20 (100%) [2021/3862 ( 52%)]  Loss: 1.009 (1.01)  LR: 3.899e-06  Grad: 27.9552  max=1.1655(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2542(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3435, loss_cls=0.0622, loss_bbox=0.3370, matched_ious=0.6097, loss_iou=0.0857, loss_iou_reg=0.1915, d_time=0.01(0.01), f_time=1.57(1.36), b_time=1.57(1.36)  Time cost: 45:58/41:51 [30:00:07/41:51]  Acc_iter 75400       Data time: 0.01(0.01)  Forward time: 1.57(1.36)  Batch time: 1.57(1.36)
2025-09-04 15:17:03,778   INFO  Train:   20/20 (100%) [2071/3862 ( 54%)]  Loss: 0.8071 (1.01)  LR: 3.690e-06  Grad: 27.9584  max=1.1630(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2604(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3264, loss_cls=0.0602, loss_bbox=0.3403, matched_ious=0.6115, loss_iou=0.0846, loss_iou_reg=0.1917, d_time=0.00(0.01), f_time=1.34(1.36), b_time=1.35(1.36)  Time cost: 47:05/40:42 [30:01:14/40:42]  Acc_iter 75450       Data time: 0.00(0.01)  Forward time: 1.34(1.36)  Batch time: 1.35(1.36)
2025-09-04 15:18:12,468   INFO  Train:   20/20 (100%) [2121/3862 ( 55%)]  Loss: 1.134 (1.01)  LR: 3.488e-06  Grad: 27.9983  max=1.1611(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2592(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3182, loss_cls=0.0584, loss_bbox=0.3296, matched_ious=0.6167, loss_iou=0.0836, loss_iou_reg=0.1875, d_time=0.00(0.01), f_time=1.27(1.36), b_time=1.27(1.36)  Time cost: 48:14/39:34 [30:02:23/39:34]  Acc_iter 75500       Data time: 0.00(0.01)  Forward time: 1.27(1.36)  Batch time: 1.27(1.36)
2025-09-04 15:19:20,600   INFO  Train:   20/20 (100%) [2171/3862 ( 56%)]  Loss: 1.048 (1.01)  LR: 3.291e-06  Grad: 28.0231  max=1.1540(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2491(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3203, loss_cls=0.0585, loss_bbox=0.3235, matched_ious=0.6184, loss_iou=0.0831, loss_iou_reg=0.1875, d_time=0.01(0.01), f_time=1.22(1.36), b_time=1.23(1.36)  Time cost: 49:22/38:26 [30:03:31/38:26]  Acc_iter 75550       Data time: 0.01(0.01)  Forward time: 1.22(1.36)  Batch time: 1.23(1.36)
2025-09-04 15:20:29,061   INFO  Train:   20/20 (100%) [2221/3862 ( 58%)]  Loss: 0.9857 (1.01)  LR: 3.100e-06  Grad: 28.0415  max=1.1541(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2582(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3111, loss_cls=0.0557, loss_bbox=0.3353, matched_ious=0.6212, loss_iou=0.0830, loss_iou_reg=0.1866, d_time=0.00(0.01), f_time=1.37(1.36), b_time=1.37(1.36)  Time cost: 50:30/37:18 [30:04:40/37:18]  Acc_iter 75600       Data time: 0.00(0.01)  Forward time: 1.37(1.36)  Batch time: 1.37(1.36)
2025-09-04 15:21:37,091   INFO  Train:   20/20 (100%) [2271/3862 ( 59%)]  Loss: 1.237 (1.01)  LR: 2.915e-06  Grad: 28.0852  max=1.1513(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2541(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3221, loss_cls=0.0576, loss_bbox=0.3413, matched_ious=0.6215, loss_iou=0.0810, loss_iou_reg=0.1831, d_time=0.01(0.01), f_time=1.67(1.36), b_time=1.68(1.36)  Time cost: 51:38/36:09 [30:05:48/36:09]  Acc_iter 75650       Data time: 0.01(0.01)  Forward time: 1.67(1.36)  Batch time: 1.68(1.36)
2025-09-04 15:22:45,331   INFO  Train:   20/20 (100%) [2321/3862 ( 60%)]  Loss: 0.8663 (1.01)  LR: 2.736e-06  Grad: 28.0631  max=1.1589(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2462(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3421, loss_cls=0.0614, loss_bbox=0.3450, matched_ious=0.6195, loss_iou=0.0836, loss_iou_reg=0.1879, d_time=0.00(0.01), f_time=1.47(1.36), b_time=1.48(1.36)  Time cost: 52:46/35:01 [30:06:56/35:01]  Acc_iter 75700       Data time: 0.00(0.01)  Forward time: 1.47(1.36)  Batch time: 1.48(1.36)
2025-09-04 15:23:52,726   INFO  Train:   20/20 (100%) [2371/3862 ( 61%)]  Loss: 1.466 (1.01)  LR: 2.562e-06  Grad: 28.0865  max=1.1641(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2301(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3507, loss_cls=0.0639, loss_bbox=0.3541, matched_ious=0.6151, loss_iou=0.0845, loss_iou_reg=0.1917, d_time=0.00(0.01), f_time=1.36(1.36), b_time=1.36(1.36)  Time cost: 53:54/33:53 [30:08:03/33:53]  Acc_iter 75750       Data time: 0.00(0.01)  Forward time: 1.36(1.36)  Batch time: 1.36(1.36)
2025-09-04 15:25:01,097   INFO  Train:   20/20 (100%) [2421/3862 ( 63%)]  Loss: 0.8356 (1.01)  LR: 2.394e-06  Grad: 28.0985  max=1.1700(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2297(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3246, loss_cls=0.0594, loss_bbox=0.3594, matched_ious=0.6121, loss_iou=0.0871, loss_iou_reg=0.1939, d_time=0.03(0.01), f_time=1.56(1.36), b_time=1.59(1.36)  Time cost: 55:02/32:44 [30:09:12/32:44]  Acc_iter 75800       Data time: 0.03(0.01)  Forward time: 1.56(1.36)  Batch time: 1.59(1.36)
2025-09-04 15:26:08,877   INFO  Train:   20/20 (100%) [2471/3862 ( 64%)]  Loss: 1.169 (1.01)  LR: 2.231e-06  Grad: 28.0640  max=1.1820(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2395(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3189, loss_cls=0.0581, loss_bbox=0.3255, matched_ious=0.6164, loss_iou=0.0841, loss_iou_reg=0.1878, d_time=0.00(0.01), f_time=1.34(1.36), b_time=1.35(1.36)  Time cost: 56:10/31:36 [30:10:19/31:36]  Acc_iter 75850       Data time: 0.00(0.01)  Forward time: 1.34(1.36)  Batch time: 1.35(1.36)
2025-09-04 15:27:16,940   INFO  Train:   20/20 (100%) [2521/3862 ( 65%)]  Loss: 1.155 (1.01)  LR: 2.074e-06  Grad: 28.1245  max=1.1784(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2274(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3292, loss_cls=0.0582, loss_bbox=0.3597, matched_ious=0.6128, loss_iou=0.0856, loss_iou_reg=0.1907, d_time=0.01(0.01), f_time=1.27(1.36), b_time=1.28(1.36)  Time cost: 57:18/30:28 [30:11:28/30:28]  Acc_iter 75900       Data time: 0.01(0.01)  Forward time: 1.27(1.36)  Batch time: 1.28(1.36)
2025-09-04 15:28:23,800   INFO  Train:   20/20 (100%) [2571/3862 ( 67%)]  Loss: 1.002 (1.01)  LR: 1.923e-06  Grad: 28.1247  max=1.1825(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2284(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3225, loss_cls=0.0598, loss_bbox=0.3441, matched_ious=0.6214, loss_iou=0.0830, loss_iou_reg=0.1868, d_time=0.00(0.01), f_time=1.24(1.36), b_time=1.24(1.36)  Time cost: 58:25/29:19 [30:12:34/29:19]  Acc_iter 75950       Data time: 0.00(0.01)  Forward time: 1.24(1.36)  Batch time: 1.24(1.36)
2025-09-04 15:29:32,113   INFO  Train:   20/20 (100%) [2621/3862 ( 68%)]  Loss: 1.036 (1.01)  LR: 1.778e-06  Grad: 28.1240  max=1.1801(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2407(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3269, loss_cls=0.0582, loss_bbox=0.3406, matched_ious=0.6140, loss_iou=0.0874, loss_iou_reg=0.1921, d_time=0.01(0.01), f_time=1.30(1.36), b_time=1.31(1.36)  Time cost: 59:33/28:11 [30:13:43/28:11]  Acc_iter 76000       Data time: 0.01(0.01)  Forward time: 1.30(1.36)  Batch time: 1.31(1.36)
2025-09-04 15:30:40,971   INFO  Train:   20/20 (100%) [2671/3862 ( 69%)]  Loss: 0.8684 (1.01)  LR: 1.639e-06  Grad: 28.1150  max=1.1834(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2476(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3408, loss_cls=0.0605, loss_bbox=0.3352, matched_ious=0.6230, loss_iou=0.0822, loss_iou_reg=0.1884, d_time=0.00(0.01), f_time=1.40(1.36), b_time=1.41(1.36)  Time cost: 1:00:42/27:03 [30:14:52/27:03]  Acc_iter 76050       Data time: 0.00(0.01)  Forward time: 1.40(1.36)  Batch time: 1.41(1.36)
2025-09-04 15:31:48,517   INFO  Train:   20/20 (100%) [2721/3862 ( 70%)]  Loss: 0.9421 (1.01)  LR: 1.505e-06  Grad: 28.1486  max=1.1857(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2378(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3265, loss_cls=0.0583, loss_bbox=0.3517, matched_ious=0.6063, loss_iou=0.0853, loss_iou_reg=0.1927, d_time=0.01(0.01), f_time=1.61(1.36), b_time=1.61(1.36)  Time cost: 1:01:50/25:55 [30:15:59/25:55]  Acc_iter 76100       Data time: 0.01(0.01)  Forward time: 1.61(1.36)  Batch time: 1.61(1.36)
2025-09-04 15:32:57,027   INFO  Train:   20/20 (100%) [2771/3862 ( 72%)]  Loss: 0.8305 (1.01)  LR: 1.377e-06  Grad: 28.1978  max=1.1857(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2221(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3330, loss_cls=0.0582, loss_bbox=0.3368, matched_ious=0.6211, loss_iou=0.0834, loss_iou_reg=0.1882, d_time=0.01(0.01), f_time=1.32(1.36), b_time=1.33(1.36)  Time cost: 1:02:58/24:47 [30:17:08/24:47]  Acc_iter 76150       Data time: 0.01(0.01)  Forward time: 1.32(1.36)  Batch time: 1.33(1.36)
2025-09-04 15:34:03,967   INFO  Train:   20/20 (100%) [2821/3862 ( 73%)]  Loss: 0.9044 (1.01)  LR: 1.254e-06  Grad: 28.1618  max=1.1802(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2330(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3430, loss_cls=0.0609, loss_bbox=0.3410, matched_ious=0.6115, loss_iou=0.0856, loss_iou_reg=0.1905, d_time=0.01(0.01), f_time=1.60(1.36), b_time=1.61(1.36)  Time cost: 1:04:05/23:38 [30:18:15/23:38]  Acc_iter 76200       Data time: 0.01(0.01)  Forward time: 1.60(1.36)  Batch time: 1.61(1.36)
2025-09-04 15:35:11,827   INFO  Train:   20/20 (100%) [2871/3862 ( 74%)]  Loss: 1.215 (1.01)  LR: 1.138e-06  Grad: 28.1765  max=1.1747(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2279(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3427, loss_cls=0.0619, loss_bbox=0.3393, matched_ious=0.6208, loss_iou=0.0835, loss_iou_reg=0.1860, d_time=0.01(0.01), f_time=1.41(1.36), b_time=1.42(1.36)  Time cost: 1:05:13/22:30 [30:19:22/22:30]  Acc_iter 76250       Data time: 0.01(0.01)  Forward time: 1.41(1.36)  Batch time: 1.42(1.36)
2025-09-04 15:36:19,928   INFO  Train:   20/20 (100%) [2921/3862 ( 76%)]  Loss: 1.066 (1.01)  LR: 1.027e-06  Grad: 28.1864  max=1.1712(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2343(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3333, loss_cls=0.0584, loss_bbox=0.3406, matched_ious=0.6129, loss_iou=0.0848, loss_iou_reg=0.1915, d_time=0.01(0.01), f_time=1.40(1.36), b_time=1.41(1.36)  Time cost: 1:06:21/21:22 [30:20:31/21:22]  Acc_iter 76300       Data time: 0.01(0.01)  Forward time: 1.40(1.36)  Batch time: 1.41(1.36)
2025-09-04 15:37:28,343   INFO  Train:   20/20 (100%) [2971/3862 ( 77%)]  Loss: 0.7650 (1.01)  LR: 9.217e-07  Grad: 28.2119  max=1.1712(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2217(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3154, loss_cls=0.0566, loss_bbox=0.3432, matched_ious=0.6231, loss_iou=0.0824, loss_iou_reg=0.1842, d_time=0.02(0.01), f_time=1.32(1.36), b_time=1.33(1.36)  Time cost: 1:07:29/20:14 [30:21:39/20:14]  Acc_iter 76350       Data time: 0.02(0.01)  Forward time: 1.32(1.36)  Batch time: 1.33(1.36)
2025-09-04 15:38:36,950   INFO  Train:   20/20 (100%) [3021/3862 ( 78%)]  Loss: 1.025 (1.01)  LR: 8.223e-07  Grad: 28.2333  max=1.1741(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2135(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3217, loss_cls=0.0566, loss_bbox=0.3428, matched_ious=0.6227, loss_iou=0.0843, loss_iou_reg=0.1875, d_time=0.01(0.01), f_time=1.30(1.36), b_time=1.31(1.36)  Time cost: 1:08:38/19:06 [30:22:48/19:06]  Acc_iter 76400       Data time: 0.01(0.01)  Forward time: 1.30(1.36)  Batch time: 1.31(1.36)
2025-09-04 15:39:45,980   INFO  Train:   20/20 (100%) [3071/3862 ( 80%)]  Loss: 0.9535 (1.01)  LR: 7.286e-07  Grad: 28.2726  max=1.1792(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2167(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3160, loss_cls=0.0554, loss_bbox=0.3432, matched_ious=0.6222, loss_iou=0.0832, loss_iou_reg=0.1870, d_time=0.00(0.01), f_time=1.33(1.36), b_time=1.34(1.36)  Time cost: 1:09:47/17:58 [30:23:57/17:58]  Acc_iter 76450       Data time: 0.00(0.01)  Forward time: 1.33(1.36)  Batch time: 1.34(1.36)
2025-09-04 15:40:54,490   INFO  Train:   20/20 (100%) [3121/3862 ( 81%)]  Loss: 1.290 (1.01)  LR: 6.407e-07  Grad: 28.2100  max=1.1819(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2375(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3389, loss_cls=0.0620, loss_bbox=0.3763, matched_ious=0.6050, loss_iou=0.0860, loss_iou_reg=0.1940, d_time=0.01(0.01), f_time=1.27(1.36), b_time=1.28(1.36)  Time cost: 1:10:56/16:50 [30:25:05/16:50]  Acc_iter 76500       Data time: 0.01(0.01)  Forward time: 1.27(1.36)  Batch time: 1.28(1.36)
2025-09-04 15:42:02,237   INFO  Train:   20/20 (100%) [3171/3862 ( 82%)]  Loss: 0.9750 (1.01)  LR: 5.584e-07  Grad: 28.2193  max=1.1843(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2417(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3140, loss_cls=0.0563, loss_bbox=0.3513, matched_ious=0.6130, loss_iou=0.0856, loss_iou_reg=0.1901, d_time=0.01(0.01), f_time=1.46(1.36), b_time=1.47(1.36)  Time cost: 1:12:03/15:41 [30:26:13/15:41]  Acc_iter 76550       Data time: 0.01(0.01)  Forward time: 1.46(1.36)  Batch time: 1.47(1.36)
2025-09-04 15:43:11,047   INFO  Train:   20/20 (100%) [3221/3862 ( 83%)]  Loss: 0.9993 (1.01)  LR: 4.820e-07  Grad: 28.2307  max=1.1981(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2507(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3152, loss_cls=0.0584, loss_bbox=0.3115, matched_ious=0.6189, loss_iou=0.0856, loss_iou_reg=0.1896, d_time=0.01(0.01), f_time=1.32(1.36), b_time=1.32(1.36)  Time cost: 1:13:12/14:33 [30:27:22/14:33]  Acc_iter 76600       Data time: 0.01(0.01)  Forward time: 1.32(1.36)  Batch time: 1.32(1.36)
2025-09-04 15:44:19,085   INFO  Train:   20/20 (100%) [3271/3862 ( 85%)]  Loss: 1.559 (1.01)  LR: 4.112e-07  Grad: 28.2043  max=1.2077(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2764(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3327, loss_cls=0.0610, loss_bbox=0.3691, matched_ious=0.6088, loss_iou=0.0857, loss_iou_reg=0.1942, d_time=0.00(0.01), f_time=1.29(1.36), b_time=1.29(1.36)  Time cost: 1:14:20/13:25 [30:28:30/13:25]  Acc_iter 76650       Data time: 0.00(0.01)  Forward time: 1.29(1.36)  Batch time: 1.29(1.36)
2025-09-04 15:45:27,093   INFO  Train:   20/20 (100%) [3321/3862 ( 86%)]  Loss: 1.125 (1.01)  LR: 3.462e-07  Grad: 28.1790  max=1.2011(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2841(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3172, loss_cls=0.0560, loss_bbox=0.3371, matched_ious=0.6239, loss_iou=0.0828, loss_iou_reg=0.1889, d_time=0.01(0.01), f_time=1.21(1.36), b_time=1.22(1.36)  Time cost: 1:15:28/12:17 [30:29:38/12:17]  Acc_iter 76700       Data time: 0.01(0.01)  Forward time: 1.21(1.36)  Batch time: 1.22(1.36)
2025-09-04 15:46:35,455   INFO  Train:   20/20 (100%) [3371/3862 ( 87%)]  Loss: 1.436 (1.01)  LR: 2.869e-07  Grad: 28.1922  max=1.1891(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2898(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3270, loss_cls=0.0577, loss_bbox=0.3442, matched_ious=0.6127, loss_iou=0.0847, loss_iou_reg=0.1905, d_time=0.00(0.01), f_time=1.34(1.36), b_time=1.34(1.36)  Time cost: 1:16:37/11:09 [30:30:46/11:09]  Acc_iter 76750       Data time: 0.00(0.01)  Forward time: 1.34(1.36)  Batch time: 1.34(1.36)
2025-09-04 15:47:43,994   INFO  Train:   20/20 (100%) [3421/3862 ( 89%)]  Loss: 0.9972 (1.01)  LR: 2.334e-07  Grad: 28.1768  max=1.1821(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2980(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3450, loss_cls=0.0603, loss_bbox=0.3600, matched_ious=0.6156, loss_iou=0.0832, loss_iou_reg=0.1906, d_time=0.01(0.01), f_time=1.36(1.36), b_time=1.37(1.36)  Time cost: 1:17:45/10:01 [30:31:55/10:01]  Acc_iter 76800       Data time: 0.01(0.01)  Forward time: 1.36(1.36)  Batch time: 1.37(1.36)
2025-09-04 15:48:51,875   INFO  Train:   20/20 (100%) [3471/3862 ( 90%)]  Loss: 0.7381 (1.01)  LR: 1.856e-07  Grad: 28.2032  max=1.1785(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2955(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3319, loss_cls=0.0575, loss_bbox=0.3475, matched_ious=0.6206, loss_iou=0.0837, loss_iou_reg=0.1876, d_time=0.00(0.01), f_time=1.36(1.36), b_time=1.37(1.36)  Time cost: 1:18:53/08:53 [30:33:02/08:53]  Acc_iter 76850       Data time: 0.00(0.01)  Forward time: 1.36(1.36)  Batch time: 1.37(1.36)
2025-09-04 15:49:59,423   INFO  Train:   20/20 (100%) [3521/3862 ( 91%)]  Loss: 1.092 (1.01)  LR: 1.436e-07  Grad: 28.2499  max=1.1645(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2749(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3321, loss_cls=0.0605, loss_bbox=0.3368, matched_ious=0.6161, loss_iou=0.0849, loss_iou_reg=0.1898, d_time=0.00(0.01), f_time=1.34(1.36), b_time=1.35(1.36)  Time cost: 1:20:01/07:44 [30:34:10/07:44]  Acc_iter 76900       Data time: 0.00(0.01)  Forward time: 1.34(1.36)  Batch time: 1.35(1.36)
2025-09-04 15:51:07,857   INFO  Train:   20/20 (100%) [3571/3862 ( 92%)]  Loss: 0.7364 (1.01)  LR: 1.073e-07  Grad: 28.2350  max=1.1580(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2994(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3288, loss_cls=0.0599, loss_bbox=0.3447, matched_ious=0.6171, loss_iou=0.0817, loss_iou_reg=0.1891, d_time=0.00(0.01), f_time=1.39(1.36), b_time=1.40(1.36)  Time cost: 1:21:09/06:36 [30:35:18/06:36]  Acc_iter 76950       Data time: 0.00(0.01)  Forward time: 1.39(1.36)  Batch time: 1.40(1.36)
2025-09-04 15:52:16,125   INFO  Train:   20/20 (100%) [3621/3862 ( 94%)]  Loss: 0.6406 (1.01)  LR: 7.672e-08  Grad: 28.2782  max=1.1596(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2768(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3071, loss_cls=0.0559, loss_bbox=0.3190, matched_ious=0.6120, loss_iou=0.0841, loss_iou_reg=0.1941, d_time=0.01(0.01), f_time=1.24(1.36), b_time=1.25(1.36)  Time cost: 1:22:17/05:28 [30:36:27/05:28]  Acc_iter 77000       Data time: 0.01(0.01)  Forward time: 1.24(1.36)  Batch time: 1.25(1.36)
2025-09-04 15:53:23,320   INFO  Train:   20/20 (100%) [3671/3862 ( 95%)]  Loss: 1.105 (1.01)  LR: 5.191e-08  Grad: 28.2720  max=1.1623(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2752(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3213, loss_cls=0.0576, loss_bbox=0.3445, matched_ious=0.6155, loss_iou=0.0853, loss_iou_reg=0.1905, d_time=0.01(0.01), f_time=1.37(1.36), b_time=1.37(1.36)  Time cost: 1:23:24/04:20 [30:37:34/04:20]  Acc_iter 77050       Data time: 0.01(0.01)  Forward time: 1.37(1.36)  Batch time: 1.37(1.36)
2025-09-04 15:54:32,129   INFO  Train:   20/20 (100%) [3721/3862 ( 96%)]  Loss: 1.019 (1.01)  LR: 3.284e-08  Grad: 28.3071  max=1.1669(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2656(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3082, loss_cls=0.0559, loss_bbox=0.3297, matched_ious=0.6079, loss_iou=0.0862, loss_iou_reg=0.1907, d_time=0.00(0.01), f_time=1.45(1.36), b_time=1.45(1.36)  Time cost: 1:24:33/03:12 [30:38:43/03:12]  Acc_iter 77100       Data time: 0.00(0.01)  Forward time: 1.45(1.36)  Batch time: 1.45(1.36)
2025-09-04 15:55:40,642   INFO  Train:   20/20 (100%) [3771/3862 ( 98%)]  Loss: 0.7687 (1.01)  LR: 1.951e-08  Grad: 28.3171  max=1.1656(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2710(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.2992, loss_cls=0.0535, loss_bbox=0.3373, matched_ious=0.6103, loss_iou=0.0869, loss_iou_reg=0.1932, d_time=0.00(0.01), f_time=1.32(1.36), b_time=1.32(1.36)  Time cost: 1:25:42/02:04 [30:39:51/02:04]  Acc_iter 77150       Data time: 0.00(0.01)  Forward time: 1.32(1.36)  Batch time: 1.32(1.36)
2025-09-04 15:56:48,829   INFO  Train:   20/20 (100%) [3821/3862 ( 99%)]  Loss: 0.9854 (1.01)  LR: 1.193e-08  Grad: 28.2868  max=1.1714(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2815(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3364, loss_cls=0.0625, loss_bbox=0.3515, matched_ious=0.6197, loss_iou=0.0843, loss_iou_reg=0.1878, d_time=0.01(0.01), f_time=1.26(1.36), b_time=1.26(1.36)  Time cost: 1:26:50/00:55 [30:40:59/00:55]  Acc_iter 77200       Data time: 0.01(0.01)  Forward time: 1.26(1.36)  Batch time: 1.26(1.36)
2025-09-04 15:57:41,772   INFO  Train:   20/20 (100%) [3861/3862 (100%)]  Loss: 0.8334 (1.01)  LR: 1.000e-08  Grad: 28.3105  max=1.1716(module.dense_head.decoder.self_attn.in_proj_weight)  min: -1.2834(module.dense_head.decoder.self_attn.in_proj_weight)  NaN: False  loss_hm=0.3579, loss_cls=0.0646, loss_bbox=0.3550, matched_ious=0.6206, loss_iou=0.0866, loss_iou_reg=0.1886, d_time=0.00(0.01), f_time=1.39(1.36), b_time=1.40(1.36)  Time cost: 1:27:43/00:01 [30:41:52/00:01]  Acc_iter 77240       Data time: 0.00(0.01)  Forward time: 1.39(1.36)  Batch time: 1.40(1.36)
train:   0%|          | 0/3862 [1:27:43<?, ?it/s]
epochs: 100%|██████████| 20/20 [30:41:53<00:00, 5340.94s/it]                                                              epochs: 100%|██████████| 20/20 [30:41:53<00:00, 5340.96s/it]                                                              epochs: 100%|██████████| 20/20 [30:41:53<00:00, 5340.96s/it]                                                              epochs: 100%|██████████| 20/20 [30:41:53<00:00, 5340.95s/it]                                                              epochs: 100%|██████████| 20/20 [30:41:53<00:00, 5340.96s/it]                                                              epochs: 100%|██████████| 20/20 [30:41:53<00:00, 5340.96s/it]                                                              epochs: 100%|██████████| 20/20 [30:41:53<00:00, 5340.97s/it]                                                              epochs: 100%|██████████| 20/20 [30:41:53<00:00, 5340.98s/it]  epochs: 100%|██████████| 20/20 [30:41:53<00:00, 5525.67s/it]
2025-09-04 15:57:42,457   INFO  **********************End training sparse_models/sparse_former_light(default)**********************



2025-09-04 15:57:42,458   INFO  **********************Start evaluation sparse_models/sparse_former_light(default)**********************
2025-09-04 15:57:42,458   INFO  Loading NuScenes dataset
2025-09-04 15:57:42,855   INFO  Total samples for NuScenes dataset: 6019
2025-09-04 15:57:42,858   INFO  ==> Loading parameters from checkpoint /mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/workdir/voxelnext/encoder/voxelnext_en_3layer_1lc_zhx_de_1layer_v3_32p_.0diff_.1lr_.1wd/ckpt/checkpoint_epoch_20.pth to CPU
2025-09-04 15:57:43,228   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+8694e7f
2025-09-04 15:57:43,259   INFO  ==> Done (loaded 695/695)
2025-09-04 15:57:43,267   INFO  *************** EPOCH 20 EVALUATION *****************
eval:   0%|          | 0/189 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 246, in <module>
    main()
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 236, in main
    repeat_eval_ckpt(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/test.py", line 154, in repeat_eval_ckpt
    tb_dict = eval_utils.eval_one_epoch(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/eval_utils/eval_utils.py", line 160, in eval_one_epoch
    pred_dicts, ret_dict = model(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/detectors/transfusion.py", line 12, in forward
    batch_dict = cur_module(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 1016, in forward
    batch_dict['final_box_dicts'] = self.get_bboxes_v2(res_layer)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 1437, in get_bboxes_v2
    if self.dataset_name == "nuScenes":
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'SparseFormerHead' object has no attribute 'dataset_name'
Traceback (most recent call last):
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 246, in <module>
    main()
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 236, in main
    repeat_eval_ckpt(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/test.py", line 154, in repeat_eval_ckpt
    tb_dict = eval_utils.eval_one_epoch(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/eval_utils/eval_utils.py", line 160, in eval_one_epoch
    pred_dicts, ret_dict = model(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/detectors/transfusion.py", line 12, in forward
    batch_dict = cur_module(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 1016, in forward
    batch_dict['final_box_dicts'] = self.get_bboxes_v2(res_layer)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 1437, in get_bboxes_v2
    if self.dataset_name == "nuScenes":
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'SparseFormerHead' object has no attribute 'dataset_name'
Traceback (most recent call last):
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 246, in <module>
    main()
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 236, in main
    repeat_eval_ckpt(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/test.py", line 154, in repeat_eval_ckpt
    tb_dict = eval_utils.eval_one_epoch(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/eval_utils/eval_utils.py", line 160, in eval_one_epoch
    pred_dicts, ret_dict = model(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/detectors/transfusion.py", line 12, in forward
    batch_dict = cur_module(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 1016, in forward
    batch_dict['final_box_dicts'] = self.get_bboxes_v2(res_layer)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 1437, in get_bboxes_v2
    if self.dataset_name == "nuScenes":
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'SparseFormerHead' object has no attribute 'dataset_name'
Traceback (most recent call last):
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 246, in <module>
    main()
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 236, in main
    repeat_eval_ckpt(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/test.py", line 154, in repeat_eval_ckpt
    tb_dict = eval_utils.eval_one_epoch(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/eval_utils/eval_utils.py", line 160, in eval_one_epoch
    pred_dicts, ret_dict = model(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/detectors/transfusion.py", line 12, in forward
    batch_dict = cur_module(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 1016, in forward
Traceback (most recent call last):
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 246, in <module>
    batch_dict['final_box_dicts'] = self.get_bboxes_v2(res_layer)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 1437, in get_bboxes_v2
    main()
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 236, in main
    repeat_eval_ckpt(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/test.py", line 154, in repeat_eval_ckpt
    if self.dataset_name == "nuScenes":
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    tb_dict = eval_utils.eval_one_epoch(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/eval_utils/eval_utils.py", line 160, in eval_one_epoch
    pred_dicts, ret_dict = model(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'SparseFormerHead' object has no attribute 'dataset_name'
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/detectors/transfusion.py", line 12, in forward
    batch_dict = cur_module(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 1016, in forward
    batch_dict['final_box_dicts'] = self.get_bboxes_v2(res_layer)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 1437, in get_bboxes_v2
    if self.dataset_name == "nuScenes":
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'SparseFormerHead' object has no attribute 'dataset_name'
Traceback (most recent call last):
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 246, in <module>
    main()
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 236, in main
    repeat_eval_ckpt(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/test.py", line 154, in repeat_eval_ckpt
    tb_dict = eval_utils.eval_one_epoch(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/eval_utils/eval_utils.py", line 160, in eval_one_epoch
    pred_dicts, ret_dict = model(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/detectors/transfusion.py", line 12, in forward
    batch_dict = cur_module(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
Traceback (most recent call last):
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 246, in <module>
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    main()
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 236, in main
    repeat_eval_ckpt(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/test.py", line 154, in repeat_eval_ckpt
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 1016, in forward
    tb_dict = eval_utils.eval_one_epoch(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/eval_utils/eval_utils.py", line 160, in eval_one_epoch
    pred_dicts, ret_dict = model(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    batch_dict['final_box_dicts'] = self.get_bboxes_v2(res_layer)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 1437, in get_bboxes_v2
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    if self.dataset_name == "nuScenes":
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'SparseFormerHead' object has no attribute 'dataset_name'
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/detectors/transfusion.py", line 12, in forward
    batch_dict = cur_module(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 1016, in forward
    batch_dict['final_box_dicts'] = self.get_bboxes_v2(res_layer)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 1437, in get_bboxes_v2
    if self.dataset_name == "nuScenes":
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'SparseFormerHead' object has no attribute 'dataset_name'
eval:   0%|          | 0/189 [00:04<?, ?it/s]
Traceback (most recent call last):
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 246, in <module>
    main()
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 236, in main
    repeat_eval_ckpt(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/test.py", line 154, in repeat_eval_ckpt
    tb_dict = eval_utils.eval_one_epoch(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/eval_utils/eval_utils.py", line 160, in eval_one_epoch
    pred_dicts, ret_dict = model(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/detectors/transfusion.py", line 12, in forward
    batch_dict = cur_module(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 1016, in forward
    batch_dict['final_box_dicts'] = self.get_bboxes_v2(res_layer)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 1437, in get_bboxes_v2
    if self.dataset_name == "nuScenes":
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'SparseFormerHead' object has no attribute 'dataset_name'
[2025-09-04 15:57:51,845] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 23) of binary: /root/miniconda3/envs/sparseformerv2/bin/python
Traceback (most recent call last):
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/distributed/launch.py", line 196, in <module>
    main()
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/distributed/launch.py", line 192, in main
    launch(args)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/distributed/launch.py", line 177, in launch
    run(args)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-09-04_15:57:51
  host      : eflops79.aliyun.com
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 24)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2025-09-04_15:57:51
  host      : eflops79.aliyun.com
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 25)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2025-09-04_15:57:51
  host      : eflops79.aliyun.com
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 26)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2025-09-04_15:57:51
  host      : eflops79.aliyun.com
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 27)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2025-09-04_15:57:51
  host      : eflops79.aliyun.com
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 28)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2025-09-04_15:57:51
  host      : eflops79.aliyun.com
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 29)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2025-09-04_15:57:51
  host      : eflops79.aliyun.com
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 30)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-09-04_15:57:51
  host      : eflops79.aliyun.com
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 23)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
