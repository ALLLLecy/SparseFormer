/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-09-01 21:38:26,619   INFO  **********************Start logging**********************
2025-09-01 21:38:26,620   INFO  CUDA_VISIBLE_DEVICES=ALL
2025-09-01 21:38:26,620   INFO  Training in distributed mode : total_batch_size: 32
2025-09-01 21:38:26,620   INFO  cfg_file         cfgs/sparse_models/sparse_former_light.yaml
2025-09-01 21:38:26,620   INFO  batch_size       4
2025-09-01 21:38:26,620   INFO  epochs           20
2025-09-01 21:38:26,620   INFO  workers          12
2025-09-01 21:38:26,620   INFO  extra_tag        default
2025-09-01 21:38:26,620   INFO  ckpt             None
2025-09-01 21:38:26,620   INFO  pretrained_model None
2025-09-01 21:38:26,620   INFO  launcher         pytorch
2025-09-01 21:38:26,620   INFO  tcp_port         18888
2025-09-01 21:38:26,620   INFO  sync_bn          True
2025-09-01 21:38:26,620   INFO  fix_random_seed  False
2025-09-01 21:38:26,620   INFO  ckpt_save_interval 1
2025-09-01 21:38:26,620   INFO  local_rank       0
2025-09-01 21:38:26,621   INFO  max_ckpt_save_num 30
2025-09-01 21:38:26,621   INFO  merge_all_iters_to_one_epoch False
2025-09-01 21:38:26,621   INFO  set_cfgs         None
2025-09-01 21:38:26,621   INFO  max_waiting_mins 0
2025-09-01 21:38:26,621   INFO  start_epoch      0
2025-09-01 21:38:26,621   INFO  num_epochs_to_eval 0
2025-09-01 21:38:26,621   INFO  save_to_file     False
2025-09-01 21:38:26,621   INFO  use_tqdm_to_record False
2025-09-01 21:38:26,621   INFO  logger_iter_interval 50
2025-09-01 21:38:26,621   INFO  ckpt_save_time_interval 300
2025-09-01 21:38:26,621   INFO  wo_gpu_stat      True
2025-09-01 21:38:26,621   INFO  use_amp          False
2025-09-01 21:38:26,621   INFO  eval_map         False
2025-09-01 21:38:26,621   INFO  dataset          nuscenes
2025-09-01 21:38:26,621   INFO  root_dir         /mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2
2025-09-01 21:38:26,621   INFO  output_dir       /mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/workdir/sparseformer/all/voxelnext_en_3layer_1lc_zhx_de_1layer_v3_32p_.0diff_.1lr_.1wd
2025-09-01 21:38:26,621   INFO  cfg.ROOT_DIR: /mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2
2025-09-01 21:38:26,621   INFO  cfg.LOCAL_RANK: 0
2025-09-01 21:38:26,621   INFO  cfg.CLASS_NAMES: ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone']
2025-09-01 21:38:26,621   INFO  ----------- DATA_CONFIG -----------
2025-09-01 21:38:26,622   INFO  cfg.DATA_CONFIG.DATASET: NuScenesDataset
2025-09-01 21:38:26,622   INFO  cfg.DATA_CONFIG.DATA_PATH: /mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/data/nuscenes
2025-09-01 21:38:26,622   INFO  cfg.DATA_CONFIG.VERSION: v1.0-trainval
2025-09-01 21:38:26,622   INFO  cfg.DATA_CONFIG.MAX_SWEEPS: 10
2025-09-01 21:38:26,622   INFO  cfg.DATA_CONFIG.PRED_VELOCITY: True
2025-09-01 21:38:26,622   INFO  cfg.DATA_CONFIG.SET_NAN_VELOCITY_TO_ZEROS: True
2025-09-01 21:38:26,622   INFO  cfg.DATA_CONFIG.FILTER_MIN_POINTS_IN_GT: 1
2025-09-01 21:38:26,622   INFO  ----------- DATA_SPLIT -----------
2025-09-01 21:38:26,622   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train
2025-09-01 21:38:26,622   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val
2025-09-01 21:38:26,622   INFO  ----------- INFO_PATH -----------
2025-09-01 21:38:26,622   INFO  cfg.DATA_CONFIG.INFO_PATH.train: ['nuscenes_infos_10sweeps_train.pkl']
2025-09-01 21:38:26,622   INFO  cfg.DATA_CONFIG.INFO_PATH.test: ['nuscenes_infos_10sweeps_val.pkl']
2025-09-01 21:38:26,622   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [-54.0, -54.0, -5.0, 54.0, 54.0, 3.0]
2025-09-01 21:38:26,622   INFO  cfg.DATA_CONFIG.BALANCED_RESAMPLING: True
2025-09-01 21:38:26,622   INFO  ----------- DATA_AUGMENTOR -----------
2025-09-01 21:38:26,622   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']
2025-09-01 21:38:26,622   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'DB_INFO_PATH': ['nuscenes_dbinfos_10sweeps_withvelo.pkl'], 'USE_SHARED_MEMORY': True, 'DB_DATA_PATH': ['nuscenes_10sweeps_withvelo_lidar.npy'], 'PREPARE': {'filter_by_min_points': ['car:5', 'truck:5', 'construction_vehicle:5', 'bus:5', 'trailer:5', 'barrier:5', 'motorcycle:5', 'bicycle:5', 'pedestrian:5', 'traffic_cone:5']}, 'SAMPLE_GROUPS': ['car:2', 'truck:3', 'construction_vehicle:7', 'bus:4', 'trailer:6', 'barrier:2', 'motorcycle:6', 'bicycle:6', 'pedestrian:2', 'traffic_cone:2'], 'NUM_POINT_FEATURES': 5, 'DATABASE_WITH_FAKELIDAR': False, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': True}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x', 'y']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.9, 1.1]}, {'NAME': 'random_world_translation', 'NOISE_TRANSLATE_STD': [0.5, 0.5, 0.5]}]
2025-09-01 21:38:26,624   INFO  ----------- POINT_FEATURE_ENCODING -----------
2025-09-01 21:38:26,624   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding
2025-09-01 21:38:26,624   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity', 'timestamp']
2025-09-01 21:38:26,624   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity', 'timestamp']
2025-09-01 21:38:26,624   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True, 'MASK_Z': True}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': True}}, {'NAME': 'transform_points_to_voxels_placeholder', 'VOXEL_SIZE': [0.075, 0.075, 0.2]}]
2025-09-01 21:38:26,624   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: cfgs/dataset_configs/nuscenes_dataset.yaml
2025-09-01 21:38:26,624   INFO  ----------- MODEL -----------
2025-09-01 21:38:26,624   INFO  cfg.MODEL.NAME: TransFusion
2025-09-01 21:38:26,624   INFO  ----------- VFE -----------
2025-09-01 21:38:26,624   INFO  cfg.MODEL.VFE.NAME: DynamicVoxelVFE
2025-09-01 21:38:26,624   INFO  cfg.MODEL.VFE.USE_NORM: True
2025-09-01 21:38:26,624   INFO  cfg.MODEL.VFE.WITH_DISTANCE: False
2025-09-01 21:38:26,624   INFO  cfg.MODEL.VFE.USE_ABSLOTE_XYZ: True
2025-09-01 21:38:26,625   INFO  cfg.MODEL.VFE.NUM_FILTERS: [64, 64]
2025-09-01 21:38:26,625   INFO  ----------- BACKBONE_3D -----------
2025-09-01 21:38:26,625   INFO  cfg.MODEL.BACKBONE_3D.NAME: VoxelResBackBone8xVoxelNeXt
2025-09-01 21:38:26,625   INFO  cfg.MODEL.BACKBONE_3D.CHANNELS: [64, 64, 64, 128, 128]
2025-09-01 21:38:26,625   INFO  ----------- DENSE_HEAD -----------
2025-09-01 21:38:26,625   INFO  cfg.MODEL.DENSE_HEAD.NAME: SparseFormerHead
2025-09-01 21:38:26,625   INFO  ----------- SPENCODER -----------
2025-09-01 21:38:26,625   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.NUM_LAYERS: 3
2025-09-01 21:38:26,625   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.ORDERS: [['z', 'z-trans'], ['hilbert', 'hilbert-trans'], ['x', 'y']]
2025-09-01 21:38:26,625   INFO  ----------- SMSA -----------
2025-09-01 21:38:26,625   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.EMBED_DIM: 128
2025-09-01 21:38:26,625   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.DEPTH: 8
2025-09-01 21:38:26,625   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.NUM_LEVELS: 3
2025-09-01 21:38:26,625   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.WINDOW_SHAPE: [9, 9]
2025-09-01 21:38:26,625   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.DROP_PATH: 0.2
2025-09-01 21:38:26,625   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.SPATIAL_ENHANCE: True
2025-09-01 21:38:26,625   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.FUSED_ADD_NORM: True
2025-09-01 21:38:26,625   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.RMS_NORM: True
2025-09-01 21:38:26,625   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.NORM_EPSILON: 1e-05
2025-09-01 21:38:26,625   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.RESIDUAL_IN_FP32: True
2025-09-01 21:38:26,625   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.DIFF_COEF: 0.0
2025-09-01 21:38:26,625   INFO  cfg.MODEL.DENSE_HEAD.SPENCODER.SMSA.DIFF_KERNEL: [7, 5, 3]
2025-09-01 21:38:26,625   INFO  ----------- SPDECODER -----------
2025-09-01 21:38:26,625   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.NUM_LAYERS: 1
2025-09-01 21:38:26,625   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.NUM_LEVELS: 3
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.WINDOW_SHAPE: [[9, 9], [5, 5], [3, 3]]
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.NUM_POINTS: [32, 32, 32]
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.DEPTH: [8, 7, 6]
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.FFN_DIM: 256
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.DROPOUT: 0.1
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.NUM_HEADS: 8
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.FUSION_HEADS: 4
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.ORDERS: [['x', 'y']]
2025-09-01 21:38:26,626   INFO  ----------- SDCA -----------
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.SDCA.EMBED_DIM: 128
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.SDCA.NUM_HEADS: 8
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.SPDECODER.SDCA.DROPOUT: 0.1
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.CLASS_AGNOSTIC: False
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.USE_BIAS_BEFORE_NORM: False
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.USE_TENSOR_MASK: True
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.USE_DENSE_HEATMAP: True
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.INPUT_FEATURES: 128
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.NUM_PROPOSALS: 200
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.HIDDEN_CHANNEL: 128
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.NUM_CLASSES: 10
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.NUM_HEADS: 8
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.NMS_KERNEL_SIZE: 3
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.FFN_CHANNEL: 256
2025-09-01 21:38:26,626   INFO  cfg.MODEL.DENSE_HEAD.DROPOUT: 0.1
2025-09-01 21:38:26,627   INFO  cfg.MODEL.DENSE_HEAD.BN_MOMENTUM: 0.1
2025-09-01 21:38:26,627   INFO  cfg.MODEL.DENSE_HEAD.ACTIVATION: relu
2025-09-01 21:38:26,627   INFO  cfg.MODEL.DENSE_HEAD.NUM_HM_CONV: 2
2025-09-01 21:38:26,627   INFO  ----------- SEPARATE_HEAD_CFG -----------
2025-09-01 21:38:26,627   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_ORDER: ['center', 'height', 'dim', 'rot', 'vel']
2025-09-01 21:38:26,627   INFO  ----------- HEAD_DICT -----------
2025-09-01 21:38:26,627   INFO  ----------- center -----------
2025-09-01 21:38:26,627   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center.out_channels: 2
2025-09-01 21:38:26,627   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center.num_conv: 2
2025-09-01 21:38:26,627   INFO  ----------- height -----------
2025-09-01 21:38:26,627   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.height.out_channels: 1
2025-09-01 21:38:26,627   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.height.num_conv: 2
2025-09-01 21:38:26,627   INFO  ----------- dim -----------
2025-09-01 21:38:26,627   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.dim.out_channels: 3
2025-09-01 21:38:26,627   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.dim.num_conv: 2
2025-09-01 21:38:26,627   INFO  ----------- rot -----------
2025-09-01 21:38:26,627   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.rot.out_channels: 2
2025-09-01 21:38:26,627   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.rot.num_conv: 2
2025-09-01 21:38:26,627   INFO  ----------- vel -----------
2025-09-01 21:38:26,627   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.vel.out_channels: 2
2025-09-01 21:38:26,627   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.vel.num_conv: 2
2025-09-01 21:38:26,627   INFO  ----------- TARGET_ASSIGNER_CONFIG -----------
2025-09-01 21:38:26,627   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.DATASET: nuScenes
2025-09-01 21:38:26,627   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.FEATURE_MAP_STRIDE: 8
2025-09-01 21:38:26,627   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.GAUSSIAN_OVERLAP: 0.1
2025-09-01 21:38:26,628   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.MIN_RADIUS: 2
2025-09-01 21:38:26,628   INFO  ----------- HUNGARIAN_ASSIGNER -----------
2025-09-01 21:38:26,628   INFO  ----------- cls_cost -----------
2025-09-01 21:38:26,628   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.HUNGARIAN_ASSIGNER.cls_cost.gamma: 2.0
2025-09-01 21:38:26,628   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.HUNGARIAN_ASSIGNER.cls_cost.alpha: 0.25
2025-09-01 21:38:26,628   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.HUNGARIAN_ASSIGNER.cls_cost.weight: 0.15
2025-09-01 21:38:26,628   INFO  ----------- reg_cost -----------
2025-09-01 21:38:26,628   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.HUNGARIAN_ASSIGNER.reg_cost.weight: 0.25
2025-09-01 21:38:26,628   INFO  ----------- iou_cost -----------
2025-09-01 21:38:26,628   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.HUNGARIAN_ASSIGNER.iou_cost.weight: 0.25
2025-09-01 21:38:26,628   INFO  ----------- LOSS_CONFIG -----------
2025-09-01 21:38:26,628   INFO  ----------- LOSS_WEIGHTS -----------
2025-09-01 21:38:26,628   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.cls_weight: 1.0
2025-09-01 21:38:26,628   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.bbox_weight: 0.25
2025-09-01 21:38:26,628   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.hm_weight: 1.0
2025-09-01 21:38:26,628   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2]
2025-09-01 21:38:26,628   INFO  ----------- LOSS_CLS -----------
2025-09-01 21:38:26,628   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_CLS.use_sigmoid: True
2025-09-01 21:38:26,628   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_CLS.gamma: 2.0
2025-09-01 21:38:26,628   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_CLS.alpha: 0.25
2025-09-01 21:38:26,628   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_IOU: False
2025-09-01 21:38:26,628   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_IOU_REG: False
2025-09-01 21:38:26,628   INFO  ----------- POST_PROCESSING -----------
2025-09-01 21:38:26,628   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.SCORE_THRESH: 0.0
2025-09-01 21:38:26,628   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.POST_CENTER_RANGE: [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
2025-09-01 21:38:26,629   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.USE_IOU_TO_RECTIFY_SCORE: False
2025-09-01 21:38:26,629   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.IOU_RECTIFIER: [0.5]
2025-09-01 21:38:26,629   INFO  ----------- NMS_CONFIG -----------
2025-09-01 21:38:26,629   INFO  cfg.MODEL.DENSE_HEAD.NMS_CONFIG.NMS_TYPE: nms_gpu
2025-09-01 21:38:26,629   INFO  cfg.MODEL.DENSE_HEAD.NMS_CONFIG.NMS_THRESH: 0.2
2025-09-01 21:38:26,629   INFO  cfg.MODEL.DENSE_HEAD.NMS_CONFIG.NMS_PRE_MAXSIZE: 1000
2025-09-01 21:38:26,629   INFO  cfg.MODEL.DENSE_HEAD.NMS_CONFIG.NMS_POST_MAXSIZE: 100
2025-09-01 21:38:26,629   INFO  cfg.MODEL.DENSE_HEAD.NMS_CONFIG.SCORE_THRES: 0.0
2025-09-01 21:38:26,629   INFO  ----------- POST_PROCESSING -----------
2025-09-01 21:38:26,629   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]
2025-09-01 21:38:26,629   INFO  cfg.MODEL.POST_PROCESSING.SCORE_THRESH: 0.1
2025-09-01 21:38:26,629   INFO  cfg.MODEL.POST_PROCESSING.OUTPUT_RAW_SCORE: False
2025-09-01 21:38:26,629   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: kitti
2025-09-01 21:38:26,629   INFO  ----------- OPTIMIZATION -----------
2025-09-01 21:38:26,629   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 4
2025-09-01 21:38:26,629   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 20
2025-09-01 21:38:26,629   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle
2025-09-01 21:38:26,629   INFO  cfg.OPTIMIZATION.LR: 0.001
2025-09-01 21:38:26,629   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01
2025-09-01 21:38:26,629   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9
2025-09-01 21:38:26,629   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]
2025-09-01 21:38:26,629   INFO  cfg.OPTIMIZATION.PCT_START: 0.4
2025-09-01 21:38:26,629   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 10
2025-09-01 21:38:26,629   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]
2025-09-01 21:38:26,629   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1
2025-09-01 21:38:26,630   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07
2025-09-01 21:38:26,630   INFO  cfg.OPTIMIZATION.LR_WARMUP: False
2025-09-01 21:38:26,630   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1
2025-09-01 21:38:26,630   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 35
2025-09-01 21:38:26,630   INFO  cfg.OPTIMIZATION.LOSS_SCALE_FP16: 4.0
2025-09-01 21:38:26,630   INFO  ----------- HOOK -----------
2025-09-01 21:38:26,630   INFO  ----------- DisableAugmentationHook -----------
2025-09-01 21:38:26,630   INFO  cfg.HOOK.DisableAugmentationHook.DISABLE_AUG_LIST: ['gt_sampling']
2025-09-01 21:38:26,630   INFO  cfg.HOOK.DisableAugmentationHook.NUM_LAST_EPOCHS: 4
2025-09-01 21:38:26,630   INFO  cfg.TAG: sparse_former_light
2025-09-01 21:38:26,630   INFO  cfg.EXP_GROUP_PATH: sparse_models
2025-09-01 21:38:26,630   INFO  cfg.OUTPUT_DIR: /mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/workdir/sparseformer/all/voxelnext_en_3layer_1lc_zhx_de_1layer_v3_32p_.0diff_.1lr_.1wd
2025-09-01 21:38:26,640   INFO  ----------- Create dataloader & network & optimizer -----------
2025-09-01 21:38:31,961   INFO  Database filter by min points car: 339949 => 294532
2025-09-01 21:38:31,972   INFO  Database filter by min points truck: 65262 => 60344
2025-09-01 21:38:31,974   INFO  Database filter by min points construction_vehicle: 11050 => 10589
2025-09-01 21:38:31,975   INFO  Database filter by min points bus: 12286 => 11619
2025-09-01 21:38:31,978   INFO  Database filter by min points trailer: 19202 => 17934
2025-09-01 21:38:31,990   INFO  Database filter by min points barrier: 107507 => 101993
2025-09-01 21:38:31,992   INFO  Database filter by min points motorcycle: 8846 => 8055
2025-09-01 21:38:31,993   INFO  Database filter by min points bicycle: 8185 => 7531
2025-09-01 21:38:32,011   INFO  Database filter by min points pedestrian: 161928 => 148520
2025-09-01 21:38:32,019   INFO  Database filter by min points traffic_cone: 62964 => 55504
2025-09-01 21:38:32,020   INFO  Loading GT database to shared memory
eflops107:23:23 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:23:23 [0] NCCL INFO Bootstrap : Using bond0:10.16.9.235<0>
eflops107:23:23 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
eflops107:23:23 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
eflops107:23:23 [0] NCCL INFO cudaDriverVersion 12050
NCCL version 2.18.5+cuda11.8
eflops107:29:29 [6] NCCL INFO cudaDriverVersion 12050
eflops107:26:26 [3] NCCL INFO cudaDriverVersion 12050
eflops107:29:29 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:26:26 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:25:25 [2] NCCL INFO cudaDriverVersion 12050
eflops107:25:25 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:27:27 [4] NCCL INFO cudaDriverVersion 12050
eflops107:30:30 [7] NCCL INFO cudaDriverVersion 12050
eflops107:27:27 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:30:30 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:29:29 [6] NCCL INFO Bootstrap : Using bond0:10.16.9.235<0>
eflops107:26:26 [3] NCCL INFO Bootstrap : Using bond0:10.16.9.235<0>
eflops107:25:25 [2] NCCL INFO Bootstrap : Using bond0:10.16.9.235<0>
eflops107:29:29 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
eflops107:29:29 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
eflops107:26:26 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
eflops107:28:28 [5] NCCL INFO cudaDriverVersion 12050
eflops107:26:26 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
eflops107:25:25 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
eflops107:25:25 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
eflops107:28:28 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:24:24 [1] NCCL INFO cudaDriverVersion 12050
eflops107:24:24 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:27:27 [4] NCCL INFO Bootstrap : Using bond0:10.16.9.235<0>
eflops107:30:30 [7] NCCL INFO Bootstrap : Using bond0:10.16.9.235<0>
eflops107:30:30 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
eflops107:30:30 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
eflops107:24:24 [1] NCCL INFO Bootstrap : Using bond0:10.16.9.235<0>
eflops107:28:28 [5] NCCL INFO Bootstrap : Using bond0:10.16.9.235<0>
eflops107:24:24 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
eflops107:24:24 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
eflops107:27:27 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
eflops107:27:27 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
eflops107:28:28 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.
eflops107:28:28 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).
eflops107:25:101 [2] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
eflops107:25:101 [2] NCCL INFO P2P plugin IBext
eflops107:25:101 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond

eflops107:25:101 [2] ibvwrap.c:66 NCCL WARN Call to ibv_open_device failed

eflops107:25:101 [2] p2p_plugin.c:233 NCCL WARN NET/IB : Unable to open device mlx5_bond_0
eflops107:25:101 [2] NCCL INFO NET/IB : No device found.
eflops107:25:101 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
eflops107:25:101 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:25:101 [2] NCCL INFO NET/Socket : Using [0]bond0:10.16.9.235<0>
eflops107:25:101 [2] NCCL INFO Using network Socket
eflops107:28:106 [5] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
eflops107:28:106 [5] NCCL INFO P2P plugin IBext
eflops107:28:106 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:23:99 [0] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
eflops107:23:99 [0] NCCL INFO P2P plugin IBext
eflops107:23:99 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond

eflops107:28:106 [5] ibvwrap.c:66 NCCL WARN Call to ibv_open_device failed

eflops107:28:106 [5] p2p_plugin.c:233 NCCL WARN NET/IB : Unable to open device mlx5_bond_0
eflops107:28:106 [5] NCCL INFO NET/IB : No device found.
eflops107:28:106 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
eflops107:28:106 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:28:106 [5] NCCL INFO NET/Socket : Using [0]bond0:10.16.9.235<0>
eflops107:28:106 [5] NCCL INFO Using network Socket

eflops107:23:99 [0] ibvwrap.c:66 NCCL WARN Call to ibv_open_device failed

eflops107:23:99 [0] p2p_plugin.c:233 NCCL WARN NET/IB : Unable to open device mlx5_bond_0
eflops107:23:99 [0] NCCL INFO NET/IB : No device found.
eflops107:23:99 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
eflops107:23:99 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:23:99 [0] NCCL INFO NET/Socket : Using [0]bond0:10.16.9.235<0>
eflops107:23:99 [0] NCCL INFO Using network Socket
eflops107:29:100 [6] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
eflops107:29:100 [6] NCCL INFO P2P plugin IBext
eflops107:29:100 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond

eflops107:29:100 [6] ibvwrap.c:66 NCCL WARN Call to ibv_open_device failed

eflops107:29:100 [6] p2p_plugin.c:233 NCCL WARN NET/IB : Unable to open device mlx5_bond_0
eflops107:29:100 [6] NCCL INFO NET/IB : No device found.
eflops107:29:100 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
eflops107:29:100 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:26:102 [3] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
eflops107:26:102 [3] NCCL INFO P2P plugin IBext
eflops107:29:100 [6] NCCL INFO NET/Socket : Using [0]bond0:10.16.9.235<0>
eflops107:26:102 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:29:100 [6] NCCL INFO Using network Socket

eflops107:26:102 [3] ibvwrap.c:66 NCCL WARN Call to ibv_open_device failed

eflops107:26:102 [3] p2p_plugin.c:233 NCCL WARN NET/IB : Unable to open device mlx5_bond_0
eflops107:26:102 [3] NCCL INFO NET/IB : No device found.
eflops107:26:102 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
eflops107:26:102 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:26:102 [3] NCCL INFO NET/Socket : Using [0]bond0:10.16.9.235<0>
eflops107:26:102 [3] NCCL INFO Using network Socket
eflops107:24:105 [1] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
eflops107:24:105 [1] NCCL INFO P2P plugin IBext
eflops107:24:105 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond

eflops107:24:105 [1] ibvwrap.c:66 NCCL WARN Call to ibv_open_device failed

eflops107:24:105 [1] p2p_plugin.c:233 NCCL WARN NET/IB : Unable to open device mlx5_bond_0
eflops107:24:105 [1] NCCL INFO NET/IB : No device found.
eflops107:24:105 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
eflops107:24:105 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:24:105 [1] NCCL INFO NET/Socket : Using [0]bond0:10.16.9.235<0>
eflops107:24:105 [1] NCCL INFO Using network Socket
eflops107:30:104 [7] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
eflops107:30:104 [7] NCCL INFO P2P plugin IBext
eflops107:30:104 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:27:103 [4] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
eflops107:27:103 [4] NCCL INFO P2P plugin IBext
eflops107:27:103 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond

eflops107:30:104 [7] ibvwrap.c:66 NCCL WARN Call to ibv_open_device failed

eflops107:30:104 [7] p2p_plugin.c:233 NCCL WARN NET/IB : Unable to open device mlx5_bond_0
eflops107:30:104 [7] NCCL INFO NET/IB : No device found.
eflops107:30:104 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
eflops107:30:104 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond

eflops107:27:103 [4] ibvwrap.c:66 NCCL WARN Call to ibv_open_device failed

eflops107:27:103 [4] p2p_plugin.c:233 NCCL WARN NET/IB : Unable to open device mlx5_bond_0
eflops107:27:103 [4] NCCL INFO NET/IB : No device found.
eflops107:27:103 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
eflops107:27:103 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to bond
eflops107:30:104 [7] NCCL INFO NET/Socket : Using [0]bond0:10.16.9.235<0>
eflops107:30:104 [7] NCCL INFO Using network Socket
eflops107:27:103 [4] NCCL INFO NET/Socket : Using [0]bond0:10.16.9.235<0>
eflops107:27:103 [4] NCCL INFO Using network Socket
eflops107:29:100 [6] NCCL INFO comm 0x11eadb50 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId a0000 commId 0x791ff0c22e1de449 - Init START
eflops107:26:102 [3] NCCL INFO comm 0x10d0fbc0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 57000 commId 0x791ff0c22e1de449 - Init START
eflops107:23:99 [0] NCCL INFO comm 0x1194f860 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 4f000 commId 0x791ff0c22e1de449 - Init START
eflops107:28:106 [5] NCCL INFO comm 0x11b40e00 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 9d000 commId 0x791ff0c22e1de449 - Init START
eflops107:30:104 [7] NCCL INFO comm 0x11154c20 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId a4000 commId 0x791ff0c22e1de449 - Init START
eflops107:25:101 [2] NCCL INFO comm 0x117dec60 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 53000 commId 0x791ff0c22e1de449 - Init START
eflops107:24:105 [1] NCCL INFO comm 0x1210e070 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 50000 commId 0x791ff0c22e1de449 - Init START
eflops107:27:103 [4] NCCL INFO comm 0x10845ec0 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 9c000 commId 0x791ff0c22e1de449 - Init START
eflops107:26:102 [3] NCCL INFO Setting affinity for GPU 3 to 0fffff,ff000000,0fffffff
eflops107:23:99 [0] NCCL INFO Setting affinity for GPU 0 to 0fffff,ff000000,0fffffff
eflops107:28:106 [5] NCCL INFO Setting affinity for GPU 5 to ffff,fff00000,00ffffff,f0000000
eflops107:24:105 [1] NCCL INFO Setting affinity for GPU 1 to 0fffff,ff000000,0fffffff
eflops107:25:101 [2] NCCL INFO Setting affinity for GPU 2 to 0fffff,ff000000,0fffffff
eflops107:30:104 [7] NCCL INFO Setting affinity for GPU 7 to ffff,fff00000,00ffffff,f0000000
eflops107:27:103 [4] NCCL INFO Setting affinity for GPU 4 to ffff,fff00000,00ffffff,f0000000
eflops107:29:100 [6] NCCL INFO Setting affinity for GPU 6 to ffff,fff00000,00ffffff,f0000000
eflops107:29:100 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
eflops107:29:100 [6] NCCL INFO P2P Chunksize set to 131072
eflops107:24:105 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
eflops107:24:105 [1] NCCL INFO P2P Chunksize set to 131072
eflops107:28:106 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4
eflops107:30:104 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
eflops107:27:103 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
eflops107:23:99 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
eflops107:25:101 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
eflops107:30:104 [7] NCCL INFO P2P Chunksize set to 131072
eflops107:28:106 [5] NCCL INFO P2P Chunksize set to 131072
eflops107:23:99 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
eflops107:27:103 [4] NCCL INFO P2P Chunksize set to 131072
eflops107:25:101 [2] NCCL INFO P2P Chunksize set to 131072
eflops107:23:99 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
eflops107:26:102 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
eflops107:23:99 [0] NCCL INFO P2P Chunksize set to 131072
eflops107:26:102 [3] NCCL INFO P2P Chunksize set to 131072
eflops107:29:100 [6] NCCL INFO Channel 00/0 : 6[6] -> 7[7] via P2P/IPC
eflops107:24:105 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/IPC
eflops107:28:106 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[6] via P2P/IPC
eflops107:25:101 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/IPC
eflops107:29:100 [6] NCCL INFO Channel 01/0 : 6[6] -> 7[7] via P2P/IPC
eflops107:24:105 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/IPC
eflops107:30:104 [7] NCCL INFO Channel 00 : 7[7] -> 0[0] via SHM/direct/direct
eflops107:28:106 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[6] via P2P/IPC
eflops107:25:101 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/IPC
eflops107:26:102 [3] NCCL INFO Channel 00 : 3[3] -> 4[4] via SHM/direct/direct
eflops107:30:104 [7] NCCL INFO Channel 01 : 7[7] -> 0[0] via SHM/direct/direct
eflops107:26:102 [3] NCCL INFO Channel 01 : 3[3] -> 4[4] via SHM/direct/direct
eflops107:23:99 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/IPC
eflops107:23:99 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/IPC
eflops107:25:101 [2] NCCL INFO Connected all rings
eflops107:29:100 [6] NCCL INFO Connected all rings
eflops107:27:103 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/IPC
eflops107:25:101 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/IPC
eflops107:27:103 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/IPC
eflops107:29:100 [6] NCCL INFO Channel 00/0 : 6[6] -> 5[5] via P2P/IPC
eflops107:25:101 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/IPC
eflops107:29:100 [6] NCCL INFO Channel 01/0 : 6[6] -> 5[5] via P2P/IPC
eflops107:24:105 [1] NCCL INFO Connected all rings
eflops107:23:99 [0] NCCL INFO Connected all rings
eflops107:30:104 [7] NCCL INFO Connected all rings
eflops107:30:104 [7] NCCL INFO Channel 00/0 : 7[7] -> 6[6] via P2P/IPC
eflops107:30:104 [7] NCCL INFO Channel 01/0 : 7[7] -> 6[6] via P2P/IPC
eflops107:24:105 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/IPC
eflops107:28:106 [5] NCCL INFO Connected all rings
eflops107:24:105 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/IPC
eflops107:26:102 [3] NCCL INFO Connected all rings
eflops107:30:104 [7] NCCL INFO Connected all trees
eflops107:30:104 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
eflops107:30:104 [7] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
eflops107:27:103 [4] NCCL INFO Connected all rings
eflops107:28:106 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/IPC
eflops107:23:99 [0] NCCL INFO Connected all trees
eflops107:23:99 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
eflops107:23:99 [0] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
eflops107:28:106 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/IPC
eflops107:24:105 [1] NCCL INFO Connected all trees
eflops107:24:105 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
eflops107:24:105 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
eflops107:27:103 [4] NCCL INFO Channel 00 : 4[4] -> 3[3] via SHM/direct/direct
eflops107:27:103 [4] NCCL INFO Channel 01 : 4[4] -> 3[3] via SHM/direct/direct
eflops107:29:100 [6] NCCL INFO Connected all trees
eflops107:29:100 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
eflops107:29:100 [6] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
eflops107:28:106 [5] NCCL INFO Connected all trees
eflops107:28:106 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
eflops107:28:106 [5] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
eflops107:26:102 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/IPC
eflops107:26:102 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/IPC
eflops107:25:101 [2] NCCL INFO Connected all trees
eflops107:25:101 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
eflops107:25:101 [2] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
eflops107:26:102 [3] NCCL INFO Connected all trees
eflops107:26:102 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
eflops107:26:102 [3] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
eflops107:27:103 [4] NCCL INFO Connected all trees
eflops107:27:103 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
eflops107:27:103 [4] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
eflops107:24:105 [1] NCCL INFO comm 0x1210e070 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 50000 commId 0x791ff0c22e1de449 - Init COMPLETE
eflops107:26:102 [3] NCCL INFO comm 0x10d0fbc0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 57000 commId 0x791ff0c22e1de449 - Init COMPLETE
eflops107:30:104 [7] NCCL INFO comm 0x11154c20 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId a4000 commId 0x791ff0c22e1de449 - Init COMPLETE
eflops107:23:99 [0] NCCL INFO comm 0x1194f860 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 4f000 commId 0x791ff0c22e1de449 - Init COMPLETE
eflops107:28:106 [5] NCCL INFO comm 0x11b40e00 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId 9d000 commId 0x791ff0c22e1de449 - Init COMPLETE
eflops107:29:100 [6] NCCL INFO comm 0x11eadb50 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId a0000 commId 0x791ff0c22e1de449 - Init COMPLETE
eflops107:27:103 [4] NCCL INFO comm 0x10845ec0 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 9c000 commId 0x791ff0c22e1de449 - Init COMPLETE
eflops107:25:101 [2] NCCL INFO comm 0x117dec60 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 53000 commId 0x791ff0c22e1de449 - Init COMPLETE
2025-09-01 21:38:44,639   INFO  GT database has been saved to shared memory
2025-09-01 21:38:44,822   INFO  Loading NuScenes dataset
2025-09-01 21:38:46,673   INFO  Total samples for NuScenes dataset: 28130
2025-09-01 21:38:46,942   INFO  Total samples after balanced resampling: 123580
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2025-09-01 21:38:48,666   INFO  ----------- Model TransFusion created, param count: 9911262 -----------
epochs:   0%|          | 0/20 [00:00<?, ?it/s]epochs:   0%|          | 0/20 [00:00<?, ?it/s]epochs:   0%|          | 0/20 [00:00<?, ?it/s]epochs:   0%|          | 0/20 [00:00<?, ?it/s]epochs:   0%|          | 0/20 [00:00<?, ?it/s]epochs:   0%|          | 0/20 [00:00<?, ?it/s]2025-09-01 21:38:48,666   INFO  DistributedDataParallel(
  (module): TransFusion(
    (vfe): DynamicVoxelVFE(
      (pfn_layers): ModuleList(
        (0): PFNLayerV2(
          (linear): Linear(in_features=11, out_features=32, bias=False)
          (norm): SyncBatchNorm(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): PFNLayerV2(
          (linear): Linear(in_features=64, out_features=64, bias=False)
          (norm): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
    )
    (backbone_3d): VoxelResBackBone8xVoxelNeXt(
      (conv_input): SparseSequential(
        (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (conv1): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (conv2): SparseSequential(
        (0): SparseSequential(
          (0): SparseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
        (2): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (conv3): SparseSequential(
        (0): SparseSequential(
          (0): SparseConv3d(64, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
        (2): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (conv4): SparseSequential(
        (0): SparseSequential(
          (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
        (2): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (conv5): SparseSequential(
        (0): SparseSequential(
          (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
        (2): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
      (conv6): SparseSequential(
        (0): SparseSequential(
          (0): SparseConv3d(128, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU()
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
        (2): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU()
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
          (bn2): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (map_to_bev_module): None
    (pfe): None
    (backbone_2d): None
    (dense_head): SparseFormerHead(
      (loss_cls): SigmoidFocalClassificationLoss()
      (loss_bbox): L1Loss()
      (loss_heatmap): GaussianFocalLoss()
      (heatmap_head): SparseSequential(
        (0): SubMConv2d(128, 128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], output_padding=[0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): SubMConv2d(128, 10, kernel_size=[1, 1], stride=[1, 1], padding=[0, 0], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
      )
      (shared_conv): SparseSequential(
        (0): SparseConv2d(128, 128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], output_padding=[0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): SubMConv2d(128, 128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (4): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
      (class_encoding): Conv1d(10, 128, kernel_size=(1,), stride=(1,))
      (prediction_head): SeparateHead(
        (center): Sequential(
          (0): Sequential(
            (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
            (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
        )
        (height): Sequential(
          (0): Sequential(
            (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
            (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv1d(64, 1, kernel_size=(1,), stride=(1,))
        )
        (dim): Sequential(
          (0): Sequential(
            (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
            (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv1d(64, 3, kernel_size=(1,), stride=(1,))
        )
        (rot): Sequential(
          (0): Sequential(
            (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
            (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
        )
        (vel): Sequential(
          (0): Sequential(
            (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
            (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
        )
        (heatmap): Sequential(
          (0): Sequential(
            (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
            (1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv1d(64, 10, kernel_size=(1,), stride=(1,))
        )
      )
      (decoder): SPDecoder(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
        )
        (cross_attn): ModuleList(
          (0): ModuleList(
            (0-2): 3 x SDCA(
              (input_layer): SerializationLayer(
                (serialization): FlattenWindowsSerialization()
              )
              (blocks): ModuleList(
                (0-1): 2 x DeformableAttention(
                  (sampling_offsets): Linear(in_features=128, out_features=256, bias=True)
                  (sampling_weights): Linear(in_features=128, out_features=256, bias=True)
                  (value_proj): Linear(in_features=128, out_features=128, bias=True)
                  (output_proj): Linear(in_features=128, out_features=128, bias=True)
                  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
        (fusions): ModuleList(
          (0): LevelFusion(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
            )
            (dropout): Dropout(p=0.1, inplace=False)
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
        )
        (linear1): Linear(in_features=128, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=128, bias=True)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_posembed): ConvEmbeddingLearned(
          (stem): Sequential(
            (0): Conv1d(2, 128, kernel_size=(1,), stride=(1,))
            (1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (cross_posembed): MSSubConvEmbeddingLearned(
          (stem): ModuleList(
            (0-2): 3 x SparseBasicBlock2D(
              (conv1): SubMConv2d(2, 128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
              (bn1): SyncBatchNorm(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU()
              (conv2): SubMConv2d(128, 128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], output_padding=[0, 0], algo=ConvAlgo.MaskImplicitGemm)
            )
          )
        )
      )
    )
    (point_head): None
    (roi_head): None
  )
)
epochs:   0%|          | 0/20 [00:00<?, ?it/s]2025-09-01 21:38:48,669   INFO  **********************Start training sparse_models/sparse_former_light(default)**********************
epochs:   0%|          | 0/20 [00:00<?, ?it/s]
train:   0%|          | 0/3862 [00:00<?, ?it/s][A                                              Traceback (most recent call last):
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 246, in <module>
    main()
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 188, in main
    train_model(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train_utils/train_utils.py", line 272, in train_model
    accumulated_iter = train_one_epoch(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train_utils/train_utils.py", line 71, in train_one_epoch
                                                  loss, tb_dict, disp_dict = model_func(model, batch)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/__init__.py", line 44, in model_func
                                              Traceback (most recent call last):
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 246, in <module>
epochs:   0%|          | 0/20 [00:11<?, ?it/s]
Traceback (most recent call last):
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 246, in <module>
Traceback (most recent call last):
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 246, in <module>
    main()
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 188, in main
    train_model(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train_utils/train_utils.py", line 272, in train_model
    accumulated_iter = train_one_epoch(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train_utils/train_utils.py", line 71, in train_one_epoch
    loss, tb_dict, disp_dict = model_func(model, batch)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/__init__.py", line 44, in model_func
    ret_dict, tb_dict, disp_dict = model(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    main()
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 188, in main
    main()
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 188, in main
        train_model(train_model(

  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train_utils/train_utils.py", line 272, in train_model
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train_utils/train_utils.py", line 272, in train_model
    accumulated_iter = train_one_epoch(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train_utils/train_utils.py", line 71, in train_one_epoch
    loss, tb_dict, disp_dict = model_func(model, batch)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/__init__.py", line 44, in model_func
    accumulated_iter = train_one_epoch(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train_utils/train_utils.py", line 71, in train_one_epoch
    loss, tb_dict, disp_dict = model_func(model, batch)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/__init__.py", line 44, in model_func
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    ret_dict, tb_dict, disp_dict = model(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    ret_dict, tb_dict, disp_dict = model(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
      File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self._call_impl(*args, **kwargs)    
return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/detectors/transfusion.py", line 12, in forward
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/detectors/transfusion.py", line 12, in forward
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/detectors/transfusion.py", line 12, in forward
    batch_dict = cur_module(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    batch_dict = cur_module(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    batch_dict = cur_module(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 972, in forward
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 972, in forward
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 972, in forward
    x_conv4, x_conv5, x_conv6 = self.encoder(mx)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    x_conv4, x_conv5, x_conv6 = self.encoder(mx)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    x_conv4, x_conv5, x_conv6 = self.encoder(mx)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'SparseFormerHead' object has no attribute 'encoder'
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'SparseFormerHead' object has no attribute 'encoder'
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'SparseFormerHead' object has no attribute 'encoder'
                                              Traceback (most recent call last):
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 246, in <module>
                                              Traceback (most recent call last):
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 246, in <module>
    main()
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 188, in main
    train_model(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train_utils/train_utils.py", line 272, in train_model
    accumulated_iter = train_one_epoch(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train_utils/train_utils.py", line 71, in train_one_epoch
    loss, tb_dict, disp_dict = model_func(model, batch)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/__init__.py", line 44, in model_func
    ret_dict, tb_dict, disp_dict = model(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/detectors/transfusion.py", line 12, in forward
    batch_dict = cur_module(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 972, in forward
    x_conv4, x_conv5, x_conv6 = self.encoder(mx)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'SparseFormerHead' object has no attribute 'encoder'
                                                                                            Traceback (most recent call last):
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 246, in <module>
Traceback (most recent call last):
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 246, in <module>
    main()
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 188, in main
    train_model(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train_utils/train_utils.py", line 272, in train_model
    accumulated_iter = train_one_epoch(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train_utils/train_utils.py", line 71, in train_one_epoch
    loss, tb_dict, disp_dict = model_func(model, batch)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/__init__.py", line 44, in model_func
    ret_dict, tb_dict, disp_dict = model(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    main()
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 188, in main
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    train_model(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train_utils/train_utils.py", line 272, in train_model
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    accumulated_iter = train_one_epoch(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train_utils/train_utils.py", line 71, in train_one_epoch
    loss, tb_dict, disp_dict = model_func(model, batch)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/__init__.py", line 44, in model_func
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    ret_dict, tb_dict, disp_dict = model(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/detectors/transfusion.py", line 12, in forward
    batch_dict = cur_module(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 972, in forward
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/detectors/transfusion.py", line 12, in forward
    batch_dict = cur_module(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
        return self._call_impl(*args, **kwargs)x_conv4, x_conv5, x_conv6 = self.encoder(mx)

  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 972, in forward
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'SparseFormerHead' object has no attribute 'encoder'
        x_conv4, x_conv5, x_conv6 = self.encoder(mx)ret_dict, tb_dict, disp_dict = model(batch_dict)

  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
        raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")return self._call_impl(*args, **kwargs)

  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
AttributeError: 'SparseFormerHead' object has no attribute 'encoder'
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/detectors/transfusion.py", line 12, in forward
    batch_dict = cur_module(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 972, in forward
    x_conv4, x_conv5, x_conv6 = self.encoder(mx)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'SparseFormerHead' object has no attribute 'encoder'
    main()
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py", line 188, in main
    train_model(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train_utils/train_utils.py", line 272, in train_model
    accumulated_iter = train_one_epoch(
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train_utils/train_utils.py", line 71, in train_one_epoch
    loss, tb_dict, disp_dict = model_func(model, batch)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/__init__.py", line 44, in model_func
    ret_dict, tb_dict, disp_dict = model(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/detectors/transfusion.py", line 12, in forward
    batch_dict = cur_module(batch_dict)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/../pcdet/models/dense_heads/sparse_former_head.py", line 972, in forward
    x_conv4, x_conv5, x_conv6 = self.encoder(mx)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'SparseFormerHead' object has no attribute 'encoder'

                                               [A[2025-09-01 21:39:05,535] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 23) of binary: /root/miniconda3/envs/sparseformerv2/bin/python
Traceback (most recent call last):
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/distributed/launch.py", line 196, in <module>
    main()
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/distributed/launch.py", line 192, in main
    launch(args)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/distributed/launch.py", line 177, in launch
    run(args)
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/root/miniconda3/envs/sparseformerv2/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/mnt/csi-data-aly/user/hongfeizhang/mypaper/SparseFormerV2/tools/train.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-09-01_21:39:05
  host      : eflops107.aliyun.com
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 24)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2025-09-01_21:39:05
  host      : eflops107.aliyun.com
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 25)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2025-09-01_21:39:05
  host      : eflops107.aliyun.com
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 26)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2025-09-01_21:39:05
  host      : eflops107.aliyun.com
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 27)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2025-09-01_21:39:05
  host      : eflops107.aliyun.com
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 28)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2025-09-01_21:39:05
  host      : eflops107.aliyun.com
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 29)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2025-09-01_21:39:05
  host      : eflops107.aliyun.com
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 30)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-09-01_21:39:05
  host      : eflops107.aliyun.com
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 23)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
